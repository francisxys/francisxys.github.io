<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Kafka基础文档]]></title>
    <url>%2F2018%2F12%2F14%2FKafka%E5%9F%BA%E7%A1%80%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[一、Kafka简介1、简介Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。Apache的Kafka™是一个分布式流平台(a distributed streaming platform)。这到底意味着什么？我们认为，一个流处理平台应该具有三个关键能力：（1）它可以让你发布和订阅记录流。在这方面，它类似于一个消息队列或企业消息系统。（2）它可以让你持久化收到的记录流，从而具有容错能力。（3）它可以让你处理收到的记录流。Kafka擅长哪些方面？它被用于两大类应用：（1）建立实时流数据管道从而能够可靠地在系统或应用程序之间的共享数据（2）构建实时流应用程序，能够变换或者对数据（3）进行相应的处理。想要了解Kafka如何具有这些能力，让我们从下往上深入探索Kafka的能力。首先，明确几个概念：（1）Kafka是运行在一个或多个服务器的集群(Cluster)上的。（2）Kafka集群分类存储的记录流被称为主题(Topics)。（3）每个消息记录包含一个键，一个值和时间戳。Kafka有四个核心API：（1）生产者 API 允许应用程序发布记录流至一个或多个Kafka的话题(Topics)。（2）消费者API允许应用程序订阅一个或多个主题，并处理这些主题接收到的记录流。（3）Streams API允许应用程序充当流处理器（stream processor），从一个或多个主题获取输入流，并生产一个输出流至一个或多个的主题，能够有效地变换输入流为输出流。（4）Connector API允许构建和运行可重用的生产者或消费者，能够把 Kafka主题连接到现有的应用程序或数据系统。例如，一个连接到关系数据库的连接器(connector)可能会获取每个表的变化。 2、应用场景主要应用场景是：（1）构建实时的流数据管道，可靠地获取系统和应用程序之间的数据。（2）构建实时流的应用程序，对数据流进行转换或反应。Kafka主要设计目标如下：（1）以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。（2）高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。（3）支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。（4）同时支持离线数据处理和实时数据处理。 3、Kafka的设计原理分析一个典型的kafka集群中包含若干producer，若干broker，若干consumer，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。producer使用push模式将消息发布到broker，consumer使用pull模式从broker订阅并消费消息。Kafka专用术语：Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。消费者可以订阅一个或多个主题(topic),并从Broker拉数据，从而消费这些已发布的消息。每个消息（也叫作record记录,也被称为消息）是由一个key，一个value和时间戳构成。Topic：一类消息，Kafka集群能够同时负责多个topic的分发。Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。Segment：partition物理上由多个segment组成。offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset，用于partition唯一标识一条消息。Producer：负责发布消息到Kafka broker，可以理解为生产者。Consumer：消息消费者，向Kafka broker读取消息的客户端，可以理解为生产者。Consumer Group：每个Consumer属于一个特定的Consumer Group。topic: 消息以topic为类别记录,Kafka将消息种子(Feed)分门别类,每一类的消息称之为一个主题(Topic)。 4、主题（Topic）和日志（Logs）作为Kafka对数据提供的核心抽象，主题是发布的数据流的类别或名称。主题在Kafka中，总是支持多订阅者的; 也就是说，主题可以有零个，一个或多个消费者订阅写到相应主题的数据. 对应每一个主题，Kafka集群会维护像一个如下这样的分区的日志：每个分区都是是一个有序的，不可变的，并且不断被附加的记录序列，—也就是一个结构化提交日志（commit log）。为了保证唯一标性识分区中的每个数据记录，分区中的记录每个都会被分配一个一个叫做偏移（offset）顺序的ID号。通过一个可配置的保留期，Kafka集群会保留所有被发布的数据，不管它们是不是已经被消费者处理。例如，如果保留期设置为两天，则在发布记录后的两天内，数据都可以被消费，之后它将被丢弃以释放空间。 卡夫卡的性能是不为因为数据量大小而受影响的，因此长时间存储数据并不成问题。事实上，在每个消费者上保留的唯一元数据是消费者在日志中的偏移位置。这个偏移由消费者控制：通常消费者会在读取记录时线性地提高其偏移值（offset++），但实际上，由于偏移位置由消费者控制，它可以以任何顺序来处理数据记录。事实上，在每个消费者上保留的唯一元数据是消费者在日志中的偏移位置。这个偏移由消费者控制：通常消费者会在读取记录时线性地提高其偏移值（offset++），但实际上，由于偏移位置由消费者控制，它可以以任何顺序来处理数据记录。 5、数据的分配（Distribution）在Kafka集群中，不同分区日志的分布在相应的不同的服务器节点上，每个服务器节点处理自己分区对应的数据和请求。每个分区都会被复制备份到几个（可配置）服务器节点，以实现容错容灾。 分布在不同节点的同一个分区都会有一个服务器节点作为领导者（”leader”）和0个或者多个跟随者（”followers”），分区的领导者会处理所有的读和写请求，而跟随者只会被动的复制领导者。如果leader挂了, 一个follower会自动变成leader。每个服务器都会作为其一些分区的领导者，但同时也可能作为其他分分区的跟随者，Kafka以此来实现在集群内的负载平衡。 6、生产者生产者将数据发布到他们选择的主题。 生产者负责选择要吧数据分配给主题中哪个分区。这可以通过循环方式（round-robin）简单地平衡负载，或者可以根据某些语义分区（例如基于数据中的某些关键字）来完成。 7、消费者消费者们使用消费群组名称来标注自己，几个消费者共享一个组群名，每一个发布到主题的数据会被传递到每个消费者群组中的一个消费者实例。 消费者实例可以在不同的进程中或不同的机器上。 如果所有的消费者实例具有相同的消费者组，则记录将在所有的消费者实例上有效地负载平衡,每个数据只发到了一个消费者 如果所有的消费者实例都有不同的消费者群体，那么每个记录将被广播给所有的消费者进程，每个数据都发到了所有的消费者。 8、Kafka作为消息系统消息系统传统上有两种模式: 队列和发布-订阅. 在队列中，消费者池可以从服务器读取，每条记录都转到其中一个; 在发布订阅中，记录将广播给所有消费者。 这两个模型中的每一个都有优点和缺点。 排队的优点是它允许您在多个消费者实例上分配数据处理，从而可以扩展您的处理。 不幸的是，队列支持多用户，一旦一个进程读取数据就没有了。 发布订阅允许您将数据广播到多个进程，但无法缩放和扩容，因为每个消息都发送给每个订阅用户。 卡夫卡消费群体概念概括了这两个概念。 与队列一样，消费者组允许您通过一系列进程（消费者组的成员）来划分处理。 与发布订阅一样，Kafka允许您将消息广播到多个消费者组。 Kafka模型的优点是，每个主题都具有这两个属性，它可以进行缩放处理，也是多用户的，没有必要选择一个而放弃另一个。 卡夫卡也比传统的消息系统有更强大的消息次序保证。 传统队列在服务器上保存顺序的记录，如果多个消费者从队列中消费，则服务器按照存储顺序输出记录。 然而，虽然服务器按顺序输出记录，但是记录被异步传递给消费者，所以它们可能会在不同的消费者处按不确定的顺序到达。 这意味着在并行消耗的情况下，记录的排序丢失。 消息传递系统通常通过使“唯一消费者”的概念只能让一个进程从队列中消费，但这当然意味着处理中没有并行性。 卡夫卡做得更好。通过分区，在一个主题之内的并行处理，Kafka能够在消费者流程池中，即提供排序保证，也负载平衡。这是通过将主题中的分区分配给消费者组中的消费者来实现的，以便每一个分区由组中的一个消费者使用。 通过这样做，我们确保消费者是该分区的唯一读者，并按顺序消耗数据。 由于有许多分区，这仍然平衡了许多消费者实例的负载。 但是请注意，消费者组中的消费者实例个数不能超过分区的个数。 9、Kafka作为存储系统任何允许发布消息，解耦使用消息的消息队列，都在本质上充当传输中途消息的存储系统。 卡夫卡的不同之处在于它是一个很好的存储系统。 写入Kafka的数据写入磁盘并进行复制以进行容错。 Kafka允许生产者等待写入完成的确认，这样在数据完全复制之前，写入是未完成的，并且即使写入服务器失败，也保证持久写入。 Kafka的磁盘结构使用可以很好的扩容，无论您在服务器上是否有50KB或50TB的持久数据，Kafka都能保持稳定的性能。 由于对存储花费了很多精力，并允许客户端控制其读取位置，您可以将Kafka视为，专用于高性能，低延迟的日志存储复制和传播的专用分布式文件系统。任何允许发布消息，解耦使用消息的消息队列，都在本质上充当传输中途消息的存储系统。 卡夫卡的不同之处在于它是一个很好的存储系统。 写入Kafka的数据写入磁盘并进行复制以进行容错。 Kafka允许生产者等待写入完成的确认，这样在数据完全复制之前，写入是未完成的，并且即使写入服务器失败，也保证持久写入。 Kafka的磁盘结构使用可以很好的扩容，无论您在服务器上是否有50KB或50TB的持久数据，Kafka都能保持稳定的性能。 由于对存储花费了很多精力，并允许客户端控制其读取位置，您可以将Kafka视为，专用于高性能，低延迟的日志存储复制和传播的专用分布式文件系统。 10、Kafka用于流数据处理仅读取，写入和存储数据流是不够的，Kafka的目的是实现流的实时处理。 在Kafka中，流处理器的定义是：任何从输入主题接收数据流，对此输入执行一些处理，并生成持续的数据流道输出主题的组件。 例如，零售应用程序可能会收到销售和出货的输入流，并输出根据该数据计算的重新排序和价格调整的输出流。 当然我们也可以直接用producer and consumer APIs在做简单的出列. 然而对于更复杂的转换，Kafka提供了一个完全集成的Streams API。这允许我们构建应用程序进行更复杂的运算，或者聚合，或将流连接在一起。 该设施有助于解决这种类型的应用程序面临的困难问题：处理无序数据，重新处理输入作为代码更改，执行有状态计算等。 Stream API基于Kafka提供的核心原语构建：它使用生产者和消费者API进行输入，使用Kafka进行有状态存储，并在流处理器实例之间使用相同的组机制来实现容错。仅读取，写入和存储数据流是不够的，Kafka的目的是实现流的实时处理。 在Kafka中，流处理器的定义是：任何从输入主题接收数据流，对此输入执行一些处理，并生成持续的数据流道输出主题的组件。 例如，零售应用程序可能会收到销售和出货的输入流，并输出根据该数据计算的重新排序和价格调整的输出流。 当然我们也可以直接用producer and consumer APIs在做简单的出列. 然而对于更复杂的转换，Kafka提供了一个完全集成的Streams API。这允许我们构建应用程序进行更复杂的运算，或者聚合，或将流连接在一起。 该设施有助于解决这种类型的应用程序面临的困难问题：处理无序数据，重新处理输入作为代码更改，执行有状态计算等。 Stream API基于Kafka提供的核心原语构建：它使用生产者和消费者API进行输入，使用Kafka进行有状态存储，并在流处理器实例之间使用相同的组机制来实现容错。综上所述：消息系统，数据存储和流处理的这种组合似乎是不寻常的，但是这些特性对于Kafka作为流媒体平台的角色至关重要。 像HDFS这样的分布式文件系统允许存储用于批处理的静态文件。 本质上，这样的系统允许存储和处理来自过去的历史数据。 传统的企业邮消息系统允许处理将在您订阅之后到达的未来消息。 以这种方式构建的应用程序在未来数据到达时即使处理。 Kafka结合了这两种功能，这种组合对于Kafka作为流应用程序和流数据管道平台来说至关重要。 通过组合存储和低延迟订阅，流式应用程序可以以相同的方式处理过去和未来的数据。 这是一个单一的应用程序可以处理历史记录数据，而不是在到达最后一个记录时结束，它可以随着将来的数据到达而继续处理。 这是一个广泛的流处理概念，其中包含批处理以及消息驱动应用程序。 同样，对于流数据流水线，订阅到实时事件的组合使得可以使用Kafka进行非常低延迟的管道传输; 可靠地存储数据的能力使得可以将其用于必须保证数据传送的关键数据，或者与仅负载数据的离线系统集成，或者可能会长时间停机以进行维护。流处理功能在数据到达时进行数据转换处理。 二、Kafka安装Kafka需要Zookeeper的监控，所以先要安装Zookeeper。新版本Kafka拥有自带的zookeeper，也可以不用安装zookeeper，根据选择的kafka版本确定。Zookeeper需要java环境支持，所以先要安装jdk。 1、JDK安装检查系统是否已经安装jdk1java -version 如果没有显示java版本信息，则表示没有安装java12345678910#安装javatar -zxvf jdk-8u161-linux-x64.tar.gzmv jdk1.8.0_161 /data/jdk1.8#修改系统变量vi /etc/profile#在文本末尾添加以下内容：PATH=/data/jdk1.8/bin:$PATHexport PATH#使添加内容生效 source /etc/profile 再查看java版本 出现如下信息表示安装成功1234# java -versionjava version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 2、Zookeeper安装官网下载地址：http://apache.fayea.com/zookeeper/stable/Zookeeper属于可选安装1234567891011#下载wget http://apache.fayea.com/zookeeper/stable/zookeeper-3.4.10.tar.gztar -zxvf zookeeper-3.4.10.tar.gz mv zookeeper-3.4.10 /data/zookeepercd /data/zookeeper/#创建数据目录mkdir /data/zookeeper/datacd conf/#创建配置文件cp zoo_sample.cfg zoo.cfg vim zoo.cfg zoo.cfg修改后为12345tickTime=2000initLimit=10syncLimit=5dataDir=/data/zookeeper/dataclientPort=2181 配置环境变量：vim /etc/profile，加入以下内容12export ZOOKEEPER_HOME=/data/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf source /etc/profile使新增加环境变量生效zookeeper相关命令123456#开启/data/zookeeper/bin/zkServer.sh start#停止/data/zookeeper/bin/zkServer.sh status#查看状态/data/zookeeper/bin/zkServer.sh status 3、Kafka安装官网下载地址：http://kafka.apache.org/downloads本次下载最新版本123wget http://mirror.bit.edu.cn/apache/kafka/1.1.0/kafka_2.12-1.1.0.tgztar -zxvf kafka_2.12-1.1.0.tgz mv kafka_2.12-1.1.0 /data/kafka 修改配置文件12cd /data/kafka/vim config/server.properties Server.properties修改后为12345678910111213141516171819broker.id=0port=9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/data/kafka/logs/kafka-logsnum.partitions=1num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=localhost:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0 修改关于zookeeper的配置文件zookeeper.properties1vim config/zookeeper.properties zookeeper.properties修改后为123dataDir=/data/kafka/zkdataclientPort=2181maxClientCnxns=0 在kafka目录启动zookeeper12cd /data/kafkabin/zookeeper-server-start.sh config/zookeeper.properties &amp; 启动kafka1bin/kafka-streams-application-reset.sh config/server.properties &amp;]]></content>
      <categories>
        <category>OS</category>
        <category>Service</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>Message</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大日志文件进行分割的N种方法]]></title>
    <url>%2F2018%2F12%2F13%2F%E5%A4%A7%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E5%89%B2%E7%9A%84N%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[当日志容量上G的时候，用vi查看具体内容效率就会变得特别低，这个时候就需要将大日志进行分割。为了比较各种分割方法的效果，我选取的测试日志基本信息如下：1234# ls -lrth test.log-rw-r--r-- 1 root root 645M 5月 30 20:42 test.log# wc -l test.log8856340 test.log 1、split方法分割split命令专门用来将一个大文件分割成很多个小文件，我把split命令的选项做一个简要说明 选项 含义 -b 分割后的文档大小，单位是byte -C 分割后的文档，单行最大byte数 -d 使用数字作为后缀，同时使用-a length指定后缀长度 -l 分割后文档的行数 为了尽量保证日志的可读性，我们按行分割大日志文件，并且指定分割后的文件的前缀和后缀 123456789101112131415#后缀是数字，占两位，前缀是test.logsplit -l 1000000 test.log -d -a 2 test.log#分割之后的结果ls -lrth总用量 1.3G-rw-r--r-- 1 root root 645M 5月 30 20:42 test.log-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log00-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log01-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log02-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log03-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log04-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log05-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log06-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log07-rw-r--r-- 1 root root 64M 5月 30 20:55 test.log08 2、dd分割123dd bs=1M count=300 if=test.log of=newlog.1dd bs=1M count=300 if=test.log of=newlog.2 skip=300dd bs=1M count=300 if=test.log of=newlog.3 skip=600 分割后的效果123456ls -lrth总用量 1.3G-rw-r--r-- 1 root root 645M 5月 30 20:42 test.log-rw-r--r-- 1 root root 300M 5月 30 21:07 newlog.1-rw-r--r-- 1 root root 300M 5月 30 21:07 newlog.2-rw-r--r-- 1 root root 45M 5月 30 21:07 newlog.3 在上面使用的命令中，bs代表数据块的大小，count表示复制的块数，if表示输入文件，of表示输出文件。这个命令不能一下就把文件分割到我们想要的状态，而且很有可能一行日志被分到两个文件中。 3、head+tail分割用这两个命令获取文件部分内容，然后重定向就能实现文件分割，但是限制也挺多，只能把文件分成两部分，如果文件特别大，想要达到预期的效果，就要一直分割下去。head/tail -n $行数 test.log &gt; newlog因为这两个命令都比较熟悉，不再多讲。 4、sed实现分割实现原理就是用sed截取特定行之间的内容，然后进行重定向。12345sed -n '1,2000000p' test.log &gt; test.log.1sed -n '2000001,4000000p' test.log &gt; test.log.2sed -n '4000001,6000000p' test.log &gt; test.log.3sed -n '6000001,8000000p' test.log &gt; test.log.4sed -n '8000001,$p' test.log &gt; test.log.5 $表示最后一行，这个如果分割过多，也需要一个循环。 5、awk实现分割实现原理和sed差不多，因为使用awk不多，这里只举一个小例子：12awk ‘&#123;if (NR&lt;120000) print $0&#125;’ test.log &gt; a.txtawk ‘&#123;if (NR&gt;=120000) print $0&#125;’ test.log &gt; b.txt 还是split用得舒服。]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>日志</tag>
        <tag>分割</tag>
        <tag>split</tag>
        <tag>dd</tag>
        <tag>head</tag>
        <tag>tail</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装Nodejs]]></title>
    <url>%2F2018%2F12%2F12%2FCentOS%E4%B8%8A%E5%AE%89%E8%A3%85Nodejs%2F</url>
    <content type="text"><![CDATA[Node官方地址：https://nodejs.org/en/选择LTS最新版本 1、二进制包安装1234wget https://nodejs.org/dist/v10.14.2/node-v10.14.2-linux-x64.tar.xztar -d node-v10.14.2-linux-x64.tar.xztar -xvf node-v8.11.3-linux-x64.tarmv node-v8.11.3-linux-x64 /data/node 配置环境变量1vim /etc/profile 最后加入以下内容并保存12#set node environmentexport PATH=/data/node/bin:$PATH 执行以下命令，使环境变量生效1source /etc/profile 验证nodejs是否安装成功。12# node -vv8.11.3 出现以上信息即表示node安装成功。 2、源码包编译安装123456wget https://nodejs.org/dist/v10.14.2/node-v10.14.2.tar.gztar -zxvf node-v10.14.2.tar.gzcd node-v10.14.2./configure –prefix=/data/nodemakemake install 配置环境变量1vim /etc/profile 最后加入以下内容并保存12#set node environmentexport PATH=/data/node/bin:$PATH 执行以下命令，使环境变量生效1source /etc/profile 验证nodejs是否安装成功。12# node -vv8.11.3 出现以上信息即表示node安装成功。]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装Maven]]></title>
    <url>%2F2018%2F12%2F12%2FCnetOS%E4%B8%8A%E5%AE%89%E8%A3%85Maven%2F</url>
    <content type="text"><![CDATA[1、下载打开官方下载地址：http://maven.apache.org/download.cgi选择版本下载，选择最优版本Maven3.3.9下载链接为：http://mirror.bit.edu.cn/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz直接通过wget下载12cd /data/backupwget http://mirror.bit.edu.cn/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz 2、安装解压Maven并移动到/data目录下12tar -zxvf apache-maven-3.3.9-bin.tar.gzmv apache-maven-3.3.9 /data/maven3 配置环境变量1vim /etc/profile 最后加入以下内容并保存1234#set maven environmentMAVEN_HOME=/data/maven3export MAVEN_HOMEexport PATH=$&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;/bin 执行以下命令，使环境变量生效1source /etc/profile 验证maven是否安装成功。1234567# mvn -vApache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)Maven home: /data/maven3Java version: 1.8.0_161, vendor: Oracle CorporationJava home: /data/jdk1.8/jreDefault locale: en_US, platform encoding: UTF-8OS name: "linux", version: "3.10.0-693.2.2.el7.x86_64", arch: "amd64", family: "unix" 出现以上信息即表示maven安装成功。]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装Java环境]]></title>
    <url>%2F2018%2F12%2F12%2FCentOS%E4%B8%8A%E5%AE%89%E8%A3%85Java%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[检查系统是否已经安装jdk1java -version 如果没有显示java版本信息，则表示没有安装java下载地址：http://www.oracle.com/technetwork/cn/java/javase/downloads/jdk8-downloads-2133151-zhs.html如果有更新最新版本，可以获取最新版本下载，需要同意协议才可获取下载链接，在服务器上可以通过wget下载 #安装java12tar -zxvf jdk-8u161-linux-x64.tar.gzmv jdk1.8.0_161 /data/jdk1.8 #修改系统变量1vi /etc/profile 在文本末尾添加以下内容：123#set java environmentPATH=/data/jdk1.8/bin:$PATHexport PATH 使添加内容生效1source /etc/profile 再查看java版本1234# java -versionjava version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 出现如下信息表示安装成功]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB基础文档]]></title>
    <url>%2F2018%2F12%2F12%2FMongoDB%E5%9F%BA%E7%A1%80%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[一、 MongoDB简介1、MongoDB历史MongoDB最初于2007年开发，当时公司正在建立一个类似于窗口天蓝(window azure)的服务平台。“Window azure是由Microsoft创建的云计算平台和基础设施，通过全球网络构建，部署和管理应用程序和服务。”MongoDB由位于纽约的一个名为10gen的组织开发，现在被称为MongoDB Inc.，它最初被开发为PAAS(平台即服务)。 2009年晚些时候，它被作为一个由MongoDB公司维护和支持的开源数据库服务器在市场上引入。MongoDB的第一个真正产品是从2010年3月发布的MongoDB 1.4版本开始的。2014年1月10日发布的最新版本：MongoDB2.4.9。首先应该知道什么是面向文档的数据库？面向文档的数据库示例MongoDB是面向文档的数据库。这是MongoDB的一个主要功能。它提供面向文档的存储。这很简单，可以很容易地编程。MongoDB将数据存储为文档，因此被称为面向文档的数据库。12345FirstName = "Max", Address = "Haikou City", Spouse = [&#123;Name: "Maxsu"&#125;]. FirstName ="Kobe", Address = "LAC" 有两个不同的文件(用“.”分隔开)。以这种方式存储数据称为面向文档的数据库。 Mongodb属于一类名为面向文档数据库(Document Oriented Databases)。它属于一个叫作“NoSQL数据库”的数据库类别称。 2、MongoDB特点MongoDB的一些重要功能特性： 支持特别查询在MongoDB中，可以通过字段，范围查询进行搜索，并且还支持正则表达式搜索。 索引可以索引文档中的任何字段。 复制MongoDB支持主从复制。主机可以执行读写操作，从机从主机复制数据，只能用于读取或备份(不写入) 复制数据MongoDB可以在多台服务器上运行。 复制数据以保持系统正常运行，并在硬件故障的情况下保持其运行状态。 负载均衡由于数据放在碎片中，因此具有自动负载平衡配置。 支持映射缩减和聚合工具 使用JavaScript而不是Procedure 它是一个用C++编写的无模式数据库 提供高性能 轻松存储任何大小的文件，而不会使您的堆栈复杂化 在故障的情况下易于管理 具有动态模式的JSON数据模型 自动分片用于水平可扩展性 内置复制高可用性现在，许多公司使用 MongoDB 来创建新类型的应用程序，以提高性能和可用性。 3、MongoDB数据库的优点到目前为止，MongoDB是一个新的和普遍使用的数据库。它是一个基于文档的非关系数据库提供程序。虽然它比传统的数据库快100倍，但早期说它将广泛地取代传统的RDBMS。但是，不可否认的是：在性能和可扩展性方面 MongoDB 有着明显的优势。关系数据库具有典型的架构设计，可以显示表的数量以及这些表之间的关系，而在MongoDB中则没有关系的概念。（1）MongoDB优点 * MongoDB 的架构较少。它是一个文档数据库，它的一个集合持有不同的文档。 * 从一个到另一个的文档的数量，内容和大小可能有差异。 * MongoDB 中单个对象的结构很清淅。 * MongoDB 中没有复杂的连接。 * MongoDB 提供深度查询的功能，因为它支持对文档的强大的动态查询。 * MongoDB 很容易扩展。 * 它使用内部存储器来存储工作集，这是其快速访问的原因。 （2）MongoDb的独特功能 * 使用方便 * 重量轻/轻量级 * 比RDBMS快得多 （3）MongoDB应用场景 * 大而复杂的数据 * 移动和社会基础设施数据 * 内容管理和交付 * 用户数据管理 * 数据中心 （4）MongoDB和RDBMS的性能分析 * 在关系数据库(RDBMS)中，表用作存储元素，而在 MongoDB 中使用的是集合。 * 在RDBMS中有多个模式，在每个模式中，可创建用于存储数据的表，而 MongoDB 是面向文档的数据库，数据是以类似JSON格式的BSON格式编写的存储的。 * MongoDB几乎比传统数据库系统快100倍。 4、MongoDB快速入门MongoDB是一个跨平台，面向文档的数据库，提供高性能，高可用性和易于扩展。MongoDB是工作在集合和文档上一种概念。数据库数据库是一个集合的物理容器。每个数据库获取其自己设定在文件系统上的文件。一个单一的MongoDB服务器通常有多个数据库。集合集合是一组MongoDB的文件。它与一个RDBMS表是等效的。一个集合存在于数据库中。集合不强制执行模式。集合中的文档可以有不同的字段。通常情况下，在一个集合中的所有文件都是类似或相关目的。文档文档是一组键值对。文档具有动态模式。动态模式是指，在同一个集合的文件不必具有相同一组集合的文档字段或结构，并且相同的字段可以保持不同类型的数据。 二、MongoDB安装1、下载MongoDb的linux版本下载地址为https://www.mongodb.org/dl/linux/选择合适的版本下载1234wget http://downloads.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.2.20.tgz?_ga=2.11328048.543796309.1528358506-412859566.1526522668mv mongodb-linux-x86_64-rhel70-3.2.20.tgz\?_ga\=2.11328048.543796309.1528358506-412859566.1526522668 mongodb-linux-x86_64-rhel70-3.2.20.tgztar -zxvf mongodb-linux-x86_64-rhel70-3.2.20.tgz mv mongodb-linux-x86_64-rhel70-3.2.20 /data/mongodb 2、安装将Mongod移动到/data目录下，然后加入系统环境变量12#set mongodb environmentexport PATH=/data/mongodb/bin:$PATH 执行以下命令使配置生效1source /etc/profile 新建log、data、conf目录，如下123456789101112# pwd/data/mongodb# lltotal 104drwxr-xr-x 2 root root 4096 Jun 7 04:16 bindrwxr-xr-x 2 root root 6 Jun 7 04:29 confdrwxr-xr-x 4 root root 4096 Jun 7 04:43 data-rw-r--r-- 1 root root 34520 May 8 18:08 GNU-AGPL-3.0drwxr-xr-x 2 root root 6 Jun 7 04:43 log-rw-r--r-- 1 root root 16726 May 8 18:08 MPL-2-rw-r--r-- 1 root root 2262 May 8 18:08 README-rw-r--r-- 1 root root 35910 May 8 18:08 THIRD-PARTY-NOTICES mongodb的bin下各工具的用途： * mongod：数据库服务端，类似mysqld，每个实例启动一个进程，可以fork为Daemon运行 * mongo：客户端命令行工具，类似sqlplus/mysql，其实也是一个js解释器，支持js语法 * mongodump/mongorestore：将数据导入为bson格式的文件/将bson文件恢复为数据库，类似xtracbackup * mongoexport/mongoimport：将collection导出为json/csv格式数据/将数据导入数据库，类似mysqldump/mysqlimport * bsondump：将bson格式的文件转储为json格式的数据 * mongos：分片路由，如果使用了sharding功能，则应用程序连接的是mongos而不是mongod * mongofiles：GridFS管理工具 * mongostat：实时监控工具启动mongodb 启动1mongod --dbpath /data/mongodb/data/ 出现以下信息表示启动成功 3、配置配置mongodb1234567891011# cat conf/mongodb.conf dbpath=/data/mongodb/datalogpath=/data/mongodb/log/mongodb.logpidfilepath=/data/mongodb/data/mongodb.pidlogappend=true#bind_ip=10.186.21.85bind_ip=0.0.0.0port=27017maxConns=20000fork=true#auth = true # 先关闭, 创建好用户在启动 mongod的主要参数有：dbpath: 数据文件存放路径，每个数据库会在其中创建一个子目录。logpath：错误日志文件logappend： 错误日志采用追加模式（默认是覆写模式）bind_ip： 对外服务的绑定ip，一般设置为空，及绑定在本机所有可用ip上，如有需要可以单独指定。只能绑定本机网卡上绑定的ip地址，如果指定ip没有绑定在本机网卡，则绑定0.0.0.0，此种情况适用于绑定云服务器的外网ip。port： 对外服务端口。Web管理端口在这个port的基础上+1000fork： 以后台Daemon形式运行服务journal：开启日志功能，通过保存操作日志来降低单机故障的恢复时间，在1.8版本后正式加入，取代在1.7.5版本中的dur参数。syncdelay： 执行sync的间隔，单位为秒。directoryperdb： 每个db存放在单独的目录中，建议设置该参数。maxConns： 最大连接数repairpath： 执行repair时的临时目录。在如果没有开启journal，异常宕机后重启，必须执行repair操作。此时可以指定配置文件启动mongodb1234# mongod -f /data/mongodb/conf/mongodb.conf about to fork child process, waiting until server is ready for connections.forked process: 20815child process started successfully, parent exiting 以上即表示启动成功 4、管理mongodb服务官网文档https://docs.mongodb.com/manual/tutorial/manage-mongodb-processes/#stop-mongod-processesStart mongod Processes（1）mongod（2）mongod –dbpath /srv/mongodb/（3）mongod –port 12345（4）mongod –fork –logpath /var/log/mongodb.log（5）mongod -f /data/mongodb/conf/mongodb.confStop mongod Processes（1）Use shutdownServer()12use admin db.shutdownServer() （2）Use –shutdown1mongod –shutdown （3）Use CTRL-C（4）Use kill12kill &lt;mongod process ID&gt;kill -2 &lt;mongod process ID&gt; 禁止使用-912WARNING:Never use kill -9 (i.e. SIGKILL) to terminate a mongod instance. 5、修复monogdb当出现服务器非正常关机的情况，重新启动的时候会出现以下类似报错12ERROR: child process failed, exited with error number 100ERROR: child process failed, exited with error number 48 解决方法为123mongod -f /data/mongodb/conf/mongodb.conf –repairmongod -f /data/mongodb/conf/mongodb.conf --authmongod -f /data/mongodb/conf/mongodb.conf 通过repair修复连接mongodb方法为1mongo --host 101.132.37.169:27017 其中ip地址为配置文件中bind_ip地址，如果是本地可以直接mongo连接6、打开网页在mongodb.conf配置文件中加入以下参数1rest=true 即可打开网页端口，默认为28017，如图所示 三、MongoDB操作1、用户操作创建用户12use admin db.createUser(&#123;user:"root",pwd:"root",roles:[&#123;role:"readWrite",db:"admin"&#125;]&#125;) 查看已存在的用户123&gt; db.system.users.find()&#123; "_id" : "admin.root", "user" : "root", "db" : "admin", "credentials" : &#123; "SCRAM-SHA-1" : &#123; "iterationCount" : 10000, "salt" : "1hkiX4Tscoj6bUpxF2x7+A==", "storedKey" : "ciyQR1bc5Bbm6Qxg4euAijnadCw=", "serverKey" : "F/Gg0NmM19ih62VjbccW/SYOAh4=" &#125; &#125;, "roles" : [ &#123; "role" : "root", "db" : "admin" &#125; ] &#125;&#123; "_id" : "testdb.testdb", "user" : "testdb", "db" : "testdb", "credentials" : &#123; "SCRAM-SHA-1" : &#123; "iterationCount" : 10000, "salt" : "VhSm/77+cGXEUwYAbdHvSw==", "storedKey" : "hDtO9gq4OVNdcChNSoRhYiXmSQQ=", "serverKey" : "L1bPBquYwey5O0BYsDl7zsiSojs=" &#125; &#125;, "roles" : [ &#123; "role" : "dbOwner", "db" : "testdb" &#125; ] &#125; 删除用户12&gt; db.system.users.remove(&#123;user:"testdb1u1"&#125;)WriteResult(&#123; "nRemoved" : 1 &#125;) 用户登录数据库测试1mongo -u testdb -p 123456 127.0.0.1:27017/testdb 2、数据库操作创建数据库12&gt; use newdbswitched to db newdb 检查当前选择的数据库12&gt; dbnewdb 检查数据库列表123&gt; show dbsadmin 0.000GBlocal 0.000GB 新创建的数据库(newdb)不在列表中。要显示数据库，需要至少插入一个文档，否则空的数据库是不显示出来的。123456&gt; db.items.insert(&#123;"name":"yiibai tutorials"&#125;)WriteResult(&#123; "nInserted" : 1 &#125;)&gt; show dbsadmin 0.000GBlocal 0.000GBnewdb 0.000GB 在 MongoDB 中默认数据库是：test。 如果您还没有创建过任何数据库，则集合/文档将存储在test数据库中。删除数据库MongoDB中的 db.dropDatabase()命令用于删除现有的数据库。123456789101112131415&gt; show dbsadmin 0.000GBlocal 0.000GBnewdb 0.000GB&gt; show dbsadmin 0.000GBlocal 0.000GBnewdb 0.000GB&gt; dbnewdb&gt; db.dropDatabase()&#123; "dropped" : "newdb", "ok" : 1 &#125;&gt; show dbsadmin 0.000GBlocal 0.000GB 以上过程已把数据库newdb删除 四、MongoDB集群1、MongoDB主从模式搭建（1）Master-Slave搭建两台服务器IP分别为：10.186.21.85（主）、10.186.21.84（从）关于mongodb的详细配置可以从配置文件看到主库配置文件1234567891011121314151617181920# cat /data/mongodb/conf/mongodb.conf dbpath=/data/mongodb/data #数据库路径logpath=/data/mongodb/log/mongodb.log #日志输出文件路径logappend=true #日志输出方式pidfilepath=/data/mongodb/data/mongodb.pid #pid文件路径#bind_ip=10.186.21.85bind_ip=0.0.0.0port=27017 #端口号rest=true #设置后打开28017网页端口httpinterface=truemaxConns=20000fork=true #设置后台运行shardsvr=true#directoryperdb=true#auth = true # 先关闭, 创建好用户在启动#nohttpinterface=falsejournal=truequiet=truemaster=true 从库配置文件123456789101112131415161718192021# cat /data/mongodb/conf/mongodb.conf dbpath=/data/mongodb/data #数据库路径logpath=/data/mongodb/log/mongodb.log #日志输出文件路径logappend=true #日志输出方式pidfilepath=/data/mongodb/data/mongodb.pid #pid文件路径#bind_ip=10.186.21.84bind_ip=0.0.0.0port=27017 #端口号rest=true #设置后打开28017网页端口httpinterface=truemaxConns=20000fork=true #设置后台运行shardsvr=true#directoryperdb=true#auth = true # 先关闭, 创建好用户在启动#nohttpinterface=falsejournal=truequiet=trueslave=truesource=10.186.21.85:27017 验证主库添加数据库12345678910111213&gt; show dbsadmin 0.000GBlocal 0.000GB&gt; use testdbswitched to db testdb&gt; db.items.insert(&#123;"name":"yiibai tutorials"&#125;)WriteResult(&#123; "nInserted" : 1 &#125;)&gt; use testdbswitched to db testdb&gt; show dbsadmin 0.000GBlocal 0.000GBtestdb 0.000GB 从库查看数据库验证12345&gt; rs.slaveOk()&gt; show dbsadmin 0.000GBlocal 0.000GBtestdb 0.000GB 登录从库后执行命令可能会报错1[thread1] Error: listDatabases failed:&#123; "ok" : 0, "errmsg" : "not master and slaveOk=false", "code" : 13435 &#125; : 解决方法为登录从库后执行rs.slaveOk()，如下123456789101112&gt; show dbs2018-06-08T05:25:43.065-0400 E QUERY [thread1] Error: listDatabases failed:&#123; "ok" : 0, "errmsg" : "not master and slaveOk=false", "code" : 13435 &#125; :_getErrorWithCode@src/mongo/shell/utils.js:25:13Mongo.prototype.getDBs@src/mongo/shell/mongo.js:62:1shellHelper.show@src/mongo/shell/utils.js:781:19shellHelper@src/mongo/shell/utils.js:671:15@(shellhelp2):1:1&gt; rs.slaveOk()&gt; show dbsadmin 0.000GBlocal 0.000GB （2）Master-Slave安全这个主从安全在 MongoDB官网说的很清楚。不能和普通的mongod权限验证那样。这里除了需要加入 —auth 还需要加入 —keyFile 的验证。首先，我们生成我们的keyFile，根据官网提供的说明，这个keyfile是可以任意内容的，只要保证所有集群中的机器都拥有同样的文件即可。在linux环境下，我们通过1openssl rand -base64 741 &gt; /data/mongodb/mongo-keyfile 这条命令来生成我们的keyFile。保证主从库上使用的配置文件相同，在配置文件中加入1keyFile=/data/mongodb/mongo-keyfile 重新启动monodb，报错1234# mongod -f /data/mongodb/conf/mongodb.confabout to fork child process, waiting until server is ready for connections.forked process: 16492ERROR: child process failed, exited with error number 1 查看日志12CONTROL [main] ***** SERVER RESTARTED *****ACCESS [main] permissions on /data/mongodb/mongo-keyfile are too open 可以看到是文件权限过大调整权限为400123456789101112# chmod 400 mongo-keyfile # lltotal 108drwxr-xr-x 2 root root 4096 Jun 7 04:16 bindrwxr-xr-x 2 root root 25 Jun 8 05:44 confdrwxr-xr-x 4 root root 4096 Jun 8 05:49 data-rw-r--r-- 1 root root 34520 May 8 18:08 GNU-AGPL-3.0drwxr-xr-x 2 root root 24 Jun 7 05:20 log-r-------- 1 root root 7 Jun 8 05:42 mongo-keyfile-rw-r--r-- 1 root root 16726 May 8 18:08 MPL-2-rw-r--r-- 1 root root 2262 May 8 18:08 README-rw-r--r-- 1 root root 35910 May 8 18:08 THIRD-PARTY-NOTICES 重新启动，即可启动成功]]></content>
      <categories>
        <category>DB</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>集群</tag>
        <tag>主从</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix安装]]></title>
    <url>%2F2018%2F12%2F11%2FZabbix%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[一、环境配置关闭selinux12vim /etc/sysconfig/selinuxSELINUX=disabled 二、Nginx安装Nginx在生产环境推荐使用编译方式安装 1、安装编译环境、gcc12yum -y install gcc gcc-c++ automake autoconf libtool makeyum install gcc gcc-c++ 一般我们都需要先装pcre, zlib，前者为了重写rewrite，后者为了gzip压缩。从ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/ 下载最新的 PCRE 源码包，使用下面命令下载编译和安装 PCRE 包： 2、安装pcre1234567cd /data/backupwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.42.tar.gztar -zxvf pcre-8.42.tar.gzcd pcre-8.42./configuremakemake install 3、安装zlib从http://zlib.net下载最新的 zlib 源码包，使用下面命令下载编译和安装 zlib包：1234567cd /data/backupwget http://zlib.net/zlib-1.2.11.tar.gz tar -zxvf zlib-1.2.11.tar.gzcd zlib-1.2.11./configuremakemake install 4、安装openssl123cd /data/backupwget https://www.openssl.org/source/openssl-1.1.0h.tar.gztar -zxvf openssl-1.1.0h.tar.gz 5、安装Nginx1234567cd /data/backupwget http://nginx.org/download/nginx-1.14.0.tar.gztar -zxvf nginx-1.14.0.tar.gz cd nginx-1.14.0./configure --prefix=/data/nginx/ --with-http_v2_module --with-http_ssl_module --with-http_flv_module --with-http_mp4_module --with-http_sub_module --with-http_stub_status_module --with-http_gzip_static_module --without-http-cache --with-http_realip_module --with-pcre=/data/backup/pcre-8.42 --with-zlib=/data/backup/zlib-1.2.11 --with-openssl=/data/backup/openssl-1.1.0hmakemake install 创建Nginx软连接到环境变量1ln -s /data/nginx/sbin/* /usr/local/sbin/ 三、php安装Zabbix界面需要支持的PHP组件可以从官网查看，如下图： 1、安装插件1yum install -y libxml2 libxml2-devel openssl openssl-devel bzip2 bzip2-devel libcurl libcurl-devel libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel gmp gmp-devel libmcrypt libmcrypt-devel readline readline-devel libxslt libxslt-devel libicu-devel 2、编译安装PHP123456wget http://cn2.php.net/distributions/php-7.2.8.tar.gztar -zxvf php-7.2.8.tar.gz cd php-7.2.8/./configure --prefix=/data/php --with-curl --with-freetype-dir --with-gd --with-gettext --with-iconv-dir --with-kerberos --with-libdir=lib64 --with-libxml-dir --with-mysqli --with-openssl --with-pcre-regex --with-pdo-mysql --with-pdo-sqlite --with-pear --with-png-dir --with-jpeg-dir --with-xmlrpc --with-xsl --with-zlib --with-bz2 --with-mhash --enable-fpm --enable-bcmath --enable-libxml --enable-inline-optimization --enable-mbregex --enable-mbstring --enable-opcache --enable-pcntl --enable-shmop --enable-soap --enable-sockets --enable-sysvsem --enable-sysvshm --enable-xml --enable-zipmakemake install 复制配置文件12cp php.ini-development /data/php/lib/php.inicp /data/php/etc/php-fpm.conf.default /data/php/etc/php-fpm.conf 启动1/data/php/sbin/php-fpm 三、Mysql安装1、yum安装123yum -y install libaiowget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpmyum localinstall mysql-community-release-el7-5.noarch.rpm 验证下是否添加成功1234yum repolist enabled | grep "mysql.*-community.*"yum install mysql-develyum install mysql-community-serversystemctl start mysqld 更改数据存放目录123mkdir /home/datamysqladmin -u root -p shutdownmv /var/lib/mysql /home/data 修改 /etc/my.cnf 文件12345[mysqld]datadir=/data/mysqldata/mysqlsocket=/data/mysqldata/mysql/mysql.sock[mysql]socket=/data/mysqldata/mysql/mysql.sock 授权1chown -R mysql:mysql /data/mysqldata/mysql 重启mysql服务配置开机自起123# systemctl is-enabled mysql.service;echo $?enabled0 如果是 enabled 则说明是开机自动，如果不是，执行1chkconfig --levels 235 mysqld on 修改 /etc/my.cnf 文件，添加字符集的设置1234[mysqld] character_set_server = utf8[mysql]default-character-set = utf8 创建数据库1create database zabbix default charset utf8; 2、源码包安装参考链接：mysql安装 四、Zabbix Server端安装创建用户12groupadd zabbixuseradd -g zabbix zabbix 安装zabbix server从官网查找最新稳定版本，当前为3.0.*，下载后解压123mkdir /data/zabbix./configure --prefix=/data/zabbix/ --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2 --enable-javamake install 启动server进程1/data/zabbix/sbin/zabbix_server -c /data/zabbix/etc/zabbix_server.conf 启动agent进程1/data/zabbix/sbin/zabbix_agentd -c /data/zabbix/etc/zabbix_agentd.conf 可能出现的报错：1234checking for mysql_config... noconfigure: error: MySQL library not found#解决方法yum -y install mysql-devel 123configure: error: Invalid Net-SNMP directory - unable to find net-snmp-config#解决方法yum -y install net-snmp net-snmp-devel 五、Zabbix Web安装12cd /data/backup/zabbix-3.0.8/frontends/phpcp -a . /data/watch01.sa.mtiancity.com/zabbix/ 配置nginx可以访问，略过修改php.ini12345post_max_size = 16Mmax_execution_time = 300date.timezone =Asia/Shanghaialways_populate_raw_post_data = -1max_input_time = 300 导入数据库1234cd /data/backup/zabbix-3.0.8/database/mysql/mysql -u root zabbix&lt;schema.sqlmysql -u root zabbix&lt;images.sqlmysql -u root zabbix&lt;data.sql 打开nginx配置的url访问，如下图：也可能出现报错此时按照提示，将配置文件放入相应目录即可初始化完成后，登陆zabbix web，默认用户名：Admin，密码：zabbix 六、Zabbix Agnet端安装安装方法二选一即可，推荐rpm安装 1、编译安装创建用户组和用户12groupadd zabbixuseradd -g zabbix zabbix yum安装组件1yum -y install mysql-devel libxml2-devel unixODBC-devel OpenIPMI-devel curl-devel net-snmp-devel 安装zabbix agent1234tar -zxvf zabbix-3.0.8.tar.gzcd zabbix-3.0.8/./configure --prefix=/data/zabbix/ --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2make &amp;&amp; make install 复制配置文件1cp /data/backup/zabbix_agentd.conf /data/zabbix/etc/ 启动agent1/data/zabbix/sbin/zabbix_agentd -c /data/zabbix/etc/zabbix_agentd.conf 2、rpm包安装12345yum -y install unixODBC#centos6rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/6/x86_64/zabbix-agent-3.0.1-1.el6.x86_64.rpm#centos7rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-agent-3.0.9-1.el7.x86_64.rpm 配置文件位置/etc/zabbix/zabbix_agentd.conf，可以根据实际场景修改启动客户端1zabbix_agentd]]></content>
      <categories>
        <category>Monitor</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS系统巡检]]></title>
    <url>%2F2018%2F12%2F11%2FCentOS%E7%B3%BB%E7%BB%9F%E5%B7%A1%E6%A3%80%2F</url>
    <content type="text"><![CDATA[1、巡检脚本首先编写单台系统巡检脚本，内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730# cat checkos.sh#!/bin/bash#################################################################### Functions: this script from polling system status# Info: be suitable for CentOS/RHEL 6/7 # Changelog:# 2016-09-15 shaon initial commit####################################################################set path env,if not set will some command not found in crontabexport PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binsource /etc/profilerm -f /data/scripts/*.csv# run this script use root[ $(id -u) -gt 0 ] &amp;&amp; echo "please use root run the script! " &amp;&amp; exit 1# check system versionOS_Version=$(awk '&#123;print $(NF-1)&#125;' /etc/redhat-release)# declare script version dateScript_Version="2018.10.30"# define polling log pathLOGPATH=/data/scripts[ -d $LOGPATH ] || mkdir -p $LOGPATHRESULTFILE="$LOGPATH/`hostname`-`date +%Y%m%d`.csv"# define globle variablereport_DateTime="" #日期 okreport_Hostname="" #主机名 okreport_OSRelease="" #发行版本 okreport_Kernel="" #内核 okreport_Language="" #语言/编码 okreport_LastReboot="" #最近启动时间 okreport_Uptime="" #运行时间（天） okreport_CPUs="" #CPU数量 okreport_CPUType="" #CPU类型 okreport_Arch="" #CPU架构 okreport_MemTotal="" #内存总容量(MB) okreport_MemFree="" #内存剩余(MB) okreport_MemUsedPercent="" #内存使用率% okreport_DiskTotal="" #硬盘总容量(GB) okreport_DiskFree="" #硬盘剩余(GB) okreport_DiskUsedPercent="" #硬盘使用率% okreport_InodeTotal="" #Inode总量 okreport_InodeFree="" #Inode剩余 okreport_InodeUsedPercent="" #Inode使用率 okreport_IP="" #IP地址 okreport_MAC="" #MAC地址 okreport_Gateway="" #默认网关 okreport_DNS="" #DNS okreport_Listen="" #监听 okreport_Selinux="" #Selinux okreport_Firewall="" #防火墙 okreport_USERs="" #用户 okreport_USEREmptyPassword="" #空密码用户 okreport_USERTheSameUID="" #相同ID的用户 ok report_PasswordExpiry="" #密码过期（天） okreport_RootUser="" #root用户 okreport_Sudoers="" #sudo授权 okreport_SSHAuthorized="" #SSH信任主机 okreport_SSHDProtocolVersion="" #SSH协议版本 okreport_SSHDPermitRootLogin="" #允许root远程登录 okreport_DefunctProsess="" #僵尸进程数量 okreport_SelfInitiatedService="" #自启动服务数量 okreport_SelfInitiatedProgram="" #自启动程序数量 okreport_RuningService="" #运行中服务数 okreport_Crontab="" #计划任务数 okreport_Syslog="" #日志服务 okreport_SNMP="" #SNMP OKreport_NTP="" #NTP okreport_JDK="" #JDK版本 okfunction version()&#123; echo "" echo "System Polling：Version $Script_Version " echo ""&#125;function getCpuStatus()&#123; echo "" echo "############################ Check CPU Status#############################" Physical_CPUs=$(grep "physical id" /proc/cpuinfo| sort | uniq | wc -l) Virt_CPUs=$(grep "processor" /proc/cpuinfo | wc -l) CPU_Kernels=$(grep "cores" /proc/cpuinfo|uniq| awk -F ': ' '&#123;print $2&#125;') CPU_Type=$(grep "model name" /proc/cpuinfo | awk -F ': ' '&#123;print $2&#125;' | sort | uniq) CPU_Arch=$(uname -m) echo "物理CPU个数:$Physical_CPUs" echo "逻辑CPU个数:$Virt_CPUs" echo "每CPU核心数:$CPU_Kernels" echo " CPU型号:$CPU_Type" echo " CPU架构:$CPU_Arch" # report information report_CPUs=$Virt_CPUs #CPU数量 report_CPUType=$CPU_Type #CPU类型 report_Arch=$CPU_Arch #CPU架构&#125;function getMemStatus()&#123; echo "" echo "############################ Check Memmory Usage ###########################" if [[ $OS_Version &lt; 7 ]];then free -mo else free -h fi # report information MemTotal=$(grep MemTotal /proc/meminfo| awk '&#123;print $2&#125;') #KB MemFree=$(grep MemFree /proc/meminfo| awk '&#123;print $2&#125;') #KB let MemUsed=MemTotal-MemFree MemPercent=$(awk "BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \"%.2f\",$MemUsed*100/$MemTotal&#125;&#125;") report_MemTotal="$((MemTotal/1024))""MB" #内存总容量(MB) report_MemFree="$((MemFree/1024))""MB" #内存剩余(MB) report_MemUsedPercent="$(awk "BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \"%.2f\",$MemUsed*100/$MemTotal&#125;&#125;")""%" #内存使用率%&#125;function getDiskStatus()&#123; echo "" echo "############################ Check Disk Status ############################" df -hiP | sed 's/Mounted on/Mounted/' &gt; /tmp/inode df -hTP | sed 's/Mounted on/Mounted/' &gt; /tmp/disk join /tmp/disk /tmp/inode | awk '&#123;print $1,$2,"|",$3,$4,$5,$6,"|",$8,$9,$10,$11,"|",$12&#125;'| column -t # report information diskdata=$(df -TP | sed '1d' | awk '$2!="tmpfs"&#123;print&#125;') #KB disktotal=$(echo "$diskdata" | awk '&#123;total+=$3&#125;END&#123;print total&#125;') #KB diskused=$(echo "$diskdata" | awk '&#123;total+=$4&#125;END&#123;print total&#125;') #KB diskfree=$((disktotal-diskused)) #KB diskusedpercent=$(echo $disktotal $diskused | awk '&#123;if($1==0)&#123;printf 100&#125;else&#123;printf "%.2f",$2*100/$1&#125;&#125;') inodedata=$(df -iTP | sed '1d' | awk '$2!="tmpfs"&#123;print&#125;') inodetotal=$(echo "$inodedata" | awk '&#123;total+=$3&#125;END&#123;print total&#125;') inodeused=$(echo "$inodedata" | awk '&#123;total+=$4&#125;END&#123;print total&#125;') inodefree=$((inodetotal-inodeused)) inodeusedpercent=$(echo $inodetotal $inodeused | awk '&#123;if($1==0)&#123;printf 100&#125;else&#123;printf "%.2f",$2*100/$1&#125;&#125;') report_DiskTotal=$((disktotal/1024/1024))"GB" #硬盘总容量(GB) report_DiskFree=$((diskfree/1024/1024))"GB" #硬盘剩余(GB) report_DiskUsedPercent="$diskusedpercent""%" #硬盘使用率% report_InodeTotal=$((inodetotal/1000))"K" #Inode总量 report_InodeFree=$((inodefree/1000))"K" #Inode剩余 report_InodeUsedPercent="$inodeusedpercent""%" #Inode使用率% echo ""&#125;function getSystemStatus()&#123; echo "" echo "############################ Check System Status ############################" if [ -e /etc/sysconfig/i18n ];then default_LANG="$(grep "LANG=" /etc/sysconfig/i18n | grep -v "^#" | awk -F '"' '&#123;print $2&#125;')" else default_LANG=$LANG fi export LANG="en_US.UTF-8" Release=$(cat /etc/redhat-release 2&gt;/dev/null) Kernel=$(uname -r) OS=$(uname -o) Hostname=$(uname -n) SELinux=$(/usr/sbin/sestatus | grep "SELinux status: " | awk '&#123;print $3&#125;') LastReboot=$(who -b | awk '&#123;print $3,$4&#125;') uptime=$(cat /proc/uptime| awk -F. '&#123;run_days=$1 / 86400;run_hour=($1 % 86400)/3600;run_minute=($1 % 3600)/60;run_second=$1 % 60;printf("%d天%d时%d分%d秒",run_days,run_hour,run_minute,run_second)&#125;') echo " 系统：$OS" echo " 发行版本：$Release" echo " 内核：$Kernel" echo " 主机名：$Hostname" echo " SELinux：$SELinux" echo "语言/编码：$default_LANG" echo " 当前时间：$(date +'%F %T')" echo " 最后启动：$LastReboot" echo " 运行时间：$uptime" # report information report_DateTime=$(date +"%F %T") #日期 report_Hostname="$Hostname" #主机名 report_OSRelease="$Release" #发行版本 report_Kernel="$Kernel" #内核 report_Language="$default_LANG" #语言/编码 report_LastReboot="$LastReboot" #最近启动时间 report_Uptime="$uptime" #运行时间（天） report_Selinux="$SELinux" export LANG="$default_LANG" echo ""&#125;function getServiceStatus()&#123; echo "" echo "############################ Check Service Status ############################" if [[ $OS_Version &gt; 7 ]];then conf=$(systemctl list-unit-files --type=service --state=enabled --no-pager | grep "enabled") process=$(systemctl list-units --type=service --state=running --no-pager | grep ".service") # report information report_SelfInitiatedService="$(echo "$conf" | wc -l)" #自启动服务数量 report_RuningService="$(echo "$process" | wc -l)" #运行中服务数量 else conf=$(/sbin/chkconfig | grep -E ":on|:启用") process=$(/sbin/service --status-all 2&gt;/dev/null | grep -E "is running|正在运行") # report information report_SelfInitiatedService="$(echo "$conf" | wc -l)" #自启动服务数量 report_RuningService="$(echo "$process" | wc -l)" #运行中服务数量 fi echo "Service Configure" echo "--------------------------------" echo "$conf" | column -t echo "" echo "The Running Services" echo "--------------------------------" echo "$process"&#125;function getAutoStartStatus()&#123; echo "" echo "############################ Check Self-starting Services ##########################" conf=$(grep -v "^#" /etc/rc.d/rc.local| sed '/^$/d') echo "$conf" # report information report_SelfInitiatedProgram="$(echo $conf | wc -l)" #自启动程序数量&#125;function getLoginStatus()&#123; echo "" echo "############################ Check Login In ############################" last | head&#125;function getNetworkStatus()&#123; echo "" echo "############################ Check Network ############################" if [[ $OS_Version &lt; 7 ]];then /sbin/ifconfig -a | grep -v packets | grep -v collisions | grep -v inet6 else #ip address for i in $(ip link | grep BROADCAST | awk -F: '&#123;print $2&#125;');do ip add show $i | grep -E "BROADCAST|global"| awk '&#123;print $2&#125;' | tr '\n' ' ' ;echo "" ;done fi GATEWAY=$(ip route | grep default | awk '&#123;print $3&#125;') DNS=$(grep nameserver /etc/resolv.conf| grep -v "#" | awk '&#123;print $2&#125;' | tr '\n' ',' | sed 's/,$//') echo "" echo "Gateway: $GATEWAY " echo " DNS: $DNS" # report information IP=$(ip -f inet addr | grep -v 127.0.0.1 | grep inet | awk '&#123;print $NF,$2&#125;' | tr '\n' ',' | sed 's/,$//') MAC=$(ip link | grep -v "LOOPBACK\|loopback" | awk '&#123;print $2&#125;' | sed 'N;s/\n//' | tr '\n' ',' | sed 's/,$//') report_IP="$IP" #IP地址 report_MAC=$MAC #MAC地址 report_Gateway="$GATEWAY" #默认网关 report_DNS="$DNS" #DNS&#125;function getListenStatus()&#123; echo "" echo "############################ Check Listen Status ############################"# TCPListen=$(ss -ntul | column -t) TCPListen=$(netstat -ntulp | column -t) AllConnect=$(ss -an | awk 'NR&gt;1 &#123;++s[$1]&#125; END &#123;for(k in s) print k,s[k]&#125;' | column -t) echo "$TCPListen" echo "$AllConnect" # report information report_Listen="$(echo "$TCPListen"| sed '1d' | awk '/tcp/ &#123;print $5&#125;' | awk -F: '&#123;print $NF&#125;' | sort | uniq | wc -l)"&#125;function getCronStatus()&#123; echo "" echo "############################ Check Crontab List ########################" Crontab=0 for shell in $(grep -v "/sbin/nologin" /etc/shells);do for user in $(grep "$shell" /etc/passwd | awk -F: '&#123;print $1&#125;');do crontab -l -u $user &gt;/dev/null 2&gt;&amp;1 status=$? if [ $status -eq 0 ];then echo "$user" echo "-------------" crontab -l -u $user let Crontab=Crontab+$(crontab -l -u $user | wc -l) echo "" fi done done # scheduled task find /etc/cron* -type f | xargs -i ls -l &#123;&#125; | column -t let Crontab=Crontab+$(find /etc/cron* -type f | wc -l) # report information report_Crontab="$Crontab" #计划任务数&#125;function getHowLongAgo()&#123; # 计算一个时间戳离现在有多久了 datetime="$*" [ -z "$datetime" ] &amp;&amp; echo "错误的参数：getHowLongAgo() $*" Timestamp=$(date +%s -d "$datetime") #转化为时间戳 Now_Timestamp=$(date +%s) Difference_Timestamp=$(($Now_Timestamp-$Timestamp)) days=0;hours=0;minutes=0; sec_in_day=$((60*60*24)); sec_in_hour=$((60*60)); sec_in_minute=60 while (( $(($Difference_Timestamp-$sec_in_day)) &gt; 1 )) do let Difference_Timestamp=Difference_Timestamp-sec_in_day let days++ done while (( $(($Difference_Timestamp-$sec_in_hour)) &gt; 1 )) do let Difference_Timestamp=Difference_Timestamp-sec_in_hour let hours++ done echo "$days 天 $hours 小时前"&#125;function getUserLastLogin()&#123; # 获取用户最近一次登录的时间，含年份 # 很遗憾last命令不支持显示年份，只有"last -t YYYYMMDDHHMMSS"表示某个时间之间的登录，我 # 们只能用最笨的方法了，对比今天之前和今年元旦之前（或者去年之前和前年之前……）某个用户 # 登录次数，如果登录统计次数有变化，则说明最近一次登录是今年。 username=$1 : $&#123;username:="`whoami`"&#125; thisYear=$(date +%Y) oldesYear=$(last | tail -n1 | awk '&#123;print $NF&#125;') while(( $thisYear &gt;= $oldesYear));do loginBeforeToday=$(last $username | grep $username | wc -l) loginBeforeNewYearsDayOfThisYear=$(last $username -t $thisYear"0101000000" | grep $username | wc -l) if [ $loginBeforeToday -eq 0 ];then echo "Never Login" break elif [ $loginBeforeToday -gt $loginBeforeNewYearsDayOfThisYear ];then lastDateTime=$(last -i $username | head -n1 | awk '&#123;for(i=4;i&lt;(NF-2);i++)printf"%s ",$i&#125;')" $thisYear" #格式如: Sat Nov 2 20:33 2015 lastDateTime=$(date "+%Y-%m-%d %H:%M:%S" -d "$lastDateTime") echo "$lastDateTime" break else thisYear=$((thisYear-1)) fi done&#125;function getUserStatus()&#123; echo "" echo "############################ Check User ############################" # /etc/passwd the last modification time pwdfile="$(cat /etc/passwd)" Modify=$(stat /etc/passwd | grep Modify | tr '.' ' ' | awk '&#123;print $2,$3&#125;') echo "/etc/passwd The last modification time：$Modify ($(getHowLongAgo $Modify))" echo "" echo "A privileged user" echo "-----------------" RootUser="" for user in $(echo "$pwdfile" | awk -F: '&#123;print $1&#125;');do if [ $(id -u $user) -eq 0 ];then echo "$user" RootUser="$RootUser,$user" fi done echo "" echo "User List" echo "--------" USERs=0 echo "$( echo "UserName UID GID HOME SHELL LasttimeLogin" for shell in $(grep -v "/sbin/nologin" /etc/shells);do for username in $(grep "$shell" /etc/passwd| awk -F: '&#123;print $1&#125;');do userLastLogin="$(getUserLastLogin $username)" echo "$pwdfile" | grep -w "$username" |grep -w "$shell"| awk -F: -v lastlogin="$(echo "$userLastLogin" | tr ' ' '_')" '&#123;print $1,$3,$4,$6,$7,lastlogin&#125;' done let USERs=USERs+$(echo "$pwdfile" | grep "$shell"| wc -l) done )" | column -t echo "" echo "Null Password User" echo "------------------" USEREmptyPassword="" for shell in $(grep -v "/sbin/nologin" /etc/shells);do for user in $(echo "$pwdfile" | grep "$shell" | cut -d: -f1);do r=$(awk -F: '$2=="!!"&#123;print $1&#125;' /etc/shadow | grep -w $user) if [ ! -z $r ];then echo $r USEREmptyPassword="$USEREmptyPassword,"$r fi done done echo "" echo "The Same UID User" echo "----------------" USERTheSameUID="" UIDs=$(cut -d: -f3 /etc/passwd | sort | uniq -c | awk '$1&gt;1&#123;print $2&#125;') for uid in $UIDs;do echo -n "$uid"; USERTheSameUID="$uid" r=$(awk -F: 'ORS="";$3=='"$uid"'&#123;print ":",$1&#125;' /etc/passwd) echo "$r" echo "" USERTheSameUID="$USERTheSameUID $r," done # report information report_USERs="$USERs" #用户 report_USEREmptyPassword=$(echo $USEREmptyPassword | sed 's/^,//') report_USERTheSameUID=$(echo $USERTheSameUID | sed 's/,$//') report_RootUser=$(echo $RootUser | sed 's/^,//') #特权用户&#125;function getPasswordStatus &#123; echo "" echo "############################ Check Password Status ############################" pwdfile="$(cat /etc/passwd)" echo "" echo "Password Expiration Check" echo "-------------------------" result="" for shell in $(grep -v "/sbin/nologin" /etc/shells);do for user in $(echo "$pwdfile" | grep "$shell" | cut -d: -f1);do get_expiry_date=$(/usr/bin/chage -l $user | grep 'Password expires' | cut -d: -f2) if [[ $get_expiry_date = ' never' || $get_expiry_date = 'never' ]];then printf "%-15s never expiration\n" $user result="$result,$user:never" else password_expiry_date=$(date -d "$get_expiry_date" "+%s") current_date=$(date "+%s") diff=$(($password_expiry_date-$current_date)) let DAYS=$(($diff/(60*60*24))) printf "%-15s %s expiration after days\n" $user $DAYS result="$result,$user:$DAYS days" fi done done report_PasswordExpiry=$(echo $result | sed 's/^,//') echo "" echo "Check The Password Policy" echo "------------" grep -v "#" /etc/login.defs | grep -E "PASS_MAX_DAYS|PASS_MIN_DAYS|PASS_MIN_LEN|PASS_WARN_AGE" echo ""&#125;function getSudoersStatus()&#123; echo "" echo "############################ Sudoers Check #########################" conf=$(grep -v "^#" /etc/sudoers| grep -v "^Defaults" | sed '/^$/d') echo "$conf" echo "" # report information report_Sudoers="$(echo $conf | wc -l)"&#125;function getInstalledStatus()&#123; echo "" echo "############################ Software Check ############################" rpm -qa --last | head | column -t &#125;function getProcessStatus()&#123; echo "" echo "############################ Process Check ############################" if [ $(ps -ef | grep defunct | grep -v grep | wc -l) -ge 1 ];then echo "" echo "zombie process"; echo "--------" ps -ef | head -n1 ps -ef | grep defunct | grep -v grep fi echo "" echo "Merory Usage TOP10" echo "-------------" echo -e "PID %MEM RSS COMMAND $(ps aux | awk '&#123;print $2, $4, $6, $11&#125;' | sort -k3rn | head -n 10 )"| column -t echo "" echo "CPU Usage TOP10" echo "------------" top b -n1 | head -17 | tail -11 # report information report_DefunctProsess="$(ps -ef | grep defunct | grep -v grep|wc -l)"&#125;function getJDKStatus()&#123; echo "" echo "############################ JDK Check #############################" java -version 2&gt;/dev/null if [ $? -eq 0 ];then java -version 2&gt;&amp;1 fi echo "JAVA_HOME=\"$JAVA_HOME\"" # report information report_JDK="$(java -version 2&gt;&amp;1 | grep version | awk '&#123;print $1,$3&#125;' | tr -d '"')"&#125;function getSyslogStatus()&#123; echo "" echo "############################ Syslog Check ##########################" echo "Service Status：$(getState rsyslog)" echo "" echo "/etc/rsyslog.conf" echo "-----------------" cat /etc/rsyslog.conf 2&gt;/dev/null | grep -v "^#" | grep -v "^\\$" | sed '/^$/d' | column -t #report information report_Syslog="$(getState rsyslog)"&#125;function getFirewallStatus()&#123; echo "" echo "############################ Firewall Check ##########################" # Firewall Status/Poilcy if [[ $OS_Version &lt; 7 ]];then /etc/init.d/iptables status &gt;/dev/null 2&gt;&amp;1 status=$? if [ $status -eq 0 ];then s="active" elif [ $status -eq 3 ];then s="inactive" elif [ $status -eq 4 ];then s="permission denied" else s="unknown" fi else s="$(getState iptables)" fi echo "iptables: $s" echo "" echo "/etc/sysconfig/iptables" echo "-----------------------" cat /etc/sysconfig/iptables 2&gt;/dev/null # report information report_Firewall="$s"&#125;function getSNMPStatus()&#123; #SNMP Service Status,Configure echo "" echo "############################ SNMP Check ############################" status="$(getState snmpd)" echo "Service Status：$status" echo "" if [ -e /etc/snmp/snmpd.conf ];then echo "/etc/snmp/snmpd.conf" echo "--------------------" cat /etc/snmp/snmpd.conf 2&gt;/dev/null | grep -v "^#" | sed '/^$/d' fi # report information report_SNMP="$(getState snmpd)"&#125;function getState()&#123; if [[ $OS_Version &lt; 7 ]];then if [ -e "/etc/init.d/$1" ];then if [ `/etc/init.d/$1 status 2&gt;/dev/null | grep -E "is running|正在运行" | wc -l` -ge 1 ];then r="active" else r="inactive" fi else r="unknown" fi else #CentOS 7+ r="$(systemctl is-active $1 2&gt;&amp;1)" fi echo "$r"&#125;function getSSHStatus()&#123; #SSHD Service Status,Configure echo "" echo "############################ SSH Check #############################" # Check the trusted host pwdfile="$(cat /etc/passwd)" echo "Service Status：$(getState sshd)" Protocol_Version=$(cat /etc/ssh/sshd_config | grep Protocol | awk '&#123;print $2&#125;') echo "SSH Protocol Version：$Protocol_Version" echo "" echo "Trusted Host" echo "------------" authorized=0 for user in $(echo "$pwdfile" | grep /bin/bash | awk -F: '&#123;print $1&#125;');do authorize_file=$(echo "$pwdfile" | grep -w $user | awk -F: '&#123;printf $6"/.ssh/authorized_keys"&#125;') authorized_host=$(cat $authorize_file 2&gt;/dev/null | awk '&#123;print $3&#125;' | tr '\n' ',' | sed 's/,$//') if [ ! -z $authorized_host ];then echo "$user authorization \"$authorized_host\" Password-less access" fi let authorized=authorized+$(cat $authorize_file 2&gt;/dev/null | awk '&#123;print $3&#125;'|wc -l) done echo "" echo "Whether to allow ROOT remote login" echo "----------------------------------" config=$(cat /etc/ssh/sshd_config | grep PermitRootLogin) firstChar=$&#123;config:0:1&#125; if [ $firstChar == "#" ];then PermitRootLogin="yes" #The default is to allow ROOT remote login else PermitRootLogin=$(echo $config | awk '&#123;print $2&#125;') fi echo "PermitRootLogin $PermitRootLogin" echo "" echo "/etc/ssh/sshd_config" echo "--------------------" cat /etc/ssh/sshd_config | grep -v "^#" | sed '/^$/d' # report information report_SSHAuthorized="$authorized" #SSH信任主机 report_SSHDProtocolVersion="$Protocol_Version" #SSH协议版本 report_SSHDPermitRootLogin="$PermitRootLogin" #允许root远程登录&#125;function getNTPStatus()&#123; # The NTP service status, the current time, configuration, etc echo "" echo "############################ NTP Check #############################" if [ -e /etc/ntp.conf ];then echo "Service Status：$(getState ntpd)" echo "" echo "/etc/ntp.conf" echo "-------------" cat /etc/ntp.conf 2&gt;/dev/null | grep -v "^#" | sed '/^$/d' fi # report information report_NTP="$(getState ntpd)"&#125;function getZabbixStatus()&#123; # Check Zabbix Serivce Status echo "" echo "######################### Zabbix Check ##############################" netstat -nltp | grep -v grep | grep zabbix &gt; /dev/null 2&gt;&amp;1 if [ $? -eq 0 ];then echo "Service Status": Zabbix is running! else echo "Service Status": Zabbix not running! fi # report information&#125;function uploadHostDailyCheckReport()&#123; json="&#123; \"DateTime\":\"$report_DateTime\", \"Hostname\":\"$report_Hostname\", \"OSRelease\":\"$report_OSRelease\", \"Kernel\":\"$report_Kernel\", \"Language\":\"$report_Language\", \"LastReboot\":\"$report_LastReboot\", \"Uptime\":\"$report_Uptime\", \"CPUs\":\"$report_CPUs\", \"CPUType\":\"$report_CPUType\", \"Arch\":\"$report_Arch\", \"MemTotal\":\"$report_MemTotal\", \"MemFree\":\"$report_MemFree\", \"MemUsedPercent\":\"$report_MemUsedPercent\", \"DiskTotal\":\"$report_DiskTotal\", \"DiskFree\":\"$report_DiskFree\", \"DiskUsedPercent\":\"$report_DiskUsedPercent\", \"InodeTotal\":\"$report_InodeTotal\", \"InodeFree\":\"$report_InodeFree\", \"InodeUsedPercent\":\"$report_InodeUsedPercent\", \"IP\":\"$report_IP\", \"MAC\":\"$report_MAC\", \"Gateway\":\"$report_Gateway\", \"DNS\":\"$report_DNS\", \"Listen\":\"$report_Listen\", \"Selinux\":\"$report_Selinux\", \"Firewall\":\"$report_Firewall\", \"USERs\":\"$report_USERs\", \"USEREmptyPassword\":\"$report_USEREmptyPassword\", \"USERTheSameUID\":\"$report_USERTheSameUID\", \"PasswordExpiry\":\"$report_PasswordExpiry\", \"RootUser\":\"$report_RootUser\", \"Sudoers\":\"$report_Sudoers\", \"SSHAuthorized\":\"$report_SSHAuthorized\", \"SSHDProtocolVersion\":\"$report_SSHDProtocolVersion\", \"SSHDPermitRootLogin\":\"$report_SSHDPermitRootLogin\", \"DefunctProsess\":\"$report_DefunctProsess\", \"SelfInitiatedService\":\"$report_SelfInitiatedService\", \"SelfInitiatedProgram\":\"$report_SelfInitiatedProgram\", \"RuningService\":\"$report_RuningService\", \"Crontab\":\"$report_Crontab\", \"Syslog\":\"$report_Syslog\", \"SNMP\":\"$report_SNMP\", \"NTP\":\"$report_NTP\", \"JDK\":\"$report_JDK\" &#125;" #echo "$json" curl -l -H "Content-type: application/json" -X POST -d "$json" "$uploadHostDailyCheckReportApi" 2&gt;/dev/null&#125;function check()&#123; version getSystemStatus getCpuStatus getMemStatus getDiskStatus getNetworkStatus getListenStatus getProcessStatus getServiceStatus getAutoStartStatus getLoginStatus getCronStatus getUserStatus getPasswordStatus getSudoersStatus getJDKStatus getFirewallStatus getSSHStatus getSyslogStatus getSNMPStatus getNTPStatus getZabbixStatus getInstalledStatus&#125;# Perform inspections and save the inspection results #执行检查并保存检查结果check &gt; $RESULTFILEecho "Check the result：$RESULTFILE"# Upload the result file #上传检查结果的文件#curl -F "filename=@$RESULTFILE" "$uploadHostDailyCheckApi" 2&gt;/dev/null#Upload inspection result report #上传检查结果的报表#uploadHostDailyCheckReport 1&gt;/dev/null 运行脚本后，会在脚本设定的目录：/data/scripts/checklog/下生成以csv为后缀的文件，文件格式也是在脚本中已经设定。 2、文件合并需要将多个csv文件合成为xlsx后缀的文件，将多台服务器的执行结果都保存在checklog目录下。脚本内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# cat toall_xlsx.py #!/usr/bin/python# coding=utf_8_sigimport osimport sysimport csvimport globimport timesys.path.append("/home/shdi/bin/pymodule")import xlsxwriterimport sysreload(sys)sys.setdefaultencoding('utf-8') def merge_csv2xlsx(csv_dir, xlsxfile): # Create a new workbook and add a worksheet workbook = xlsxwriter.Workbook(xlsxfile) fmt_plain = workbook.add_format(&#123; 'font_size': 12, 'font_name': "Arial Narrow", &#125;) for filename in glob.glob("%s/*.csv" % csv_dir): print " procsss %s" % filename (f_path, f_name) = os.path.split(filename) (f_short_name, f_extension) = os.path.splitext(f_name) sheet_name = f_short_name worksheet = workbook.add_worksheet(sheet_name) spamReader = csv.reader(open(filename, 'rb'), delimiter=',',quotechar='"') row_count = 0 for row in spamReader: for col in range(len(row)): #ws.write(row_count,col,row[col]) worksheet.write(row_count, col, row[col],fmt_plain) row_count +=1 workbook.close() print "xlsx file saved: %s" % xlsxfile returnif __name__ == "__main__": if len(sys.argv) != 2: print "Usage:" print "\t%s &lt;csvdir&gt;" % sys.argv[0] sys.exit(0) csvdir = sys.argv[1] savefile = time.strftime("/data/scripts/checklog/check_%Y%m%d.xlsx") merge_csv2xlsx(csvdir, savefile) print("\n\nCVS merged file saved to %s" % savefile) 此脚本放在checklog下，讲同目录下所有文件合并成xlsx文件。 3、定时任务添加多台服务器ip，并将脚本添加进定时任务脚本如下：123456789101112131415161718192021222324252627282930313233343536373839404142# pwd/data/scripts[root@gbw_manage scripts]# cat run_xunjian.sh #!/bin/bashHOSTLIST=("172.16.109.139 172.16.109.149172.16.109.145 172.16.109.146 172.16.109.150 172.16.109.140 172.16.109.151 172.16.109.147 172.16.109.141 172.16.109.137 172.16.109.138 172.16.109.144 172.16.109.148 172.16.109.143 172.16.109.142172.16.109.153")#echo "$HOSTLIST"COUNT=`echo "$HOSTLIST" |grep -v '^$'|wc -l`#echo $COUNTfor ip in $&#123;HOSTLIST[*]&#125;do /usr/bin/ssh root@$ip -C "/bin/bash" &lt; /data/scripts/checkos.sh echo $ipdonerm -f /data/scripts/checklog/*.csvfor ip in $&#123;HOSTLIST[*]&#125;do scp root@$ip:/data/scripts/*.csv /data/scripts/checklog/ echo $ipdone/usr/bin/python /data/scripts/checklog/toall_xlsx.py /data/scripts/checklog 最后的结果文档会保存在/data/scripts/checklog下，文件后缀为xlsx。将此脚本添加定时任务，每天1点执行一次，即可实现定时巡检系统。完善：可以在脚本内增加邮件发送功能，将最后的结果文件发送到对应的接收人员。]]></content>
      <categories>
        <category>Scripts</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Python</tag>
        <tag>巡检</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ应用文档]]></title>
    <url>%2F2018%2F12%2F10%2FRabbitMQ%E5%BA%94%E7%94%A8%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[一、Rabbitmq简介1、Rabbitmq介绍RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。AMQP，即Advanced message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 2、Rabbitmq系统概念 RabbitMQ Server 也叫broker server，是一种传输服务，负责维护一条从Producer到consumer的路线，保证数据能够按照指定的方式进行传输。 Producer 数据的发送方。 Consumer 数据的接收方。 Exchanges 接收消息，转发消息到绑定的队列。主要使用3种类型：direct， topic， fanout。 Queue RabbitMQ内部存储消息的对象。相同属性的queue可以重复定义，但只有第一次定义的有效。 Bindings 绑定Exchanges和Queue之间的路由。 Connection 就是一个TCP的连接。Producer和consumer都是通过TCP连接到RabbitMQ Server的。 Channel 虚拟连接。它建立在上述的TCP连接中。数据流动都是在Channel中进行的。也就是说，一般情况是程序起始建立TCP连接，第二步就是建立这个Channel。 3、AMQP协议简介AMQP在一致性客户端和消息中间件(也称为”brokers”)之间创建了全功能的互操作．为了完全实现消息中间件的互操作性，需要充分定义网络协议和消息代理服务的功能语义。因此，AMQP通过如下来定义了网络协议(AMQP是协议！)和服务端服务：1、一套确定的消息交换功能，也就是“高级消息交换协议模型”。AMQP模型包括一套用于路由和存储消息的功能模块，以及一套在这些模块之间交换消息的规则。2、 一个网络线级协议（数据传输格式），AMQP促使客户端可使用AMQ模型来与服务器交互。可以只实现AMQP协议规范中的的部分语义，但是我们相信这些明确的语义有助于理解这个协议。我们需要明确定义服务器语义，因为所有服务器实现都应该与这些语义保持一致性，否则就无法进行互操作. 因此AMQ 模型定义了一系列模块化组件和标准规则来进行协作. 有三种类型的组件可以连接服务器处理链来创建预期的功能:1、”交换器(exchange)” ：接收来自发布者应用程序的消息，并基于任意条件(通常是消息属性和内容）将这些消息路由到消息队列(message queues).2、”消息队列(message queue)”：存储消息直到它们可以被消费客户端应用程序(或多线程应用程序)安全处理。3、”绑定(binding)”:定义了消息队列与交换器之间的关系，并提供了消息路由条件．使用这些模型我们可以很容易地模拟经典的存储转发队列和面向消息中间件的主题订阅概念. 我们还可以表示更为复杂的概念，例如：基于内容的路由，工作负载分配和按需消息队列。大致上讲， AMQP 服务器类似与邮件服务器, 每个交换器都扮演了消息传送代理,每个消息队列都作为邮箱，而绑定则定义了每个传送代理中的路由表.发布者发送消息给独立的传送代理,然后传送代理再路由消息到邮箱中.消费者从邮箱中收取消息. 相比较而言，在AMQP之前的许多中间件系统中，发布者直接发送消息到独立收件箱(在存储转发队列的情况下),或者发布到邮件列表中 (在主题订阅的情况下)。区别就在于用户可以控制消息队列和交换器之间的绑定规则，这可以做很多有趣的事情，比如定义一条规则：“将所有包含这样消息头的消息都复制一份再发送到消息队列中”。AMQ模型是基于下面的需求来驱动设计的：1、支持与主要消息产品相媲美的语义。.2、 提供与主要消息产品相媲美的性能水平.3、允许通过应用程序使用服务器特定语义来编程.4、灵活性，可扩展性，简单性 二、安装Rabbitmq1、安装好系统运行12yum update -yreboot #一般情况不用重启 2、安装依赖文件12yum -y install gcc glibc-devel make ncurses-devel openssl-devel xmlto perl wget#部分依赖可能在安装其他服务时已安装 3、安装erlang语言环境官网地址：http://www.erlang.org/downloads，由于环境支持问题，建议下载最新版本123456wget http://erlang.org/download/otp_src_20.3.tar.gztar -zxvf otp_src_20.3.tar.gz cd otp_src_20.3./configure --prefix=/data/erlangmakemake install 配置erlang环境变量12345678vi /etc/profile #在底部添加以下内容 #set erlang environmentERL_HOME=/data/erlangPATH=$ERL_HOME/bin:$PATHexport ERL_HOME PATHsource /etc/profile #生效 在控制台输入命令erl如果进入erlang的shell则证明安装成功，退出即可。 4、安装rabbitmq官网地址：http://www.rabbitmq.com/install-generic-unix.html，下载最新稳定版本1234wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.4/rabbitmq-server-generic-unix-3.7.4.tar.xzxz -d rabbitmq-server-generic-unix-3.7.4.tar.xz tar -xvf rabbitmq-server-generic-unix-3.7.4.tar mv rabbitmq_server-3.7.4 /data/rabbitmq 配置rabbitmq环境变量123456vi /etc/profile #在底部添加以下内容 #set rabbitmq environmentexport PATH=$PATH:/data/rabbitmq/sbinsource /etc/profile #生效 启动服务1rabbitmq-server -detached #启动rabbitmq，-detached代表后台守护进程方式启动 出现以下界面此时rabbit-servery已经启动官网解释：http://www.rabbitmq.com/rabbitmq-server.8.html但是由于没有写入PID file文件，可能导致服务停止查看状态1rabbitmqctl status 如果显示如下截图说明安装成功其他相关命令 启动服务：rabbitmq-server -detached 或者/data/rabbitmq/sbin/rabbitmq-server -detached 查看状态：rabbitmqctl status 或者/usr/local/rabbitmq/sbin/rabbitmqctl status 关闭服务：rabbitmqctl stop 或者/usr/local/rabbitmq/sbin/rabbitmqctl stop 列出角色：rabbitmqctl list_users 或者/usr/local/rabbitmq/sbin/rabbitmqctl list_users 5、配置网页插件首先创建目录，否则可能报错1mkdir /etc/rabbitmq 启用web管理插件1rabbitmq-plugins enable rabbitmq_management 6、配置防火墙配置linux端口15672网页管理5672AMQP端口123firewall-cmd --permanent --add-port=15672/tcpfirewall-cmd --permanent --add-port=5672/tcpsystemctl restart firewalld.service 在浏览器输入http://ip:15672，可以看到RabbitMQ的WEB管理页面，如下 7、配置访问账号密码和权限默认网页是不允许访问的，需要增加一个用户修改一下权限123rabbitmqctl add_user action action #添加用户，后面两个参数分别是用户名和密码rabbitmqctl set_permissions -p / action ".*" ".*" ".*" #添加权限rabbitmqctl set_user_tags action administrator #修改用户角色 查看角色并确认123# rabbitmqctl list_usersListing users ...action [administrator] 然后就可以远程访问了，然后可直接配置用户权限等信息。登录：http://ip:15672 登录之后在admin里面把guest删除。 8、Rabbitmq配置RabbitMQ 提供了三种方式来定制服务器: 环境变量：定义端口，文件位置和名称(接受shell输入,或者在环境配置文件（rabbitmq-env.conf）中设置) 配置文件：为服务器组件设置权限,限制和集群，也可以定义插件设置. 运行时参数和策略：可在运行时进行修改集群设置 1）配置文件rabbitmq.config 文件rabbitmq.config配置文件允许配置RabbitMQ 核心程序， Erlang 服务和RabbitMQ 插件. 它是标准的Erlang 配置文件, 文档位于Erlang Config Man Page.最小化的样例配置文件如下:1[ &#123;rabbit, [&#123;tcp_listeners, [5673]&#125;]&#125; ]. 这个例子中将会修改RabbitMQ监听AMQP 0-9-1 客户端连接端口，5672修改为5673.配置文件不同于环境配置文件rabbitmq-env.conf这些文件的位置分布特定的. 默认情况下，这些文件是没有创建的,但每个平台上期望的位置如下：12345Generic UNIX - $RABBITMQ_HOME/etc/rabbitmq/Debian - /etc/rabbitmq/RPM - /etc/rabbitmq/Mac OS X (Homebrew) - $&#123;install_prefix&#125;/etc/rabbitmq/, the Homebrew prefix is usually/usr/localWindows - %APPDATA%\RabbitMQ\ 如果rabbitmq-env.conf不存在, 可在默认位置中手动创建.。它不能用于Windows系统.如果rabbitmq.config不存在，可以手动创建它. 如果你修改了位置，可设置RABBITMQ_CONFIG_FILE 环境变量来指定. Erlang 运行时会自动在此变量值后添加.config扩展名，重启服务器后生效。Windows 服务用户在删除配置文件后，需要重新安装服务。 2）rabbitmq.config中的变量配置大部分的RabbitMQ用户都会不会修改这些值，有些是相当模糊的。为了完整性，他们都在这里列出。 Key Documentation tcp_listeners 用于监听 AMQP连接的端口列表(无SSL). 可以包含整数 (即”监听所有接口”)或者元组如 {“127.0.0.1”, 5672} 用于监听一个或多个接口. Default: [5672] num_tcp_acceptors 接受TCP侦听器连接的Erlang进程数。 Default: 10 handshake_timeout AMQP 0-8/0-9/0-9-1 handshake (在 socket 连接和SSL 握手之后）的最大时间, 毫秒为单位. Default: 10000 ssl_listeners 如上所述，用于SSL连接。 Default: [] num_ssl_acceptors 接受SSL侦听器连接的Erlang进程数。 Default: 1 ssl_options SSL配置.参考SSL documentation. Default: [] ssl_handshake_timeout SSL handshake超时时间,毫秒为单位. Default: 5000 vm_memory_high_watermark 流程控制触发的内存阀值．相看memory-based flow control 文档. Default: 0.4 vm_memory_high_watermark_paging_ratio 高水位限制的分数，当达到阀值时，队列中消息消息会转移到磁盘上以释放内存. 参考memory-based flow control 文档. Default: 0.5 disk_free_limit RabbitMQ存储数据分区的可用磁盘空间限制．当可用空间值低于阀值时，流程控制将被触发. 此值可根据RAM的总大小来相对设置 (如.{mem_relative, 1.0}). 此值也可以设为整数(单位为bytes)或者使用数字单位(如．”50MB”). 默认情况下，可用磁盘空间必须超过50MB. 参考 Disk Alarms 文档. Default: 50000000 log_levels 控制日志的粒度.其值是日志事件类别(category)和日志级别(level)成对的列表． level 可以是 ‘none’ (不记录日志事件), ‘error’ (只记录错误), ‘warning’ (只记录错误和警告), ‘info’ (记录错误，警告和信息), or ‘debug’ (记录错误，警告，信息以及调试信息). 目前定义了４种日志类别. 它们是： channel -针对所有与AMQP channels相关的事件 connection - 针对所有与网络连接相关的事件 federation - 针对所有与federation相关的事件 mirroring -针对所有与 mirrored queues相关的事件 Default: [{connection, info}] frame_max 与客户端协商的允许最大frame大小. 设置为０表示无限制，但在某些QPid客户端会引发bug. 设置较大的值可以提高吞吐量;设置一个较小的值可能会提高延迟. Default: 131072 channel_max 与客户端协商的允许最大chanel大小. 设置为０表示无限制．该数值越大，则broker使用的内存就越高． Default: 0 channel_operation_timeout Channel 操作超时时间(毫秒为单位） (内部使用，因为消息协议的区别和限制，不暴露给客户端). Default: 5000 heartbeat 表示心跳延迟(单位为秒) ，服务器将在connection.tune frame中发送.如果设置为 0, 心跳将被禁用. 客户端可以不用遵循服务器的建议, 查看 AMQP reference 来了解详情. 禁用心跳可以在有大量连接的场景中提高性能，但可能会造成关闭了非活动连接的网络设备上的连接落下． Default: 60 (3.5.5之前的版本是580) default_vhost 当RabbitMQ从头开始创建数据库时创建的虚拟主机. amq.rabbitmq.log交换器会存在于这个虚拟主机中. Default: &lt;&lt;”/“&gt;&gt; default_user RabbitMQ从头开始创建数据库时，创建的用户名. Default: &lt;&lt;”guest”&gt;&gt; default_pass 默认用户的密码. Default: &lt;&lt;”guest”&gt;&gt; default_user_tags 默认用户的Tags. Default: [administrator] default_permissions 创建用户时分配给它的默认Permissions . Default: [&lt;&lt;”.“&gt;&gt;, &lt;&lt;”.“&gt;&gt;, &lt;&lt;”.*”&gt;&gt;] loopback_users 只能通过环回接口(即localhost)连接broker的用户列表 如果你希望默认的guest用户能远程连接,你必须将其修改为[]. Default: [&lt;&lt;”guest”&gt;&gt;] cluster_nodes 当节点第一次启动的时候，设置此选项会导致集群动作自动发生. 元组的第一个元素是其它节点想与其建立集群的节点. 第二个元素是节点的类型，要么是disc,要么是ram Default: {[], disc} server_properties 连接时向客户端声明的键值对列表 Default: [] collect_statistics 统计收集模式。主要与管理插件相关。选项： none (不发出统计事件) coarse (发出每个队列 /每个通道 /每个连接的统计事件) fine (也发出每个消息统计事件) 你自已可不用修改此选项. Default: none collect_statistics_interval 统计收集时间间隔(毫秒为单位)． 主要针对于 management plugin. Default: 5000 auth_mechanisms 提供给客户端的SASL authentication mechanisms. Default: [‘PLAIN’, ‘AMQPLAIN’] auth_backends 用于 authentication / authorisation backends 的列表. 此列表可包含模块的名称(在模块相同的情况下，将同时用于认证来授权)或像{ModN, ModZ}这样的元组，在这里ModN将用于认证，ModZ将用于授权. 在２元组的情况中, ModZ可由列表代替,列表中的所有元素必须通过每个授权的确认，如{ModN, [ModZ1, ModZ2]}. 这就允许授权插件进行组合提供额外的安全约束. 除rabbit_auth_backend_internal外，其它数据库可以通常 plugins来使用. Default: [rabbit_auth_backend_internal] reverse_dns_lookups 设置为true,可让客户端在连接时让RabbitMQ 执行一个反向DNS查找, 然后通过 rabbitmqctl 和 管理插件来展现信息. Default: false delegate_count 内部集群通信中，委派进程的数目. 在一个有非常多核的机器(集群的一部分)上,你可以增加此值. Default: 16 trace_vhosts tracer内部使用. 你不应该修改. Default: [] tcp_listen_options 默认socket选项. 你可能不想修改这个选项. Default: [{backlog, 128}, {nodelay, true}, {exit_on_close, false}] hipe_compile 将此选项设置为true,将会使用HiPE预编译部分RabbitMQ,Erlang的即时编译器. 这可以增加服务器吞吐量，但会增加服务器的启动时间． 你可以看到花费几分钟延迟启动的成本，就可以带来20-50% 更好性能.这些数字与高度依赖于工作负载和硬件． HiPE 支持可能没有编译进你的Erlang安装中.如果没有的话，启用这个选项,并启动RabbitMQ时，会看到警告消息． 例如, Debian / Ubuntu 用户需要安装erlang-base-hipe 包. HiPE并非在所有平台上都可用, 尤其是Windows. 在 Erlang/OTP 1７.５版本之前，HiPE有明显的问题 . 对于HiPE,使用最新的OTP版本是高度推荐的． Default: false cluster_partition_handling 如何处理网络分区.可用模式有: ignore pause_minority {pause_if_all_down, [nodes], ignore autoheal}where [nodes] is a list of node names (ex: [‘rabbit@node1’, ‘rabbit@node2’]) autoheal 参考documentation on partitions 来了解更多信息 Default: ignore cluster_keepalive_interval 节点向其它节点发送存活消息和频率(毫秒). 注意，这与 net_ticktime是不同的; 丢失存活消息不会引起节点掉线 Default: 10000 queue_index_embed_msgs_below 消息大小在此之下的会直接内嵌在队列索引中. 在修改此值时，建议你先阅读 persister tuning 文档. Default: 4096 msg_store_index_module 队列索引的实现模块. 在修改此值时，建议你先阅读 persister tuning 文档. Default: rabbit_msg_store_ets_index backing_queue_module 队列内容的实现模块. 你可能不想修改此值． Default: rabbit_variable_queue msg_store_file_size_limit Tunable value for the persister. 你几乎肯定不应该改变此值。 Default: 16777216 mnesia_table_loading_timeout 在集群中等待使用Mnesia表可用的超时时间。 Default: 30000 queue_index_max_ journal_entries Tunable value for the persister. 你几乎肯定不应该改变此值。 Default: 65536 queue_master_locator Queue master 位置策略. 可用策略有: &lt;&lt;”min-masters”&gt;&gt; &lt;&lt;”client-local”&gt;&gt; &lt;&lt;”random”&gt;&gt; 查看documentation on queue master location 来了解更多信息． Default: &lt;&lt;”client-local”&gt;&gt; 此外，许多插件也可以在配置文件中配置, 其名称是rabbitmq_plugin的形式. 我们的维护的插件被记录在以下位置： 123456rabbitmq_managementrabbitmq_management_agentrabbitmq_mochiwebrabbitmq_stomprabbitmq_shovelrabbitmq_auth_backend_ldap 3）文件位置 名称 描述 RABBITMQ_BASE 此基础目录包含了RabbitMQ server的数据库，日志文件的子目录. 另外，也可以独立设置RABBITMQ_MNESIA_BASE 和 RABBITMQ_LOG_BASE 目录. RABBITMQ_CONFIG_FILE 用于配置文件的路径，无.config扩展名. 如果 configuration file 存在，服务器将使用它来配置RabbitMQ组件. 参考 Configuration guide 来了解更多信息. RABBITMQ_MNESIA_BASE 包含RabbitMQ 服务器Mnesia数据库文件子目录的基本目录,除非明确设置了RABBITMQ_MNESIA_DIR目录，否则每个节点都应该配置一个. (除了Mnesia文件，这个位置还包含消息存储和索引文件以及模式和集群的细节．） RABBITMQ_MNESIA_DIR RabbitMQ节点Mnesia数据库文件安放的目录. (除了Mnesia文件，这个位置还包含消息存储和索引文件以及模式和集群的细节.) RABBITMQ_LOG_BASE 用于包含RabbitMQ 服务器日志文件的基本目录, 除非明确设置了RABBITMQ_LOGS 或 RABBITMQ_SASL_LOGS. RABBITMQ_LOGS RabbitMQ 服务器的Erlang日志文件路径.在Window上不能覆盖此变量． RABBITMQ_SASL_LOGS RabbitMQ服务器的Erlang SASL (System Application Support Libraries)日志文件路径. 在Window上不能覆盖此变量． RABBITMQ_PLUGINS_DIR 用于查找插件的目录 . RABBITMQ_PLUGINS_EXPAND_DIR 用于在启动服务器时扩展启用插件的工作目录。 RABBITMQ_ENABLED_PLUGINS_FILE 此文件记录了显式启用的插件。 RABBITMQ_PID_FILE 此文件中包含了rabbitmqctl所等待进程ID的信息． Unix默认位置在下面的表格中，${install_prefix}表示某个路径. Homebrew 安装时使用installation-prefix (Homebrew Cellar) . 默认是/usr/local.Deb / RPM 包安装使用空${install_prefix}. Name Location RABBITMQ_BASE (Not used) RABBITMQ_CONFIG_FILE ${install_prefix}/etc/rabbitmq/rabbitmq RABBITMQ_MNESIA_BASE ${install_prefix}/var/lib/rabbitmq/mnesia RABBITMQ_MNESIA_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME RABBITMQ_LOG_BASE ${install_prefix}/var/log/rabbitmq RABBITMQ_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME.log RABBITMQ_SASL_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME-sasl.log RABBITMQ_PLUGINS_DIR $RABBITMQ_HOME/plugins RABBITMQ_PLUGINS_EXPAND_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME-plugins-expand RABBITMQ_ENABLED_PLUGINS_FILE ${install_prefix}/etc/rabbitmq/enabled_plugins RABBITMQ_PID_FILE $RABBITMQ_MNESIA_DIR.pid Windows默认位置 Name Location RABBITMQ_BASE %APPDATA%\RabbitMQ RABBITMQ_CONFIG_FILE %RABBITMQ_BASE%\rabbitmq RABBITMQ_MNESIA_BASE %RABBITMQ_BASE%\db RABBITMQ_MNESIA_DIR %RABBITMQ_MNESIA_BASE%\%RABBITMQ_NODENAME% RABBITMQ_LOG_BASE %RABBITMQ_BASE%\log RABBITMQ_LOGS %RABBITMQ_LOG_BASE%\%RABBITMQ_NODENAME%.log RABBITMQ_SASL_LOGS %RABBITMQ_LOG_BASE%\%RABBITMQ_NODENAME%-sasl.log RABBITMQ_PLUGINS_DIR Installation-directory/plugins RABBITMQ_PLUGINS_EXPAND_DIR %RABBITMQ_MNESIA_BASE%\%RABBITMQ_NODENAME%-plugins-expand RABBITMQ_ENABLED_PLUGINS_FILE %RABBITMQ_BASE%\enabled_plugins RABBITMQ_PID_FILE (Not currently supported) 通用Unix默认位置（即本次测试使用Rabbitmq版本）当解压Generic Unix tar文件并运行时，由于默认获得到位置，不需要进行. 在下面的表格中，$RABBITMQ_HOME指的是rabbitmq_server-3.7.4解压后的目录。 Name Location RABBITMQ_BASE (Not used) RABBITMQ_CONFIG_FILE $RABBITMQ_HOME/etc/rabbitmq/rabbitmq RABBITMQ_MNESIA_BASE $RABBITMQ_HOME/var/lib/rabbitmq/mnesia RABBITMQ_MNESIA_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME RABBITMQ_LOG_BASE $RABBITMQ_HOME/var/log/rabbitmq RABBITMQ_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME.log RABBITMQ_SASL_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME-sasl.log RABBITMQ_PLUGINS_DIR $RABBITMQ_HOME/plugins RABBITMQ_PLUGINS_EXPAND_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME-plugins-expand RABBITMQ_ENABLED_PLUGINS_FILE $RABBITMQ_HOME/etc/rabbitmq/enabled_plugins RABBITMQ_PID_FILE $RABBITMQ_MNESIA_DIR.pid 4）持久化配置RabbitMQ持久层的目的是为了得到好的结果，在大多数情况下没有配置。然而，一些配置有时是有用的。首先，先讲一下背景: 持久化和短暂消息都可以写入磁盘。持久化消息一旦到达队列，就会写入磁盘,而短暂消息只在内存压力较大被赶出内存时才会写入磁盘。持久化消息在内存紧张释放内存时，依然也会存在内存中． 持久层指的是存储这两种类型消息到磁盘的机制。队列是指无镜像队列或master队列或slave队列。 队列镜像会发生以上的持久化。持久层有两个组件: 队列索引和消息存储.队列索引负责维护消息在队列的位置，以及是否被投递，是否应答的信息. 因此，每个队列都有一个队列索引。消息存储是消息的key-value存储, 由服务器中的所有队列共享.消息(消息体, 消息属性或消息头)可直接存储于队列索引，也可以写到消息存储中.在技术上有两个消息存储（一个暂时的和一个持久的消息），但他们通常一起被被认为是“消息存储”。内存成本在内存压力下，持久层试图尽可能多地写入磁盘，并尽可能的从内存中删除。然而有一些事情必须留在内存中：每个队列都会为每个未应答消息维护一些元数据．如果它的目的地是消息存储，则消息本身可以从内存中删除。消息存储需要索引. 默认消息存储索引对于存储中的每个消息会使用少量内存。队列索引中的消息将消息写入队列索引有优点也有缺点。优点:消息可在一个操作中(而不是两个）写入磁盘; 对于微小的消息，这可以是一个实质性的增益。写入队列索引的消息不需要消息存储索引中的条目，因此当页出(paged out)时，不需要花费内存成本。缺点:队列索引在内存中保有固定数量的记录块;如果写入队列索引中的消息不是小消息，那么内存占用也是巨大的。如果一个消息通过一个交换路由到多个队列，则消息将需要写入多个队列索引。如果这样的消息被写入消息存储区，则只有一个副本需要被写入。目的地是队列索引的未应答消息总会保存在内存中。将小消息存储在队列索引中目的是优化，所有其它消息将会写入消息存储.这可以配置项queue_index_embed_msgs_below来配置.默认情况下，序列后大小小于4096字节 (包括属性和头)会存储在队列索引中。当从磁盘中读取消息时，每个队列索引至少需要在内存中保留一个段文件(segment file). 段文件中包含了16,384个消息. 因此要谨慎如果增加queue_index_embed_msgs_below；小的增加会导致大量的内存使用。无意中有限的持久性能(Accidentally limited persister performance）持久化有可能表现不佳，因为持久化受限于文件句柄的数目或与它工作的异步线程.在这两种情况下，当您有大量需要同时访问磁盘的队列时，会发生这样的情况。.太少的文件句柄RabbitMQ 服务器通常受限于它能打开的文件句柄数量(在Unix上，无论如何). 每个运行的网络连接都需要一个文件句柄, 其余的可用于队列使用。如果磁盘访问队列比考虑到网络连接后文件句柄更多，那么磁盘访问队列将与文件句柄一起共享; 每个都会在它返回交给另一个队列之前，都会使用文件句柄一段时间。当有太多磁盘访问队列时，这可以防止服务器崩溃,但代价是昂贵的. 管理插件可以显示集群中每个节点的统计I/O统计信息，如读，写，查找的速率．同时它也会显示重新开始(reopens)的速率- 文件句柄通过这种方式来回收利用. 一个有太少文件句柄繁忙的服务器每秒可能会做几百次reopens - 在这种情况下，如果增加文件句柄，就有可能提高性能。太少的异步线程Erlang 虚拟机创建异步线程池来处理长时间运行的文件I/O操作. 这些线程池是所有队列所共享的.每个活跃的文件I/O操作都会使用一个异步线程. 太少的异步线程可以因此伤害性能。注意，异步线程的情况并不完全类似与文件句柄的情况. 如果一个队列按顺序来执行一定数量的I/O操作，假设它持有一个文件句柄来所理所有操作，其性能是最好的，否则，我们会占用ＣＰＵ来做更多的刷新，查找 操作. 然而,队列不能从持有一个异步线程执行一系列的操作中获益(事实上也做不到)。因此理论上应该要有足够的文件句柄来处理所有队列上的I/O流操作, 并且要有足够的线程来处理并发的 (simultaneous )的I/O操作。由异步线程缺乏造成的性能问题，不是太明显. (一般情况下都不太可能，可首先检查其它地方!) 。太少异步线程的典型症状是，当服务器忙于持久化时，在很短的时间内，每秒 I/O操作的数目将会下降到０(管理插件可报告) ,报告的每个 I/O操作的时间将会增加。Erlang虚拟主机的异步线程数目可通过+A 参数进行配置，这里有描述, 通常情况下，也可以通过环境变量RABBITMQ_SERVER_ERL_ARGS来配置. 默认值是 +A 30. 在修改之前，多进行几次尝试总是好主意。 三、Rabbitmq集群RabbitMQ是用erlang开发的，集群非常方便，因为erlang天生就是一门分布式语言,但其本身并不支持负载均衡。Rabbit模式大概分为以下三种：单一模式、普通模式、镜像模式单一模式：最简单的情况，非集群模式。普通模式：默认的集群模式。对于Queue来说，消息实体只存在于其中一个节点，A、B两个节点仅有相同的元数据，即队列结构。当消息进入A节点的Queue中后，consumer从B节点拉取时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连A或B，出口总在A，会产生瓶颈。该模式存在一个问题就是当A节点故障后，B节点无法取到A节点中还未消费的消息实体。如果做了消息持久化，那么得等A节点恢复，然后才可被消费；如果没有持久化的话，就会很容易发生故障。镜像模式：把需要的队列做成镜像队列，存在于多个节点，属于RabbitMQ的HA方案。该模式解决了上述问题，其实质和普通模式不同之处在于，消息实体会主动在镜像节点间同步，而不是在consumer取数据时临时拉取。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉，所以在对可靠性要求较高的场合中适用。 1、集群中的基本概念RabbitMQ的集群节点包括内存节点、磁盘节点。顾名思义内存节点就是将所有数据放在内存，磁盘节点将数据放在磁盘。不过，如前文所述，如果在投递消息时，打开了消息的持久化，那么即使是内存节点，数据还是安全的放在磁盘。一个rabbitmq集群中可以共享 user，vhost，queue，exchange等，所有的数据和状态都是必须在所有节点上复制的，一个例外是，那些当前只属于创建它的节点的消息队列，尽管它们可见且可被所有节点读取。rabbitmq节点可以动态的加入到集群中，一个节点它可以加入到集群中，也可以从集群环集群会进行一个基本的负载均衡。集群中有两种节点：1 内存节点：只保存状态到内存（一个例外的情况是：持久的queue的持久内容将被保存到disk）2 磁盘节点：保存状态到内存和磁盘。内存节点虽然不写入磁盘，但是它执行比磁盘节点要好。集群中，只需要一个磁盘节点来保存状态 就足够了如果集群中只有内存节点，那么不能停止它们，否则所有的状态，消息等都会丢失。 2、集群模式配置1）配置hosts在2台节点服务器中，分别修改/etc/hosts文件1210.186.21.84 10-186-21-8410.186.21.85 10-186-21-85 还有hostname文件也要正确，分别是10-186-21-84、10-186-21-85，如果修改hostname建议安装rabbitmq前修改。请注意RabbitMQ集群节点必须在同一个网段里，如果是跨广域网效果就差。 2）设置每个节点CookieRabbitmq的集群是依赖于erlang的集群来工作的，所以必须先构建起erlang的集群环境。Erlang的集群中各节点是通过一个magic cookie来实现的，这个cookie存放在 /var/lib/rabbitmq/.erlang.cookie 中，文件是400的权限。所以必须保证各节点cookie保持一致，否则节点之间就无法通信。将10-186-21-84中的cookie 复制到10-186-21-85中，先修改下10-186-21-84中的.erlang.cookie权限1chmod 777 /root/.erlang.cookie 将queue的/root/.erlang.cookie这个文件，拷贝到10-186-21-85的同一位置（反过来亦可），该文件是集群节点进行通信的验证密钥，所有节点必须一致。拷完后重启下RabbitMQ。复制好后别忘记还原.erlang.cookie的权限，否则可能会遇到错误chmod 400 /root/.erlang.cookie设置好cookie后先将三个节点的rabbitmq重启12rabbitmqctl stoprabbitmq-server start 3）重启所有节点停止所有节点RabbitMq服务，然后使用detached参数独立运行，尤其增加节点停止节点后再次启动遇到无法启动都可以参照这个顺序（此步骤很重要）12rabbitmqctl stoprabbitmq-server -detached 分别查看节点集群信息第一台1234567[root@10-186-21-84 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-30-84 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-30-84']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-30-84']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-30-84"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-30-84',[]&#125;]&#125;] 第二台1234567[root@10-186-21-85 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-21-85 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-21-85']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-21-85']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-21-85"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-21-85',[]&#125;]&#125;] 4）配置集群10-186-21-84作为内存节点，10-186-21-84作为磁盘节点创建集群。在10-186-21-84上操作加入集群rabbit@10-186-21-851234567[root@10-186-21-84 ~]# rabbitmqctl stop_appStopping rabbit application on node rabbit@10-186-30-84 ...[root@10-186-21-84 ~]# rabbitmqctl join_cluster --ram rabbit@10-186-21-85Clustering node rabbit@10-186-30-84 with rabbit@10-186-21-85[root@10-186-21-84 ~]# rabbitmqctl start_appStarting node rabbit@10-186-30-84 ... completed with 3 plugins. 此时重新查看节点上集群信息在10-186-21-84上查看1234567[root@10-186-21-84 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-21-84 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-21-85']&#125;,&#123;ram,['rabbit@10-186-21-84']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-21-85','rabbit@10-186-21-84']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-21-85"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-21-85',[]&#125;,&#123;'rabbit@10-186-21-84',[]&#125;]&#125;] 在10-186-21-85上查看1234567[root@10-186-21-85 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-21-85 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-21-85']&#125;,&#123;ram,['rabbit@10-186-21-84']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-21-84','rabbit@10-186-21-85']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-21-85"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-21-84',[]&#125;,&#123;'rabbit@10-186-21-85',[]&#125;]&#125;] disc代表磁盘模式ram代表内存模式cluster_name代表集群名称查看消息队列是否一致1rabbitmqctl list_queues -p hrsystem 5）节点相关操作change_cluster_node_type {disc | ram}修改集群节点的类型. 要成功执行此操作，必须首先停止节点，要将节点转换为RAM节点，则此节点不能是集群中的唯一disc节点。ram节点转换为disc节点亦然。例如:1rabbitmqctl change_cluster_node_type disc 此命令会将一个RAM节点转换为disc节点。 forget_cluster_node [–offline][–offline]允许节点从脱机节点中删除. 这只在所有节点都脱机且最后一个掉线节点不能再上线的情况下有用，从而防止整个集群从启动。它不能使用在其它情况下，因为这会导致不一致．远程删除一个集群节点.要删除的节点必须是脱机的, 而在删除节点期间节点必须是在线的，除非使用了–offline 标志.当使用–offline 标志时，rabbitmqctl不会尝试正常连接节点;相反，它会临时改变节点以作修改.如果节点不能正常启动的话，这是非常有用的.在这种情况下，节点将变成集群元数据的规范源（例如，队列的存在），即使它不是以前的。因此，如果有可能，你应该在最新的节点上使用这个命令来关闭。例如:1rabbitmqctl -n hare@mcnulty forget_cluster_node rabbit@stringer 此命令会从节点hare@mcnulty中删除rabbit@stringer节点.1rename_cluster_node &#123;oldnode1&#125; &#123;newnode1&#125; [oldnode2] [newnode2 ...] 支持在本地数据库中重命名集群节点.此子命令会促使rabbitmqctl临时改变节点以作出修改. 因此本地集群必须是停止的，其它节点可以是在线或离线的．这个子命令接偶数个参数，成对表示节点的旧名称和新名称.你必须指定节点的旧名称和新名称，因为其它停止的节点也可能在同一时间重命名.同时停止所有节点来重命名也是可以的(在这种情况下，每个节点都必须给出旧名称和新名称)或一次停止一个节点来重命名(在这种情况下，每个节点只需要被告知其名句是如何变化的).例如:1rabbitmqctl rename_cluster_node rabbit@misshelpful rabbit@cordelia 此命令来将节点名称rabbit@misshelpful 重命名为rabbit@cordelia.12update_cluster_nodes &#123;clusternode&#125;clusternode 用于咨询具有最新消息的节点.指示已集群的节点醒来时联系clusternode.这不同于join_cluster ，因为它不会加入任何集群 - 它会检查节点已经以clusternode的形式存在于集群中了．需要这个命令的动机是当节点离线时，集群可以变化.考虑这样的情况，节点Ａ和节点Ｂ都在集群里边，这里节点Ａ掉线了，Ｃ又和Ｂ集群了，然后Ｂ又离开了集群．当Ａ醒来的时候，它会尝试联系Ｂ，但这会失败，因为Ｂ已经不在集群中了.update_cluster_nodes -n A C 可解决这种场景．1force_boot 确保节点将在下一次启动，即使它不是最后一个关闭的。通常情况下，当你关闭整个RabbitMQ 集群时，你重启的第一个节点应该是最后一个下线的节点，因为它可以看到其它节点所看不到的事情. 但有时这是不可能的:例如，如果整个集群是失去了电力而所有节点都在想它不是最后一个关闭的．在这种节点掉线情况下，你可以调用rabbitmqctl force_boot ．这就告诉节点下一次无条件的启动节点.在此节点关闭后，集群的任何变化，它都会丢失．如果最后一个掉线的节点永久丢失了，那么你需要优先使用rabbitmqctl forget_cluster_node –offline, 因为它可以确保在丢失的节点上掌握的镜像队列得到提升。例如:1rabbitmqctl force_boot 这可以强制节点下次启动时不用等待其它节点．12sync_queue [-p vhost] &#123;queue&#125;queue 同步队列的名称指示未同步slaves上的镜像队列自行同步.同步发生时，队列会阻塞(所有出入队列的发布者和消费者都会阻塞).此命令成功执行后，队列必须是镜像的。注意，未同步队列中的消息被耗尽后，最终也会变成同步. 此命令主要用于未耗尽的队列。12cancel_sync_queue [-p vhost] &#123;queue&#125;queue 取消同步的队列名称.指示同步镜像队列停止同步.12purge_queue [-p vhost] &#123;queue&#125;queue 要清除队列的名称.清除队列(删除其中的所有消息).1set_cluster_name &#123;name&#125; 设置集群名称. 集群名称在client连接时，会通报给client,也可用于federation和shovel插件记录消息的来源地. 群集名称默认是来自在群集中的第一个节点的主机名，但可以改变。例如:1rabbitmqctl set_cluster_name london 设置集群名称为”london”. 3、镜像模式配置上面配置RabbitMQ默认集群模式，但并不保证队列的高可用性，尽管交换机、绑定这些可以复制到集群里的任何一个节点，但是队列内容不会复制，虽然该模式解决一部分节点压力，但队列节点宕机直接导致该队列无法使用，只能等待重启，所以要想在队列节点宕机或故障也能正常使用，就要复制队列内容到集群里的每个节点，需要创建镜像队列。下面配置镜像模式来解决复制的问题，从而提高可用性。 1）增加负载均衡器选择HAProxy作为RabbitMQ前端的LB安装haproxy1yum install haproxy 配置负载均衡，在/etc/haproxy/haproxy.cfg中加入以下内容12345listen rabbitmq_cluster 0.0.0.0:5672 mode tcp balance roundrobin server rqslave1 10.186.21.84:5672 check inter 2000 rise 2 fall 3# server rqslave2 10.186.21.85:5672 check inter 2000 rise 2 fall 3 负载均衡器会监听5672端口，轮询内存节点10.186.21.84的5672端口,由于资源问题，此处只配置一个内存节点，应该是配置多个才有意义。10.186.21.85为磁盘节点，只做备份不提供给生产者、消费者使用，当然如果我们服务器资源充足情况也可以配置多个磁盘节点，这样磁盘节点除了故障也不会影响，除非同时出故障。 2）配置策略使用Rabbit镜像功能，需要基于rabbitmq策略来实现，政策是用来控制和修改群集范围的某个vhost队列行为和Exchange行为。在cluster中任意节点启用策略，策略会自动同步到集群节点rabbitmqctl set_policy -p hrsystem ha-allqueue”^” ‘{“ha-mode”:”all”}’这行命令在vhost名称为hrsystem创建了一个策略，策略名称为ha-allqueue,策略模式为 all 即复制到所有节点，包含新增节点，策略正则表达式为 “^” 表示所有匹配所有队列名称。Set_policy语法参看官网：1set_policy [-p vhost] [--priority priority] [--apply-to apply-to] name pattern definition 用法12Usage:rabbitmqctl [-n &lt;node&gt;] [-t &lt;timeout&gt;] [-q] set_policy [-p &lt;vhost&gt;] [--priority &lt;priority&gt;] [--apply-to &lt;apply-to&gt;] &lt;name&gt; &lt;pattern&gt; &lt;definition&gt; 通过命令行添加，例如12[root@10-186-21-84 ~]# rabbitmqctl set_policy delete_ha "^delete" '&#123;"ha-mode":"all"&#125;'Setting policy "delete_ha" for pattern "^delete" to "&#123;"ha-mode":"all"&#125;" with priority "0" for vhost "/" .. 查看web界面从上图可以看到已添加成功。也可以通过rabbit控制台添加下图为以添加的两个policy下图可以看到在exchanges中已经可以看all_ha已经被应用 3）新加入队列创建队列时需要指定ha 参数，如果不指定x-ha-prolicy 的话将无法复制。 4、单机多节点集群配置在启动RabbitMQ节点之后，服务器默认的节点名称是Rabbit和监听端口5672，如果想在同一台机器上启动多个节点，那么其他的节点就会因为节点名称和端口与默认的冲突而导致启动失败，可以通过设置环境变量来实现，具体方法如下：配置三个rabbitmq节点，分别为rabbit1, rabbit2和rabbit3主要开启命令如下：123RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit1 rabbitmq-server -detachedRABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit2 rabbitmq-server -detachedRABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=rabbit3 rabbitmq-server -detached 结束命令如下：123rabbitmqctl -n rabbit1 stoprabbitmqctl -n rabbit2 stoprabbitmqctl -n rabbit3 stop rabbit1上配置集群1234rabbitmqctl -n rabbit1 stop_apprabbitmqctl -n rabbit1 resetrabbitmqctl -n rabbit1 cluster rabbitmqctl -n rabbit1 start_app rabbit2加入rabbit1集群1234rabbitmqctl -n rabbit2 stop_apprabbitmqctl -n rabbit2 resetrabbitmqctl -n rabbit2 cluster rabbit1@`hostname -s`rabbitmqctl -n rabbit2 start_app 查看集群状态1rabbitmqctl -n rabbit1 cluster_status 将rabbit3加入集群1234rabbitmqctl -n rabbit3 stop_apprabbitmqctl -n rabbit3 resetrabbitmqctl -n rabbit3 cluster rabbit1@`hostname -s`rabbitmqctl -n rabbit3 start_app 再查看集群状态1rabbitmqctl -n rabbit1 cluster_status 由于此种集群方案对于并无太大意思，所以只简单讲述方法。同理可以配置多机多节点集群。]]></content>
      <categories>
        <category>OS</category>
        <category>Service</category>
      </categories>
      <tags>
        <tag>集群</tag>
        <tag>erlang</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat基础文档]]></title>
    <url>%2F2018%2F12%2F10%2FTomcat%E5%9F%BA%E7%A1%80%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[一、 前言1、Tomcat是什么Tomcat 是由 Apache 开发的一个 Servlet 容器，实现了对 Servlet 和 JSP 的支持，并提供了作为Web服务器的一些特有功能，如Tomcat管理和控制平台、安全域管理和Tomcat阀等。由于 Tomcat 本身也内含了一个 HTTP 服务器，它也可以被视作一个单独的 Web 服务器。但是，不能将 Tomcat 和 Apache HTTP 服务器混淆，Apache HTTP 服务器是一个用 C 语言实现的 HTTP Web 服务器；这两个 HTTP web server 不是捆绑在一起的。Tomcat 包含了一个配置管理工具，也可以通过编辑XML格式的配置文件来进行配置。 2、Tomcat重要目录1234* /bin - Tomcat 脚本存放目录（如启动、关闭脚本）。 *.sh 文件用于 Unix 系统； *.bat 文件用于 Windows 系统。* /conf - Tomcat 配置文件目录。* /logs - Tomcat 默认日志目录。* /webapps - webapp 运行的目录。 3、web工程发布目录一般web项目路径结构123456789101112|-- webapp # 站点根目录 |-- META-INF # META-INF 目录 | `-- MANIFEST.MF # 配置清单文件 |-- WEB-INF # WEB-INF 目录 | |-- classes # class文件目录 | | |-- *.class # 程序需要的 class 文件 | | `-- *.xml # 程序需要的 xml 文件 | |-- lib # 库文件夹 | | `-- *.jar # 程序需要的 jar 包 | `-- web.xml # Web应用程序的部署描述文件 |-- &lt;userdir&gt; # 自定义的目录 |-- &lt;userfiles&gt; # 自定义的资源文件 webapp：工程发布文件夹。其实每个 war 包都可以视为 webapp 的压缩包。 META-INF：META-INF 目录用于存放工程自身相关的一些信息，元文件信息，通常由开发工具，环境自动生成。 WEB-INF：Java web应用的安全目录。所谓安全就是客户端无法访问，只有服务端可以访问的目录。 /WEB-INF/classes：存放程序所需要的所有 Java class 文件。 /WEB-INF/lib：存放程序所需要的所有 jar 文件。 /WEB-INF/web.xml：web 应用的部署配置文件。它是工程中最重要的配置文件，它描述了servlet和组成应用的其它组件，以及应用初始化参数、安全管理约束等。 二、安装Tomcat需要java环境支持，无论windows server还是linux server都需要先安装JAVA环境，本次安装tomcat8.5.29版本需要最低JAVA SE 7或以上版本支持。具体的JAVA版本支持可以从tomcat官网tomcat.apache.org查看。 1、 windwos server安装Tomcat由于windows server环境安装过于简单，以及实际使用较少，在这里只简述过程。 1）安装JDK下载JDK版本为1.8.0_161，windows版本可以双击直接安装，或者添加系统环境变量JAVA_HOME，环境变量的值为JDK的路径。 2）安装Tomcat下载zip压缩版本，下载后解压，可以直接双击bin目录下的startup.bat启动，也可以注册服务，以服务方式启动。 2、linux server安装Tomcat1）安装JDK检查系统是否已经安装jdk1java -version 如果没有显示java版本信息，则表示没有安装java12345678910#安装javatar -zxvf jdk-8u161-linux-x64.tar.gzmv jdk1.8.0_161 /data/jdk1.8#修改系统变量vi /etc/profile#在文本末尾添加以下内容：PATH=/data/jdk1.8/bin:$PATHexport PATH#使添加内容生效 source /etc/profile 再查看java版本 出现如下信息表示安装成功1234# java -versionjava version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 2）安装Tomcat12345678910111213141516171819202122232425#解压tar zxvf apache-tomcat-8.5.29.tar.gz#修改目录名并移动位置mv apache-tomcat-8.5.29 /data/tomcat#修改默认启动脚本cd /usr/local/tomcat/binvim catalina.sh#首先找到CLASSPATH=，改为CLASSPATH=/data/jdk1.8/lib/tools.jar:/data/jdk1.8/lib/dt.jar#然后在文件的第二行空行插入以下内容（带#号注释的那行也要）：#chkconfig: 35 85 15CATALINA_HOME=/data/tomcatJAVA_HOME=/data/jdk1.8JRE_HOME=/data/jdk1.8#复制脚本到/etc/init.d/cp catalina.sh /etc/init.d/tomcat #给脚本加上可可执行权限chmod +x /etc/init.d/tomcat#启动tomcatservice tomcat start#查看进程# netstat -lntp|grep javatcp6 0 0 :::8009 :::* LISTEN 19310/java tcp6 0 0 :::8080 :::* LISTEN 19310/java tcp6 0 0 127.0.0.1:8005 :::* LISTEN 19310/java 访问ip:8080就能看到欢迎页 三、配置详解本节将列举一些重要、常见的配置项。 1、ServerServer 元素表示整个 Catalina servlet 容器。因此，它必须是 conf/server.xml 配置文件中的根元素。它的属性代表了整个 servlet 容器的特性。属性 描述 备注className 这个类必须实现org.apache.catalina.Server接口。 默认 org.apache.catalina.core.StandardServeraddress 服务器等待关机命令的TCP / IP地址。如果没有指定地址，则使用localhost。port 服务器等待关机命令的TCP / IP端口号。设置为-1以禁用关闭端口。shutdown 必须通过TCP / IP连接接收到指定端口号的命令字符串，以关闭Tomcat。 2、ServiceService元素表示一个或多个连接器组件的组合，这些组件共享一个用于处理传入请求的引擎组件。Server 中可以有多个 Service。属性 描述 备注className 这个类必须实现org.apache.catalina.Service接口。 默认 org.apache.catalina.core.StandardServicename 此服务的显示名称，如果您使用标准 Catalina 组件，将包含在日志消息中。与特定服务器关联的每个服务的名称必须是唯一的。conf/server.xml配置文件示例：123456&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8080" shutdown="SHUTDOWN"&gt; &lt;Service name="xxx"&gt; ... &lt;/Service&gt;&lt;/Server&gt; 3、ExecutorExecutor表示可以在Tomcat中的组件之间共享的线程池。属性 描述 备注className 这个类必须实现org.apache.catalina.Executor接口。 默认 org.apache.catalina.core.StandardThreadExecutorname 线程池名称。 要求唯一, 供Connector元素的executor属性使用namePrefix 线程名称前缀。maxThreads 最大活跃线程数。 默认200minSpareThreads 最小活跃线程数。 默认25maxIdleTime 当前活跃线程大于minSpareThreads时,空闲线程关闭的等待最大时间。 默认60000msmaxQueueSize 线程池满情况下的请求排队大小。 默认Integer.MAX_VALUE示例：123&lt;Service name="xxx"&gt; &lt;Executor name="tomcatThreadPool" namePrefix="catalina-exec-" maxThreads="300" minSpareThreads="25"/&gt;&lt;/Service&gt; 4、ConnectorConnector代表连接组件。Tomcat 支持三种协议：HTTP/1.1、HTTP/2.0、AJP。属性 说明 备注asyncTimeout Servlet3.0规范中的异步请求超时 默认30sport 请求连接的TCP Port 设置为0,则会随机选取一个未占用的端口号protocol 协议. 一般情况下设置为 HTTP/1.1,这种情况下连接模型会在NIO和APR/native中自动根据配置选择URIEncoding 对URI的编码方式. 如果设置系统变量org.apache.catalina.STRICT_SERVLET_COMPLIANCE为true,使用 ISO-8859-1编码;如果未设置此系统变量且未设置此属性, 使用UTF-8编码useBodyEncodingForURI 是否采用指定的contentType而不是URIEncoding来编码URI中的请求参数以下属性在标准的Connector(NIO, NIO2 和 APR/native)中有效:属性 说明 备注acceptCount 当最大请求连接maxConnections满时的最大排队大小 默认100,注意此属性和Executor中属性maxQueueSize的区别.这个指的是请求连接满时的堆栈大小,Executor的maxQueueSize指的是处理线程满时的堆栈大小connectionTimeout 请求连接超时 默认60000msexecutor 指定配置的线程池名称keepAliveTimeout keeAlive超时时间 默认值为connectionTimeout配置值.-1表示不超时maxConnections 最大连接数 连接满时后续连接放入最大为acceptCount的队列中. 对 NIO和NIO2连接,默认值为10000;对 APR/native,默认值为8192maxThreads 如果指定了Executor, 此属性忽略;否则为Connector创建的内部线程池最大值 默认200minSpareThreads 如果指定了Executor, 此属性忽略;否则为Connector创建线程池的最小活跃线程数 默认10processorCache 协议处理器缓存Processor对象的大小 -1表示不限制.当不使用servlet3.0的异步处理情况下: 如果配置Executor,配置为Executor的maxThreads;否则配置为Connnector的maxThreads. 如果使用Serlvet3.0异步处理, 取maxThreads和maxConnections的最大值 5、ContextContext元素表示一个Web应用程序，它在特定的虚拟主机中运行。每个Web应用程序都基于Web应用程序存档（WAR）文件，或者包含相应的解包内容的相应目录，如Servlet规范中所述。属性 说明 备注altDDName web.xml部署描述符路径 默认 /WEB-INF/web.xmldocBase Context的Root路径 和Host的appBase相结合, 可确定web应用的实际目录failCtxIfServletStartFails 同Host中的failCtxIfServletStartFails, 只对当前Context有效 默认为falselogEffectiveWebXml 是否日志打印web.xml内容(web.xml由默认的web.xml和应用中的web.xml组成) 默认为falsepath web应用的context path 如果为根路径,则配置为空字符串(“”), 不能不配置privileged 是否使用Tomcat提供的manager servletreloadable /WEB-INF/classes/ 和/WEB-INF/lib/ 目录中class文件发生变化是否自动重新加载 默认为falseswallowOutput true情况下, System.out和System.err输出将被定向到web应用日志中 默认为false 6、EngineEngine元素表示与特定的Catalina服务相关联的整个请求处理机器。它接收并处理来自一个或多个连接器的所有请求，并将完成的响应返回给连接器，以便最终传输回客户端。属性 描述 备注defaultHost 默认主机名，用于标识将处理指向此服务器上主机名称但未在此配置文件中配置的请求的主机。 这个名字必须匹配其中一个嵌套的主机元素的名字属性。name 此引擎的逻辑名称，用于日志和错误消息。 在同一服务器中使用多个服务元素时，每个引擎必须分配一个唯一的名称。 7、HostHost元素表示一个虚拟主机，它是一个服务器的网络名称（如“www.mycompany.com”）与运行Tomcat的特定服务器的关联。属性 说明 备注name 名称 用于日志输出appBase 虚拟主机对应的应用基础路径 可以是个绝对路径, 或${CATALINA_BASE}相对路径xmlBase 虚拟主机XML基础路径,里面应该有Context xml配置文件 可以是个绝对路径, 或${CATALINA_BASE}相对路径createDirs 当appBase和xmlBase不存在时,是否创建目录 默认为trueautoDeploy 是否周期性的检查appBase和xmlBase并deploy web应用和context描述符 默认为truedeployIgnore 忽略deploy的正则deployOnStartup Tomcat启动时是否自动deploy 默认为truefailCtxIfServletStartFails 配置为true情况下,任何load-on-startup &gt;=0的servlet启动失败,则其对应的Contxt也启动失败 默认为false 8、ClusterTomcat集群配置。集群的配置比较复杂，默认的集群配置可以满足一般的开发需求。一个Cluster配置案例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120&lt;!-- Cluster(集群,族) 节点,如果你要配置tomcat集群,则需要使用此节点. className 表示tomcat集群时,之间相互传递信息使用那个类来实现信息之间的传递. channelSendOptions可以设置为2、4、8、10，每个数字代表一种方式 2 = Channel.SEND_OPTIONS_USE_ACK(确认发送) 4 = Channel.SEND_OPTIONS_SYNCHRONIZED_ACK(同步发送) 8 = Channel.SEND_OPTIONS_ASYNCHRONOUS(异步发送) 在异步模式下，可以通过加上确认发送(Acknowledge)来提高可靠性，此时channelSendOptions设为10--&gt;&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;!-- Manager决定如何管理集群的Session信息。Tomcat提供了两种Manager：BackupManager和DeltaManager BackupManager－集群下的所有Session，将放到一个备份节点。集群下的所有节点都可以访问此备份节点 DeltaManager－集群下某一节点生成、改动的Session，将复制到其他节点。 DeltaManager是Tomcat默认的集群Manager，能满足一般的开发需求 使用DeltaManager，每个节点部署的应用要一样；使用BackupManager，每个节点部署的应用可以不一样. className－指定实现org.apache.catalina.ha.ClusterManager接口的类,信息之间的管理. expireSessionsOnShutdown－设置为true时，一个节点关闭，将导致集群下的所有Session失效 notifyListenersOnReplication－集群下节点间的Session复制、删除操作，是否通知session listeners maxInactiveInterval－集群下Session的有效时间(单位:s)。 maxInactiveInterval内未活动的Session，将被Tomcat回收。默认值为1800(30min) --&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;!-- Channel是Tomcat节点之间进行通讯的工具。 Channel包括5个组件：Membership、Receiver、Sender、Transport、Interceptor --&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;!-- Membership维护集群的可用节点列表。它可以检查到新增的节点，也可以检查到没有心跳的节点 className－指定Membership使用的类 address－组播地址 port－组播端口 frequency－发送心跳(向组播地址发送UDP数据包)的时间间隔(单位:ms)。默认值为500 dropTime－Membership在dropTime(单位:ms)内未收到某一节点的心跳，则将该节点从可用节点列表删除。默认值为3000 注: 组播（Multicast）：一个发送者和多个接收者之间实现一对多的网络连接。 一个发送者同时给多个接收者传输相同的数据，只需复制一份相同的数据包。 它提高了数据传送效率，减少了骨干网络出现拥塞的可能性 相同组播地址、端口的Tomcat节点，可以组成集群下的子集群 --&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;!-- Receiver : 接收器，负责接收消息 接收器分为两种：BioReceiver(阻塞式)、NioReceiver(非阻塞式) className－指定Receiver使用的类 address－接收消息的地址 port－接收消息的端口 autoBind－端口的变化区间 如果port为4000，autoBind为100，接收器将在4000-4099间取一个端口，进行监听 selectorTimeout－NioReceiver内轮询的超时时间 maxThreads－线程池的最大线程数 --&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;!-- Sender : 发送器，负责发送消息 Sender内嵌了Transport组件，Transport真正负责发送消息 --&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;!-- Transport分为两种：bio.PooledMultiSender(阻塞式)、nio.PooledParallelSender(非阻塞式) --&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;!-- Interceptor : Cluster的拦截器 TcpFailureDetector－网络、系统比较繁忙时，Membership可能无法及时更新可用节点列表， 此时TcpFailureDetector可以拦截到某个节点关闭的信息， 并尝试通过TCP连接到此节点，以确保此节点真正关闭，从而更新集群可以用节点列表 --&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;!-- MessageDispatch15Interceptor－查看Cluster组件发送消息的方式是否设置为 Channel.SEND_OPTIONS_ASYNCHRONOUS(Cluster标签下的channelSendOptions为8时)。 设置为Channel.SEND_OPTIONS_ASYNCHRONOUS时， MessageDispatch15Interceptor先将等待发送的消息进行排队，然后将排好队的消息转给Sender --&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;!-- Valve : 可以理解为Tomcat的拦截器 ReplicationValve－在处理请求前后打日志；过滤不涉及Session变化的请求 vmRouteBinderValve－Apache的mod_jk发生错误时，保证同一客户端的请求发送到集群的同一个节点 --&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;!-- Deployer : 同步集群下所有节点的一致性。 --&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;!-- ClusterListener : 监听器，监听Cluster组件接收的消息 使用DeltaManager时，Cluster接收的信息通过ClusterSessionListener传递给DeltaManager --&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt;&lt;/Cluster&gt; 四、配置实例1、Tomcat配置使用manager管理项目Tomcat在部署新项目时，可以通过/manager/html来上传war包，来完成部署。部署完成的访问路径为：ip:8080/warname。首先配置tomcat可以访问manager和host-manager在conf/tomcat-users.xml中标签中添加以下配置信息：123456789&lt;role rolename="admin"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="admin-script"/&gt;&lt;role rolename="manager"/&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;role rolename="manager-jmx"/&gt; &lt;role rolename="manager-status"/&gt; &lt;user username="tomcat" password="tomcat" roles="admin,admin-gui,admin-script,manager,manager-gui,manager-script,manager-jmx,manager-status"/&gt; 相关配置注释：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157manager-gui #允许访问html接口(即URL路径为/manager/html/*)manager-script #允许访问纯文本接口(即URL路径为/manager/text/*)manager-jmx #允许访问JMX代理接口(即URL路径为/manager/jmxproxy/*)manager-status #允许访问Tomcat只读状态页面(即URL路径为/manager/status/*)特别需要说明的是：manager-gui、manager-script、manager-jmx均具备manager-status的权限，也就是说，manager-gui、manager-script、manager-jmx三种角色权限无需再额外添加manager-status权限，即可直接访问路径”/manager/status/*”。Tomcat8中还需要增加一段配置才能满足要求，在conf/Catalina/localhost中新建文件名manager.xml，内容为：&lt;Context privileged="true" antiResourceLocking="false" docBase="$&#123;catalina.home&#125;/webapps/manager"&gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="^.*$" /&gt; &lt;/Context&gt;在conf/Catalina/localhost中新建文件名host-manager.xml，内容为：&lt;Context privileged="true" antiResourceLocking="false" docBase="$&#123;catalina.home&#125;/webapps/host-manager"&gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="^.*$" /&gt; &lt;/Context&gt;``` 配置完成后，重启tomcat，即可以访问manager。### 2、Nginx+Tomcat配置+多Tomcat负载均衡关于Nginx的配置请查看文档《Nginx应用文档》，Nginx的配置文件如下：```bashuser nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream lvs &#123; #配置两台tomcat负载均衡，ip：port地址为tomcat地址。weight为权重，权重越大，访问概率越大， server 127.0.0.1:8081 weight=10; server 127.0.0.1:8082 weight=10; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; # access_log logs/host.access.log main; location ~ .*\.(gif|jpg|jpeg|bmp|png|ico|txt|js|css)$ &#123; root /data/nainx/html/; #expires定义用户浏览器缓存的时间为7天，如果静态页面不常更新，可以设置更长，这样可以节省带宽和缓解服务器的压力 expires 7d; &#125; location ~ (\.jsp)|(\.do)$ &#123; #root html; #index index.jsp index.htm; #lvs是 upstream 后面的名字 lvs proxy_pass http://lvs; #localhost是nginx服务器的主机地址，如果不写此句，会导致静态文件访问路径为http://lvs，导致找不到地址 proxy_set_header Host localhost; #forwarded信息，用于告诉后端服务器终端用户的ip地址，否则后端服务器只能获取前端代理服务器的ip地址。 proxy_set_header Forwarded $remote_addr; &#125; # / 表示匹配所有地址，默认最大前缀匹配，如果其他没有匹配的才会匹配 location /&#123; root /data/lvs; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html #错误页面地址，500 502 503 504错误的地址 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 路径转发配置（可以不用配置）：1234567891011121314151617181920server &#123; listen 80; server_name *.*.*.*;#本服务器ip地址 #charset koi8-r; #access_log logs/host.access.log main; location /&#123; #root html; #index index.html index.htm; proxy_pass http://10.8.0.66:8090/; #当地址最后加上 /时，匹配路径的 yanshi 不会加到转发路径中 proxy_set_header X-Forwarded-For $remote_addr; #当下面这句话不加，Host $host; 会导致post请求参数丢失 proxy_set_header Host $host; proxy_set_header X-Real-Ip $remote_addr; &#125;&#125; 以下是关于tomcat的配置：同一服务器部署多个tomcat时，存在端口号冲突的问题，所以需要修改tomcat配置文件server.xml：首先了解下tomcat的几个主要端口：12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="60000" redirectPort="8443" disableUploadTimeout="false" executor="tomcatThreadPool" URIEncoding="UTF-8"/&gt;其中8080为HTTP端口，8443为HTTPS端口&lt;Server port="8005" shutdown="SHUTDOWN"&gt; 8005为远程停服务端口&lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt;``` 8009为AJP端口，APACHE能过AJP协议访问TOMCAT的8009端口。部署多个tomcat主要修改三个端口：第一个tomcat配置server.xml如下：```bash&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8006" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8081" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8010" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="/data/lvs " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8006、8081、8010第二个tomcat配置server.xml如下：123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8007" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8082" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8011" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="/data/lvs " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8007、8082、8011如果需要更多的tomcat做负载，端口号依次增加即可。nginx与tomcat的结合，主要用的是nginx中的upstream,后端可包括有多台tomcat来处ginx的upstream目前支持5种方式的分配 1）轮询（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 2）weight指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如：1234 upstream bakend &#123; server 192.168.0.14 weight=10; server 192.168.0.15 weight=10;&#125; 3）ip_hash每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session 的问题。例如：12345upstreambakend &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80; &#125; 4）fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。12345upstream backend &#123; server server1; server server2; fair;&#125; 5）url_hash（第三方）按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法123456upstream backend &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_methodcrc32;&#125; 示例：1234567upstream bakend&#123;#定义负载均衡设备的Ip及设备状态 ip_hash; server127.0.0.1:9090 down; server127.0.0.1:8080 weight=2; server127.0.0.1:6060; server127.0.0.1:7070 backup;&#125; 在需要使用负载均衡的server中增加1proxy_pass http://bakend/; 每个设备的状态设置为:1.down 表示单前的server暂时不参与负载2.weight 默认为1.weight越大，负载的权重就越大。3.max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误4.fail_timeout:max_fails次失败后，暂停的时间。5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 nginx支持同时设置多组的负载均衡，用来给不用的server来使用。client_body_in_file_only 设置为On 可以讲clientpost过来的数据记录到文件中用来做debugclient_body_temp_path 设置记录文件的目录 可以设置最多3层目录location 对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡 3、Apache+Tomcat集群配置1）集群简述集群是一组协同工作的服务实体，用以提供比单一服务实体更具扩展性与可用性的服务平台。在客户端看来，一个集群就象是一个服务实体，但 事实上集群由一组服务实体组成。与单一服务实体相比较，集群提供了以下两个关键特性：·可扩展性－－集群的性能不限于单一的服务实体，新的服 务实体可以动态地加入到集群，从而增强集群的性能。·高可用性－－集群通过服务实体冗余使客户端免于轻易遇到out of service的警告。在集群中，同样的服务可以由多个服务实体提供。如果一个服务实体失败了，另一个服务实体会接管失败的服务实体。集群提供的从一个出 错的服务实体恢复到另一个服务实体的功能增强了应用的可用性。为了具有可扩展性和高可用性特点，集群的必须具备以下两大能力： 负载均衡－－负载均衡能把任务比较均衡地分布到集群环境下的计算和网络资源。 错误恢复－－由于某种原因，执行某个任务的资源出现故障，另一服 务实体中执行同一任务的资源接着完成任务。这种由于一个实体中的资源不能工作，另一个实体中的资源透明的继续完成任务的过程叫错误恢复。负载均衡 和错误恢复都要求各服务实体中有执行同一任务的资源存在，而且对于同一任务的各个资源来说，执行任务所需的信息视图（信息上下文）必须是一样的。 集群主要分成三大类：高可用集群(High Availability Cluster/HA)， 负载均衡集群(Load Balance Cluster)，高性能计算集群(High Performance Computing Cluster/HPC) 高可用集群(High Availability Cluster/HA)：一般是指当集群中有某个节点失效的情况下，其上的任务会自动转移到其他正常的节点上。还指可以将集群中的某节点进行离线维护再上线，该过程并不影响整个集群的运行。常见的就是2个节点做 成的HA集群，有很多通俗的不科学的名称，比如”双机热备”, “双机互备”, “双机”，高可用集群解决的是保障用户的应用程序持续对外提供服 务的能力。 负载均衡集群(Load Balance Cluster)：负载均衡集群运行时一般通过一个或者多个前端负载均衡器将工作负载分发到后端的一组服务器上，从而达到将工作负载分发。这样的计算机集群有时也被称为服务器群（Server Farm）。一般web服务器集群、数据库集群 和应用服务器集群都属于这种类型。这种集群可以在接到请求时，检查接受请求较少，不繁忙的服务器，并把请求转到这些服务器 上。从检查其他服务器状态这一点上 看，负载均衡和容错集群很接近，不同之处是数量上更多。 高性能计算集群(High Performance Computing Cluster/HPC)：高性能计算集群采用将计算任务分配到集群的不同计算节点而提高计算能力，因而主要应用在科学计算领域。这类集群致力于提供单个计算机所不能提供的强大的计算能力 Tomcat集群配置的优缺点：通常配置tomcat集群有三种方式：使用DNS轮询，使用apache r-proxy代理方式，使用apache mod_jk方式。（1）DNS轮询的缺点：当集群中某台服务器停止之后，用户由于dns缓存的缘故，便无法访问服务，必 须等到dns解析更新，或者这台服务器重新启动。还有就是必须把集群中的所有服务端口暴露给外界，没有用apache做前置代理的方式安全，并 且占用大量公网IP地址，而且tomcat还要负责处理静态网页资源，影响效率。优点是集群配置最简单，dns设置也非常简单。（2）R- proxy的缺点：当其中一台tomcat停止运行的时候，apache仍然会转发请求过去，导致502网关错误。但是只要服务器再启动就不存 在这个问题。（3）mod_jk方式的优点是，Apache 会自动检测到停止掉的tomcat，然后不再发请求过去。缺点就是，当停 止掉的tomcat服务器再次启动的时候，Apache检测不到，仍然不会转发请求过去。R-proxy和mod_jk的共同优点是.可 以只将Apache置于公网，节省公网IP地址资源。可以通过设置来实现Apache专门负责处理静态网页，让Tomcat专门负责处理jsp和 servlet等动态请求。共同缺点是：如果前置Apache代理服务器停止运行，所有集群服务将无法对外提供。R-proxy和 mod_jk对静态页面请求的处理，都可以通设置来选取一个尽可能优化的效果。这三种方式对实现最佳负载均衡都有一定不足，mod_jk相对好些，可以通过设置lbfactor参数来分配请求任务。2）Apache安装12345678910111213141516171819202122232425#下载安装包wget http://mirrors.hust.edu.cn/apache//httpd/httpd-2.4.33.tar.gzwget http://archive.apache.org/dist/apr/apr-1.4.5.tar.gzwget http://archive.apache.org/dist/apr/apr-util-1.3.12.tar.gzwget http://jaist.dl.sourceforge.net/project/pcre/pcre/8.10/pcre-8.42.zip#apr安装tar -zxf apr-1.4.5.tar.gz cd apr-1.4.5 ./configure --prefix=/usr/local/apr make &amp;&amp; make install #apr-util安装tar -zxf apr-util-1.3.12.tar.gz cd apr-util-1.3.12 ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr/bin/apr-1-config make &amp;&amp; make install#pcre安装unzip -o pcre-8.42.zip cd pcre-8.42./configure --prefix=/usr/local/pcre make &amp;&amp; make install #apache安装tar -zxvf httpd-2.4.33.tar.gzcd httpd-2.4.33./configure --prefix=/data/apache --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util --with-pcre=/usr/local/pcremake &amp;&amp; make install 在apache安装过程中会有报错：差找不到文件apr_escape.h由于centos7默认是使用的是xfs的硬盘格式，在安装apr的时候由于automake编译根据硬盘格式会默认系统不需要这个文件，如果是其他硬盘格式，比如：ext3、ext4，则不会出现这个问题。解决方法：从apache官网上查找该文件源码，并放入apr的include/apr-1内，本次环境apr的目录为：/usr/local/apr/include/apr-1以下为apr_escape.h文件的源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374/* Licensed to the Apache Software Foundation (ASF) under one or more* contributor license agreements. See the NOTICE file distributed with* this work for additional information regarding copyright ownership.* The ASF licenses this file to You under the Apache License, Version 2.0* (the "License"); you may not use this file except in compliance with* the License. You may obtain a copy of the License at** http://www.apache.org/licenses/LICENSE-2.0** Unless required by applicable law or agreed to in writing, software* distributed under the License is distributed on an "AS IS" BASIS,* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.* See the License for the specific language governing permissions and* limitations under the License.*//*** @file apr_escape.h* @brief APR-UTIL Escaping*/#ifndef APR_ESCAPE_H#define APR_ESCAPE_H#include "apr.h"#include "apr_general.h"#ifdef __cplusplusextern "C" &#123;#endif/*** @defgroup APR_Util_Escaping Escape functions* @ingroup APR* @&#123;*//* Simple escape/unescape functions.**//*** When passing a string to one of the escape functions, this value can be* passed to indicate a string-valued key, and have the length computed* automatically.*/#define APR_ESCAPE_STRING (-1)/*** Perform shell escaping on the provided string.** Shell escaping causes characters to be prefixed with a '\' character.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_shell(char *escaped, const char *str,apr_ssize_t slen, apr_size_t *len);/*** Perform shell escaping on the provided string, returning the result* from the pool.** Shell escaping causes characters to be prefixed with a '\' character.** If no characters were escaped, the original string is returned.* @param p Pool to allocate from* @param str The original string* @return the encoded string, allocated from the pool, or the original* string if no escaping took place or the string was NULL.*/APR_DECLARE(const char *) apr_pescape_shell(apr_pool_t *p, const char *str)__attribute__((nonnull(1)));/*** Unescapes a URL, leaving reserved characters intact.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param url String to be unescaped* @param slen The length of the original url, or APR_ESCAPE_STRING* @param forbid Optional list of forbidden characters, in addition to* 0x00* @param reserved Optional list of reserved characters that will be* left unescaped* @param plus If non zero, '+' is converted to ' ' as per* application/x-www-form-urlencoded encoding* @param len If set, the length of the escaped string will be returned* @return APR_SUCCESS on success, APR_NOTFOUND if no characters are* decoded or the string is NULL, APR_EINVAL if a bad escape sequence is* found, APR_BADCH if a character on the forbid list is found.*/APR_DECLARE(apr_status_t) apr_unescape_url(char *escaped, const char *url,apr_ssize_t slen, const char *forbid, const char *reserved, int plus,apr_size_t *len);/*** Unescapes a URL, leaving reserved characters intact, returning the* result from a pool.* @param p Pool to allocate from* @param url String to be unescaped in place* @param forbid Optional list of forbidden characters, in addition to* 0x00* @param reserved Optional list of reserved characters that will be* left unescaped* @param plus If non zero, '+' is converted to ' ' as per* application/x-www-form-urlencoded encoding* @return A string allocated from the pool on success, the original string* if no characters are decoded, or NULL if a bad escape sequence is found* or if a character on the forbid list is found, or if the original string* was NULL.*/APR_DECLARE(const char *) apr_punescape_url(apr_pool_t *p, const char *url,const char *forbid, const char *reserved, int plus)__attribute__((nonnull(1)));/*** Escape a path segment, as defined in RFC1808.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_path_segment(char *escaped,const char *str, apr_ssize_t slen, apr_size_t *len);/*** Escape a path segment, as defined in RFC1808, returning the result from a* pool.* @param p Pool to allocate from* @param str String to be escaped* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_pescape_path_segment(apr_pool_t *p,const char *str) __attribute__((nonnull(1)));/*** Converts an OS path to a URL, in an OS dependent way, as defined in RFC1808.* In all cases if a ':' occurs before the first '/' in the URL, the URL should* be prefixed with "./" (or the ':' escaped). In the case of Unix, this means* leaving '/' alone, but otherwise doing what escape_path_segment() does. For* efficiency reasons, we don't use escape_path_segment(), which is provided for* reference. Again, RFC 1808 is where this stuff is defined.** If partial is set, os_escape_path() assumes that the path will be appended to* something with a '/' in it (and thus does not prefix "./").* @param escaped Optional buffer to write the encoded string, can be* NULL* @param path The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param partial If non zero, suppresses the prepending of "./"* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or if the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_path(char *escaped, const char *path,apr_ssize_t slen, int partial, apr_size_t *len);/*** Converts an OS path to a URL, in an OS dependent way, as defined in RFC1808,* returning the result from a pool.** In all cases if a ':' occurs before the first '/' in the URL, the URL should* be prefixed with "./" (or the ':' escaped). In the case of Unix, this means* leaving '/' alone, but otherwise doing what escape_path_segment() does. For* efficiency reasons, we don't use escape_path_segment(), which is provided for* reference. Again, RFC 1808 is where this stuff is defined.** If partial is set, os_escape_path() assumes that the path will be appended to* something with a '/' in it (and thus does not prefix "./").* @param p Pool to allocate from* @param str The original string* @param partial If non zero, suppresses the prepending of "./"* @return A string allocated from the pool on success, the original string* if no characters are encoded or if the string was NULL.*/APR_DECLARE(const char *) apr_pescape_path(apr_pool_t *p, const char *str,int partial) __attribute__((nonnull(1)));/*** Urlencode a string, as defined in* http://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.1.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or if the stirng was NULL*/APR_DECLARE(apr_status_t) apr_escape_urlencoded(char *escaped, const char *str,apr_ssize_t slen, apr_size_t *len);/*** Urlencode a string, as defined in* http://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.1, returning* the result from a pool.* @param p Pool to allocate from* @param str String to be escaped* @return A string allocated from the pool on success, the original string* if no characters are encoded or if the string was NULL.*/APR_DECLARE(const char *) apr_pescape_urlencoded(apr_pool_t *p,const char *str) __attribute__((nonnull(1)));/*** Apply entity encoding to a string. Characters are replaced as follows:* '&lt;' becomes '&amp;lt;', '&gt;' becomes '&amp;gt;', '&amp;' becomes '&amp;amp;', the* double quote becomes '&amp;quot;" and the single quote becomes '&amp;apos;'.** If toasc is not zero, any non ascii character will be encoded as* '%\#ddd;', where ddd is the decimal code of the character.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param toasc If non zero, encode non ascii characters* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_entity(char *escaped, const char *str,apr_ssize_t slen, int toasc, apr_size_t *len);/*** Apply entity encoding to a string, returning the result from a pool.* Characters are replaced as follows: '&lt;' becomes '&amp;lt;', '&gt;' becomes* '&amp;gt;', '&amp;' becomes '&amp;amp;', the double quote becomes '&amp;quot;" and the* single quote becomes '&amp;apos;'.* @param p Pool to allocate from* @param str The original string* @param toasc If non zero, encode non ascii characters* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_pescape_entity(apr_pool_t *p, const char *str,int toasc) __attribute__((nonnull(1)));/*** Decodes html entities or numeric character references in a string. If* the string to be unescaped is syntactically incorrect, then the* following fixups will be made:* unknown entities will be left undecoded;* references to unused numeric characters will be deleted.* In particular, &amp;#00; will not be decoded, but will be deleted.* @param unescaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_unescape_entity(char *unescaped, const char *str,apr_ssize_t slen, apr_size_t *len);/*** Decodes html entities or numeric character references in a string. If* the string to be unescaped is syntactically incorrect, then the* following fixups will be made:* unknown entities will be left undecoded;* references to unused numeric characters will be deleted.* In particular, &amp;#00; will not be decoded, but will be deleted.* @param p Pool to allocate from* @param str The original string* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_punescape_entity(apr_pool_t *p, const char *str)__attribute__((nonnull(1)));/*** Escape control characters in a string, as performed by the shell's* 'echo' command. Characters are replaced as follows:* \\a alert (bell), \\b backspace, \\f form feed, \\n new line, \\r carriage* return, \\t horizontal tab, \\v vertical tab, \\ backslash.** Any non ascii character will be encoded as '\\xHH', where HH is the hex* code of the character.** If quote is not zero, the double quote character will also be escaped.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param quote If non zero, encode double quotes* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_echo(char *escaped, const char *str,apr_ssize_t slen, int quote, apr_size_t *len);/*** Escape control characters in a string, as performed by the shell's* 'echo' command, and return the results from a pool. Characters are* replaced as follows: \\a alert (bell), \\b backspace, \\f form feed,* \\n new line, \\r carriage return, \\t horizontal tab, \\v vertical tab,* \\ backslash.** Any non ascii character will be encoded as '\\xHH', where HH is the hex* code of the character.** If quote is not zero, the double quote character will also be escaped.* @param p Pool to allocate from* @param str The original string* @param quote If non zero, encode double quotes* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_pescape_echo(apr_pool_t *p, const char *str,int quote);/*** Convert binary data to a hex encoding.* @param dest The destination buffer, can be NULL* @param src The original buffer* @param srclen The length of the original buffer* @param colon If not zero, insert colon characters between hex digits.* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_hex(char *dest, const void *src,apr_size_t srclen, int colon, apr_size_t *len);/*** Convert binary data to a hex encoding, and return the results from a* pool.* @param p Pool to allocate from* @param src The original buffer* @param slen The length of the original buffer* @param colon If not zero, insert colon characters between hex digits.* @return A zero padded buffer allocated from the pool on success, or* NULL if src was NULL.*/APR_DECLARE(const char *) apr_pescape_hex(apr_pool_t *p, const void *src,apr_size_t slen, int colon) __attribute__((nonnull(1)));/*** Convert hex encoded string to binary data.* @param dest The destination buffer, can be NULL* @param str The original buffer* @param slen The length of the original buffer* @param colon If not zero, ignore colon characters between hex digits.* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if the string was NULL, or APR_BADCH* if a non hex character is present.*/APR_DECLARE(apr_status_t) apr_unescape_hex(void *dest, const char *str,apr_ssize_t slen, int colon, apr_size_t *len);/*** Convert hex encoding to binary data, and return the results from a pool.* If the colon character appears between pairs of hex digits, it will be* ignored.* @param p Pool to allocate from* @param str The original string* @param colon If not zero, ignore colon characters between hex digits.* @param len If present, returns the length of the final buffer* @return A buffer allocated from the pool on success, or NULL if src was* NULL, or a bad character was present.*/APR_DECLARE(const void *) apr_punescape_hex(apr_pool_t *p, const char *str,int colon, apr_size_t *len);/** @&#125; */#ifdef __cplusplus&#125;#endif#endif /* !APR_ESCAPE_H */ 由于Apache和Nginx同台安装，所以修改Apache的端口为88，配置ServerName启动apache1./bin/apachectl start 访问apache服务器：http://ip:88响应结果：It works！ #apache服务器安装成功 3）Tomcat安装配置同一服务器部署多个tomcat时，存在端口号冲突的问题，所以需要修改tomcat配置文件server.xml：首先了解下tomcat的几个主要端口：123456&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="60000" redirectPort="8443" disableUploadTimeout="false" executor="tomcatThreadPool" URIEncoding="UTF-8"/&gt;#其中8080为HTTP端口，8443为HTTPS端口&lt;Server port="8005" shutdown="SHUTDOWN"&gt; #8005为远程停服务端口&lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; #8009为AJP端口，APACHE能过AJP协议访问TOMCAT的8009端口。 部署多个tomcat主要修改三个端口：第一个tomcat配置server.xml如下：123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8006" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8081" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8010" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat1"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8006、8081、8010第二个tomcat配置server.xml如下：123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8007" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8082" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8011" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat2"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8007、8082、8011如果需要更多的tomcat做负载，端口号依次增加即可。tomcat1测试http://ip:8081tomcat2 测试http://ip:8082结果：显示tomcat首页 4）集群配置创建mod_jk.so文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142#下载wget http://archive.apache.org/dist/tomcat/tomcat-connectors/jk/tomcat-connectors-1.2.41-src.tar.gztar -zxvf tomcat-connectors-1.2.41-src.tar.gz cd tomcat-connectors-1.2.41-srccd native/#进行编译，生成文件，但是不需要make install./configure --with-apxs=/data/apache/bin/apxsmakecd apache-2.0/#拷贝到apache目录下cp mod_jk.so /data/apache/modules//data/apache/modules/在httpd.conf中加入配置Include conf/mod_jk.conf/data/apache/conf下创建mod_jk.conf文件，文件内容为#mod_jk 配置mod_jk包 LoadModule jk_module modules/mod_jk.so #workers 配置工作负责文件 JkWorkersFile conf/workers.properties #jk log 配置jk日志文件 JkLogFile logs/mod_jk.log #jk log leve 配置日志级别 JkLogLevel info #配置jk日志内存共享 JkShmFile logs/mod_jk.shm #balancer 配置负载均衡模式 JkMount /*.jsp balancer 在/data/apache/conf下创建workers.properties文件，文件内容为#tomcat1的配置 worker.tomcat1.port=8010worker.tomcat1.host=127.0.0.1worker.tomcat1.reference=worker.template worker.tomcat1.activation=A #worker.tomcat1.lbfactor=1 #tomcat2 的配置 worker.tomcat2.port=8011 worker.tomcat2.host=127.0.0.1worker.tomcat2.reference=worker.template worker.tomcat2.activation=A #worker.tomcat2.lbfactor=1 worker.list=balancer #balancer 负载配置 worker.balancer.type=lb worker.balancer.balance_workers=tomcat1,tomcat2 worker.balancer.sticky_session=1 #tempalte 负载模板配置 worker.template.type=ajp13``` 重启apache、tomcat1、tomcat2验证，可以访问apache地址http://ip:88/testjsp.jsp，可以看到不同的客户端或刷新后显示的可以是tomcat1，也可以是tomcat2，验证成功。#### 5）Session复制在Tomcat集群中实现session同步，可以通过session共享和复制来实现，下面以session复制来实现session同步。Session复制需要修改server.xml配置Tomcat1中在&lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat1"&gt;后面加上以下配置```bash&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" #默认为auto，改为自己的IP port="4001" #同一台服务器上的tomcat必须修改为不同的端口，tomcat1修改为4001，tomcat2修改为4002。 autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt;``` Tomcat2中在&lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat1"&gt;后面加上以下配置```bash &lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" #默认为auto，改为自己的IP port="4002" #同一台服务器上的tomcat必须修改为不同的端口，tomcat1修改为4001，tomcat2修改为4002。 autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt; ``` 在集群中所有tomcat的应用项目中web.xml中的配置 ：在WEB-INF/web.xml中加入以下内容```bash&lt;!--此应用将与群集服务器复制Session--&gt; &lt;distributable/&gt;]]></content>
      <categories>
        <category>OS</category>
        <category>Service</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx+lua组建基础waf防火墙]]></title>
    <url>%2F2018%2F12%2F10%2Fnginx-lua%E7%BB%84%E5%BB%BA%E5%9F%BA%E7%A1%80waf%E9%98%B2%E7%81%AB%E5%A2%99%2F</url>
    <content type="text"><![CDATA[一、nginx+Lua环境部署1、系统基础信息123456# ifconfig eth0|grep 'inet addr'|awk -F ":" '&#123;print $2&#125;'|awk '&#123;print $1&#125;'192.168.83.129# cat /etc/redhat-releaseCentOS release 6.5 (Final)# uname -r2.6.32-431.el6.x86_64 2、安装基础库12yum -y install gcc gcc-c++yum -y install openssl openssl-devel 3、创建Nginx运行的普通用户1useradd -s /sbin/nologin -M www 4、下载需要的程序并安装123456789cd /usr/local/src/wget http://nginx.org/download/nginx-1.9.4.tar.gzwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.38.tar.gzwget -c http://luajit.org/download/LuaJIT-2.0.4.tar.gzwget https://github.com/simpl/ngx_devel_kit/archive/v0.2.19.tar.gzwget https://github.com/openresty/lua-nginx-module/archive/v0.9.16.tar.gztar zxvf ngx_devel_kit-0.2.19.tar.gztar zxvf lua-nginx-module-0.9.16.tar.gztar zxvf pcre-8.38.tar.gz 5、安装LuaJIT Luajit是Lua即时编译器123tar zxvf LuaJIT-2.0.4.tar.gzcd /usr/local/src/LuaJIT-2.0.4make &amp;&amp; make install 6、安装nginx并加载模块123456cd nginx-1.9.4/export LUAJIT_LIB=/usr/local/libexport LUAJIT_INC=/usr/local/include/luajit-2.0/./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-http_stub_status_module --with-file-aio --with-http_dav_module --add-module=../ngx_devel_kit-0.2.19/ --add-module=../lua-nginx-module-0.9.16/ --with-pcre=/usr/local/src/pcre-8.38/make -j2 &amp;&amp; make installln -s /usr/local/lib/libluajit-5.1.so.2 /lib64/libluajit-5.1.so.2 安装完毕后，下面可以测试安装了，修改nginx.conf 增加第一个配置123456789101112131415161718 server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location /hello &#123; default_type 'text/plain'; content_by_lua 'ngx.say("hello,lua")'; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 启动nginx1234/usr/local/nginx/sbin/nginx -t nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful/usr/local/nginx/sbin/nginx 7、测试看lua环境是否正常 二、openresty实现WAF功能1、系统基础信息123456# ifconfig eth0|grep 'inet addr'|awk -F ":" '&#123;print $2&#125;'|awk '&#123;print $1&#125;'192.168.83.129# cat /etc/redhat-releaseCentOS release 6.5 (Final)# uname -r2.6.32-431.el6.x86_64 2、安装基础依赖包1yum install -y readline-devel pcre-devel openssl-devel 3、下载并编译安装openresty1234567cd /usr/local/src/wget https://openresty.org/download/ngx_openresty-1.9.3.2.tar.gztar zxvf ngx_openresty-1.9.3.2.tar.gzcd ngx_openresty-1.9.3.2./configure --prefix=/usr/local/openresty-1.9.3.2 --with-luajit --with-http_stub_status_module --with-pcre --with-pcre-jitgmake &amp;&amp; gmake installln -s /usr/local/openresty-1.9.3.2/ /usr/local/openresty 4、测试openresty安装12345678910111213# vim /usr/local/openresty/nginx/conf/nginx.conf server &#123; location /hello &#123; default_type text/html; content_by_lua_block &#123; ngx.say("HelloWorld") &#125; &#125; &#125;# /usr/local/openresty/nginx/sbin/nginx -t nginx: the configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf test is successful# /usr/local/openresty/nginx/sbin/nginx 5、WAF部署：在github上克隆下代码123yum -y install gitcd /usr/local/openresty/nginx/conf/git clone https://github.com/unixhot/waf.git 6、修改Nginx的配置文件，加入（http字段）以下配置。注意路径，同时WAF日志默认存放在/tmp/日期_waf.log12345678910111213# vim /usr/local/openresty/nginx/conf/nginx.conf http &#123; include mime.types; default_type application/octet-stream; #WAF lua_shared_dict limit 50m; lua_package_path "/usr/local/openresty/nginx/conf/waf/?.lua"; init_by_lua_file "/usr/local/openresty/nginx/conf/waf/init.lua"; access_by_lua_file "/usr/local/openresty/nginx/conf/waf/access.lua";# /usr/local/openresty/nginx/sbin/nginx -t nginx: the configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf test is successful# /usr/local/openresty/nginx/sbin/nginx -s reload 7、根据日志记录位置，创建日志目录12# mkdir /tmp/waf_logs# chown www.www /tmp/waf_logs 8、配置信息与注释1234567891011121314151617181920212223242526272829303132333435363738394041424344# cat /usr/local/openresty/nginx/conf/waf/config.lua--WAF config file,enable = "on",disable = "off" --waf status config_waf_enable = "on" #是否开启配置 --log dir config_log_dir = "/tmp/waf_logs" #日志记录地址 --rule setting config_rule_dir = "/usr/local/nginx/conf/waf/rule-config" #匹配规则缩放地址 --enable/disable white url config_white_url_check = "on" #是否开启url检测 --enable/disable white ip config_white_ip_check = "on" #是否开启IP白名单检测 --enable/disable block ip config_black_ip_check = "on" #是否开启ip黑名单检测 --enable/disable url filtering config_url_check = "on" #是否开启url过滤 --enalbe/disable url args filtering config_url_args_check = "on" #是否开启参数检测 --enable/disable user agent filtering config_user_agent_check = "on" #是否开启ua检测 --enable/disable cookie deny filtering config_cookie_check = "on" #是否开启cookie检测 --enable/disable cc filtering config_cc_check = "on" #是否开启防cc攻击 --cc rate the xxx of xxx seconds config_cc_rate = "10/60" #允许一个ip60秒内只能访问10此 --enable/disable post filtering config_post_check = "on" #是否开启post检测 --config waf output redirect/html config_waf_output = "html" #action一个html页面，也可以选择跳转 --if config_waf_output ,setting url config_waf_redirect_url = "http://www.baidu.com" config_output_html=[[ #下面是html的内容 &lt;html&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt; &lt;meta http-equiv="Content-Language" content="zh-cn" /&gt; &lt;title&gt;网站防火墙&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1 align="center"&gt; # 您的行为已违反本网站相关规定，注意操作规范。 &lt;/body&gt; &lt;/html&gt; ]] 三、启用waf并做测试1、模拟sql注入即url攻击日志显示如下,记录了UA，匹配规则，URL，客户端类型，攻击的类型，请求的数据12# tail -f /tmp/2018-07-30_waf.log&#123;"user_agent":"Mozilla\/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/67.0.3396.99 Safari\/537.36","rule_tag":"\\.(bak|inc|old|mdb|sql|backup|java|class|tgz|gz|tar|zip)$","req_url":"\/eastmonet.sql","client_ip":"192.168.83.1","local_time":"2018-07-30 10:46:52","attack_method":"Deny_URL","req_data":"-","server_name":"localhost"&#125; 2、使用ab压力测试工具模拟防CC攻击12# ifconfig eth0|grep 'inet addr'|awk -F ":" '&#123;print $2&#125;'|awk '&#123;print $1&#125;'192.168.83.131 将对方IP放入黑名单12# echo 192.168.83.131 &gt;&gt; /usr/local/openresty/nginx/conf/waf/rule-config/blackip.rule# /usr/local/openresty/nginx/sbin/nginx -s reload 再拿192.168.83.131访问的时候就提示403了将对方IP放入白名单12[root@tiejiang-src1 ~]# echo 192.168.83.131 &gt;&gt; /usr/local/openresty/nginx/conf/waf/rule-config/whiteip.rule[root@tiejiang-src1 ~]# /usr/local/openresty/nginx/sbin/nginx -s reload 此时将不对此ip进行任何防护措施，所以sql注入时应该返回404目录： waf目录：/usr/local/openresty/nginx/conf/waf 配置文件：/usr/local/openresty/nginx/conf/waf/config.lua Waf的ip黑名单：/usr/local/openresty/nginx/conf/waf/rule-config/blackip.rule Waf的ip白名单：/usr/local/openresty/nginx/conf/waf/rule-config/whiteip.rule]]></content>
      <categories>
        <category>OS</category>
        <category>Service</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Nginx</tag>
        <tag>lua</tag>
        <tag>waf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7升级python版本]]></title>
    <url>%2F2018%2F12%2F10%2FCentOS7%E5%8D%87%E7%BA%A7python%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[centos7.4中默认python默认安装版本为2.7.*。12345# pythonPython 2.7.5 (default, Oct 30 2018, 23:45:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux2Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; quit() 但是随着python3的成熟，生产需要需要使用python3版本进行支持，以下升级安装3.*版本python。 1、python3安装python官网地址：https://www.python.org/查看python的各个支持版本的最新版，本次开发需求为python3.6版本，官网最新3.6版本为3.6.6版本。首先安装编译模块支持yum -y install zlib*其他在安装过程中提示需要的模块请自行安装。下载、安装1234567wget https://www.python.org/ftp/python/3.6.6/Python-3.6.6.tgztar -zxvf Python-3.6.6.tgzmkdir /data/pythoncd Python-3.6.6./configure --prefix=/data/pythonmakemake install 安装检查1234567# /data/python/bin/python3Python 3.6.6 (default, Aug 10 2018, 16:26:38) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; quit()# /data/python/bin/pip3 -Vpip 10.0.1 from /data/python/lib/python3.6/site-packages/pip (python 3.6) 可以看到安装的python版本为3.6.6，pip版本为10.0.1。 2、环境配置为了符合代码习惯制作软连接12ln -s /data/python/bin/python3.6 /usr/bin/python3ln -s /data/python/bin/pip3 /usr/bin/pip3 再次验证1234567891011# python3Python 3.6.6 (default, Aug 10 2018, 16:26:38) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; print("hello world")hello world&gt;&gt;&gt; quit()# pip3 -Vpip 10.0.1 from /data/python/lib/python3.6/site-packages/pip (python 3.6)# whereis python3python3: /usr/bin/python3 查看/usr/bin/下python版本123456# ll /usr/bin/py*-rwxr-xr-x. 1 root root 78 Aug 4 2017 /usr/bin/pydoclrwxrwxrwx 1 root root 24 Aug 10 16:55 /usr/bin/python -&gt; /data/python/bin/python3lrwxrwxrwx. 1 root root 9 Oct 15 2017 /usr/bin/python2 -&gt; python2.7-rwxr-xr-x. 1 root root 7136 Aug 4 2017 /usr/bin/python2.7lrwxrwxrwx 1 root root 26 Aug 10 16:33 /usr/bin/python3 -&gt; /data/python/bin/python3.6 可以看到同时存在两个版本，python2.7和python3.6。不建议将python3直接软连接到/usr/bin/python，因为可能影响yum使用。可以在代码中头文件中说明调用/usr/bin/python3。 3、单版本配置同上述步骤，在配置软连接1ln -s /data/python/bin/python3.6 /usr/bin/python 查看/usr/bin/1234567ll /usr/bin/py*-rwxr-xr-x. 1 root root 78 Aug 4 2017 /usr/bin/pydoclrwxrwxrwx 1 root root 30 Aug 6 18:24 /usr/bin/python -&gt; /data/python/bin/python3lrwxrwxrwx. 1 root root 9 Oct 15 2017 /usr/bin/python2 -&gt; python2.7-rwxr-xr-x. 1 root root 7136 Aug 4 2017 /usr/bin/python2.7lrwxrwxrwx 1 root root 26 Aug 6 14:01 /usr/bin/python3 -&gt; /data/python/bin/python3.6lrwxrwxrwx. 1 root root 7 Oct 15 2017 /usr/bin/python.bak -&gt; python2 此时，系统默认python版本即为python3.6.6。需要注意的是，由于系统默认python版本更换，需要更改之前使用python2的应用配置，比如yum等。]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK6.3+head插件安装配置]]></title>
    <url>%2F2018%2F12%2F10%2FELK6-3-head%E6%8F%92%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[一、前言1、为什么用ELK一般我们需要进行日志分析场景：直接在日志文件中 grep、awk 就可以获得自己想要的信息。但在规模较大的场景中，此方法效率低下，面临问题包括日志量太大如何归档、文本搜索太慢怎么办、如何多维度查询。需要集中化的日志管理，所有服务器上的日志收集汇总。常见解决思路是建立集中式日志收集系统，将所有节点上的日志统一收集，管理，访问。一般大型系统是一个分布式部署的架构，不同的服务模块部署在不同的服务器上，问题出现时，大部分情况需要根据问题暴露的关键信息，定位到具体的服务器和服务模块，构建一套集中式日志系统，可以提高定位问题的效率。一个完整的集中式日志系统，需要包含以下几个主要特点： * 收集－能够采集多种来源的日志数据 * 传输－能够稳定的把日志数据传输到中央系统 * 存储－如何存储日志数据 * 分析－可以支持 UI 分析 * 警告－能够提供错误报告，监控机制 ELK提供了一整套解决方案，并且都是开源软件，之间互相配合使用，完美衔接，高效的满足了很多场合的应用。目前主流的一种日志系统。 2、ELK简介ELK是三个开源软件的缩写，分别表示：Elasticsearch , Logstash, Kibana , 它们都是开源软件。新增了一个FileBeat，它是一个轻量级的日志收集处理工具(Agent)，Filebeat占用资源少，适合于在各个服务器上搜集日志后传输给Logstash，官方也推荐此工具。Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。Logstash 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。Filebeat隶属于Beats。目前Beats包含四种工具：（1）Packetbeat（搜集网络流量数据）（2）Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）（3）Filebeat（搜集文件数据）（4）Winlogbeat（搜集 Windows 事件日志数据） 3、设计架构1）简单架构一般最简单的架构只用elasticsearch、logstash、kibana组成即可，如下图：logstash收集处理数据，并输出到elasticsearchelasticsearch存储日志数据kibana用于数据的检索、查询、web展示2）高可用架构随着业务、性能、稳定性等需求的增加，架构中引进filebeat和缓存机制，如下图filebeat：用于收集数据，替代logstash，在每台agent端需要部署，相比于logstash，filebeat占用更少的系统资源缓存集群：可以使用kafka或者redis，使日志的汇总处理更快速logstash集群：提高日志管道的传输速度和系统性能elasticsearch集群：存储日志数据kibana集群：提高web的访问负载能力，前端使用nginx代替这种架构中各节点使用集群替代，具有更大的负载能力和数据处理能力。 二、 安装1、环境准备修改/etc/sysctl.conf，并使之生效12345678910111213141516171819# cat /etc/sysctl.conf |grep vm.maxvm.max_map_count=262144[root@izuf63k1rfnrzs6zc1g95qz elasticsearch-head]# sysctl -p /etc/sysctl.conf net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1net.ipv6.conf.lo.disable_ipv6 = 1vm.swappiness = 0net.ipv4.neigh.default.gc_stale_time = 120net.ipv4.conf.all.rp_filter = 0net.ipv4.conf.default.rp_filter = 0net.ipv4.conf.default.arp_announce = 2net.ipv4.conf.lo.arp_announce = 2net.ipv4.conf.all.arp_announce = 2net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_syn_backlog = 1024net.ipv4.tcp_synack_retries = 2kernel.sysrq = 1vm.max_map_count = 262144 修改/etc/security/limits.conf，添加以下两行123# cat /etc/security/limits.conf |grep elasticsearchelasticsearch soft nofile 65536elasticsearch hard nofile 65536 关于网络设置和端口开放部分不再描述，使用端口可以根据自己需求修改。 2、elasticsearch安装ELK官网地址：https://www.elastic.co/Elasticsearch需要java环境支持，请自行安装。需要的安装文件自行下载，不再给予下载地址。12345678910111213141516171819# tar -zxvf elasticsearch-6.3.2.tar.gz# mv elasticsearch-6.3.2 /data/elasticsearch创建用户和用户组groupadd elasticsearch #新建elsearch组useradd elasticsearch -g elasticsearch -p elasticsearch #新建一个elsearch用户chown -R elasticsearch. elasticsearch /data/elasticsearch #对文件夹授权配置elasticsearch# cd /data/elasticsearch# cat config/elasticsearch.yml |grep -v '^#'|grep -v '^$'path.data: /data/elasticsearch/datapath.logs: /data/elasticsearch/logsbootstrap.memory_lock: falsenetwork.host: 0.0.0.0http.port: 9200http.cors.enabled: truehttp.cors.allow-origin: "*"切换用户，启动elasticsearch# su elasticsearch$ /data/elasticsearch/bin/elasticsearch -d -d是以后台进程方式启动浏览器访问，如下图表示安装成功，也可以使用curl方式访问。 3、logstash安装Logstash安装可以切换到root用户进行安装1234567891011121314151617181920212223242526# tar -zxvf logstash-6.3.2.tar.gz# mv logstash-6.3.2 /data/logstash配置logstash# cd /data/logstash/# mkdir conf.d# cat config/logstash.yml |grep -v '^$'|grep -v '^#'path.config: /data/logstash/conf.dpath.logs: /data/logstash/logs# cat conf.d/logstash_test.confinput&#123; file&#123; path =&gt;"/data/work/logs/MsgService.log" start_position=&gt;"beginning" &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "MsgService-%&#123;+YYYY.MM.dd&#125;" &#125; stdout&#123; codec=&gt;rubydebug &#125;&#125; 启动并验证1# /data/logstash/bin/logstash -f /data/logstash/conf.d/logstash_test.conf --path.data=/data/logstash/data/002 出现以下格式信息表示启动成功1234567&#123; "message" =&gt; "2018-07-19 10:18:23.431 INFO 21554 --- [tbeatExecutor-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_MSGSERVICE/172.19.254.54:23000/msgService - registration status: 204", "path" =&gt; "/data/work/logs/MsgService.log", "@timestamp" =&gt; 2018-07-26T08:43:43.081Z, "host" =&gt; "izuf63k1rfnrzs6zc1g95qz", "@version" =&gt; "1"&#125; logstash中input表示读取日志文件，filter表示过滤，output表示输出具体的语法，根据不同的日志文件配置。input、filter、output其实都是logstash的插件，根据需求我们可以安装检查和卸载插件。通过1# ./bin/logstash-plugin list 查看插件管理的命令帮助。常用的命令有1234bin/logstash-plugin list #查看已安装插件列表bin/logstash-plugin install plugin_name #安装插件bin/logstash-plugin update plugin_name #卸载插件bin/logstash-plugin uninstall plugin_name #卸载插件 通过list命令查看插件列表时候，无非下列四种类型的插件： * logstash-codec-* #编码解码插件 * logstash-filter-* #数据处理插件 * logstash-input-* #输入插件 * logstash-output-* #输出插件 此处需要完善一个概念：Logstash 不只是一个input | filter | output 的数据流，而是一个 input | decode | filter | encode | output 的数据流！上面插件中的codec 就是用来 decode、encode 事件的。启动语句中–path.data表示指定目录，为了实现多实例启动，在配置文件中可以不配置path.data参数，在启动时候加上。以后台方式启动1# nohup /data/logstash/bin/logstash -f /data/logstash/conf.d/logstash_test.conf --path.data=/data/logstash/data/002 &amp; 4、安装elasticsearch-headelasticsearch-head从5.x版本以后不再依附于elasticsearch安装，作为独立进程安装。elasticsearch-head项目地址：https://github.com/mobz/elasticsearch-head#connecting-to-elasticsearchelasticsearch-head需要node环境，首先安装node，这里不贴出详细步骤。验证node版本12# node -vv8.11.3 下载安装123456789101112131415161718192021# wget https://github.com/mobz/elasticsearch-head/archive/master.zip为了后续安装phantomjs，使用bzip2解压，需要安装bzip2# yum install bzip2 -y解压到/data目录# cd /data/elasticsearch-head# npm -v5.6.0# npm install --registry=https://registry.npm.taobao.org --unsafe-perm安装过程会有点慢--registry=https://registry.npm.taobao.org表示使用国内镜像资源--unsafe-perm表示取消秘钥验证验证安装# ll ./node_modules/grunttotal 32drwxr-xr-x 2 root root 4096 Jul 26 14:03 bin-rw-r--r-- 1 root root 7111 Apr 6 2016 CHANGELOGdrwxr-xr-x 4 root root 4096 Jul 26 14:03 lib-rw-r--r-- 1 root root 1592 Mar 23 2016 LICENSEdrwxr-xr-x 4 root root 4096 Jul 26 14:03 node_modules-rw-r--r-- 1 root root 2442 Jul 26 14:03 package.json-rw-r--r-- 1 root root 878 Feb 12 2016 README.md 修改配置Gruntfile.js，增加hostname，如下图所示启动1npm run start 浏览器访问比如我们在服务器上配置，但是在本地通过外网访问elasticsearch-head，那么elasticsearch的地址不应该是elasticsearch所在服务器的内网地址，而应该是外网地址，注意对应使用的端口应该打开。elasticsearch-head是一个查看集群信息的工具，我们现在只配置一台elasticsearch，如果是多台，也可以用于查看集群内其他elasticsearch信息。查看页面表示安装成功。以后台方式运行1# nohup npm run start &amp; 5、kibana安装1234567891011解压配置# tar -zxvf kibana-6.3.2-linux-x86_64^C# mv kibana-6.3.2-linux-x86_64 /data/kibana^C# cd /data/kibana/# cat config/kibana.yml |grep -v '^#'|grep -v '^$'server.port: 80server.host: "0.0.0.0"elasticsearch.url: "http://localhost:9200"kibana.index: ".kibana"后台启动nohup /data/kibana/bin/kibana &amp; 浏览器访问后，配置index pattern，根据日志index标识不同，自己灵活掌握。 6、kibana汉化对于习惯使用英文界面的也可以不用汉化。 1）官网汉化方式ELK6.x版本提供国际化的标准，可以自己翻译汉化1、复制src/core_plugins/kibana/translations/en.json的内容，创建一个新的json文件，比如ch.json。2、翻译并修改ch.json中对应的文字。3、 在src/core_plugins/kibana/index.js文件中，找到translations，然后添加对应的内容。4、 最后在配置文件config/kibana.yml（开发模式下，创建并使用配置文件kibana.dev.yml）中，加入默认的语言设置：i18n.defaultLocale: “ch”5、 等kibana服务器重启之后，刷新页面就可以看见效果了。 2）github个人项目翻译方式项目地址：https://github.com/anbai-inc/Kibana_Hanization具体的使用方法也有介绍，但是非官方方法，具体的效果不太理想。个人认为6.x版本使用此方法汉化后会影响系统启动。 三、高级配置1、filebeat安装12345678910111213141516171819202122下载地址https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-linux-x86_64.tar.gz解压包到对应目录# tar -zxvf filebeat-6.3.2-linux-x86_64.tar.gz# mv filebeat-6.3.2-linux-x86_64 /data/filebeat修改配置文件# cat filebeat.yml |grep -v '#'|grep -v '^$'filebeat.inputs:- type: log enabled: true paths: - /data/work/logs/*.logfilebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 3setup.kibana: host: "localhost:80"#output.elasticsearch:# hosts: ["localhost:9200"]output.logstash: hosts: ["localhost:5044"] 6.x版本中filebeat，只支持一个output输出，如果把日志输出到elasticsearch，则需要把输出到logstash段配置注释。一般情况下输出到logstash，进行过滤，再由logstash输出到elasticsearch。启动1nohup ./filebeat -c filebeat.yml &amp; 同一台服务器上可以启动多个filebeat，但是需要指定不同的配置文件。 2、logstash相关配置主要配置如下123456789101112131415161718# cat /data/logstash/conf.d/logstash_test.conf input&#123; beats &#123; port =&gt; 5044 &#125; &#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "MsgService-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; Index定义日志头Logstash可以根据conf和path.data的不同启动多个进程 3、filter配置filter主要对日志进行过滤和筛选，以剔除不必要的日志，使用的方法为grok。grok中配置macth来匹配日志，使用正则表达式。相关正则表达式字段可以查看github：https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns匹配的验证测试可以使用以下地址：https://grokconstructor.appspot.com/do/matchhttp://grokdebug.herokuapp.com/个人体验，推荐使用第一个地址，需要使用科学上网。实例： 1、匹配nginx access的日志nginx中access日志的模式配置为123log_format main '$remote_addr $remote_user $time_local $request ' '$http_referer $status $body_bytes_sent $request_body ' '"$http_user_agent" "$http_x_forwarded_for"'; 验证匹配字段其中第一个框内为nginx access的日志第二个框内为匹配准则，准则的大写字段是从github地址上查找得到，小写字段为自定义执行，得到如下所示可以看到匹配完成，match即为匹配准则，日志中不重要的部分可以不进行匹配。将match写入logstash配置文件1234567891011121314151617181920212223242526272829303132# cat conf.d/nginx_access_log.conf input&#123; beats &#123; port =&gt; 5055 &#125; &#125;filter &#123; grok &#123; match =&gt; ["message","%&#123;IP:clientip&#125; %&#123;USER:user&#125; %&#123;HTTPDATE:timestamp&#125; %&#123;WORD:request_method&#125; %&#123;URIPATHPARAM:uri&#125; HTTP/%&#123;NUMBER:httpversion&#125; (?:%&#123;URI:referrer&#125;|-) %&#123;NUMBER:status:int&#125; %&#123;NUMBER:body_bytes_sent:int&#125; "] &#125; # if [loglevel] == "DEBUG" &#123;# drop &#123;&#125;# &#125; if [uri] == "/" &#123; drop &#123;&#125; &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "nginx_access_log-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; drop是跟字段匹配进行过滤，过滤掉的日志将不会再进行output。此处drop掉的是slb的检测访问的日志，即非业务的日志。需要注意的是：对message进行匹配，后面的准测内不允许使用多个””，所以在nginx的配置文件内需要修改日志格式的相关字段，不要加双引号。 2、匹配nodejs的日志验证执行，查看结果关于每条日志的记录的行为的相应时间是没有进行匹配的，所以出现在after match处。写入logstash配置1234567891011121314151617181920212223242526272829303132# cat conf.d/nodejs_log.conf input&#123; beats &#123; port =&gt; 5077 &#125; &#125;filter &#123; grok &#123; match =&gt; ["message","logger: %&#123;TIMESTAMP_ISO8601:time&#125; %&#123;WORD:request_method&#125; %&#123;URIPATHPARAM:uri&#125; %&#123;NUMBER:status:int&#125; %&#123;NUMBER:body_bytes_sent:int&#125; "] &#125; # if [loglevel] == "DEBUG" &#123;# drop &#123;&#125;# &#125;# if [uri] == "/" &#123;# drop &#123;&#125;# &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "nodejs_log-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; 以上配置是没有对日志进行drop操作的，日志是否需要进行drop根据实际情况操作。 3、匹配java的日志java是世界上最不友好的语言，反正我就是这么认为！java的日志格式不像web应用暴露的日志一样格式规范，所以很难匹配。如下所示after match部分毫无规律，不知道这是什么玩意儿，就不匹配了，够用就行。添加logstash配置123456789101112131415161718192021222324252627282930313233# cat conf.d/springcloud_log.conf input&#123; beats &#123; port =&gt; 5044 &#125; &#125;filter &#123; grok &#123; match =&gt; ["message","%&#123;TIMESTAMP_ISO8601:datestamp&#125; *%&#123;LOGLEVEL:loglevel&#125; %&#123;INT:digital&#125; *"] &#125; # if [loglevel] == "DEBUG" &#123;# drop &#123;&#125;# &#125; if [loglevel] == "INFO" &#123; drop &#123;&#125; &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "springcloud_log-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; 此处drop的为类型是INFO的日志。 4、其他配置关于elasticsearch和kibana的配置不用调整。]]></content>
      <categories>
        <category>Monitor</category>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>日志</tag>
        <tag>head</tag>
        <tag>ELK</tag>
        <tag>Elasticsearch</tag>
        <tag>Logstash</tag>
        <tag>Kibana</tag>
        <tag>FileBeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python购物车程序]]></title>
    <url>%2F2018%2F12%2F07%2Fshopping%2F</url>
    <content type="text"><![CDATA[程序：购物车程序需求 1、启动程序后，让用户输入工资，然后打开商品列表 2、允许用户根据商品编号购买商品 3、用户选择商品后，检测余额是否够，够就直接扣款，不够就提醒 4、可随时退出，退出时，打印已购商品和余额 code123456789101112131415161718192021222324252627282930313233343536373839# -*- coding:utf-8 -*-#Author:Francisproduct_list = [ ('Iphone',5800), ('Mac Pro',9800), ('Bike',800), ('Watch',10600), ('Coffee',31), ('Alex Python',120),]shopping_list = []salary = input("Input your salary:")if salary.isdigit(): salary = int(salary) while True: for index,item in enumerate(product_list): #print(product_list.index(item),item) print(index,item) user_choice = input("选择要买嘛？&gt;&gt;&gt;:") if user_choice.isdigit(): user_choice = int(user_choice) if user_choice &lt; len(product_list) and user_choice &gt;=0: p_item = product_list[user_choice] if p_item[1] &lt;= salary: #买的起 shopping_list.append(p_item) salary -= p_item[1] print("Added %s into shopping cart,your current balance is \033[31;1m%s\033[0m" %(p_item,salary) ) else: print("\033[41;1m你的余额只剩[%s]啦，还买个毛线\033[0m" % salary) else: print("product code [%s] is not exist!"% user_choice) elif user_choice == 'q': print("--------shopping list------") for p in shopping_list: print(p) print("Your current balance:",salary) exit() else: print("invalid option")]]></content>
      <categories>
        <category>Scripts</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix监控redis]]></title>
    <url>%2F2018%2F12%2F06%2FZabbix%E7%9B%91%E6%8E%A7Redis%2F</url>
    <content type="text"><![CDATA[zabbix监控redis实例有个不方便的地方是只能监控固定的6379端口，如果是非6379端口的话，需要修改模板，如果主机有多个redis实例的话，需要具有不同的redis模板，然后在管理监控，很是麻烦，为了解决这个问题，我使用lld（low level discovery）方式监控redis，只需要你在正则表达式里把需要监控的端口标上，就可以监控redis多实例。 一、agent端配置agent端脚本，获取正在运行的redis实例端口1234567891011121314151617181920212223242526# pwd/etc/zabbix/scripts# cat redis_low_discovery.sh #!/bin/bash#Script_name redis_low_discovery.shredis() &#123;# port=($(sudo netstat -tpln | awk -F "[ :]+" '/redis/ &amp;&amp; /0.0.0.0/ &#123;print $5&#125;')) port=($(netstat -tpln | awk -F "[ :]+" '/redis/ &amp;&amp; /0.0.0.0/ &#123;print $5&#125;')) printf '&#123;\n' printf '\t"data":[\n' for key in $&#123;!port[@]&#125; do if [[ "$&#123;#port[@]&#125;" -gt 1 &amp;&amp; "$&#123;key&#125;" -ne "$(($&#123;#port[@]&#125;-1))" ]];then socket=`ps aux|grep $&#123;port[$&#123;key&#125;]&#125;|grep -v grep|awk -F '=' '&#123;print $10&#125;'|cut -d ' ' -f 1` printf '\t &#123;\n' printf "\t\t\t\"&#123;#REDISPORT&#125;\":\"$&#123;port[$&#123;key&#125;]&#125;\"&#125;,\n" else [[ "$&#123;key&#125;" -eq "(($&#123;#port[@]&#125;-1))" ]] socket=`ps aux|grep $&#123;port[$&#123;key&#125;]&#125;|grep -v grep|awk -F '=' '&#123;print $10&#125;'|cut -d ' ' -f 1` printf '\t &#123;\n' printf "\t\t\t\"&#123;#REDISPORT&#125;\":\"$&#123;port[$&#123;key&#125;]&#125;\"&#125;\n" fi done printf '\t ]\n' printf '&#125;\n'&#125;$1 验证脚本是否正常监控redis实例的json展示12345678910# ./redis_low_discovery.sh redis&#123; "data":[ &#123; "&#123;#REDISPORT&#125;":"6379"&#125; ] &#123; "&#123;#REDISPORT&#125;":"6380"&#125; ]&#125; 添加UserParameter12345# pwd/etc/zabbix/zabbix_agentd.d# cat userparameter_redis.conf UserParameter=zabbix_low_discovery[*],/bin/bash /etc/zabbix/scripts/redis_low_discovery.sh $1UserParameter=redis_stats[*],(/bin/echo info; sleep 1) | telnet 127.0.0.1 $1 2&gt;&amp;1 |grep $2|cut -d : -f2 注：zabbix_agentd.conf配置文件中吧UnsafeUserParameters=1设置为1并打开注释即可，这里我的redis示例没有设置密码，如果有密码就加上-a password，telnet对空密码可以。有密码的话telnet换成$(which redis-cli)。12UserParameter=zabbix_low_discovery[*],/bin/bash /etc/zabbix/scripts/redis/redis_low_discovery.sh $1UserParameter=redis_stats[*],(/bin/echo info; sleep 1) | /data/redis/bin/redis-cli -h 172.16.109.138 -p $1 -a 5U7pp/pQLbdGLA 2&gt;&amp;1 |grep $2|cut -d : -f2 然后重启agent即可把redis_low_discovery.sh文件存放到/etc/zabbix/scripts/目录下，然后给与755权限，并修改用户与组为zabbix，同时允许zabbix用户无密码运行1echo "zabbix ALL=(root) NOPASSWD:/bin/netstat"&gt;&gt;/etc/sudoers 关闭requiretty1sed -i 's/^Defaults.*.requiretty/#Defaults requiretty/' /etc/sudoers 二、server端配置使用zabbix_get获取redis键值123456789# zabbix_get -s 172.19.231.227 -p 10050 -k zabbix_low_discovery[redis]&#123;"data":[ &#123;"&#123;#REDISPORT&#125;":"6379"&#125;, &#123;"&#123;#REDISPORT&#125;":"6380"&#125; ]&#125; redis每秒更新时间12# zabbix_get -s 172.19.231.227 -p 10050 -k redis_stats[6381,uptime_in_seconds]8 三、web界面配置导入模板以及主机连接模板，还需要设置正则等模板在此处下载，然后导入模板，并且关联对应的主机。设置正则表达式name：Redis regexResult TRUE = ^(6380|6381)$正则表达式根据端口配置，可以增加最后把主机连接到模板上即可，默认间隔时间1小时，方便测试我改成60s，数据收集后然后改过了即可检查思路如下： 1：agent端可以使用脚步获取json化的信息 2：server端可以zabbix_get获取json化信息以及item的值注：基于以上2步骤，按理说可以获取到相应的item值了。 3：打开agent端debug模式获取更多的日志信息，日志无问题，显示过程中没有显示json化的item 4：检查redis多实例模板中自动发现规则的键值与agent端中UnsafeUserParameters中定义键值不一样，修改与模板中对应的键值一样即可，重启agent即可]]></content>
      <categories>
        <category>Monitor</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云ECS漏洞修复]]></title>
    <url>%2F2018%2F12%2F05%2F%E9%98%BF%E9%87%8C%E4%BA%91ECS%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[一、关于glibc的报警1、问题确认关于glibc的报警，具体如下所示：此处报警我们可以根据漏洞编号进行查询，可以看到是因为glibc的版本太低，具有以下上图所示两个漏洞。阿里云进行的报警的依据是根据探测ECS相关软件的版本，如下图所示： 2、解决方案上图可以看到我们需要升级的软件一共有5个，分别是glibc、glibc-common、glibc-headers、glibc-devel、nscd。rpm包可从此处下载，选择稳定版本即可。 3、升级脚本将下载、安装过程脚本话12345678910111213141516171819#!/bin/sh#Francis#切换到下载目录cd /data/backup# update glibc to 2.22 for CentOS 7wget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-common-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-headers-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-devel-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/nscd-2.22.90-21.el7.x86_64.rpmrpm -Uvh glibc-2.22.90-21.el7.x86_64.rpm \ glibc-common-2.22.90-21.el7.x86_64.rpm \ glibc-devel-2.22.90-21.el7.x86_64.rpm \ glibc-headers-2.22.90-21.el7.x86_64.rpm \ nscd-2.22.90-21.el7.x86_64.rpm \ --force --nodeps 二、关于curl的报警1、问题确认关于glibc的报警，具体如下所示：此处报警我们可以根据漏洞编号进行查询，可以看到是因为curl的版本太低，具有以下上图所示四个漏洞。阿里云进行的报警的依据是根据探测ECS相关软件的版本，如下图所示： 2、解决方案上图可以看到curl版本7.12到7.58都有漏洞，所以我们选择安装7.60以后的版本 1、编译安装123456wget https://curl.haxx.se/download/curl-7.62.0.tar.gztar -zxvf curl-7.62.0.tar.gz cd curl-7.62.0./configure --prefix=/usrmakemake install 查看curl版本1234567# curl --versioncurl 7.62.0 (x86_64-pc-linux-gnu) libcurl/7.47.1 NSS/3.21.3 Basic ECC zlib/1.2.7 libidn/1.28 libssh2/1.4.3Release-Date: 2018-10-31Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp Features: AsynchDNS IDN IPv6 Largefile GSS-API Kerberos SPNEGO NTLM NTLM_WB SSL libz UnixSockets # curl-config --versionlibcurl 7.62.0 2、yum安装查看已安装版本1234# curl --versioncurl 7.29.0 (x86_64-redhat-linux-gnu) libcurl/7.29.0 NSS/3.34 zlib/1.2.7 libidn/1.28 libssh2/1.4.3Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smtp smtps telnet tftp Features: AsynchDNS GSS-Negotiate IDN IPv6 Largefile NTLM NTLM_WB SSL libz unix-sockets 安装repo1rpm -Uvh http://www.city-fan.org/ftp/contrib/yum-repo/rhel6/x86_64/city-fan.org-release-2-1.rhel6.noarch.rpm 查看该 repo 包含的 curl 版本12345678910# yum --showduplicates list curl --disablerepo="*" --enablerepo="city*"Loaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * city-fan.org: cityfan.mirror.digitalpacific.com.au * city-fan.org-debuginfo: cityfan.mirror.digitalpacific.com.au * city-fan.org-source: cityfan.mirror.digitalpacific.com.auInstalled Packagescurl.x86_64 7.29.0-51.el7 @base Available Packagescurl.x86_64 7.62.0-1.7.cf.rhel7 city-fan.org 修改该repo的enable为1123456789101112131415vi /etc/yum.repos.d/city-fan.org.repo[city-fan.org]name=city-fan.org repository for Red Hat Enterprise Linux (and clones) $releasever ($basearch)#baseurl=http://mirror.city-fan.org/ftp/contrib/yum-repo/rhel$releasever/$basearchmirrorlist=http://mirror.city-fan.org/ftp/contrib/yum-repo/mirrorlist-rhel$releaseverenabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-city-fan.org 升级最新的curl1yum upgrade curl -y 查看版本12345# curl -Vcurl 7.62.0 (x86_64-redhat-linux-gnu) libcurl/7.62.0 NSS/3.36 zlib/1.2.7 libpsl/0.7.0 (+libicu/50.1.2) libssh2/1.8.0 nghttp2/1.31.1Release-Date: 2018-10-31Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp Features: AsynchDNS IPv6 Largefile GSS-API Kerberos SPNEGO NTLM NTLM_WB SSL libz HTTP2 UnixSockets HTTPS-proxy PSL Metalink 升级完成]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
        <tag>软件漏洞修复</tag>
        <tag>glibc</tag>
        <tag>curl</tag>
        <tag>nss-pem</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql安装]]></title>
    <url>%2F2018%2F11%2F29%2FMysql%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[一、软件部署1、MySQL安装123456789101112131415161718192021222324252627282930313233343536373839## 安装软件依赖shell&gt; yum install libaio -y## 创建用户和组shell&gt; groupadd mysqlshell&gt; useradd -r -g mysql -s /bin/false mysql## 解压软件包并创建软连接shell&gt; tar xzvf mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz -C /usr/local/shell&gt; cd /usr/local/shell&gt; ln -s mysql-5.7.22-linux-glibc2.12-x86_64 mysql## 修改软件目录权限为mysql用户shell&gt; cd /usr/local/mysqlshell&gt; chown -R mysql:mysql .## 创建数据目录权限并修改权限为mysql用户shell&gt; mkdir -p /data/mysql/&#123;data,tmp&#125;shell&gt; chown -R mysql:mysql /data/mysql/## 拷贝启动脚本至系统启动目录shell&gt; cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld## 执行数据库初始化操作shell&gt; cd /usr/local/mysqlshell&gt; bin/mysqld --initialize --user=mysql## 启动MySQLshell&gt; systemctl enable mysqldshell&gt; systemctl start mysqldshell&gt; systemctl status mysqldshell&gt; systemctl disable mysqldshell&gt; cat /data/mysql/data/mysql-error.log |grep passshell&gt; /usr/local/mysql/bin/mysql -S /data/mysql/data/mysql_3306.sock -p## 输入查看到的随机密码## 登录数据库后需先修改密码mysql&gt; set password='emhlbnhpbmcxMDA0';mysql&gt; exit; 2、配置环境变量12345shell&gt; vim ~/.bash_profile MYSQL_HOME=/usr/local/mysql PATH=$PATH:$HOME/bin:$MYSQL_HOME/binshell&gt; source ~/.bash_profileshell&gt; mysql -V 从库的搭建方式为在从库所在服务器重复步骤一和步骤二全部操作 二、复制配置1、复制用户创建12## 主库创建复制用户mysql&gt; grant replication slave on *.* to 'repl'@'%' identified by 'cmVwbGRiYQ=='; 2、配置复制同步123456789101112## 从库配置复制同步mysql&gt; change master to master_host='172.16.109.144',master_user='repl',master_password='cmVwbGRiYQ==',master_port=3306,master_auto_position=1;## 从库启动复制mysql&gt; start slave;mysql&gt; show slave status\G;mysql&gt; show processlist; 三、备份配置1、部署xtrabackup主从都需要部署，文件上传操作：略1234567891011## 解压percona-xtrabackupcd /opt/for_gongbao_mysql/tar xzvf percona-xtrabackup-2.4.9-Linux-x86_64.tar.gz## 拷贝命令至系统可执行目录cp percona-xtrabackup-2.4.9-Linux-x86_64/bin/* /usr/local/bin/rm percona-xtrabackup-2.4.9-Linux-x86_64 -rf## 拷贝qpress解压缩命令至系统可执行目录cd /opt/for_gongbao_mysql/cp qpress /usr/local/bin/ 2、配置自动化备份脚本脚本模板已上传，暂未配置 四、慢查询配置1、日志轮换脚本配置脚本模板已上传，暂未配置 2、日志格式化脚本配置脚本模板已上传，暂未配置]]></content>
      <categories>
        <category>DB</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
</search>
