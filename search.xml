<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python系统监控脚本]]></title>
    <url>%2F2019%2F01%2F25%2FPython%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[需求领导要求春节期间对某台业务服务器进行重点巡检，但是回老家很不方便，所以制定一个脚本。脚本思路大概如下： 1、获取服务器的性能信息，业务信息，数据库备份信息等 2、制定word模板 3、将服务器信息插入到word模板中生成新的word文档 4、将word文档通过邮件方式发送给领导 具体实现word模板主要信息定制如下 CPU利用率 系统平均负载 内存使用率 used/total 磁盘空间可用率 Filesystem Size Used Avail Use% Mounted on 应用程序状态 业务报错日志 数据库运行状态 数据库备份 脚本内容如下使用脚本之前需要解决缺少openssl-devel支持的问题，命令如下：1yum install gcc libffi-devel python-devel openssl-devel -y 在脚本内需要使用psutil包和docxtpl包，使用pip安装：12pip install psutilpip install docxtpl 脚本内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264#!/usr/bin/python# coding:utf-8#Author:Francisimport osimport subprocessimport psutilimport timeimport commandsimport datetimeimport smtplibfrom email.header import Headerfrom email.mime.text import MIMETextfrom email.mime.multipart import MIMEMultipartfrom email.mime.application import MIMEApplicationfrom psutil import *from docxtpl import DocxTemplatedef date_1(): return time.strftime(&apos;%Y/%m/%d&apos;,time.localtime(time.time())) def date_2(): return time.strftime(&apos;%Y%m%d&apos;,time.localtime(time.time()))def hostname(): print socket.gethostname()def cpu_usage_rate(): #cmd = &quot;&quot;&quot; top -bn1 | grep &apos;%Cpu(s)&apos;|awk &apos;&#123;for(i=1;i&lt;9;i=i+1)&#123;printf $i&quot; &quot;&#125;;printf &quot;\n&quot;&#125;&apos; &quot;&quot;&quot; cmd = &quot;&quot;&quot; top -bn1 | grep &apos;%Cpu(s)&apos;|awk &apos;&#123;for(i=1;i&lt;9;i=i+1)&#123;printf $i&quot; &quot;&#125;&#125;&apos; &quot;&quot;&quot; cpu_usage = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT) #print (cpu_usage.stdout.read()) #print (&apos;获取内存占用率： &apos;+(str)(psutil.virtual_memory().percent)+&apos;%&apos;) #print (&apos;打印本机cpu占用率： &apos;+(str)(psutil.cpu_percent(0))+&apos;%&apos;) return cpu_usage.stdout.read()def os_load_average(): cmd = &quot;&quot;&quot; uptime | sed &apos;s/,//g&apos; | awk &apos;&#123;print $8,$9,$10&#125;&apos; &quot;&quot;&quot; load_average = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT) #rint (load_average.stdout.read()) return load_average.stdout.read()def memory_usage_rate(): vime = virtual_memory() #print &apos;Memory: %5s%% %6s/%s&apos; % ( #vime.percent, str(int(vime.used / 1024 / 1024)) + &apos;M&apos;, str(int(vime.total / 1024 / 1024)) + &apos;M&apos;) return &apos;Memory: %5s%% %6s/%s&apos; % ( vime.percent, str(int(vime.used / 1024 / 1024)) + &apos;M&apos;, str(int(vime.total / 1024 / 1024)) + &apos;M&apos;)def disk_info(): cmd = &quot;&quot;&quot; df -h|grep &apos;/dev/vd&apos; &quot;&quot;&quot; disk_info = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT) #print (disk_info.stdout.read()) return disk_info.stdout.read()def process_info(): cmd = &quot;&quot;&quot; ps -ef|grep java|grep -Ev &apos;grep&apos; &quot;&quot;&quot; process_info = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT) #print (process_info.stdout.read()) return process_info.stdout.read()def is_error(SubStrList,Str):#判断字符串Str是否包含序列SubStrList中的每一个子字符串 flag=[] for substr in SubStrList: for i in Str: if substr in i: flag.append(i) return flagdef new_error_file(): #要求文件名称中包含这些字符 keyword=[&apos;error&apos;] file_dir = &quot;/data/work/log/&quot; listtmp=os.listdir(file_dir) #rint listtmp #rint &apos;—&apos;*100 list=is_error(keyword,listtmp) #rint list list.sort(key=lambda fn: os.path.getmtime(file_dir+fn) if not os.path.isdir(file_dir+fn) else 0) file=os.path.join(file_dir,list[-1]) d=datetime.datetime.fromtimestamp(os.path.getmtime(file_dir+list[-1])) #rint &apos;—&apos;*100 #rint(&apos;最后改动的文件是&apos;+list[-1]+&quot;，时间：&quot;+d.strftime(&quot;%Y-%m-%d %H-%M-%S&quot;)) #rint file return filedef mysql_status(): cmd = &quot;&quot;&quot; ps -ef|grep mysql|grep -Ev &apos;grep&apos; &quot;&quot;&quot; mysql_status = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT) #print (mysql_status.stdout.read()) return mysql_status.stdout.read()def mysql_backup_file(): testdir = &quot;/data/mysql/backup/&quot; #列出目录下所有的文件 list = os.listdir(testdir) #对文件修改时间进行升序排列 list.sort(key=lambda fn: os.path.getmtime(testdir+fn) if not os.path.isdir(testdir+fn) else 0) #获取最新修改时间的文件 filetime = datetime.datetime.fromtimestamp(os.path.getmtime(testdir+list[-1])) #获取文件所在目录 filepath = os.path.join(testdir,list[-1]) #rint(&quot;最新修改的文件(夹)：&quot;+list[-1]) #rint(&quot;时间：&quot;+filetime.strftime(&apos;%Y-%m-%d %H-%M-%S&apos;)) #print filepath return filepath def mysql_backup(): testdir = &quot;/data/mysql/backup/&quot; #列出目录下所有的文件 list = os.listdir(testdir) #对文件修改时间进行升序排列 list.sort(key=lambda fn:os.path.getmtime(testdir + fn)) #获取最新修改时间的文件 filetime = datetime.datetime.fromtimestamp(os.path.getmtime(testdir+list[-1])) #获取文件所在目录 filepath = os.path.join(testdir,list[-1]) #rint(&quot;最新修改的文件(夹)：&quot;+list[-1]) #rint(&quot;时间：&quot;+filetime.strftime(&apos;%Y-%m-%d %H-%M-%S&apos;)) #print filepath return filepathdef get_disk_info(): print &apos;磁盘信息：&apos; for i in disk_io_counters(perdisk=True).items(): print i def get_net_info(): print &apos;网络情况：&apos; for i in net_io_counters(pernic=True).items(): print idef create_email(email_from, email_to, email_Subject, email_text, annex_path, annex_name): # 输入发件人昵称、收件人昵称、主题，正文，附件地址,附件名称生成一封邮件 #生成一个空的带附件的邮件实例 message = MIMEMultipart() #将正文以text的形式插入邮件中 message.attach(MIMEText(email_text, &apos;plain&apos;, &apos;utf-8&apos;)) #生成发件人名称（这个跟发送的邮件没有关系） message[&apos;From&apos;] = Header(email_from, &apos;utf-8&apos;) #生成收件人名称（这个跟接收的邮件也没有关系） message[&apos;To&apos;] = Header(email_to, &apos;utf-8&apos;) #生成邮件主题 message[&apos;Subject&apos;] = Header(email_Subject, &apos;utf-8&apos;) #读取附件的内容 att1 = MIMEText(open(annex_path, &apos;rb&apos;).read(), &apos;base64&apos;, &apos;utf-8&apos;) att1[&quot;Content-Type&quot;] = &apos;application/octet-stream&apos; #生成附件的名称 att1.add_header(&apos;Content-Disposition&apos;, u&apos;attachment&apos;, filename = (&quot;utf-8&quot;, &quot;&quot;,annex_name)) #att1[&quot;Content-Disposition&quot;] = add_header(&apos;attachment; filename=&apos; + annex_name) #att1[&quot;Content-Disposition&quot;] = &apos;attachment; filename=&apos; + annex_name #将附件内容插入邮件中 message.attach(att1) #返回邮件 return messagedef send_email(sender, password, receiver, msg): # 一个输入邮箱、密码、收件人、邮件内容发送邮件的函数 try: #找到你的发送邮箱的服务器地址，已加密的形式发送 server = smtplib.SMTP_SSL(&quot;smtp.exmail.qq.com&quot;, 465) # 发件人邮箱中的SMTP服务器 server.ehlo() #登录你的账号 server.login(sender, password) # 括号中对应的是发件人邮箱账号、邮箱密码 #发送邮件 server.sendmail(sender, receiver, msg.as_string()) # 括号中对应的是发件人邮箱账号、收件人邮箱账号（是一个列表）、邮件内容 print(&quot;邮件发送成功&quot;) server.quit() # 关闭连接 except Exception: print(traceback.print_exc()) print(&quot;邮件发送失败&quot;)session000 = date_2()session001 = cpu_usage_rate()session002 = os_load_average()session003 = memory_usage_rate()session004 = disk_info()session005 = process_info()session006 = new_error_file()session007 = mysql_status()session008 = mysql_backup_file()session009 = date_1()def main(): docx_into = &quot;/data/scripts/gbj_ls_checkos_template.docx&quot; docx_out = open(&quot;gbj_ls_checkos_&quot; + session000 + &quot;.docx&quot;,&apos;w&apos;) tpl=DocxTemplate(docx_into) sd = tpl.new_subdoc() context = &#123; &apos;output001&apos; : &quot;%s&quot; % session001, &apos;output002&apos; : &quot;%s&quot; % session002, &apos;output003&apos; : &quot;%s&quot; % session003, &apos;output004&apos; : &quot;%s&quot; % session004, &apos;output005&apos; : &quot;%s&quot; % session005, &apos;output006&apos; : &quot;%s&quot; % session006, &apos;output007&apos; : &quot;%s&quot; % session007, &apos;output008&apos; : &quot;%s&quot; % session008, &apos;output009&apos; : &quot;%s&quot; % session009, &#125; tpl.render(context) tpl.save(docx_out) my_email_from = &apos;我发&apos; my_email_to = &apos;你收&apos; # 邮件标题 my_email_Subject = &apos;巡检报告&apos; # 邮件正文 my_email_text = &quot;Dear all,\n\t附件为你猜猜是什么，请查收！\n\n我发的&quot; #附件地址 my_annex_path = &quot;gbj_ls_checkos_&quot; + session000 + &quot;.docx&quot; #附件名称 my_annex_name = &quot;gbj_ls_checkos__&quot; + session000 + &quot;.docx&quot; # 生成邮件 my_msg = create_email(my_email_from, my_email_to, my_email_Subject, my_email_text, my_annex_path, my_annex_name) my_sender = &apos;yunwei@actionsky.com&apos; my_password = &apos;Action!23&apos; #接收人邮箱列表 my_receiver = [&apos;fujinpeng@actionsky.com&apos;,&apos;dutingting@actionsky.com&apos;,&apos;meilei@actionsky.com&apos;] #发送邮件 send_email(my_sender, my_password, my_receiver, my_msg) print(datetime.datetime.now()) &apos;&apos;&apos; print &apos;—&apos;*100 hostname() print &apos;\n&apos; cpu_usage_rate() print &apos;\n&apos; os_load_average() print &apos;\n&apos; memory_usage_rate() print &apos;\n&apos; disk_info() print &apos;\n&apos; process_info() print &apos;\n&apos; new_error_file() print &apos;\n&apos; mysql_status() print &apos;\n&apos; mysql_backup_file() print &apos;\n&apos; mysql_backup() print &apos;\n&apos; get_net_info() print &apos;\n&apos; get_disk_info() print &apos;\n&apos; print date_1() print &apos;\n&apos; print date_2()&apos;&apos;&apos;if __name__ == &apos;__main__&apos;: main()]]></content>
      <categories>
        <category>Scripts</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Word</tag>
        <tag>邮件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB定时备份]]></title>
    <url>%2F2019%2F01%2F04%2FMongoDB%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[MongoDB数据备份在MongoDB中我们使用mongodump命令来备份MongoDB数据语法： mongodump -h dbhost --port dbport -u user -p password -d dbname --authenticationDatabase admin -o dbdirectory -h MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017，-h 127.0.0.1:27017等同于-h 127.0.0.1 –port 27017-d 需要备份的数据库实例，例如：test，没有指定即使备份全部数据库-o 备份的数据存放位置，例如：c:datadump，当然该目录需要提前建立，在备份完成后，系统自动在dump目录下建立一个test目录，这个目录里面存放该数据库实例的备份数据。-u -p 如果有设置用户和密码，需要设置对应的用户名和密码，否则没有权限–authenticationDatabase admin 验证权限 MongoDB数据恢复mongodb 使用 mongorestore 命令来恢复备份的数据 mongorestore -h &lt;hostname&gt;&lt;:port&gt; -d dbname &lt;path&gt; –host &lt;:port&gt;, -h &lt;:port&gt;：MongoDB所在服务器地址，默认为： localhost:27017–db , -d ：需要恢复的数据库实例，例如：test，当然这个名称也可以和备份时候的不一样，比如test2–drop：恢复的时候，先删除当前数据，然后恢复备份的数据。就是说，恢复后，备份后添加修改的数据都会被删除，慎用哦！ ：最后的一个参数，设置备份数据所在位置，例如：c:datadumptest。你不能同时指定 和 –dir 选项，–dir也可以设置备份目录。–dir：指定备份的目录不能同时指定 和 –dir 选项。 MongoDB定时备份Shell脚本编写脚步mongodb_bak.sh，脚本内容为12345678910111213141516171819202122232425262728293031323334#!/bin/shDUMP=/data/mongodb/bin/mongodump #mongodump备份文件执行路径OUT_DIR=/data/backup/mongodb_bak/baknow#临时备份目录TAR_DIR=/data/backup/mongodb_bak/baklist#备份存放路径DATE=`date +%Y%m%d` #获取当前系统时间DB_HOST=127.0.0.1#数据库地址DB_PORT=27017#数据库端口DB_USER=***#数据库账号DB_PASS=******#数据库密码DAYS=30#DAYS=30代表删除7天前的备份，即只保留最近7天的备份TAR_BAK="mongodb_bak_$DATE.tar.gz" #最终保存的数据库备份文件名cd $OUT_DIRrm -rf $OUT_DIR/*mkdir -p $OUT_DIR/$DATE$DUMP -h $DB_HOST --port $DB_PORT -u $DB_USER -p $DB_PASS --authenticationDatabase admin -o $OUT_DIR/$DATE#备份全部数据库tar -zcvP -f $TAR_DIR/$TAR_BAK $OUT_DIR/$DATE/*#压缩为.tar.gz格式find $TAR_DIR/ -mtime +$DAYS -delete #删除30天前的备份文件 脚本中的目录、host、port、user、password等需要根据实际情况自行修改，脚本放在/data/scripts目录下 创建对应的备份目录12mkdir -p /data/backup/mongodb_bak/baknowmkdir -p /data/backup/mongodb_bak/baklist 修改文件属性，使其可执行1chmod +x /data/scripts/mongodb_bak.sh 添加计划任务执行crontab -e添加130 1 * * * root /data/scripts/mongodb_bak.sh 其中计划任务是每天1点半执行备份任务crontab命令1234/sbin/service crond start /sbin/service crond stop /sbin/service crond restart /sbin/service crond reload 以上分别为重启服务、停止服务、启动服务、重新加载配置的命令修改过计划任务，需要执行restart或者reload]]></content>
      <categories>
        <category>DB</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>Shell</tag>
        <tag>定时任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix自动监控Windows端口]]></title>
    <url>%2F2018%2F12%2F29%2FZabbix%E8%87%AA%E5%8A%A8%E7%9B%91%E6%8E%A7Windows%E7%AB%AF%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[Windows服务端有需要监控的端口，主要监控处于LISTEN状态、协议为TCP的端口。 脚本首先编写脚本，脚本名为discovertcpport.bat，脚本内容如下1234567@echo offecho &#123;echo "data":[for /F "tokens=2 delims= " %%i IN ('netstat -anp tcp^|find /i "LISTENING"') DO for /F "tokens=2 delims=:" %%j IN ("%%i") DO echo &#123;"&#123;#LISTEN_PORT&#125;":"%%j"&#125;,echo &#123;"&#123;#LISTEN_PORT&#125;":"10050"&#125;echo ]echo &#125; 脚本说明：命令netstat -anp tcp ^|find /i &quot;LISTENING&quot;用来查看监听状态的TCP端口；for /F “tokens=2 delims= “表示循环输出的截取值，即每行以空格（delims=）分隔的第2段（token=2）值，以变量%%i输出；之后以同样的循环截取出端口号并格式化输出结果；这里的输出格式必须按JSON对象格式输出，否则报错“Value should be a JSON object”；特别要注意最后一行没有逗号，因此单独添加一行1echo &#123;"&#123;#LISTEN_PORT&#125;":"10050"&#125; 来结束，以满足JSON对象格式。 配置文件客户端的zabbix_agentd.conf中添加以下内容：12UnsafeUserParameters=1UserParameter=tcpportlisten,C:\zabbix_agents_3.0.10.win\discovertcpport.bat 说明：一条表示允许使用用户自定义参数，第二条设置用户参数，名称tcpportlisten是自定义的KEY名，后接KEY要执行的命令或脚本文件。 重新启动zabbix agentd服务12C:\zabbix_agents_3.0.10.win\bin\win64\zabbix_agentd.exe -c C:\zabbix_agents_3.0.10.win\conf\zabbix_agentd.win.conf -xC:\zabbix_agents_3.0.10.win\bin\win64\zabbix_agentd.exe -c C:\zabbix_agents_3.0.10.win\conf\zabbix_agentd.win.conf -s server端从server端尝试获取数据12345678910111213141516171819202122232425# /data/zabbix/bin/zabbix_get -s 172.16.92.251 -k Port_Low_Discovery&#123; "data":[ &#123;"&#123;#LISTEN_PORT&#125;":"22"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"80"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"135"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"443"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"445"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"593"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"3388"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"3389"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"5504"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"8122"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"10050"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"28000"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"28001"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"47001"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"49152"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"49153"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"49154"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"49155"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"139"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"10050"&#125; ]&#125; 可以看到获取了很多端口，这些端口有些是我们要监控的服务的端口，有些是系统主服务的端口，所以我们要过滤我们需要监控的端口。在zabbixserver的web界面去配置正则表达式。正则表达式如下图所示可以换个理解方式，只有在正则表达式中填写的端口号，zabbix才能去discovery。接下来配置模板和自发现准则，如下图所示下图为配置使用正则表达式来过滤获取到的端口Item prototypes配置如下Trigger prototypes配置如下 {Template OS Windows Port:net.tcp.listen[{#LISTEN_PORT}].count(#3,0,&quot;eq&quot;)}=3 表示三次获取信息为0即触发报警，Item prototypes配置时间为30秒，即90秒没有回应触发报警。这样配置是为了防止zabbixserver端和agent端通讯质量不好。]]></content>
      <categories>
        <category>Monitor</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
        <tag>Windows</tag>
        <tag>Port</tag>
        <tag>Discovery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop2.9.2源码编译]]></title>
    <url>%2F2018%2F12%2F27%2FHadoop2-9-2%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%2F</url>
    <content type="text"><![CDATA[官方对每个版本的hadoop提供了源码版本和二进制版本，但是官方提供的二进制版本是32位的，所以在安装hadoop时，为了更好的兼容系统位数和系统版本，或者添加Hadoop一些额外功能时，需要对Hadoop源码进行编译，本文以Hadoop2.9.2为例进行源码编译。 编译准备查看系统信息1234# cat /etc/redhat-release CentOS Linux release 7.6.1810 (Core) # uname -aLinux node-01 3.10.0-862.14.4.el7.x86_64 #1 SMP Wed Sep 26 15:12:11 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux 可以看到当前系统版本为centos7.6，64位，内核版本为3.10。 Hadoop下载下载地址：Hadoop2.9.2下载123tar -zxvf hadoop-2.9.2-src.tar.gzcd hadoop-2.9.2-srcless BUILDING.txt 可以看到所需编译环境 Requirements: * Unix System * JDK 1.7 or 1.8 * Maven 3.0 or later * Findbugs 1.3.9 (if running findbugs) * ProtocolBuffer 2.5.0 * CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac * Zlib devel (if compiling native code) * openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance) * Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs) * Internet connection for first build (to fetch all Maven and Hadoop dependencies) * python (for releasedocs) * Node.js / bower / Ember-cli (for YARN UI v2 building) 这是编译所需要的软件，包括： JDK1.7 or 1.8 maven 3.0 or later findbugs 1.3.9 protocolBuffer 2.5.0 cmake 2.6 zlib-devel openssl-devel 解决编译依赖需安装autoconf automake gcc等。 软件安装安装库文件yum -y install patch svn ncurses-devel gcc* yum -y install lzo-devel zlib-devel autoconf automake libtool cmake openssl-devel 安装JDK参考：CentOS上安装Java环境 安装Maven参考：CentOS上安装Maven 安装protocolBuffer概述：Google Protocol Buffer( 简称 Protobuf) 是 Google 公司内部的混合语言数据标准,Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 RPC 数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。目前提供了 C++、Java、Python 三种语言的 API。下载地址：protocol-buffers-2.5.0.tar.gz解压并编译安装1234567cd /data/backupwget https://github.com/protocolbuffers/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gztar -zxvf protobuf-2.5.0.tar.gzcd protobuf-2.5.0/./configuremakemake install 验证：输入protoc –version,有下面输出结果则安装并配置正确。12# protoc --versionlibprotoc 2.5.0 安装findbugs概述：FindBugs 是由马里兰大学提供的一款开源 Java静态代码分析工具。FindBugs通过检查类文件或 JAR文件，将字节码与一组缺陷模式进行对比从而发现代码缺陷，完成静态代码分析。下载地址：findbugs-1.3.9 下载解压123cd /data/backupwget https://jaist.dl.sourceforge.net/project/findbugs/findbugs/1.3.9/findbugs-1.3.9.tar.gztar -zxvf findbugs-1.3.9.tar.gz -C /data/findbugs1.3.9 配置环境变量1vim /etc/profile 末尾添加以下内容123#set findbugs environmentexport FINDBUGS_HOME=/data/findbugs1.3.9export PATH=$PATH:$FINDBUGS_HOME/bin 使环境变量生效1source /etc/profile (立即生效) 验证12# findbugs -version1.3.9 编译首先保证主机能上网，在编译过程中网络保持畅通；为了保证maven编译更顺畅，也可以更本地maven仓库地址更改为国内地址。进入到hadoop2.9.1源码的解压目录下，输入下面命令： # mvn package -Pdist,native -DskipTests -Dtar 或者 # mvn package -Pdist,native,docs,src -DskipTests -Dtar 前面只编译本地代码，后者编译本地代码和文档，因此前者速度较快。接下来开始等待出现如下界面表示编译成功编译好的文件在../hadoop-dist/target/hadoop-2.7.1.tar.gz下。 编译中的问题错误11Connection to http://repo.maven.apache.org refused 表示连接maven远程仓库拒绝，此时再运行一下编译命令，就会接着下载jar包。错误212[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hadoop-nfs: Compilation failure: Compilation failure:[ERROR] /data/backup/hadoop-2.9.2-src/hadoop-common-project/hadoop-nfs/src/main/java/org/apache/hadoop/oncrpc/XDR.java:[23,30] package org.jboss.netty.buffer does not exist 这个错误估计很少遇到，这是因为更换的仓库地址不能用，恢复成默认的仓库地址就好，虽然有点慢。错误312[ERROR] around Ant part ...&lt;exec dir="/data/backup/hadoop-2.9.2-src/hadoop-hdfs-project/hadoop-hdfs-httpfs/target" executable="sh" failonerror="true"&gt;... @ 10:123 in /data/backup/hadoop-2.9.2-src/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/antrun/build-main.xml[ERROR] -&gt; [Help 1] 这是由于tomcat的apache-tomcat-6.0.41.tar.gz包太大，没有下载完整，可以到…/hadoop-2.9.2-src/hadoop-hdfs-project/hadoop-hdfs-httpfs/downloads/apache-tomcat-6.0.41.tar.gz这个目录下，删除重新下载。提醒： 有时候编译过程中会出现下载某个包的时间太久，这是由于连接网站的过程中会出现假死，此时按ctrl+c，重新运行编译命令。 如果出现缺少了某个文件的情况，则要先清理maven(使用命令 mvn clean) 再重新编译。]]></content>
      <categories>
        <category>BigData</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>编译</tag>
        <tag>Maven</tag>
        <tag>Protobuf</tag>
        <tag>FindBugs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据离线-Hadoop入门]]></title>
    <url>%2F2018%2F12%2F26%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF-Hadoop%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Hadoop介绍一般我们讲的Hadoop分为狭义和广义两部分 狭义上讲Hadoop 指 Apache 这款开源框架Hadoop 是 Apache 旗下的一个用 java 语言实现开源软件框架， 是一个开发和运行处理大规模数据的软件平台。 允许使用简单的编程模型在大量计算机集群上对大型数据集进行分布式处理。它的核心组件有： HDFS（分布式文件系统）：解决海量数据存储 YARN（作业调度和集群资源管理的框架）：解决资源任务调度 MAPREDUCE（分布式运算编程框架）： 解决海量数据计算 广义上讲Hadoop 通常是指一个更广泛的概念——Hadoop 生态圈。当下的 Hadoop 已经成长为一个庞大的体系，随着生态系统的成长，新出现的项目越来越多，其中不乏一些非 Apache 主管的项目，这些项目对 HADOOP 是很好的补充或者更高层的抽象。 比如： HDFS：分布式文件系统 MAPREDUCE：分布式运算程序开发框架 HIVE：基于 HADOOP 的分布式数据仓库，提供基于 SQL 的查询数据操作 HBASE：基于 HADOOP 的分布式海量数据库 ZOOKEEPER：分布式协调服务基础组件 Mahout：基于 mapreduce/spark/flink 等分布式运算框架的机器学习算法库 Oozie：工作流调度框架 Sqoop：数据导入导出工具（比如用于 mysql 和 HDFS 之间） Flume：日志数据采集框架 Impala： 基于 Hadoop 的实时分析 Hadoop发展历史 Hadoop 是 Apache Lucene 创始人 Doug Cutting 创建的。最早起源于 Nutch，它是 Lucene 的子项目。 Nutch 的设计目标是构建一个大型的全网搜索引擎，包括网页抓取、索引、查询等功能，但随着抓取网页数量的增加，遇到了严重的可扩展性问题： 如何解决数十亿网页的存储和索引问题。 2003 年 Google 发表了一篇论文为该问题提供了可行的解决方案。 论文中描述的是谷歌的产品架构，该架构称为： 谷歌分布式文件系统（GFS） ,可以解决他们在网页爬取和索引过程中产生的超大文件的存储需求。 2004 年 Google 发表论文向全世界介绍了谷歌版的 MapReduce 系统。同时期， Nutch 的开发人员完成了相应的开源实现 HDFS 和 MAPREDUCE，并从Nutch 中剥离成为独立项目 HADOOP，到 2008 年 1 月， HADOOP 成为 Apache 顶级项目，迎来了它的快速发展期。 2006 年 Google 发表了论文是关于 BigTable 的，这促使了后来的 Hbase 的发展。 因此， Hadoop 及其生态圈的发展离不开 Google 的贡献。 Hadoop的特点1、扩容能力Hadoop 是在可用的计算机集群间分配数据并完成计算任务的，这些集群可用方便的扩展到数以千计的节点中。2、成本低Hadoop 通过普通廉价的机器组成服务器集群来分发以及处理数据，以至于成本很低。3、高效率通过并发数据， Hadoop 可以在节点之间动态并行的移动数据，使得速度非常快。4、可靠性能自动维护数据的多份复制，并且在任务失败后能自动地重新部署（redeploy）计算任务。所以 Hadoop 的按位存储和处理数据的能力值得人们信赖。 Hadoop 国内外应用不管是国内还是国外， Hadoop 最受青睐的行业是互联网领域， 可以说互联网公司是 hadoop 的主要使用力量。国外应用 Yahoo 的 Hadoop 应用在支持广告系统、 用户行为分析、 支持 Web 搜索等。 Facebook 主要使用 Hadoop 存储内部日志与多维数据，并以此作为报告、分析和机器学习的数据源。 国内应用国内来说，BAT领头的互联网公司是当仁不让的 Hadoop 使用者、维护者。比如 Ali 云梯（14 年国内最大 Hadoop 集群）、百度的日志分析平台、推荐引擎系统等。国内其他非互联网领域也有不少 hadoop 的应用，比如： 金融行业： 个人征信分析 证券行业： 投资模型分析 交通行业： 车辆、路况监控分析 电信行业： 用户上网行为分析 总之： hadoop 并不会跟某种具体的行业或者某个具体的业务挂钩，它只是一种用来做海量数据分析处理的工具。 Hadoop集群搭建发行版本Hadoop 发行版本分为开源社区版和商业版。 社区版是指由 Apache 软件基金会维护的版本，是官方维护的版本体系。 商业版 Hadoop 是指由第三方商业公司在社区版 Hadoop 基础上进行了一些修改、整合以及各个服务组件兼容性测试而发行的版本， 比较著名的有 cloudera 的 CDH、 mapR 等。 我们介绍的是社区版： Apache Hadoop。 后续如未说明都是指 Apache 版。Hadoop 的版本很特殊，是由多条分支并行的发展着。 大的来看分为 3 个大的系列版本： 1.x、 2.x、 3.x。 Hadoop1.0 由一个分布式文件系统 HDFS 和一个离线计算框架 MapReduce 组成。 Hadoop 2.0 则包含一个支持 NameNode 横向扩展的 HDFS，一个资源管理系统YARN 和一个运行在 YARN 上的离线计算框架 MapReduce。相比于 Hadoop1.0，Hadoop 2.0 功能更加强大，且具有更好的扩展性、性能，并支持多种计算框架。 Hadoop 3.0 相比之前的 Hadoop 2.0 有一系列的功能增强。但目前还是个alpha 版本，有很多 bug，且不能保证 API 的稳定和质量。 当前 2 系列最稳定版本： Apache Hadoop 2.9.2。 集群介绍HADOOP 集群具体来说包含两个集群：HDFS集群和YARN集群，两者逻辑上分 离，但物理上常在一起。 HDFS 集群负责海量数据的存储，集群中的角色主要有：NameNode、 DataNode、 SecondaryNameNode YARN 集群负责海量数据运算时的资源调度，集群中的角色主要有：ResourceManager、 NodeManager mapreduce 是一个分布式运算编程框架，是应用程序开发包，由用户按照编程规范进行程序开发，后打包运行在 HDFS 集群上，并且受到 YARN 集群的资源调度管理。 Hadoop 部署方式分三种: 独立模式又称为单机模式， 仅 1 个机器运行 1 个 java 进程，主要用于调试。(单机) 伪分布模式也是在 1 个机器上运行 HDFS 的 NameNode 和 DataNode、 YARN 的ResourceManger 和 NodeManager， 但分别启动单独的 java 进程，主要用于调试。（单机） 集群模式主要用于生产环境部署。 会使用 N 台主机组成一个 Hadoop 集群。这种部署模式下， 主节点和从节点会分开部署在不同的机器上。 我们以 3 节点为例进行搭建，角色分配如下：角色分配如下： node-01 NameNode DataNode ResourceManager node-02 DataNode NodeManager SecondaryNameNode node-03 DataNode NodeManager 集群安装服务器准备node-01 10.186.60.12 node-02 10.186.60.60 node-03 10.186.65.43 服务器系统设置同步时间 #手动同步集群各机器时间 12date -s "2017-03-03 03:03:03"yum install ntpdate #网络同步时间 1ntpdate ntp6.aliyun.com 设置主机名 Linux主机名设置1vim /etc/hosts 输入内容 10.186.60.12 node-01 10.186.60.60 node-02 10.186.65.43 node-03 window主机名映射地址：C:\Windows\System32\drivers\etc修改hosts文件，添加内容 192.168.33.101 node-01 192.168.33.102 node-02 192.168.33.103 node-03 配置 ssh 免密登陆生成 ssh 免登陆密钥1ssh-keygen -t rsa （四个回车） 执行完这个命令后，会生成 id_rsa（私钥）、 id_rsa.pub（公钥）将公钥拷贝到要免密登陆的目标机器上12ssh-copy-id node-02ssh-copy-id node-03 配置防火墙查看防火墙状态 service iptables status关闭防火墙 service iptables stop查看防火墙开机启动状态 chkconfig iptables –list关闭防火墙开机启动 chkconfig iptables off JDK环境安装 上传 jdk 安装包 jdk-8u161-linux-x64.tar.gz 解压安装包 tar -zxvf jdk-8u161-linux-x64.tar.gz -C /data/jdk1.8 配置环境变量 vim /etc/profile 插入下面的内容 123export JAVA_HOME=/data/jdk1.8export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 刷新配置:source /etc/profile Hadoop 安装首先我们要有一版是适合我们系统版本的hadoop，所以我们需要编译。为什么要编译以及如何编译参考：Hadoop2.9.2源码编译 上传hadoop,解压hadoop-2.9.2-with-centos7.6.tar.gzhadoop的目录结构1234567891011121314# pwd/data/hadoop/hadoop-2.9.2[root@node-01 hadoop-2.9.2]# lltotal 128drwxr-xr-x 2 root root 194 Dec 27 03:45 bindrwxr-xr-x 3 root root 20 Dec 27 03:45 etcdrwxr-xr-x 2 root root 106 Dec 27 03:45 includedrwxr-xr-x 3 root root 20 Dec 27 03:45 libdrwxr-xr-x 2 root root 239 Dec 27 03:45 libexec-rw-r--r-- 1 root root 106210 Dec 27 03:45 LICENSE.txt-rw-r--r-- 1 root root 15917 Dec 27 03:45 NOTICE.txt-rw-r--r-- 1 root root 1366 Dec 27 03:45 README.txtdrwxr-xr-x 3 root root 4096 Dec 27 03:45 sbindrwxr-xr-x 4 root root 31 Dec 27 03:45 share bin： Hadoop 最基本的管理脚本和使用脚本的目录，这些脚本是 sbin 目录下管理脚本的基础实现，用户可以直接使用这些脚本管理和使用 Hadoop。 etc： Hadoop 配置文件所在的目录，包括 core-site,xml、 hdfs-site.xml、mapred-site.xml 等从 Hadoop1.0 继承而来的配置文件和 yarn-site.xml Hadoop2.0 新增的配置文件。 include：对外提供的编程库头文件（具体动态库和静态库在 lib 目录中），这些头文件均是用 C++定义的，通常用于 C++程序访问 HDFS 或者编写 MapReduce程序。 lib：该目录包含了 Hadoop 对外提供的编程动态库和静态库，与 include 目录中的头文件结合使用。 libexec：各个服务对用的 shell 配置文件所在的目录，可用于配置日志输出、启动参数（比如 JVM 参数）等基本信息。 sbin： Hadoop 管理脚本所在的目录，主要包含 HDFS 和 YARN 中各类服务的启动/关闭脚本。 share： Hadoop 各个模块编译后的 jar 包所在的目录。 Hadoop配置文件修改Hadoop 安装主要就是配置文件的修改， 一般在主节点进行修改，完毕后 scp下发给其他各个从节点机器。下面的文件都在 hadoop的etc/hadoop目录下： 修改hadoop-env.sh文件，更改 1export JAVA_HOME=$&#123;JAVA_HOME&#125; 为1export JAVA_HOME=/data/jdk1.8 此处JAVA_HOME为JDK的位置。 修改core-site.xml文件，在configuration中增加代码 1234567891011121314&lt;configuration&gt;&lt;!-- 用于设置 Hadoop 的文件系统，由 URI 指定 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://node-1:9000&lt;/value&gt; &lt;/property&gt;&lt;!-- 配置 Hadoop 的临时目录,默认/tmp/hadoop-$&#123;user.name&#125; --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/export/data/hadoopData&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改hdfs-site.xml，在configuration中增加代码 123456789101112&lt;configuration&gt;&lt;!-- 指定 HDFS 副本的数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt;&lt;!-- secondary namenode 所在主机的 ip 和端口-&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;node-02:50090&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改mapred-site.xml的，configuration中增加代码 1234567&lt;configuration&gt;&lt;!-- 指定 mr 运行时框架，这里指定在 yarn 上，默认是 local --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改yarn-site.xml的，configuration中增加代码 123456789101112&lt;configuration&gt;&lt;!-- 指定 YARN 的老大（ ResourceManager）的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;node-1&lt;/value&gt; &lt;/property&gt;&lt;!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序默认值： "" --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 创建slaves文件，如果存在进行编辑，删除locahost，增加文件 123node-1node-2node-3 将hadoop添加到环境变量 ，命令vim /etc/proflie 12export HADOOP_HOME=/data/hadoop/hadoop-2.9.2export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 保存配置文件，刷新配置文件：source /etc/profile 集群启动 启动方式 要启动 Hadoop 集群，需要启动 HDFS 和 YARN 两个集群。注意： 首次启动 HDFS 时，必须对其进行格式化操作。 本质上是一些清理和准备工作，因为此时的 HDFS 在物理上还是不存在的。hdfs namenode –format或者hadoop namenode –format 单节点逐个启动 1、在主节点上使用以下命令启动 HDFS NameNode：hadoop-daemon.sh start namenode2、在每个从节点上使用以下命令启动 HDFS DataNode：hadoop-daemon.sh start datanode3、在主节点上使用以下命令启动 YARN ResourceManager：yarn-daemon.sh start resourcemanager4、在每个从节点上使用以下命令启动 YARN nodemanager：yarn-daemon.sh start nodemanager以上脚本位于$HADOOP_PREFIX/sbin/目录下。 如果想要停止某个节点上某个角色，只需要把命令中的 start 改为 stop 即可。 脚本一键启动 如果配置了 etc/hadoop/slaves 和 ssh 免密登录，则可以使用程序脚本启动所有 Hadoop 两个集群的相关进程，在主节点所设定的机器上执行。hdfs： /sbin/start-dfs.shyarn: /sbin/start-yarn.sh停止集群： stop-dfs.sh、 stop-yarn.sh集群 web-ui一旦 Hadoop 集群启动并运行， 可以通过 web-ui 进行集群查看，如下所述：node-1:50070 HDFS的NameNode节点node-1:8088 YARN的主页 Hadoop初体验上传文件 从 Linux 本地上传一个文本文件到 hdfs 的/test/input 目录下 hadoop fs -mkdir -p /wordcount/input 创建文件夹 hadoop fs -put /root/somewords.txt /wordcount/input Linux上传到hadoop 运行程序 运行 mapreduce 程序 在 Hadoop 安装包的 hadoop-2.7.4/share/hadoop/mapreduce 下有官方自带的 mapreduce 程序。 我们可以使用如下的命令进行运行测试。示例程序 jar: hadoop-mapreduce-examples-2.7.4.jar 计算圆周率 计算圆周率: hadoop jar hadoop-mapreduce-examples-2.7.4.jar pi 20 50 这里使用的是Monte Carlo 方法来计算 Pi 值 使用Monte Carlo 计算圆周率]]></content>
      <categories>
        <category>BigData</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker容器进入的4种方式]]></title>
    <url>%2F2018%2F12%2F25%2FDocker%E5%AE%B9%E5%99%A8%E8%BF%9B%E5%85%A5%E7%9A%844%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[进入Docker容器比较常见的几种做法如下： 使用docker attach 使用SSH 使用nsenter 使用exec 一、使用docker attach进入Docker容器Docker提供了attach命令来进入Docker容器。创建一个守护态的Docker容器，然后使用docker attach命令进入该容器。过程如下：1234567891011# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest 568c4670fa80 4 weeks ago 109MBghost latest dffc1260f5f5 4 weeks ago 814MB# docker run -itd nginx /bin/bash 85c99fad833008a67114dab7f774e091e7286a58d13278dc984544e18eb5bf91# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES85c99fad8330 nginx "/bin/bash" 5 seconds ago Up 4 seconds 80/tcp cranky_hamilton# docker attach 85c99fad8330root@85c99fad8330:/# 可以看到我们已经进入到该容器中了。但在，使用该命令有一个问题。当多个窗口同时使用该命令进入该容器时，所有的窗口都会同步显示。如果有一个窗口阻塞了，那么其他窗口也无法再进行操作。因为这个原因，所以docker attach命令不太适合于生产环境，平时自己开发应用时可以使用该命令。 二、使用SSH进入Docker容器在生产环境中排除了使用docker attach命令进入容器之后，相信大家第一个想到的就是ssh。在镜像（或容器）中安装SSH Server，这样就能保证多人进入容器且相互之间不受干扰了，相信大家在当前的生产环境中（没有使用Docker的情况）也是这样做的。但是使用了Docker容器之后不建议使用ssh进入到Docker容器内。请参考文章：为什么不需要在 Docker 容器中运行 sshd 三、使用nsenter进入Docker容器在上面两种方式都不适合的情况下，还有一种比较方便的方法，即使用nsenter进入Docker容器。关于什么是nsenter请参考如下文章：https://github.com/jpetazzo/nsenter在了解了什么是nsenter之后，系统默认将我们需要的nsenter安装到主机中如果没有安装的话，按下面步骤安装即可（注意是主机而非容器或镜像）下载地址：https://mirrors.edge.kernel.org/pub/linux/utils/util-linux/选择最新版本，具体的安装命令如下： 123456wget https://mirrors.edge.kernel.org/pub/linux/utils/util-linux/v2.33/util-linux-2.33.tar.gztar -zxvf util-linux-2.33.tar.gz cd util-linux-2.33./configure --without-ncursesmake nsentercp nsenter /usr/local/bin 安装好nsenter之后可以查看一下该命令的使用。12345678910111213141516171819202122232425262728# nsenter --helpUsage: nsenter [options] [&lt;program&gt; [&lt;argument&gt;...]]Run a program with namespaces of other processes.Options: -a, --all enter all namespaces -t, --target &lt;pid&gt; target process to get namespaces from -m, --mount[=&lt;file&gt;] enter mount namespace -u, --uts[=&lt;file&gt;] enter UTS namespace (hostname etc) -i, --ipc[=&lt;file&gt;] enter System V IPC namespace -n, --net[=&lt;file&gt;] enter network namespace -p, --pid[=&lt;file&gt;] enter pid namespace -C, --cgroup[=&lt;file&gt;] enter cgroup namespace -U, --user[=&lt;file&gt;] enter user namespace -S, --setuid &lt;uid&gt; set uid in entered namespace -G, --setgid &lt;gid&gt; set gid in entered namespace --preserve-credentials do not touch uids or gids -r, --root[=&lt;dir&gt;] set the root directory -w, --wd[=&lt;dir&gt;] set the working directory -F, --no-fork do not fork before exec'ing &lt;program&gt; -h, --help display this help -V, --version display versionFor more details see nsenter(1). 连接容器的格式 nsenter --target $PID --mount --uts --ipc --net --pid 容器的PID如何获取 PID=$(docker inspect --format &quot;{{ .State.Pid}}&quot; &lt;container id&gt;) 示例12345678# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa409b84edf94 nginx "nginx -g 'daemon of…" 50 seconds ago Up 49 seconds 80/tcp nginx02# docker inspect --format "&#123;&#123; .State.Pid&#125;&#125;" a409b84edf948335# nsenter --target 8335 --mount --uts --ipc --net --pidroot@a409b84edf94:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 如果觉得查找PID过程麻烦可以使用shell脚本docker-enter，内容如下：1234567891011121314151617181920212223242526272829303132#!/bin/shif [ -e $(dirname "$0")/nsenter ]; then # with boot2docker, nsenter is not in the PATH but it is in the same folder NSENTER=$(dirname "$0")/nsenterelse NSENTER=nsenterfiif [ -z "$1" ]; then echo "Usage: `basename "$0"` CONTAINER [COMMAND [ARG]...]" echo "" echo "Enters the Docker CONTAINER and executes the specified COMMAND." echo "If COMMAND is not specified, runs an interactive shell in CONTAINER."else PID=$(docker inspect --format "&#123;&#123;.State.Pid&#125;&#125;" "$1") if [ -z "$PID" ]; then exit 1 fi shift OPTS="--target $PID --mount --uts --ipc --net --pid --" if [ -z "$1" ]; then # No command given. # Use su to clear all host environment variables except for TERM, # initialize the environment variables HOME, SHELL, USER, LOGNAME, PATH, # and start a login shell. "$NSENTER" $OPTS su - root else # Use env to clear all host environment variables. "$NSENTER" $OPTS env --ignore-environment -- "$@" fifi 增加执行权限chmod +x docker-enter，运行docker-enter &lt;container id&gt;，这样就进入到指定的容器中。 四、使用docker exec进入Docker容器除了上面几种做法之外，docker在1.3.X版本之后还提供了一个新的命令exec用于进入容器，这种方式相对更简单一些，下面我们来看一下该命令的使用：123456789101112131415# docker exec --helpUsage: docker exec [OPTIONS] CONTAINER COMMAND [ARG...]Run a command in a running containerOptions: -d, --detach Detached mode: run command in the background --detach-keys string Override the key sequence for detaching a container -e, --env list Set environment variables -i, --interactive Keep STDIN open even if not attached --privileged Give extended privileges to the command -t, --tty Allocate a pseudo-TTY -u, --user string Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;]) -w, --workdir string Working directory inside the container 示例1234567# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa409b84edf94 nginx "nginx -g 'daemon of…" 24 minutes ago Up 24 minutes 80/tcp nginx02# docker exec -it a409b84edf94 /bin/bashroot@a409b84edf94:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr varroot@a409b84edf94:/#]]></content>
      <categories>
        <category>VT</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile命令详解]]></title>
    <url>%2F2018%2F12%2F25%2FDockerfile%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Dockerfile 指令详解1 FROM 指定基础镜像FROM 指令用于指定其后构建新镜像所使用的基础镜像。FROM 指令必是 Dockerfile 文件中的首条命令，启动构建流程后，Docker 将会基于该镜像构建新镜像，FROM 后的命令也会基于这个基础镜像。 FROM语法格式为： FROM &lt;image&gt; 或 FROM &lt;image&gt;:&lt;tag&gt; 或 FROM &lt;image&gt;:&lt;digest&gt; 通过 FROM 指定的镜像，可以是任何有效的基础镜像。FROM 有以下限制： FROM 必须 是 Dockerfile 中第一条非注释命令 在一个 Dockerfile 文件中创建多个镜像时，FROM 可以多次出现。只需在每个新命令 FROM 之前，记录提交上次的镜像 ID。 tag 或 digest 是可选的，如果不使用这两个值时，会使用 latest 版本的基础镜像 2 RUN 执行命令在镜像的构建过程中执行特定的命令，并生成一个中间镜像。格式: #shell格式 RUN &lt;command&gt; #exec格式 RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] RUN 命令将在当前 image 中执行任意合法命令并提交执行结果。命令执行提交后，就会自动执行 Dockerfile 中的下一个指令。 层级 RUN 指令和生成提交是符合 Docker 核心理念的做法。它允许像版本控制那样，在任意一个点，对 image 镜像进行定制化构建。 RUN 指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定 –no-cache 参数，如：docker build –no-cache。 3 COPY 复制文件格式： COPY &lt;源路径&gt;... &lt;目标路径&gt; COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 和 RUN 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。COPY 指令将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置。比如： COPY package.json /usr/src/app/ &lt;源路径&gt;可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则，如： COPY hom* /mydir/ COPY hom?.txt /mydir/ &lt;目标路径&gt;可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。 此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。 4 ADD 更高级的复制文件ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。比如&lt;源路径&gt;可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到&lt;目标路径&gt;去。 在构建镜像时，复制上下文中的文件到镜像内，格式： ADD &lt;源路径&gt;... &lt;目标路径&gt; ADD [&quot;&lt;源路径&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 注意如果 docker 发现文件内容被改变，则接下来的指令都不会再使用缓存。关于复制文件时需要处理的/，基本跟正常的 copy 一致 5 ENV 设置环境变量格式有两种： ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 ENV VERSION=1.0 DEBUG=on \ NAME=&quot;Happy Feet&quot; 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。 6 EXPOSE为构建的镜像设置监听端口，使容器在运行时监听。格式： EXPOSE &lt;port&gt; [&lt;port&gt;...] EXPOSE 指令并不会让容器监听 host 的端口，如果需要，需要在 docker run 时使用 -p、-P 参数来发布容器端口到 host 的某个端口上。 7 VOLUME 定义匿名卷VOLUME用于创建挂载点，即向基于所构建镜像创始的容器添加卷： VOLUME [&quot;/data&quot;] 一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能： 卷可以容器间共享和重用 容器并不一定要和其它容器共享卷 修改卷后会立即生效 对卷的修改不会对镜像产生影响 卷会一直存在，直到没有任何容器在使用它 VOLUME 让我们可以将源代码、数据或其它内容添加到镜像中，而又不并提交到镜像中，并使我们可以多个容器间共享这些内容。 8 WORKDIR 指定工作目录WORKDIR用于在容器内设置一个工作目录： WORKDIR /path/to/workdir 通过WORKDIR设置工作目录后，Dockerfile 中其后的命令 RUN、CMD、ENTRYPOINT、ADD、COPY 等命令都会在该目录下执行。 如，使用WORKDIR设置工作目录： WORKDIR /a WORKDIR b WORKDIR c RUN pwd 在以上示例中，pwd 最终将会在 /a/b/c 目录中执行。在使用 docker run 运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。 9 USER 指定当前用户USER 用于指定运行镜像所使用的用户： USER daemon 使用USER指定用户时，可以使用用户名、UID 或 GID，或是两者的组合。以下都是合法的指定试： USER user USER user:group USER uid USER uid:gid USER user:gid USER uid:group 使用USER指定用户后，Dockerfile 中其后的命令 RUN、CMD、ENTRYPOINT 都将使用该用户。镜像构建完成后，通过 docker run 运行容器时，可以通过 -u 参数来覆盖所指定的用户。 10 CMDCMD用于指定在容器启动时所要执行的命令。CMD 有以下三种格式： CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] CMD [&quot;param1&quot;,&quot;param2&quot;] CMD command param1 param2 省略可执行文件的 exec 格式，这种写法使 CMD 中的参数当做 ENTRYPOINT 的默认参数，此时 ENTRYPOINT 也应该是 exec 格式，具体与 ENTRYPOINT 的组合使用，参考 ENTRYPOINT。注意与 RUN 指令的区别：RUN 在构建的时候执行，并生成一个新的镜像，CMD 在容器运行的时候执行，在构建时不进行任何操作。 11 ENTRYPOINTENTRYPOINT 用于给容器配置一个可执行程序。也就是说，每次使用镜像创建容器时，通过 ENTRYPOINT 指定的程序都会被设置为默认程序。ENTRYPOINT 有以下两种形式： ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] ENTRYPOINT command param1 param2 ENTRYPOINT 与 CMD 非常类似，不同的是通过docker run执行的命令不会覆盖 ENTRYPOINT，而docker run命令中指定的任何参数，都会被当做参数再次传递给 ENTRYPOINT。Dockerfile 中只允许有一个 ENTRYPOINT 命令，多指定时会覆盖前面的设置，而只执行最后的 ENTRYPOINT 指令。 docker run运行容器时指定的参数都会被传递给 ENTRYPOINT ，且会覆盖 CMD 命令指定的参数。如，执行docker run &lt;image&gt; -d时，-d 参数将被传递给入口点。 也可以通过docker run –entrypoint重写 ENTRYPOINT 入口点。如：可以像下面这样指定一个容器执行程序： ENTRYPOINT [&quot;/usr/bin/nginx&quot;] 完整构建代码： # Version: 0.0.3 FROM ubuntu:16.04 MAINTAINER 何民三 &quot;cn.liuht@gmail.com&quot; RUN apt-get update RUN apt-get install -y nginx RUN echo &apos;Hello World, 我是个容器&apos; \ &gt; /var/www/html/index.html ENTRYPOINT [&quot;/usr/sbin/nginx&quot;] EXPOSE 80 使用docker build构建镜像，并将镜像指定为 itbilu/test： docker build -t=&quot;itbilu/test&quot; . 构建完成后，使用itbilu/test启动一个容器： docker run -i -t itbilu/test -g &quot;daemon off;&quot; 在运行容器时，我们使用了 -g “daemon off;”，这个参数将会被传递给 ENTRYPOINT，最终在容器中执行的命令为 /usr/sbin/nginx -g “daemon off;”。 12 LABELLABEL用于为镜像添加元数据，元数以键值对的形式指定： LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ... 使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。 如，通过LABEL指定一些元数据： LABEL version=&quot;1.0&quot; description=&quot;这是一个Web服务器&quot; by=&quot;IT笔录&quot; 指定后可以通过docker inspect查看： docker inspect itbilu/test &quot;Labels&quot;: { &quot;version&quot;: &quot;1.0&quot;, &quot;description&quot;: &quot;这是一个Web服务器&quot;, &quot;by&quot;: &quot;IT笔录&quot; }, 13 ARGARG用于指定传递给构建运行时的变量： ARG &lt;name&gt;[=&lt;default value&gt;] 如，通过ARG指定两个变量： ARG site ARG build_user=IT笔录 以上我们指定了 site 和 build_user 两个变量，其中 build_user 指定了默认值。在使用 docker build 构建镜像时，可以通过 –build-arg = 参数来指定或重设置这些变量的值。 docker build --build-arg site=itiblu.com -t itbilu/test . 这样我们构建了 itbilu/test 镜像，其中site会被设置为 itbilu.com，由于没有指定 build_user，其值将是默认值 IT 笔录。 14 ONBUILDONBUILD用于设置镜像触发器： ONBUILD [INSTRUCTION] 当所构建的镜像被用做其它镜像的基础镜像，该镜像中的触发器将会被钥触发。 如，当镜像被使用时，可能需要做一些处理： [...] ONBUILD ADD . /app/src ONBUILD RUN /usr/local/bin/python-build --dir /app/src [...] 15 STOPSIGNALSTOPSIGNAL用于设置停止容器所要发送的系统调用信号： STOPSIGNAL signal 所使用的信号必须是内核系统调用表中的合法的值，如：SIGKILL。 16 SHELLSHELL用于设置执行命令（shell式）所使用的的默认 shell 类型： SHELL [&quot;executable&quot;, &quot;parameters&quot;] SHELL在Windows环境下比较有用，Windows 下通常会有 cmd 和 powershell 两种 shell，可能还会有 sh。这时就可以通过 SHELL 来指定所使用的 shell 类型： FROM microsoft/windowsservercore # Executed as cmd /S /C echo default RUN echo default # Executed as cmd /S /C powershell -command Write-Host default RUN powershell -command Write-Host default # Executed as powershell -command Write-Host hello SHELL [&quot;powershell&quot;, &quot;-command&quot;] RUN Write-Host hello # Executed as cmd /S /C echo hello SHELL [&quot;cmd&quot;, &quot;/S&quot;&quot;, &quot;/C&quot;] RUN echo hello Dockerfile 使用经验Dockerfile 示例构建Nginx运行环境Dockerfile文件 # 指定基础镜像 FROM sameersbn/ubuntu:14.04.20161014 # 维护者信息 MAINTAINER sameer@damagehead.com # 设置环境 ENV RTMP_VERSION=1.1.10 \ NPS_VERSION=1.11.33.4 \ LIBAV_VERSION=11.8 \ NGINX_VERSION=1.10.1 \ NGINX_USER=www-data \ NGINX_SITECONF_DIR=/etc/nginx/sites-enabled \ NGINX_LOG_DIR=/var/log/nginx \ NGINX_TEMP_DIR=/var/lib/nginx \ NGINX_SETUP_DIR=/var/cache/nginx # 设置构建时变量，镜像建立完成后就失效 ARG BUILD_LIBAV=false ARG WITH_DEBUG=false ARG WITH_PAGESPEED=true ARG WITH_RTMP=true # 复制本地文件到容器目录中 COPY setup/ ${NGINX_SETUP_DIR}/ RUN bash ${NGINX_SETUP_DIR}/install.sh # 复制本地配置文件到容器目录中 COPY nginx.conf /etc/nginx/nginx.conf COPY entrypoint.sh /sbin/entrypoint.sh # 运行指令 RUN chmod 755 /sbin/entrypoint.sh # 允许指定的端口 EXPOSE 80/tcp 443/tcp 1935/tcp # 指定网站目录挂载点 VOLUME [&quot;${NGINX_SITECONF_DIR}&quot;] ENTRYPOINT [&quot;/sbin/entrypoint.sh&quot;] CMD [&quot;/usr/sbin/nginx&quot;] 构建Tomcat环境Dockerfile文件 # 指定基于的基础镜像 FROM ubuntu:13.10 # 维护者信息 MAINTAINER zhangjiayang &quot;zhangjiayang@sczq.com.cn&quot; # 镜像的指令操作 # 获取APT更新的资源列表 RUN echo &quot;deb http://archive.ubuntu.com/ubuntu precise main universe&quot;&gt; /etc/apt/sources.list # 更新软件 RUN apt-get update # Install curl RUN apt-get -y install curl # Install JDK 7 RUN cd /tmp &amp;&amp; curl -L &apos;http://download.oracle.com/otn-pub/java/jdk/7u65-b17/jdk-7u65-linux-x64.tar.gz&apos; -H &apos;Cookie: oraclelicense=accept-securebackup-cookie; gpw_e24=Dockerfile&apos; | tar -xz RUN mkdir -p /usr/lib/jvm RUN mv /tmp/jdk1.7.0_65/ /usr/lib/jvm/java-7-oracle/ # Set Oracle JDK 7 as default Java RUN update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-7-oracle/bin/java 300 RUN update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java-7-oracle/bin/javac 300 # 设置系统环境 ENV JAVA_HOME /usr/lib/jvm/java-7-oracle/ # Install tomcat7 RUN cd /tmp &amp;&amp; curl -L &apos;http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.8/bin/apache-tomcat-7.0.8.tar.gz&apos; | tar -xz RUN mv /tmp/apache-tomcat-7.0.8/ /opt/tomcat7/ ENV CATALINA_HOME /opt/tomcat7 ENV PATH $PATH:$CATALINA_HOME/bin # 复件tomcat7.sh到容器中的目录 ADD tomcat7.sh /etc/init.d/tomcat7 RUN chmod 755 /etc/init.d/tomcat7 # Expose ports. 指定暴露的端口 EXPOSE 8080 # Define default command. ENTRYPOINT service tomcat7 start &amp;&amp; tail -f /opt/tomcat7/logs/catalina.out tomcat7.sh命令文件 export JAVA_HOME=/usr/lib/jvm/java-7-oracle/ export TOMCAT_HOME=/opt/tomcat7 case $1 in start) sh $TOMCAT_HOME/bin/startup.sh ;; stop) sh $TOMCAT_HOME/bin/shutdown.sh ;; restart) sh $TOMCAT_HOME/bin/shutdown.sh sh $TOMCAT_HOME/bin/startup.sh ;; esac exit 0 原则与建议 容器轻量化。从镜像中产生的容器应该尽量轻量化，能在足够短的时间内停止、销毁、重新生成并替换原来的容器。 使用 .gitignore。在大部分情况下，Dockerfile 会和构建所需的文件放在同一个目录中，为了提高构建的性能，应该使用 .gitignore 来过滤掉不需要的文件和目录。 为了减少镜像的大小，减少依赖，仅安装需要的软件包。 一个容器只做一件事。解耦复杂的应用，分成多个容器，而不是所有东西都放在一个容器内运行。如一个 Python Web 应用，可能需要 Server、DB、Cache、MQ、Log 等几个容器。一个更加极端的说法：One process per container。 减少镜像的图层。不要多个 Label、ENV 等标签。 对续行的参数按照字母表排序，特别是使用apt-get install -y安装包的时候。 使用构建缓存。如果不想使用缓存，可以在构建的时候使用参数–no-cache=true来强制重新生成中间镜像。]]></content>
      <categories>
        <category>VT</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Dockerfile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门教程]]></title>
    <url>%2F2018%2F12%2F25%2FDocker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[如今Docker的使用已经非常普遍，特别在一线互联网公司。使用Docker技术可以帮助企业快速水平扩展服务，从而到达弹性部署业务的能力。在云服务概念兴起之后，Docker的使用场景和范围进一步发展，如今在微服务架构越来越流行的情况下，微服务+Docker的完美组合，更加方便微服务架构运维部署落地。 Docker简介Docker 是世界领先的软件容器平台。开发人员利用 Docker 可以消除协作编码时“在我的机器上可正常工作”的问题。运维人员利用 Docker 可以在隔离容器中并行运行和管理应用，获得更好的计算密度。企业利用 Docker 可以构建敏捷的软件交付管道，以更快的速度、更高的安全性和可靠的信誉为 Linux 和 Windows Server 应用发布新功能。 Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。 Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目已经超过 4 万 6 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 为什么要使用Docker容器除了运行其中应用外，基本不消耗额外的系统资源，使得应用的性能很高，同时系统的开销尽量小。传统虚拟机方式运行 10 个不同的应用就要起 10 个虚拟机，而Docker 只需要启动 10 个隔离的应用即可。 具体说来，Docker 在如下几个方面具有较大的优势。 1、更快速的交付和部署对开发和运维（devop）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。 开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码。 Docker 可以快速创建容器，快速迭代应用程序，并让整个过程全程可见，使团队中的其他成员更容易理解应用程序是如何创建和工作的。 Docker 容器很轻很快！容器的启动时间是秒级的，大量地节约开发、测试、部署的时间。 2、更高效的虚拟化Docker 容器的运行不需要额外的 hypervisor 支持，它是内核级的虚拟化，因此可以实现更高的性能和效率。 3、更轻松的迁移和扩展Docker 容器几乎可以在任意的平台上运行，包括物理机、虚拟机、公有云、私有云、个人电脑、服务器等。 这种兼容性可以让用户把一个应用程序从一个平台直接迁移到另外一个。 4、更简单的管理使用 Docker，只需要小小的修改，就可以替代以往大量的更新工作。所有的修改都以增量的方式被分发和更新，从而实现自动化并且高效的管理。 Docker vs VM从下图可以看出，VM是一个运行在宿主机之上的完整的操作系统，VM运行自身操作系统会占用较多的CPU、内存、硬盘资源。Docker不同于VM，只包含应用程序以及依赖库，基于libcontainer运行在宿主机上，并处于一个隔离的环境中，这使得Docker更加轻量高效，启动容器只需几秒钟之内完成。由于Docker轻量、资源占用少，使得Docker可以轻易的应用到构建标准化的应用中。但Docker目前还不够完善，比如隔离效果不如VM，共享宿主机操作系统的一些基础库等；网络配置功能相对简单，主要以桥接方式为主；查看日志也不够方便灵活。Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。 作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多；Docker 对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器。 相关概念Docker是CS架构，主要有两个概念： Docker daemon: 运行在宿主机上，Docker守护进程，用户通过Docker client(Docker命令)与Docker daemon交互 Docker client: Docker 命令行工具，是用户使用Docker的主要方式，Docker client与Docker daemon通信并将结果返回给用户，Docker client也可以通过socket或者RESTful api访问远程的Docker daemon 了解了Docker的组成，再来了解一下Docker的三个主要概念： Docker image：镜像是只读的，镜像中包含有需要运行的文件。镜像用来创建container，一个镜像可以运行多个container；镜像可以通过Dockerfile创建，也可以从Docker hub/registry上下载。 Docker container：容器是Docker的运行组件，启动一个镜像就是一个容器，容器是一个隔离环境，多个容器之间不会相互影响，保证容器中的程序运行在一个相对安全的环境中。 Docker hub/registry: 共享和管理Docker镜像，用户可以上传或者下载上面的镜像，官方地址为https://registry.hub.docker.com/，也可以搭建自己私有的Docker registry。 镜像就相当于打包好的版本，镜像启动之后运行在容器中，仓库就是装存储镜像的地方。 Docker安装建议在linux环境下安装Docker，window环境搭建比较复杂且容易出错，使用Centos7+yum来安装Docker环境很方便。 Docker 软件包已经包括在默认的 CentOS-Extras 软件源里。因此想要安装 docker，只需要运行下面的 yum 命令： yum install docker 安装完成后，使用下面的命令来启动 docker 服务，并将其设置为开机启动： service docker start chkconfig docker on LCTT 译注：此处采用了旧式的 sysv 语法，如采用CentOS 7中支持的新式 systemd 语法，如下： systemctl start docker.service systemctl enable docker.service 测试 docker version 输入上述命令，返回docker的版本相关信息，证明docker安装成功。 Hello World下面，我们通过最简单的 image 文件”hello world”，感受一下 Docker。 因为国内连接 Docker 的官方仓库很慢，因此我们在日常使用中会使用Docker 中国加速器。通过 Docker 官方镜像加速，中国区用户能够快速访问最流行的 Docker 镜像。该镜像托管于中国大陆，本地用户现在将会享受到更快的下载速度和更强的稳定性，从而能够更敏捷地开发和交付 Docker 化应用。 Docker 中国官方镜像加速可通过registry.docker-cn.com访问。该镜像库只包含流行的公有镜像，私有镜像仍需要从美国镜像库中拉取。 修改系统中docker对应的配置文件即可，如下： vi /etc/docker/daemon.json #添加后 { &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;], &quot;live-restore&quot;: true } 运行下面的命令，将 image 文件从仓库抓取到本地。 docker pull library/hello-world 上面代码中，docker image pull是抓取 image 文件的命令。library/hello-world是 image 文件在仓库里面的位置，其中library是 image 文件所在的组，hello-world是 image 文件的名字。 抓取成功以后，就可以在本机看到这个 image 文件了。 docker images #显示结果 REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/hello-world latest f2a91732366c 3 months ago 1.848 kB 现在，运行这个 image 文件。 docker run hello-world #显示结果 Hello from Docker! This message shows that your installation appears to be working correctly. ... 输出这段提示以后，hello world就会停止运行，容器自动终止。有些容器不会自动终止，因为提供的是服务，比如Mysql镜像等。 常用命令除过以上我们使用的Docker命令外，Docker还有一些其它常用的命令 拉取docker镜像 docker pull image_name 查看宿主机上的镜像，Docker镜像保存在/var/lib/docker目录下: docker images 删除镜像 docker rmi docker.io/tomcat:7.0.77-jre7 或者 docker rmi b39c68b7af30 查看当前有哪些容器正在运行 docker ps 查看所有容器 docker ps -a 启动、停止、重启容器命令： docker start container_name/container_id docker stop container_name/container_id docker restart container_name/container_id 后台启动一个容器后，如果想进入到这个容器，可以使用attach命令： docker attach container_name/container_id 删除容器的命令： docker rm container_name/container_id 删除所有停止的容器： docker rm $(docker ps -a -q) 查看当前系统Docker信息 docker info 从Docker hub上下载某个镜像: docker pull centos:latest docker pull centos:latest 查找Docker Hub上的nginx镜像 docker search nginx 执行docker pull centos会将Centos这个仓库下面的所有镜像下载到本地repository。]]></content>
      <categories>
        <category>VT</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下解决docker端口映射到宿主机后外网无法访问的问题]]></title>
    <url>%2F2018%2F12%2F24%2FLinux%E4%B8%8B%E8%A7%A3%E5%86%B3docker%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E5%88%B0%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%90%8E%E5%A4%96%E7%BD%91%E6%97%A0%E6%B3%95%E8%AE%BF%E9%97%AE%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[解决办法：1# vim /etc/sysctl.conf 或者1# vim /usr/lib/sysctl.d/00-system.conf 添加如下代码：1net.ipv4.ip_forward=1 重启network服务1# systemctl restart network 查看是否修改成功1# sysctl net.ipv4.ip_forward 如果返回为“net.ipv4.ip_forward = 1”则表示成功了最后重启docker服务1# systemvtl restart docker.service]]></content>
      <categories>
        <category>VT</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell脚本常见面试题]]></title>
    <url>%2F2018%2F12%2F24%2FShell%E8%84%9A%E6%9C%AC%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[注意事项1）开头加解释器：#!/bin/bash 2）语法缩进，使用四个空格；多加注释说明。 3）命名建议规则：变量名大写、局部变量小写，函数名小写，名字体现出实际作用。 4）默认变量是全局的，在函数中变量local指定为局部变量，避免污染其他作用域。 5）有两个命令能帮助我调试脚本：set -e 遇到执行非0时退出脚本，set-x 打印执行过程。 6）写脚本一定先测试再到生产上。 脚本目录1、获取随机字符串或数字获取随机8位字符串：123456789方法1：# echo $RANDOM |md5sum |cut -c 1-8471b94f2方法2：# openssl rand -base64 4vg3BEg==方法3：# cat /proc/sys/kernel/random/uuid |cut -c 1-8ed9e032c 获取随机8位数字：123456789方法1：# echo $RANDOM |cksum |cut -c 1-823648321方法2：# openssl rand -base64 4 |cksum |cut -c 1-838571131方法3：# date +%N |cut -c 1-869024815 cksum：打印CRC效验和统计字节 2、定义一个颜色输出字符串函数123456789101112131415161718192021方法1：function echo_color() &#123; if [ $1 == "green" ]; then echo -e "\033[32;40m$2\033[0m" elif [ $1 == "red" ]; then echo -e "\033[31;40m$2\033[0m" fi&#125;方法2：function echo_color() &#123; case $1 in green) echo -e "\033[32;40m$2\033[0m" ;; red) echo -e "\033[31;40m$2\033[0m" ;; *) echo "Example: echo_color red string" esac&#125; 使用方法：echo_color green “test”function关键字定义一个函数，可加或不加。 3、批量创建用户12345678910111213141516171819202122232425262728#!/bin/bashDATE=$(date +%F_%T)USER_FILE=user.txtecho_color()&#123; if [ $1 == "green" ]; then echo -e "\033[32;40m$2\033[0m" elif [ $1 == "red" ]; then echo -e "\033[31;40m$2\033[0m" fi&#125;# 如果用户文件存在并且大小大于0就备份if [ -s $USER_FILE ]; then mv $USER_FILE $&#123;USER_FILE&#125;-$&#123;DATE&#125;.bak echo_color green "$USER_FILE exist, rename $&#123;USER_FILE&#125;-$&#123;DATE&#125;.bak"fiecho -e "User\tPassword" &gt;&gt; $USER_FILEecho "----------------" &gt;&gt; $USER_FILEfor USER in user&#123;1..10&#125;; do if ! id $USER &amp;&gt;/dev/null; then PASS=$(echo $RANDOM |md5sum |cut -c 1-8) useradd $USER echo $PASS |passwd --stdin $USER &amp;&gt;/dev/null echo -e "$USER\t$PASS" &gt;&gt; $USER_FILE echo "$USER User create successful." else echo_color red "$USER User already exists!" fidone 4、检查软件包是否安装123456#!/bin/bashif rpm -q sysstat &amp;&gt;/dev/null; then echo "sysstat is already installed."else echo "sysstat is not installed!"fi 5、检查服务状态123456#!/bin/bashPORT_C=$(ss -anu |grep -c 123)PS_C=$(ps -ef |grep ntpd |grep -vc grep)if [ $PORT_C -eq 0 -o $PS_C -eq 0 ]; then echo "内容" | mail -s "主题" dst@example.comfi 6、检查主机存活状态方法1：将错误IP放到数组里面判断是否ping失败三次12345678910111213141516171819#!/bin/bash IP_LIST="192.168.18.1 192.168.1.1 192.168.18.2"for IP in $IP_LIST; do NUM=1 while [ $NUM -le 3 ]; do if ping -c 1 $IP &gt; /dev/null; then echo "$IP Ping is successful." break else # echo "$IP Ping is failure $NUM" FAIL_COUNT[$NUM]=$IP let NUM++ fi done if [ $&#123;#FAIL_COUNT[*]&#125; -eq 3 ];then echo "$&#123;FAIL_COUNT[1]&#125; Ping is failure!" unset FAIL_COUNT[*] fidone 方法2：将错误次数放到FAIL_COUNT变量里面判断是否ping失败三次1234567891011121314151617#!/bin/bash IP_LIST="192.168.18.1 192.168.1.1 192.168.18.2"for IP in $IP_LIST; do FAIL_COUNT=0 for ((i=1;i&lt;=3;i++)); do if ping -c 1 $IP &gt;/dev/null; then echo "$IP Ping is successful." break else # echo "$IP Ping is failure $i" let FAIL_COUNT++ fi done if [ $FAIL_COUNT -eq 3 ]; then echo "$IP Ping is failure!" fidone 方法3：利用for循环将ping通就跳出循环继续，如果不跳出就会走到打印ping失败1234567891011121314#!/bin/bashping_success_status() &#123; if ping -c 1 $IP &gt;/dev/null; then echo "$IP Ping is successful." continue fi&#125;IP_LIST="192.168.18.1 192.168.1.1 192.168.18.2"for IP in $IP_LIST; do ping_success_status ping_success_status ping_success_status echo "$IP Ping is failure!"done 7、监控CPU、内存和硬盘利用率1）CPU借助vmstat工具来分析CPU统计信息。1234567891011121314151617181920#!/bin/bashDATE=$(date +%F" "%H:%M)IP=$(ifconfig eth0 |awk -F '[ :]+' '/inet addr/&#123;print $4&#125;') # 只支持CentOS6MAIL="example@mail.com"if ! which vmstat &amp;&gt;/dev/null; then echo "vmstat command no found, Please install procps package." exit 1fiUS=$(vmstat |awk 'NR==3&#123;print $13&#125;')SY=$(vmstat |awk 'NR==3&#123;print $14&#125;')IDLE=$(vmstat |awk 'NR==3&#123;print $15&#125;')WAIT=$(vmstat |awk 'NR==3&#123;print $16&#125;')USE=$(($US+$SY))if [ $USE -ge 50 ]; then echo " Date: $DATE Host: $IP Problem: CPU utilization $USE " | mail -s "CPU Monitor" $MAILfi 2）内存123456789101112131415#!/bin/bashDATE=$(date +%F" "%H:%M)IP=$(ifconfig eth0 |awk -F '[ :]+' '/inet addr/&#123;print $4&#125;') MAIL="example@mail.com"TOTAL=$(free -m |awk '/Mem/&#123;print $2&#125;')USE=$(free -m |awk '/Mem/&#123;print $3-$6-$7&#125;')FREE=$(($TOTAL-$USE))# 内存小于1G发送报警邮件if [ $FREE -lt 1024 ]; then echo " Date: $DATE Host: $IP Problem: Total=$TOTAL,Use=$USE,Free=$FREE " | mail -s "Memory Monitor" $MAILfi 3）硬盘12345678910111213141516171819#!/bin/bashDATE=$(date +%F" "%H:%M)IP=$(ifconfig eth0 |awk -F '[ :]+' '/inet addr/&#123;print $4&#125;') MAIL="example@mail.com"TOTAL=$(fdisk -l |awk -F'[: ]+' 'BEGIN&#123;OFS="="&#125;/^Disk \/dev/&#123;printf "%s=%sG,",$2,$3&#125;')PART_USE=$(df -h |awk 'BEGIN&#123;OFS="="&#125;/^\/dev/&#123;print $1,int($5),$6&#125;')for i in $PART_USE; do PART=$(echo $i |cut -d"=" -f1) USE=$(echo $i |cut -d"=" -f2) MOUNT=$(echo $i |cut -d"=" -f3) if [ $USE -gt 80 ]; then echo " Date: $DATE Host: $IP Total: $TOTAL Problem: $PART=$USE($MOUNT) " | mail -s "Disk Monitor" $MAIL fidone 8、批量主机磁盘利用率监控前提监控端和被监控端SSH免交互登录或者密钥登录。写一个配置文件保存被监控主机SSH连接信息，文件内容格式：IP User Port12345678910111213141516#!/bin/bashHOST_INFO=host.infofor IP in $(awk '/^[^#]/&#123;print $1&#125;' $HOST_INFO); do USER=$(awk -v ip=$IP 'ip==$1&#123;print $2&#125;' $HOST_INFO) PORT=$(awk -v ip=$IP 'ip==$1&#123;print $3&#125;' $HOST_INFO) TMP_FILE=/tmp/disk.tmp ssh -p $PORT $USER@$IP 'df -h' &gt; $TMP_FILE USE_RATE_LIST=$(awk 'BEGIN&#123;OFS="="&#125;/^\/dev/&#123;print $1,int($5)&#125;' $TMP_FILE) for USE_RATE in $USE_RATE_LIST; do PART_NAME=$&#123;USE_RATE%=*&#125; USE_RATE=$&#123;USE_RATE#*=&#125; if [ $USE_RATE -ge 80 ]; then echo "Warning: $PART_NAME Partition usage $USE_RATE%!" fi donedone 9、检查网站可用性1）检查URL可用性方法1：123456check_url() &#123; HTTP_CODE=$(curl -o /dev/null --connect-timeout 3 -s -w "%&#123;http_code&#125;" $1) if [ $HTTP_CODE -ne 200 ]; then echo "Warning: $1 Access failure!" fi&#125; 方法2：123456check_url() &#123;if ! wget -T 10 --tries=1 --spider $1 &gt;/dev/null 2&gt;&amp;1; then #-T超时时间，--tries尝试1次，--spider爬虫模式 echo "Warning: $1 Access failure!" fi&#125; 使用方法：check_url www.baidu.com 2）判断三次URL可用性思路与上面检查主机存活状态一样。方法1：利用循环技巧，如果成功就跳出当前循环，否则执行到最后一行1234567891011121314#!/bin/bash check_url() &#123; HTTP_CODE=$(curl -o /dev/null --connect-timeout 3 -s -w "%&#123;http_code&#125;" $1) if [ $HTTP_CODE -eq 200 ]; then continue fi&#125;URL_LIST="www.baidu.com www.agasgf.com"for URL in $URL_LIST; do check_url $URL check_url $URL check_url $URL echo "Warning: $URL Access failure!"done 方法2：错误次数保存到变量12345678910111213141516#!/bin/bash URL_LIST="www.baidu.com www.agasgf.com"for URL in $URL_LIST; do FAIL_COUNT=0 for ((i=1;i&lt;=3;i++)); do HTTP_CODE=$(curl -o /dev/null --connect-timeout 3 -s -w "%&#123;http_code&#125;" $URL) if [ $HTTP_CODE -ne 200 ]; then let FAIL_COUNT++ else break fi done if [ $FAIL_COUNT -eq 3 ]; then echo "Warning: $URL Access failure!" fidone 方法3：错误次数保存到数组123456789101112131415161718#!/bin/bash URL_LIST="www.baidu.com www.agasgf.com"for URL in $URL_LIST; do NUM=1 while [ $NUM -le 3 ]; do HTTP_CODE=$(curl -o /dev/null --connect-timeout 3 -s -w "%&#123;http_code&#125;" $URL) if [ $HTTP_CODE -ne 200 ]; then FAIL_COUNT[$NUM]=$IP #创建数组，以$NUM下标，$IP元素 let NUM++ else break fi done if [ $&#123;#FAIL_COUNT[*]&#125; -eq 3 ]; then echo "Warning: $URL Access failure!" unset FAIL_COUNT[*] #清空数组 fidone 10、检查MySQL主从同步状态1234567891011#!/bin/bash USER=bakPASSWD=123456IO_SQL_STATUS=$(mysql -u$USER -p$PASSWD -e 'show slave status\G' |awk -F: '/Slave_.*_Running/&#123;gsub(": ",":");print $0&#125;') #gsub去除冒号后面的空格for i in $IO_SQL_STATUS; do THREAD_STATUS_NAME=$&#123;i%:*&#125; THREAD_STATUS=$&#123;i#*:&#125; if [ "$THREAD_STATUS" != "Yes" ]; then echo "Error: MySQL Master-Slave $THREAD_STATUS_NAME status is $THREAD_STATUS!" fidone]]></content>
      <categories>
        <category>Scripts</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM调优命令]]></title>
    <url>%2F2018%2F12%2F20%2FJVM%E8%B0%83%E4%BC%98%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[运用jvm自带的命令可以方便的在生产监控和打印堆栈的日志信息帮忙我们来定位问题！虽然jvm调优成熟的工具已经有很多：jconsole、大名鼎鼎的VisualVM，IBM的Memory Analyzer等等，但是在生产环境出现问题的时候，一方面工具的使用会有所限制，另一方面喜欢装X的我们，总喜欢在出现问题的时候在终端输入一些命令来解决。所有的工具几乎都是依赖于jdk的接口和底层的这些命令，研究这些命令的使用也让我们更能了解jvm构成和特性。 Sun JDK监控和故障处理命令有jps jstat jmap jhat jstack jinfo下面做一一介绍 jpsJVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。 命令格式1jps [options] [hostid] option参数-l : 输出主类全名或jar路径 -q : 只输出LVMID -m : 输出JVM启动时传递给main()的参数 -v : 输出JVM启动时显示指定的JVM参数 其中[option]、[hostid]参数也可以不写。 示例1234$ jps -l -m 28920 org.apache.catalina.startup.Bootstrap start 11589 org.apache.catalina.startup.Bootstrap start 25816 sun.tools.jps.Jps -l -m jstatjstat(JVM statistics Monitoring)是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。 命令格式1jstat [option] LVMID [interval] [count] 参数[option] : 操作参数 LVMID : 本地虚拟机进程ID [interval] : 连续输出的时间间隔 [count] : 连续输出的次数 option 参数总览 Option Displays… class class loader的行为统计。Statistics on the behavior of the class loader. compiler HotSpt JIT编译器行为统计。Statistics of the behavior of the HotSpot Just-in-Time compiler. gc 垃圾回收堆的行为统计。Statistics of the behavior of the garbage collected heap. gccapacity 各个垃圾回收代容量(young,old,perm)和他们相应的空间统计。Statistics of the capacities of the generations and their corresponding spaces. gcutil 垃圾回收统计概述。Summary of garbage collection statistics. gccause 垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因。Summary of garbage collection statistics (same as -gcutil), with the cause of the last and gcnew 新生代行为统计。Statistics of the behavior of the new generation. gcnewcapacity 新生代与其相应的内存空间的统计。Statistics of the sizes of the new generations and its corresponding spaces. gcold 年老代和永生代行为统计。Statistics of the behavior of the old and permanent generations. gcoldcapacity 年老代行为统计。Statistics of the sizes of the old generation. gcpermcapacity 永生代行为统计。Statistics of the sizes of the permanent generation. printcompilation HotSpot编译方法统计。HotSpot compilation method statistics. option 参数详解-class监视类装载、卸载数量、总空间以及耗费的时间 123$ jstat -class 11589 Loaded Bytes Unloaded Bytes Time 7035 14506.3 0 0.0 3.67 Loaded : 加载class的数量 Bytes : class字节大小 Unloaded : 未加载class的数量 Bytes : 未加载class的字节大小 Time : 加载时间 -compiler输出JIT编译过的方法数量耗时等123$ jstat -compiler 1262Compiled Failed Invalid Time FailedType FailedMethod 2573 1 0 47.60 1 org/apache/catalina/loader/WebappClassLoader findResourceInternal Compiled : 编译数量 Failed : 编译失败数量 Invalid : 无效数量 Time : 编译耗时 FailedType : 失败类型 FailedMethod : 失败方法的全限定名 -gc垃圾回收堆的行为统计，常用命令123$ jstat -gc 1262 S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT 26112.0 24064.0 6562.5 0.0 564224.0 76274.5 434176.0 388518.3 524288.0 42724.7 320 6.417 1 0.398 6.815 C即Capacity 总容量，U即Used 已使用的容量 S0C : survivor0区的总容量 S1C : survivor1区的总容量 S0U : survivor0区已使用的容量 S1U : survivor1区已使用的容量 EC : Eden区的总容量 EU : Eden区已使用的容量 OC : Old区的总容量 OU : Old区已使用的容量 PC 当前perm的容量 (KB) PU perm的使用 (KB) YGC : 新生代垃圾回收次数 YGCT : 新生代垃圾回收时间 FGC : 老年代垃圾回收次数 FGCT : 老年代垃圾回收时间 GCT : 垃圾回收总消耗时间 1$ jstat -gc 1262 2000 20 这个命令意思就是每隔2000ms输出1262的gc情况，一共输出20次-gccapacity同-gc，不过还会输出Java堆各区域使用到的最大、最小空间123$ jstat -gccapacity 1262 NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC PGCMN PGCMX PGC PC YGC FGC 614400.0 614400.0 614400.0 26112.0 24064.0 564224.0 434176.0 434176.0 434176.0 434176.0 524288.0 1048576.0 524288.0 524288.0 320 1 NGCMN : 新生代占用的最小空间 NGCMX : 新生代占用的最大空间 OGCMN : 老年代占用的最小空间 OGCMX : 老年代占用的最大空间 OGC：当前年老代的容量 (KB) OC：当前年老代的空间 (KB) PGCMN : perm占用的最小空间 PGCMX : perm占用的最大空间 -gcutil同-gc，不过输出的是已使用空间占总空间的百分比123$ jstat -gcutil 28920 S0 S1 E O P YGC YGCT FGC FGCT GCT 12.45 0.00 33.85 0.00 4.44 4 0.242 0 0.000 0.242 -gccause垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因123$ jstat -gccause 28920 S0 S1 E O P YGC YGCT FGC FGCT GCT LGCC GCC 12.45 0.00 33.85 0.00 4.44 4 0.242 0 0.000 0.242 Allocation Failure No GC LGCC：最近垃圾回收的原因 GCC：当前垃圾回收的原因 -gcnew统计新生代的行为123$ jstat -gcnew 28920 S0C S1C S0U S1U TT MTT DSS EC EU YGC YGCT 419392.0 419392.0 52231.8 0.0 6 6 209696.0 3355520.0 1172246.0 4 0.242 TT：Tenuring threshold(提升阈值) MTT：最大的tenuring threshold DSS：survivor区域大小 (KB) -gcnewcapacity新生代与其相应的内存空间的统计123$ jstat -gcnewcapacity 28920 NGCMN NGCMX NGC S0CMX S0C S1CMX S1C ECMX EC YGC FGC 4194304.0 4194304.0 4194304.0 419392.0 419392.0 419392.0 419392.0 3355520.0 3355520.0 4 0 NGC:当前年轻代的容量 (KB) S0CMX:最大的S0空间 (KB) S0C:当前S0空间 (KB) ECMX:最大eden空间 (KB) EC:当前eden空间 (KB) -gcold统计旧生代的行为123$ jstat -gcold 28920 PC PU OC OU YGC FGC FGCT GCT 1048576.0 46561.7 6291456.0 0.0 4 0 0.000 0.242 -gcoldcapacity统计旧生代的大小和空间123$ jstat -gcoldcapacity 28920 OGCMN OGCMX OGC OC YGC FGC FGCT GCT 6291456.0 6291456.0 6291456.0 6291456.0 4 0 0.000 0.242 -gcpermcapacity永生代行为统计123$ jstat -gcpermcapacity 28920 PGCMN PGCMX PGC PC YGC FGC FGCT GCT 1048576.0 2097152.0 1048576.0 1048576.0 4 0 0.000 0.242 -printcompilationhotspot编译方法统计123$ jstat -printcompilation 28920 Compiled Size Type Method 1291 78 1 java/util/ArrayList indexOf Compiled：被执行的编译任务的数量 Size：方法字节码的字节数 Type：编译类型 Method：编译方法的类名和方法名。类名使用”/” 代替 “.” 作为空间分隔符. 方法名是给出类的方法名. 格式是一致于HotSpot - XX:+PrintComplation 选项 jmapjmap(JVM Memory Map)命令用于生成heap dump文件，如果不使用这个命令，还阔以使用-XX:+HeapDumpOnOutOfMemoryError参数来让虚拟机出现OOM的时候·自动生成dump文件。 jmap不仅能生成dump文件，还阔以查询finalize执行队列、Java堆和永久代的详细信息，如当前使用率、当前使用的是哪种收集器等。 命令格式1jmap [option] LVMID option参数 dump : 生成堆转储快照 finalizerinfo : 显示在F-Queue队列等待Finalizer线程执行finalizer方法的对象 heap : 显示Java堆详细信息 histo : 显示堆中对象的统计信息 permstat : to print permanent generation statistics F : 当-dump没有响应时，强制生成dump快照 示例-dump常用格式1234567-dump::live,format=b,file=&lt;filename&gt; pid``` dump堆到文件,format指定输出格式，live指明是活着的对象,file指定文件名```bash$ jmap -dump:live,format=b,file=dump.hprof 28920 Dumping heap to /home/xxx/dump.hprof ... Heap dump file created dump.hprof这个后缀是为了后续可以直接用MAT(Memory Anlysis Tool)打开。 -finalizerinfo打印等待回收对象的信息123456$ jmap -finalizerinfo 28920 Attaching to process ID 28920, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.71-b01 Number of objects pending for finalization: 0 可以看到当前F-QUEUE队列中并没有等待Finalizer线程执行finalizer方法的对象。-heap打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况,可以用此来判断内存目前的使用情况以及垃圾回收情况123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051$ jmap -heap 28920 Attaching to process ID 28920, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.71-b01 using thread-local object allocation. Parallel GC with 4 thread(s)//GC 方式 Heap Configuration: //堆内存初始化配置 MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40) MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70) MaxHeapSize = 2082471936 (1986.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 1310720 (1.25MB)//对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小 MaxNewSize = 17592186044415 MB//对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小 OldSize = 5439488 (5.1875MB)//对应jvm启动参数-XX:OldSize=&lt;value&gt;:设置JVM堆的‘老生代’的大小 NewRatio = 2 //对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率 SurvivorRatio = 8 //对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 PermSize = 21757952 (20.75MB) //对应jvm启动参数-XX:PermSize=&lt;value&gt;:设置JVM堆的‘永生代’的初始大小 MaxPermSize = 85983232 (82.0MB)//对应jvm启动参数-XX:MaxPermSize=&lt;value&gt;:设置JVM堆的‘永生代’的最大大小 G1HeapRegionSize = 0 (0.0MB) Heap Usage://堆内存使用情况 PS Young Generation Eden Space://Eden区内存分布 capacity = 33030144 (31.5MB)//Eden区总容量 used = 1524040 (1.4534378051757812MB) //Eden区已使用 free = 31506104 (30.04656219482422MB) //Eden区剩余容量 4.614088270399305% used //Eden区使用比率 From Space: //其中一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% used To Space: //另一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% used PS Old Generation //当前的Old区内存分布 capacity = 86507520 (82.5MB) used = 0 (0.0MB) free = 86507520 (82.5MB) 0.0% used PS Perm Generation//当前的 “永生代” 内存分布 capacity = 22020096 (21.0MB) used = 2496528 (2.3808746337890625MB) free = 19523568 (18.619125366210938MB) 11.337498256138392% used 670 interned Strings occupying 43720 bytes. 可以很清楚的看到Java堆中各个区域目前的情况。-histo打印堆的对象统计，包括对象数、内存大小等等 （因为在dump:live前会进行full gc，如果带上live则只统计活对象，因此不加live的堆大小要大于加live堆的大小 ）1234567891011121314$ jmap -histo:live 28920 | more num #instances #bytes class name---------------------------------------------- 1: 83613 12012248 &lt;constMethodKlass&gt; 2: 23868 11450280 [B 3: 83613 10716064 &lt;methodKlass&gt; 4: 76287 10412128 [C 5: 8227 9021176 &lt;constantPoolKlass&gt; 6: 8227 5830256 &lt;instanceKlassKlass&gt; 7: 7031 5156480 &lt;constantPoolCacheKlass&gt; 8: 73627 1767048 java.lang.String 9: 2260 1348848 &lt;methodDataKlass&gt; 10: 8856 849296 java.lang.Class .... 仅仅打印了前10行xml class name是对象类型，说明如下： B byte C char D double F float I int J long Z boolean [ 数组，如[I表示int[] [L+类名 其他对象 -permstat打印Java堆内存的永久保存区域的类加载器的智能统计信息。对于每个类加载器而言，它的名称、活跃度、地址、父类加载器、它所加载的类的数量和大小都会被打印。此外，包含的字符串数量和大小也会被打印。123456789101112131415$ jmap -permstat 28920 Attaching to process ID 28920, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.71-b01 finding class loader instances ..done. computing per loader stat ..done. please wait.. computing liveness.liveness analysis may be inaccurate ... class_loader classes bytes parent_loader alive? type &lt;bootstrap&gt; 3111 18154296 null live &lt;internal&gt; 0x0000000600905cf8 1 1888 0x0000000600087f08 dead sun/reflect/DelegatingClassLoader@0x00000007800500a0 0x00000006008fcb48 1 1888 0x0000000600087f08 dead sun/reflect/DelegatingClassLoader@0x00000007800500a0 0x00000006016db798 0 0 0x00000006008d3fc0 dead java/util/ResourceBundle$RBClassLoader@0x0000000780626ec0 0x00000006008d6810 1 3056 null dead sun/reflect/DelegatingClassLoader@0x00000007800500a0 -F强制模式。如果指定的pid没有响应，请使用jmap -dump或jmap -histo选项。此模式下，不支持live子选项。 jhatjhat(JVM Heap Analysis Tool)命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP/HTML服务器，生成dump的分析结果后，可以在浏览器中查看。在此要注意，一般不会直接在服务器上进行分析，因为jhat是一个耗时并且耗费硬件资源的过程，一般把服务器生成的dump文件复制到本地或其他机器上进行分析。 命令格式1jhat [dumpfile] 参数 -stack false|true 关闭对象分配调用栈跟踪(tracking object allocation call stack)。 如果分配位置信息在堆转储中不可用. 则必须将此标志设置为 false. 默认值为 true.&gt; -refs false|true 关闭对象引用跟踪(tracking of references to objects)。 默认值为 true. 默认情况下, 返回的指针是指向其他特定对象的对象,如反向链接或输入引用(referrers or incoming references), 会统计/计算堆中的所有对象。&gt; -port port-number 设置 jhat HTTP server 的端口号. 默认值 7000.&gt; -exclude exclude-file 指定对象查询时需要排除的数据成员列表文件(a file that lists data members that should be excluded from the reachable objects query)。 例如, 如果文件列列出了 java.lang.String.value , 那么当从某个特定对象 Object o 计算可达的对象列表时, 引用路径涉及 java.lang.String.value 的都会被排除。&gt; -baseline exclude-file 指定一个基准堆转储(baseline heap dump)。 在两个 heap dumps 中有相同 object ID 的对象会被标记为不是新的(marked as not being new). 其他对象被标记为新的(new). 在比较两个不同的堆转储时很有用.&gt; -debug int 设置 debug 级别. 0 表示不输出调试信息。 值越大则表示输出更详细的 debug 信息.&gt; -version 启动后只显示版本信息就退出&gt; -J&lt; flag &gt; 因为 jhat 命令实际上会启动一个JVM来执行, 通过 -J 可以在启动JVM时传入一些启动参数. 例如, -J-Xmx512m 则指定运行 jhat 的Java虚拟机使用的最大堆内存为 512 MB. 如果需要使用多个JVM启动参数,则传入多个 -Jxxxxxx. 示例12345678910$ jhat -J-Xmx512m dump.hprof eading from dump.hprof... Dump file created Fri Mar 11 17:13:42 CST 2016 Snapshot read, resolving... Resolving 271678 objects... Chasing references, expect 54 dots...................................................... Eliminating duplicate references...................................................... Snapshot resolved. Started HTTP server on port 7000 Server is ready. 中间的-J-Xmx512m是在dump快照很大的情况下分配512M内存去启动HTTP服务器，运行完之后就可在浏览器打开Http://localhost:7000进行快照分析 堆快照分析主要在最后面的Heap Histogram里，里面根据class列出了dump的时候所有存活对象。分析同样一个dump快照，MAT需要的额外内存比jhat要小的多的多，所以建议使用MAT来进行分析，当然也看个人偏好。分析打开浏览器Http://localhost:7000，该页面提供了几个查询功能可供使用：1234567All classes including platformShow all members of the rootsetShow instance counts for all classes (including platform)Show instance counts for all classes (excluding platform)Show heap histogramShow finalizer summaryExecute Object Query Language (OQL) query 一般查看堆异常情况主要看这个两个部分： Show instance counts for all classes (excluding platform)，平台外的所有对象信息。如下图：Show heap histogram 以树状图形式展示堆情况。如下图：具体排查时需要结合代码，观察是否大量应该被回收的对象在一直被引用或者是否有占用内存特别大的对象无法被回收。一般情况，会down到客户端用工具来分析 jstackjstack用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。 命令格式1jstack [option] LVMID option参数 -F : 当正常输出请求不被响应时，强制输出线程堆栈 -l : 除堆栈外，显示关于锁的附加信息 -m : 如果调用到本地方法的话，可以显示C/C++的堆栈 示例12345678910111213141516171819202122232425262728$ jstack -l 11494|more2016-07-28 13:40:04Full thread dump Java HotSpot(TM) 64-Bit Server VM (24.71-b01 mixed mode):"Attach Listener" daemon prio=10 tid=0x00007febb0002000 nid=0x6b6f waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE Locked ownable synchronizers: - None"http-bio-8005-exec-2" daemon prio=10 tid=0x00007feb94028000 nid=0x7b8c waiting on condition [0x00007fea8f56e000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000cae09b80&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:104) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:32) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - None ..... 分析这里有一篇文章解释的很好 分析打印出的文件内容 jinfojinfo(JVM Configuration info)这个命令作用是实时查看和调整虚拟机运行参数。 之前的jps -v口令只能查看到显示指定的参数，如果想要查看未被显示指定的参数的值就要使用jinfo口令 命令格式1jinfo [option] [args] LVMID option参数 -flag : 输出指定args参数的值 -flags : 不需要args参数，输出所有JVM参数的值 -sysprops : 输出系统属性，等同于System.getProperties() 示例12$ jinfo -flag 11494-XX:CMSInitiatingOccupancyFraction=80]]></content>
      <categories>
        <category>OS</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>jps</tag>
        <tag>jstat</tag>
        <tag>jmap</tag>
        <tag>jhat</tag>
        <tag>jstack</tag>
        <tag>jinfo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC算法和垃圾回收器]]></title>
    <url>%2F2018%2F12%2F20%2FGC%E7%AE%97%E6%B3%95%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[概述垃圾收集 Garbage Collection 通常被称为“GC”，它诞生于1960年 MIT 的 Lisp 语言，经过半个多世纪，目前已经十分成熟了。 jvm 中，程序计数器、虚拟机栈、本地方法栈都是随线程而生随线程而灭，栈帧随着方法的进入和退出做入栈和出栈操作，实现了自动的内存清理，因此，我们的内存垃圾回收主要集中于 java 堆和方法区中，在程序运行期间，这部分内存的分配和使用都是动态的. 对象存活判断判断对象是否存活一般有两种方式：引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。不可达对象。在Java语言中，GC Roots包括： 虚拟机栈中引用的对象。 方法区中类静态属性实体引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI引用的对象。 垃圾收集算法标记 -清除算法“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。 它的主要缺点有两个：一个是效率问题，标记和清除过程的效率都不高；另外一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 这样使得每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为原来的一半，持续复制长生存期的对象则导致效率降低。 标记-压缩算法复制收集算法在对象存活率较高时就要执行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。 根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法GC分代的基本假设：绝大部分对象的生命周期都非常短暂，存活时间短。 “分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。 垃圾收集器1如果说收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现 Serial收集器串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。新生代、老年代使用串行回收；新生代复制算法、老年代标记-压缩；垃圾收集的过程中会Stop The World（服务暂停） 参数控制：-XX:+UseSerialGC 串行收集器 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本。新生代并行，老年代串行；新生代复制算法、老年代标记-压缩 参数控制：-XX:+UseParNewGC ParNew收集器-XX:ParallelGCThreads 限制线程数量 Parallel收集器Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。可以通过参数来打开自适应调节策略，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量；也可以通过参数控制GC的时间不大于多少毫秒或者比例；新生代复制算法、老年代标记-压缩 参数控制：-XX:+UseParallelGC使用Parallel收集器+ 老年代串行 Parallel Old 收集器Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。这个收集器是在JDK 1.6中才开始提供 参数控制：-XX:+UseParallelOldGC使用Parallel收集器+ 老年代并行 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。 从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤，包括： 初始标记（CMS initial mark） 并发标记（CMS concurrent mark） 重新标记（CMS remark） 并发清除（CMS concurrent sweep） 其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行。老年代收集器（新生代使用ParNew） 优点: 并发收集、低停顿缺点: 产生大量空间碎片、并发阶段会降低吞吐量 参数控制：-XX:+UseConcMarkSweepGC 使用CMS收集器-XX:+ UseCMSCompactAtFullCollection Full GC后，进行一次碎片整理；整理过程是独占的，会引起停顿时间变长-XX:+CMSFullGCsBeforeCompaction 设置进行几次Full GC后，进行一次碎片整理-XX:ParallelCMSThreads 设定CMS的线程数量（一般情况约等于可用CPU数量） G1收集器G1是目前技术发展的最前沿成果之一，HotSpot开发团队赋予它的使命是未来可以替换掉JDK1.5中发布的CMS收集器。与CMS收集器相比G1收集器有以下特点： 1、空间整合，G1收集器采用标记整理算法，不会产生内存空间碎片。分配大对象时不会因为无法找到连续空间而提前触发下一次GC。 2、可预测停顿，这是G1的另一大优势，降低停顿时间是G1和CMS的共同关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为N毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。 上面提到的垃圾收集器，收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔阂了，它们都是一部分（可以不连续）Region的集合。G1的新生代收集跟ParNew类似，当新生代占用达到一定比例的时候，开始出发收集。和CMS类似，G1收集器收集老年代对象会有短暂停顿。收集步骤： 1、标记阶段，首先初始标记(Initial-Mark),这个阶段是停顿的(Stop the World Event)，并且会触发一次普通Mintor GC。对应GC log:GC pause (young) (inital-mark) 2、Root Region Scanning，程序运行过程中会回收survivor区(存活到老年代)，这一过程必须在young GC之前完成。 3、Concurrent Marking，在整个堆中进行并发标记(和应用程序并发执行)，此过程可能被young GC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，会计算每个区域的对象活性(区域中存活对象的比例)。 4、Remark, 再标记，会有短暂停顿(STW)。再标记阶段是用来收集 并发标记阶段 产生新的垃圾(并发阶段和应用程序一同运行)；G1中采用了比CMS更快的初始快照算法:snapshot-at-the-beginning (SATB)。 5、Copy/Clean up，多线程清除失活对象，会有STW。G1将回收区域的存活对象拷贝到新区域，清除Remember Sets，并发清空回收区域并把它返回到空闲区域链表中。 6、复制/清除过程后。回收区域的活性对象已经被集中回收到深蓝色和深绿色区域。 常用的收集器组合 /* 第一列表格宽度 */ table th:nth-of-type(1){ width: 11%; } /* 第二列表格宽度 */ table th:nth-of-type(2){ width: 15%; } /* 第三列表格宽度 */ table th:nth-of-type(3){ width: 17%; } /* 第四列表格宽度 */ table th:nth-of-type(4){ width: 57%; } /* ... ... */ 服务器 新生代GC策略 老年老代GC策略 说明 组合1 Serial Serial Old Serial和Serial Old都是单线程进行GC，特点就是GC时暂停所有应用线程。 组合2 Serial CMS+Serial Old CMS（Concurrent Mark Sweep）是并发GC，实现GC线程和应用线程并发工作，不需要暂停所有应用线程。另外，当CMS进行GC失败时，会自动使用Serial Old策略进行GC。 组合3 ParNew CMS 使用-XX:+UseParNewGC选项来开启。ParNew是Serial的并行版本，可以指定GC线程数，默认GC线程数为CPU的数量。可以使用-XX:ParallelGCThreads选项指定GC的线程数。如果指定了选项-XX:+UseConcMarkSweepGC选项，则新生代默认使用ParNew GC策略。 组合4 ParNew Serial Old 使用-XX:+UseParNewGC选项来开启。新生代使用ParNew GC策略，年老代默认使用Serial Old GC策略。 组合5 Parallel Scavenge Serial Old Parallel Scavenge策略主要是关注一个可控的吞吐量：应用程序运行时间 / (应用程序运行时间 + GC时间)，可见这会使得CPU的利用率尽可能的高，适用于后台持久运行的应用程序，而不适用于交互较多的应用程序。 组合6 Parallel Scavenge Parallel Old Parallel Old是Serial Old的并行版本 组合7 G1GC G1GC -XX:+UnlockExperimentalVMOptions -XX:+UseG1GC #开启；-XX:MaxGCPauseMillis =50 #暂停时间目标；-XX:GCPauseIntervalMillis =200 #暂停间隔目标；-XX:+G1YoungGenSize=512m #年轻代大小；-XX:SurvivorRatio=6 #幸存区比例]]></content>
      <categories>
        <category>OS</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>GC</tag>
        <tag>垃圾回收器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存结构]]></title>
    <url>%2F2018%2F12%2F20%2FJVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[所有的Java开发人员和运维人员可能会遇到这样的困惑？我该为堆内存设置多大空间呢？OutOfMemoryError的异常到底涉及到运行时数据的哪块区域？该怎么解决呢？其实如果你经常解决服务器性能问题，那么这些问题就会变的非常常见，了解JVM内存也是为了服务器出现性能问题的时候可以快速的了解那块的内存区域出现问题，以便于快速的解决生产故障。 先看一张图，这张图能很清晰的说明JVM内存结构布局。JVM内存结构主要有三大块：堆内存、方法区和栈。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配； 方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)；栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。 在通过一张图来了解如何通过参数来控制各区域的内存大小控制参数 -Xms设置堆的最小空间大小。 -Xmx设置堆的最大空间大小。 -XX:NewSize设置新生代最小空间大小。 -XX:MaxNewSize设置新生代最大空间大小。 -XX:PermSize设置永久代最小空间大小。 -XX:MaxPermSize设置永久代最大空间大小。 -Xss设置每个线程的堆栈大小。 没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制。 老年代空间大小=堆空间大小-年轻代大空间大小 从更高的一个维度再次来看JVM和系统调用之间的关系方法区和对是所有线程共享的内存区域；而java栈、本地方法栈和程序员计数器是运行是线程私有的内存区域。 下面我们详细介绍每个区域的作用 Java堆（Heap）对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。 根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 方法区（Method Area）方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。 对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。 Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。 根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 方法区有时被称为持久代（PermGen）。所有的对象在实例化后的整个运行周期内，都被存放在堆内存中。堆内存又被划分成不同的部分：伊甸区(Eden)，幸存者区域(Survivor Sapce)，老年代（Old Generation Space）。 方法的执行都是伴随着线程的。原始类型的本地变量以及引用都存放在线程栈中。而引用关联的对象比如String，都存在在堆中。为了更好的理解上面这段话，我们可以看一个例子：123456789101112import java.text.SimpleDateFormat;import java.util.Date;import org.apache.log4j.Logger; public class HelloWorld &#123; private static Logger LOGGER = Logger.getLogger(HelloWorld.class.getName()); public void sayHello(String message) &#123; SimpleDateFormat formatter = new SimpleDateFormat(&quot;dd.MM.YYYY&quot;); String today = formatter.format(new Date()); LOGGER.info(today + &quot;: &quot; + message); &#125;&#125; 这段程序的数据在内存中的存放如下：通过JConsole工具可以查看运行中的Java程序（比如Eclipse）的一些信息：堆内存的分配，线程的数量以及加载的类的个数； 程序计数器（Program Counter Register）程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 JVM栈（JVM Stacks）与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。 其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈（Native Method Stacks）本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 哪儿的OutOfMemoryError对内存结构清晰的认识同样可以帮助理解不同OutOfMemoryErrors： 1Exception in thread “main”: java.lang.OutOfMemoryError: Java heap space 原因：对象不能被分配到堆内存中 1Exception in thread “main”: java.lang.OutOfMemoryError: PermGen space 原因：类或者方法不能被加载到持久代。它可能出现在一个程序加载很多类的时候，比如引用了很多第三方的库； 1Exception in thread “main”: java.lang.OutOfMemoryError: Requested array size exceeds VM limit 原因：创建的数组大于堆内存的空间 1Exception in thread “main”: java.lang.OutOfMemoryError: request &lt;size&gt; bytes for &lt;reason&gt;. Out of swap space? 原因：分配本地分配失败。JNI、本地库或者Java虚拟机都会从本地堆中分配内存空间。 1Exception in thread “main”: java.lang.OutOfMemoryError: &lt;reason&gt; &lt;stack trace&gt;（Native method） 原因：同样是本地方法内存分配失败，只不过是JNI或者本地方法或者Java虚拟机发现]]></content>
      <categories>
        <category>OS</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins发布SpringCloud微服务到WindowsServer]]></title>
    <url>%2F2018%2F12%2F19%2FJenkins%E5%8F%91%E5%B8%83SpringCloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%88%B0WindowsServer%2F</url>
    <content type="text"><![CDATA[SpringCloud微服务可以在Jenkins上配置Maven项目打包发布到Linux系统，打包后发布到远程系统上文件为jar包。需要Jenkins系统环境支持为：Git：用以从Gitlab&amp;Github拉取代码。Maven：用以对代码进行打包，打包成jar格式的服务包。Jdk：用以运行Jar包所需的Java环境。SpringCloud架构中的微服务本质为可以独立运行的jar包。Jenkins发布服务到WindosServer则需要以下步骤。 一、配置WindowsServer支持SSH1、配置SSH环境当前系统为WindowsServer2012R2，实现SSH连接windows服务器，需要使用PowerShell Server。从官网下载后安装，具体配置如下建议勾选Run as a Windows Service，然后启动12345[2018/12/19 14:46:02] [2808] [1] Starting (user initiated).[2018/12/19 14:46:02] [2808] [1] Starting PowerShell Server Win32 Service...[2018/12/19 14:46:03] [33576] [4] PowerShell Server Started. Version: 16.0.6801.[2018/12/19 14:46:03] [33576] [4] Max Connections: 5[2018/12/19 14:46:04] [2808] [8] PowerShell Server Win32 Service started. 出现以上信息表示启动成功关系客户端连接的日志信息、报错信息等都会出现在这个界面内，出现问题时候可以注意检查。PowerShell Server支持如下客户端： Putty on Windows Connect-PowerShellServer, Invoke-PowerShellServer, and Disconnect-PowerShellServer Cmdlets included in NetCmdlets. PSClient in IP*Works! SSH Any SSH client on a mobile device. OpenSSH with XTerm, gnome-terminal, Konsole. 具体链接过程不再演示系统用户名为administrator 远程端口为22 IP不变 密码不变 2、配置Java环境Java环境配置直接官网下载，默认安装即可，不再详细描述。只是要注意JAVA_HOME的路径即好。 二、Jenkins相关配置首先将WindowsServer的的远程密码配置进Jenkisn的全局凭据中。在配置中的SSH sites中和SSH Servers中添加WindowsServer，如下图所示：test显示成功则可以继续进行Jenkins Job的配置，Jenkins Job的配置和LinuxServer区别不大，不再详细描述。 三、WindowsServer相关脚本配置首先Jenkins发布的jar包会上传到上图二中所示，目录C:\work\service_jar下。 1、启动脚本关于启动脚本使用bat脚本jar包启动需要特殊权限，所以需要先获取管理员权限。脚本执行完成以后需要返回给Jenkins状态码0，不然Jenkins会提示报错，提示发布不稳定。完整脚本如下：12345678910111213141516171819202122232425@echo offecho Get Administrator privilegescacls.exe "%SystemDrive%\System Volume Information" &gt;nul 2&gt;nulif %errorlevel%==0 goto Adminif exist "%temp%\getadmin.vbs" del /f /q "%temp%\getadmin.vbs"echo Set RequestUAC = CreateObject^("Shell.Application"^)&gt;"%temp%\getadmin.vbs"echo RequestUAC.ShellExecute "%~s0","","","runas",1 &gt;&gt;"%temp%\getadmin.vbs"echo WScript.Quit &gt;&gt;"%temp%\getadmin.vbs""%temp%\getadmin.vbs" /fif exist "%temp%\getadmin.vbs" del /f /q "%temp%\getadmin.vbs"exit:Adminecho Get Administrator privileges Successfullyset YYYYmmdd=%date:~0,4%%date:~5,2%%date:~8,2%set t=%time:~,8%set t=%t::=%set t=%t: =0%SET JAVA_HOME="C:\jdk1.8"copy "%JAVA_HOME%\bin\java.exe" "%JAVA_HOME%\bin\riskArchiveService.exe""%JAVA_HOME%\bin\riskArchiveService.exe" -Xms1024M -Xmx1024M -Xmn385M -XX:+PrintGCDetails -jar C:\work\service_jar\riskArchiveService.jar --server.port=28000 --management.port=28001 --config.profile=pro --config.ip=http://172.16.109.142:17001/ &gt; C:\work\logs\riskArchiveService_%YYYYmmdd%_%t%.log 2&gt;&amp;1exit 0 脚本中讲java.execopy为servicename.exe，以此种方式启动后，则服务名为独立的，可以启动多个jar服务。如果进行此操作也可以启动，但是服务名为java.exe，则整个系统只能启动一个服务，不利于系统资源利用。可以从任务管理器和系统信息中查看启动的服务。 2、停止脚本WindowsServer上停止服务比较简单，依旧使用bat脚本，如下：12tasklist|find /i "riskArchiveService.exe"||exit 0taskkill -f -t -im riskArchiveService.exe 首先查找具体服务，如果服务不存在，则返回码为0。如果服务存在则taskkill。]]></content>
      <categories>
        <category>Automation</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>Windwos</tag>
        <tag>PowerShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置http跳转到https]]></title>
    <url>%2F2018%2F12%2F17%2FNginx%E9%85%8D%E7%BD%AEhttp%E8%B7%B3%E8%BD%AC%E5%88%B0https%2F</url>
    <content type="text"><![CDATA[现有域名test.com www.test.com配置https需要将http跳转到https，将test.com跳转到www.test.comNginx配置示例如下1234567891011121314151617181920212223242526272829303132333435363738server &#123; listen 80; server_name www.test.com test.com; rewrite ^(.*)$ https://$&#123;server_name&#125;$1 permanent; &#125;server &#123; listen 443; server_name www.test.com test.com; if ( $host != 'www.test.com' ) &#123; rewrite ^/(.*)$ https://www.test.com/$1 permanent; &#125; ssl on; ssl_certificate /data/nginx/cert/cert_www.test.com.crt; ssl_certificate_key /data/nginx/cert/cert_www.test.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; access_log logs/access_test.log main; error_log logs/error_test.log error; location / &#123; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow_Credentials' 'true'; add_header 'Access-Control-Allow-Headers' 'Authorization,Accept,Origin,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range'; add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS,PUT,DELETE,PATCH'; root /data/work/test; index login.html login.htm; error_page 405 =200 $uri; &#125;&#125; 以上配置访问http://www.test.com https://test.com https://test.com最终都会跳转到https://www.test.com也可以将配置一个server实例如下：12345678910111213141516171819202122232425262728293031323334server &#123; listen 80; listen 443 sssl; server_name www.test.com test.com; if ( $host != 'www.test.com' ) &#123; rewrite ^/(.*)$ https://www.test.com/$1 permanent; &#125; #ssl on; ssl_certificate /data/nginx/cert/cert_www.test.com.crt; ssl_certificate_key /data/nginx/cert/cert_www.test.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; access_log logs/access_test.log main; error_log logs/error_test.log error; location / &#123; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow_Credentials' 'true'; add_header 'Access-Control-Allow-Headers' 'Authorization,Accept,Origin,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range'; add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS,PUT,DELETE,PATCH'; root /data/work/test; index login.html login.htm; error_page 405 =200 $uri; &#125;&#125; 其中需要将ssl on;注释，将443修改为443 ssl。]]></content>
      <categories>
        <category>OS</category>
        <category>Service</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>http</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka基础文档]]></title>
    <url>%2F2018%2F12%2F14%2FKafka%E5%9F%BA%E7%A1%80%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[一、Kafka简介1、简介Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。Apache的Kafka™是一个分布式流平台(a distributed streaming platform)。这到底意味着什么？我们认为，一个流处理平台应该具有三个关键能力：（1）它可以让你发布和订阅记录流。在这方面，它类似于一个消息队列或企业消息系统。（2）它可以让你持久化收到的记录流，从而具有容错能力。（3）它可以让你处理收到的记录流。Kafka擅长哪些方面？它被用于两大类应用：（1）建立实时流数据管道从而能够可靠地在系统或应用程序之间的共享数据（2）构建实时流应用程序，能够变换或者对数据（3）进行相应的处理。想要了解Kafka如何具有这些能力，让我们从下往上深入探索Kafka的能力。首先，明确几个概念：（1）Kafka是运行在一个或多个服务器的集群(Cluster)上的。（2）Kafka集群分类存储的记录流被称为主题(Topics)。（3）每个消息记录包含一个键，一个值和时间戳。Kafka有四个核心API：（1）生产者 API 允许应用程序发布记录流至一个或多个Kafka的话题(Topics)。（2）消费者API允许应用程序订阅一个或多个主题，并处理这些主题接收到的记录流。（3）Streams API允许应用程序充当流处理器（stream processor），从一个或多个主题获取输入流，并生产一个输出流至一个或多个的主题，能够有效地变换输入流为输出流。（4）Connector API允许构建和运行可重用的生产者或消费者，能够把 Kafka主题连接到现有的应用程序或数据系统。例如，一个连接到关系数据库的连接器(connector)可能会获取每个表的变化。 2、应用场景主要应用场景是：（1）构建实时的流数据管道，可靠地获取系统和应用程序之间的数据。（2）构建实时流的应用程序，对数据流进行转换或反应。Kafka主要设计目标如下：（1）以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。（2）高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。（3）支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。（4）同时支持离线数据处理和实时数据处理。 3、Kafka的设计原理分析一个典型的kafka集群中包含若干producer，若干broker，若干consumer，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。producer使用push模式将消息发布到broker，consumer使用pull模式从broker订阅并消费消息。Kafka专用术语：Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。消费者可以订阅一个或多个主题(topic),并从Broker拉数据，从而消费这些已发布的消息。每个消息（也叫作record记录,也被称为消息）是由一个key，一个value和时间戳构成。Topic：一类消息，Kafka集群能够同时负责多个topic的分发。Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。Segment：partition物理上由多个segment组成。offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset，用于partition唯一标识一条消息。Producer：负责发布消息到Kafka broker，可以理解为生产者。Consumer：消息消费者，向Kafka broker读取消息的客户端，可以理解为生产者。Consumer Group：每个Consumer属于一个特定的Consumer Group。topic: 消息以topic为类别记录,Kafka将消息种子(Feed)分门别类,每一类的消息称之为一个主题(Topic)。 4、主题（Topic）和日志（Logs）作为Kafka对数据提供的核心抽象，主题是发布的数据流的类别或名称。主题在Kafka中，总是支持多订阅者的; 也就是说，主题可以有零个，一个或多个消费者订阅写到相应主题的数据. 对应每一个主题，Kafka集群会维护像一个如下这样的分区的日志：每个分区都是是一个有序的，不可变的，并且不断被附加的记录序列，—也就是一个结构化提交日志（commit log）。为了保证唯一标性识分区中的每个数据记录，分区中的记录每个都会被分配一个一个叫做偏移（offset）顺序的ID号。通过一个可配置的保留期，Kafka集群会保留所有被发布的数据，不管它们是不是已经被消费者处理。例如，如果保留期设置为两天，则在发布记录后的两天内，数据都可以被消费，之后它将被丢弃以释放空间。 卡夫卡的性能是不为因为数据量大小而受影响的，因此长时间存储数据并不成问题。事实上，在每个消费者上保留的唯一元数据是消费者在日志中的偏移位置。这个偏移由消费者控制：通常消费者会在读取记录时线性地提高其偏移值（offset++），但实际上，由于偏移位置由消费者控制，它可以以任何顺序来处理数据记录。事实上，在每个消费者上保留的唯一元数据是消费者在日志中的偏移位置。这个偏移由消费者控制：通常消费者会在读取记录时线性地提高其偏移值（offset++），但实际上，由于偏移位置由消费者控制，它可以以任何顺序来处理数据记录。 5、数据的分配（Distribution）在Kafka集群中，不同分区日志的分布在相应的不同的服务器节点上，每个服务器节点处理自己分区对应的数据和请求。每个分区都会被复制备份到几个（可配置）服务器节点，以实现容错容灾。 分布在不同节点的同一个分区都会有一个服务器节点作为领导者（”leader”）和0个或者多个跟随者（”followers”），分区的领导者会处理所有的读和写请求，而跟随者只会被动的复制领导者。如果leader挂了, 一个follower会自动变成leader。每个服务器都会作为其一些分区的领导者，但同时也可能作为其他分分区的跟随者，Kafka以此来实现在集群内的负载平衡。 6、生产者生产者将数据发布到他们选择的主题。 生产者负责选择要吧数据分配给主题中哪个分区。这可以通过循环方式（round-robin）简单地平衡负载，或者可以根据某些语义分区（例如基于数据中的某些关键字）来完成。 7、消费者消费者们使用消费群组名称来标注自己，几个消费者共享一个组群名，每一个发布到主题的数据会被传递到每个消费者群组中的一个消费者实例。 消费者实例可以在不同的进程中或不同的机器上。 如果所有的消费者实例具有相同的消费者组，则记录将在所有的消费者实例上有效地负载平衡,每个数据只发到了一个消费者 如果所有的消费者实例都有不同的消费者群体，那么每个记录将被广播给所有的消费者进程，每个数据都发到了所有的消费者。 8、Kafka作为消息系统消息系统传统上有两种模式: 队列和发布-订阅. 在队列中，消费者池可以从服务器读取，每条记录都转到其中一个; 在发布订阅中，记录将广播给所有消费者。 这两个模型中的每一个都有优点和缺点。 排队的优点是它允许您在多个消费者实例上分配数据处理，从而可以扩展您的处理。 不幸的是，队列支持多用户，一旦一个进程读取数据就没有了。 发布订阅允许您将数据广播到多个进程，但无法缩放和扩容，因为每个消息都发送给每个订阅用户。 卡夫卡消费群体概念概括了这两个概念。 与队列一样，消费者组允许您通过一系列进程（消费者组的成员）来划分处理。 与发布订阅一样，Kafka允许您将消息广播到多个消费者组。 Kafka模型的优点是，每个主题都具有这两个属性，它可以进行缩放处理，也是多用户的，没有必要选择一个而放弃另一个。 卡夫卡也比传统的消息系统有更强大的消息次序保证。 传统队列在服务器上保存顺序的记录，如果多个消费者从队列中消费，则服务器按照存储顺序输出记录。 然而，虽然服务器按顺序输出记录，但是记录被异步传递给消费者，所以它们可能会在不同的消费者处按不确定的顺序到达。 这意味着在并行消耗的情况下，记录的排序丢失。 消息传递系统通常通过使“唯一消费者”的概念只能让一个进程从队列中消费，但这当然意味着处理中没有并行性。 卡夫卡做得更好。通过分区，在一个主题之内的并行处理，Kafka能够在消费者流程池中，即提供排序保证，也负载平衡。这是通过将主题中的分区分配给消费者组中的消费者来实现的，以便每一个分区由组中的一个消费者使用。 通过这样做，我们确保消费者是该分区的唯一读者，并按顺序消耗数据。 由于有许多分区，这仍然平衡了许多消费者实例的负载。 但是请注意，消费者组中的消费者实例个数不能超过分区的个数。 9、Kafka作为存储系统任何允许发布消息，解耦使用消息的消息队列，都在本质上充当传输中途消息的存储系统。 卡夫卡的不同之处在于它是一个很好的存储系统。 写入Kafka的数据写入磁盘并进行复制以进行容错。 Kafka允许生产者等待写入完成的确认，这样在数据完全复制之前，写入是未完成的，并且即使写入服务器失败，也保证持久写入。 Kafka的磁盘结构使用可以很好的扩容，无论您在服务器上是否有50KB或50TB的持久数据，Kafka都能保持稳定的性能。 由于对存储花费了很多精力，并允许客户端控制其读取位置，您可以将Kafka视为，专用于高性能，低延迟的日志存储复制和传播的专用分布式文件系统。任何允许发布消息，解耦使用消息的消息队列，都在本质上充当传输中途消息的存储系统。 卡夫卡的不同之处在于它是一个很好的存储系统。 写入Kafka的数据写入磁盘并进行复制以进行容错。 Kafka允许生产者等待写入完成的确认，这样在数据完全复制之前，写入是未完成的，并且即使写入服务器失败，也保证持久写入。 Kafka的磁盘结构使用可以很好的扩容，无论您在服务器上是否有50KB或50TB的持久数据，Kafka都能保持稳定的性能。 由于对存储花费了很多精力，并允许客户端控制其读取位置，您可以将Kafka视为，专用于高性能，低延迟的日志存储复制和传播的专用分布式文件系统。 10、Kafka用于流数据处理仅读取，写入和存储数据流是不够的，Kafka的目的是实现流的实时处理。 在Kafka中，流处理器的定义是：任何从输入主题接收数据流，对此输入执行一些处理，并生成持续的数据流道输出主题的组件。 例如，零售应用程序可能会收到销售和出货的输入流，并输出根据该数据计算的重新排序和价格调整的输出流。 当然我们也可以直接用producer and consumer APIs在做简单的出列. 然而对于更复杂的转换，Kafka提供了一个完全集成的Streams API。这允许我们构建应用程序进行更复杂的运算，或者聚合，或将流连接在一起。 该设施有助于解决这种类型的应用程序面临的困难问题：处理无序数据，重新处理输入作为代码更改，执行有状态计算等。 Stream API基于Kafka提供的核心原语构建：它使用生产者和消费者API进行输入，使用Kafka进行有状态存储，并在流处理器实例之间使用相同的组机制来实现容错。仅读取，写入和存储数据流是不够的，Kafka的目的是实现流的实时处理。 在Kafka中，流处理器的定义是：任何从输入主题接收数据流，对此输入执行一些处理，并生成持续的数据流道输出主题的组件。 例如，零售应用程序可能会收到销售和出货的输入流，并输出根据该数据计算的重新排序和价格调整的输出流。 当然我们也可以直接用producer and consumer APIs在做简单的出列. 然而对于更复杂的转换，Kafka提供了一个完全集成的Streams API。这允许我们构建应用程序进行更复杂的运算，或者聚合，或将流连接在一起。 该设施有助于解决这种类型的应用程序面临的困难问题：处理无序数据，重新处理输入作为代码更改，执行有状态计算等。 Stream API基于Kafka提供的核心原语构建：它使用生产者和消费者API进行输入，使用Kafka进行有状态存储，并在流处理器实例之间使用相同的组机制来实现容错。综上所述：消息系统，数据存储和流处理的这种组合似乎是不寻常的，但是这些特性对于Kafka作为流媒体平台的角色至关重要。 像HDFS这样的分布式文件系统允许存储用于批处理的静态文件。 本质上，这样的系统允许存储和处理来自过去的历史数据。 传统的企业邮消息系统允许处理将在您订阅之后到达的未来消息。 以这种方式构建的应用程序在未来数据到达时即使处理。 Kafka结合了这两种功能，这种组合对于Kafka作为流应用程序和流数据管道平台来说至关重要。 通过组合存储和低延迟订阅，流式应用程序可以以相同的方式处理过去和未来的数据。 这是一个单一的应用程序可以处理历史记录数据，而不是在到达最后一个记录时结束，它可以随着将来的数据到达而继续处理。 这是一个广泛的流处理概念，其中包含批处理以及消息驱动应用程序。 同样，对于流数据流水线，订阅到实时事件的组合使得可以使用Kafka进行非常低延迟的管道传输; 可靠地存储数据的能力使得可以将其用于必须保证数据传送的关键数据，或者与仅负载数据的离线系统集成，或者可能会长时间停机以进行维护。流处理功能在数据到达时进行数据转换处理。 二、Kafka安装Kafka需要Zookeeper的监控，所以先要安装Zookeeper。新版本Kafka拥有自带的zookeeper，也可以不用安装zookeeper，根据选择的kafka版本确定。Zookeeper需要java环境支持，所以先要安装jdk。 1、JDK安装检查系统是否已经安装jdk1java -version 如果没有显示java版本信息，则表示没有安装java12345678910#安装javatar -zxvf jdk-8u161-linux-x64.tar.gzmv jdk1.8.0_161 /data/jdk1.8#修改系统变量vi /etc/profile#在文本末尾添加以下内容：PATH=/data/jdk1.8/bin:$PATHexport PATH#使添加内容生效 source /etc/profile 再查看java版本 出现如下信息表示安装成功1234# java -versionjava version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 2、Zookeeper安装官网下载地址：http://apache.fayea.com/zookeeper/stable/Zookeeper属于可选安装1234567891011#下载wget http://apache.fayea.com/zookeeper/stable/zookeeper-3.4.10.tar.gztar -zxvf zookeeper-3.4.10.tar.gz mv zookeeper-3.4.10 /data/zookeepercd /data/zookeeper/#创建数据目录mkdir /data/zookeeper/datacd conf/#创建配置文件cp zoo_sample.cfg zoo.cfg vim zoo.cfg zoo.cfg修改后为12345tickTime=2000initLimit=10syncLimit=5dataDir=/data/zookeeper/dataclientPort=2181 配置环境变量：vim /etc/profile，加入以下内容12export ZOOKEEPER_HOME=/data/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf source /etc/profile使新增加环境变量生效zookeeper相关命令123456#开启/data/zookeeper/bin/zkServer.sh start#停止/data/zookeeper/bin/zkServer.sh status#查看状态/data/zookeeper/bin/zkServer.sh status 3、Kafka安装官网下载地址：http://kafka.apache.org/downloads本次下载最新版本123wget http://mirror.bit.edu.cn/apache/kafka/1.1.0/kafka_2.12-1.1.0.tgztar -zxvf kafka_2.12-1.1.0.tgz mv kafka_2.12-1.1.0 /data/kafka 修改配置文件12cd /data/kafka/vim config/server.properties Server.properties修改后为12345678910111213141516171819broker.id=0port=9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/data/kafka/logs/kafka-logsnum.partitions=1num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=localhost:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0 修改关于zookeeper的配置文件zookeeper.properties1vim config/zookeeper.properties zookeeper.properties修改后为123dataDir=/data/kafka/zkdataclientPort=2181maxClientCnxns=0 在kafka目录启动zookeeper12cd /data/kafkabin/zookeeper-server-start.sh config/zookeeper.properties &amp; 启动kafka1bin/kafka-streams-application-reset.sh config/server.properties &amp;]]></content>
      <categories>
        <category>OS</category>
        <category>Service</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>Message</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大日志文件进行分割的N种方法]]></title>
    <url>%2F2018%2F12%2F13%2F%E5%A4%A7%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E5%89%B2%E7%9A%84N%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[当日志容量上G的时候，用vi查看具体内容效率就会变得特别低，这个时候就需要将大日志进行分割。为了比较各种分割方法的效果，我选取的测试日志基本信息如下：1234# ls -lrth test.log-rw-r--r-- 1 root root 645M 5月 30 20:42 test.log# wc -l test.log8856340 test.log 1、split方法分割split命令专门用来将一个大文件分割成很多个小文件，我把split命令的选项做一个简要说明 选项 含义 -b 分割后的文档大小，单位是byte -C 分割后的文档，单行最大byte数 -d 使用数字作为后缀，同时使用-a length指定后缀长度 -l 分割后文档的行数 为了尽量保证日志的可读性，我们按行分割大日志文件，并且指定分割后的文件的前缀和后缀 123456789101112131415#后缀是数字，占两位，前缀是test.logsplit -l 1000000 test.log -d -a 2 test.log#分割之后的结果ls -lrth总用量 1.3G-rw-r--r-- 1 root root 645M 5月 30 20:42 test.log-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log00-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log01-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log02-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log03-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log04-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log05-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log06-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log07-rw-r--r-- 1 root root 64M 5月 30 20:55 test.log08 2、dd分割123dd bs=1M count=300 if=test.log of=newlog.1dd bs=1M count=300 if=test.log of=newlog.2 skip=300dd bs=1M count=300 if=test.log of=newlog.3 skip=600 分割后的效果123456ls -lrth总用量 1.3G-rw-r--r-- 1 root root 645M 5月 30 20:42 test.log-rw-r--r-- 1 root root 300M 5月 30 21:07 newlog.1-rw-r--r-- 1 root root 300M 5月 30 21:07 newlog.2-rw-r--r-- 1 root root 45M 5月 30 21:07 newlog.3 在上面使用的命令中，bs代表数据块的大小，count表示复制的块数，if表示输入文件，of表示输出文件。这个命令不能一下就把文件分割到我们想要的状态，而且很有可能一行日志被分到两个文件中。 3、head+tail分割用这两个命令获取文件部分内容，然后重定向就能实现文件分割，但是限制也挺多，只能把文件分成两部分，如果文件特别大，想要达到预期的效果，就要一直分割下去。head/tail -n $行数 test.log &gt; newlog因为这两个命令都比较熟悉，不再多讲。 4、sed实现分割实现原理就是用sed截取特定行之间的内容，然后进行重定向。12345sed -n '1,2000000p' test.log &gt; test.log.1sed -n '2000001,4000000p' test.log &gt; test.log.2sed -n '4000001,6000000p' test.log &gt; test.log.3sed -n '6000001,8000000p' test.log &gt; test.log.4sed -n '8000001,$p' test.log &gt; test.log.5 $表示最后一行，这个如果分割过多，也需要一个循环。 5、awk实现分割实现原理和sed差不多，因为使用awk不多，这里只举一个小例子：12awk ‘&#123;if (NR&lt;120000) print $0&#125;’ test.log &gt; a.txtawk ‘&#123;if (NR&gt;=120000) print $0&#125;’ test.log &gt; b.txt 还是split用得舒服。]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>日志</tag>
        <tag>分割</tag>
        <tag>split</tag>
        <tag>dd</tag>
        <tag>head</tag>
        <tag>tail</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装Nodejs]]></title>
    <url>%2F2018%2F12%2F12%2FCentOS%E4%B8%8A%E5%AE%89%E8%A3%85Nodejs%2F</url>
    <content type="text"><![CDATA[Node官方地址：https://nodejs.org/en/选择LTS最新版本 1、二进制包安装1234wget https://nodejs.org/dist/v10.14.2/node-v10.14.2-linux-x64.tar.xztar -d node-v10.14.2-linux-x64.tar.xztar -xvf node-v8.11.3-linux-x64.tarmv node-v8.11.3-linux-x64 /data/node 配置环境变量1vim /etc/profile 最后加入以下内容并保存12#set node environmentexport PATH=/data/node/bin:$PATH 执行以下命令，使环境变量生效1source /etc/profile 验证nodejs是否安装成功。12# node -vv8.11.3 出现以上信息即表示node安装成功。 2、源码包编译安装123456wget https://nodejs.org/dist/v10.14.2/node-v10.14.2.tar.gztar -zxvf node-v10.14.2.tar.gzcd node-v10.14.2./configure –prefix=/data/nodemakemake install 配置环境变量1vim /etc/profile 最后加入以下内容并保存12#set node environmentexport PATH=/data/node/bin:$PATH 执行以下命令，使环境变量生效1source /etc/profile 验证nodejs是否安装成功。12# node -vv8.11.3 出现以上信息即表示node安装成功。]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装Maven]]></title>
    <url>%2F2018%2F12%2F12%2FCnetOS%E4%B8%8A%E5%AE%89%E8%A3%85Maven%2F</url>
    <content type="text"><![CDATA[1、下载打开官方下载地址：http://maven.apache.org/download.cgi选择版本下载，选择最优版本Maven3.3.9下载链接为：http://mirror.bit.edu.cn/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz直接通过wget下载12cd /data/backupwget http://mirror.bit.edu.cn/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz 2、安装解压Maven并移动到/data目录下12tar -zxvf apache-maven-3.3.9-bin.tar.gzmv apache-maven-3.3.9 /data/maven3 配置环境变量1vim /etc/profile 最后加入以下内容并保存1234#set maven environmentMAVEN_HOME=/data/maven3export MAVEN_HOMEexport PATH=$&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;/bin 执行以下命令，使环境变量生效1source /etc/profile 验证maven是否安装成功。1234567# mvn -vApache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)Maven home: /data/maven3Java version: 1.8.0_161, vendor: Oracle CorporationJava home: /data/jdk1.8/jreDefault locale: en_US, platform encoding: UTF-8OS name: "linux", version: "3.10.0-693.2.2.el7.x86_64", arch: "amd64", family: "unix" 出现以上信息即表示maven安装成功。]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装Java环境]]></title>
    <url>%2F2018%2F12%2F12%2FCentOS%E4%B8%8A%E5%AE%89%E8%A3%85Java%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[检查系统是否已经安装jdk1java -version 如果没有显示java版本信息，则表示没有安装java下载地址：http://www.oracle.com/technetwork/cn/java/javase/downloads/jdk8-downloads-2133151-zhs.html如果有更新最新版本，可以获取最新版本下载，需要同意协议才可获取下载链接，在服务器上可以通过wget下载 #安装java12tar -zxvf jdk-8u161-linux-x64.tar.gzmv jdk1.8.0_161 /data/jdk1.8 #修改系统变量1vi /etc/profile 在文本末尾添加以下内容：123#set java environmentPATH=/data/jdk1.8/bin:$PATHexport PATH 使添加内容生效1source /etc/profile 再查看java版本1234# java -versionjava version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 出现如下信息表示安装成功]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB基础文档]]></title>
    <url>%2F2018%2F12%2F12%2FMongoDB%E5%9F%BA%E7%A1%80%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[一、 MongoDB简介1、MongoDB历史MongoDB最初于2007年开发，当时公司正在建立一个类似于窗口天蓝(window azure)的服务平台。“Window azure是由Microsoft创建的云计算平台和基础设施，通过全球网络构建，部署和管理应用程序和服务。”MongoDB由位于纽约的一个名为10gen的组织开发，现在被称为MongoDB Inc.，它最初被开发为PAAS(平台即服务)。 2009年晚些时候，它被作为一个由MongoDB公司维护和支持的开源数据库服务器在市场上引入。MongoDB的第一个真正产品是从2010年3月发布的MongoDB 1.4版本开始的。2014年1月10日发布的最新版本：MongoDB2.4.9。首先应该知道什么是面向文档的数据库？面向文档的数据库示例MongoDB是面向文档的数据库。这是MongoDB的一个主要功能。它提供面向文档的存储。这很简单，可以很容易地编程。MongoDB将数据存储为文档，因此被称为面向文档的数据库。12345FirstName = "Max", Address = "Haikou City", Spouse = [&#123;Name: "Maxsu"&#125;]. FirstName ="Kobe", Address = "LAC" 有两个不同的文件(用“.”分隔开)。以这种方式存储数据称为面向文档的数据库。 Mongodb属于一类名为面向文档数据库(Document Oriented Databases)。它属于一个叫作“NoSQL数据库”的数据库类别称。 2、MongoDB特点MongoDB的一些重要功能特性： 支持特别查询在MongoDB中，可以通过字段，范围查询进行搜索，并且还支持正则表达式搜索。 索引可以索引文档中的任何字段。 复制MongoDB支持主从复制。主机可以执行读写操作，从机从主机复制数据，只能用于读取或备份(不写入) 复制数据MongoDB可以在多台服务器上运行。 复制数据以保持系统正常运行，并在硬件故障的情况下保持其运行状态。 负载均衡由于数据放在碎片中，因此具有自动负载平衡配置。 支持映射缩减和聚合工具 使用JavaScript而不是Procedure 它是一个用C++编写的无模式数据库 提供高性能 轻松存储任何大小的文件，而不会使您的堆栈复杂化 在故障的情况下易于管理 具有动态模式的JSON数据模型 自动分片用于水平可扩展性 内置复制高可用性现在，许多公司使用 MongoDB 来创建新类型的应用程序，以提高性能和可用性。 3、MongoDB数据库的优点到目前为止，MongoDB是一个新的和普遍使用的数据库。它是一个基于文档的非关系数据库提供程序。虽然它比传统的数据库快100倍，但早期说它将广泛地取代传统的RDBMS。但是，不可否认的是：在性能和可扩展性方面 MongoDB 有着明显的优势。关系数据库具有典型的架构设计，可以显示表的数量以及这些表之间的关系，而在MongoDB中则没有关系的概念。（1）MongoDB优点 * MongoDB 的架构较少。它是一个文档数据库，它的一个集合持有不同的文档。 * 从一个到另一个的文档的数量，内容和大小可能有差异。 * MongoDB 中单个对象的结构很清淅。 * MongoDB 中没有复杂的连接。 * MongoDB 提供深度查询的功能，因为它支持对文档的强大的动态查询。 * MongoDB 很容易扩展。 * 它使用内部存储器来存储工作集，这是其快速访问的原因。 （2）MongoDb的独特功能 * 使用方便 * 重量轻/轻量级 * 比RDBMS快得多 （3）MongoDB应用场景 * 大而复杂的数据 * 移动和社会基础设施数据 * 内容管理和交付 * 用户数据管理 * 数据中心 （4）MongoDB和RDBMS的性能分析 * 在关系数据库(RDBMS)中，表用作存储元素，而在 MongoDB 中使用的是集合。 * 在RDBMS中有多个模式，在每个模式中，可创建用于存储数据的表，而 MongoDB 是面向文档的数据库，数据是以类似JSON格式的BSON格式编写的存储的。 * MongoDB几乎比传统数据库系统快100倍。 4、MongoDB快速入门MongoDB是一个跨平台，面向文档的数据库，提供高性能，高可用性和易于扩展。MongoDB是工作在集合和文档上一种概念。数据库数据库是一个集合的物理容器。每个数据库获取其自己设定在文件系统上的文件。一个单一的MongoDB服务器通常有多个数据库。集合集合是一组MongoDB的文件。它与一个RDBMS表是等效的。一个集合存在于数据库中。集合不强制执行模式。集合中的文档可以有不同的字段。通常情况下，在一个集合中的所有文件都是类似或相关目的。文档文档是一组键值对。文档具有动态模式。动态模式是指，在同一个集合的文件不必具有相同一组集合的文档字段或结构，并且相同的字段可以保持不同类型的数据。 二、MongoDB安装1、下载MongoDb的linux版本下载地址为https://www.mongodb.org/dl/linux/选择合适的版本下载1234wget http://downloads.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.2.20.tgz?_ga=2.11328048.543796309.1528358506-412859566.1526522668mv mongodb-linux-x86_64-rhel70-3.2.20.tgz\?_ga\=2.11328048.543796309.1528358506-412859566.1526522668 mongodb-linux-x86_64-rhel70-3.2.20.tgztar -zxvf mongodb-linux-x86_64-rhel70-3.2.20.tgz mv mongodb-linux-x86_64-rhel70-3.2.20 /data/mongodb 2、安装将Mongod移动到/data目录下，然后加入系统环境变量12#set mongodb environmentexport PATH=/data/mongodb/bin:$PATH 执行以下命令使配置生效1source /etc/profile 新建log、data、conf目录，如下123456789101112# pwd/data/mongodb# lltotal 104drwxr-xr-x 2 root root 4096 Jun 7 04:16 bindrwxr-xr-x 2 root root 6 Jun 7 04:29 confdrwxr-xr-x 4 root root 4096 Jun 7 04:43 data-rw-r--r-- 1 root root 34520 May 8 18:08 GNU-AGPL-3.0drwxr-xr-x 2 root root 6 Jun 7 04:43 log-rw-r--r-- 1 root root 16726 May 8 18:08 MPL-2-rw-r--r-- 1 root root 2262 May 8 18:08 README-rw-r--r-- 1 root root 35910 May 8 18:08 THIRD-PARTY-NOTICES mongodb的bin下各工具的用途： * mongod：数据库服务端，类似mysqld，每个实例启动一个进程，可以fork为Daemon运行 * mongo：客户端命令行工具，类似sqlplus/mysql，其实也是一个js解释器，支持js语法 * mongodump/mongorestore：将数据导入为bson格式的文件/将bson文件恢复为数据库，类似xtracbackup * mongoexport/mongoimport：将collection导出为json/csv格式数据/将数据导入数据库，类似mysqldump/mysqlimport * bsondump：将bson格式的文件转储为json格式的数据 * mongos：分片路由，如果使用了sharding功能，则应用程序连接的是mongos而不是mongod * mongofiles：GridFS管理工具 * mongostat：实时监控工具启动mongodb 启动1mongod --dbpath /data/mongodb/data/ 出现以下信息表示启动成功 3、配置配置mongodb1234567891011# cat conf/mongodb.conf dbpath=/data/mongodb/datalogpath=/data/mongodb/log/mongodb.logpidfilepath=/data/mongodb/data/mongodb.pidlogappend=true#bind_ip=10.186.21.85bind_ip=0.0.0.0port=27017maxConns=20000fork=true#auth = true # 先关闭, 创建好用户在启动 mongod的主要参数有：dbpath: 数据文件存放路径，每个数据库会在其中创建一个子目录。logpath：错误日志文件logappend： 错误日志采用追加模式（默认是覆写模式）bind_ip： 对外服务的绑定ip，一般设置为空，及绑定在本机所有可用ip上，如有需要可以单独指定。只能绑定本机网卡上绑定的ip地址，如果指定ip没有绑定在本机网卡，则绑定0.0.0.0，此种情况适用于绑定云服务器的外网ip。port： 对外服务端口。Web管理端口在这个port的基础上+1000fork： 以后台Daemon形式运行服务journal：开启日志功能，通过保存操作日志来降低单机故障的恢复时间，在1.8版本后正式加入，取代在1.7.5版本中的dur参数。syncdelay： 执行sync的间隔，单位为秒。directoryperdb： 每个db存放在单独的目录中，建议设置该参数。maxConns： 最大连接数repairpath： 执行repair时的临时目录。在如果没有开启journal，异常宕机后重启，必须执行repair操作。此时可以指定配置文件启动mongodb1234# mongod -f /data/mongodb/conf/mongodb.conf about to fork child process, waiting until server is ready for connections.forked process: 20815child process started successfully, parent exiting 以上即表示启动成功 4、管理mongodb服务官网文档https://docs.mongodb.com/manual/tutorial/manage-mongodb-processes/#stop-mongod-processesStart mongod Processes（1）mongod（2）mongod –dbpath /srv/mongodb/（3）mongod –port 12345（4）mongod –fork –logpath /var/log/mongodb.log（5）mongod -f /data/mongodb/conf/mongodb.confStop mongod Processes（1）Use shutdownServer()12use admin db.shutdownServer() （2）Use –shutdown1mongod –shutdown （3）Use CTRL-C（4）Use kill12kill &lt;mongod process ID&gt;kill -2 &lt;mongod process ID&gt; 禁止使用-912WARNING:Never use kill -9 (i.e. SIGKILL) to terminate a mongod instance. 5、修复monogdb当出现服务器非正常关机的情况，重新启动的时候会出现以下类似报错12ERROR: child process failed, exited with error number 100ERROR: child process failed, exited with error number 48 解决方法为123mongod -f /data/mongodb/conf/mongodb.conf –repairmongod -f /data/mongodb/conf/mongodb.conf --authmongod -f /data/mongodb/conf/mongodb.conf 通过repair修复连接mongodb方法为1mongo --host 101.132.37.169:27017 其中ip地址为配置文件中bind_ip地址，如果是本地可以直接mongo连接6、打开网页在mongodb.conf配置文件中加入以下参数1rest=true 即可打开网页端口，默认为28017，如图所示 三、MongoDB操作1、用户操作创建用户12use admin db.createUser(&#123;user:"root",pwd:"root",roles:[&#123;role:"readWrite",db:"admin"&#125;]&#125;) 查看已存在的用户123&gt; db.system.users.find()&#123; "_id" : "admin.root", "user" : "root", "db" : "admin", "credentials" : &#123; "SCRAM-SHA-1" : &#123; "iterationCount" : 10000, "salt" : "1hkiX4Tscoj6bUpxF2x7+A==", "storedKey" : "ciyQR1bc5Bbm6Qxg4euAijnadCw=", "serverKey" : "F/Gg0NmM19ih62VjbccW/SYOAh4=" &#125; &#125;, "roles" : [ &#123; "role" : "root", "db" : "admin" &#125; ] &#125;&#123; "_id" : "testdb.testdb", "user" : "testdb", "db" : "testdb", "credentials" : &#123; "SCRAM-SHA-1" : &#123; "iterationCount" : 10000, "salt" : "VhSm/77+cGXEUwYAbdHvSw==", "storedKey" : "hDtO9gq4OVNdcChNSoRhYiXmSQQ=", "serverKey" : "L1bPBquYwey5O0BYsDl7zsiSojs=" &#125; &#125;, "roles" : [ &#123; "role" : "dbOwner", "db" : "testdb" &#125; ] &#125; 删除用户12&gt; db.system.users.remove(&#123;user:"testdb1u1"&#125;)WriteResult(&#123; "nRemoved" : 1 &#125;) 用户登录数据库测试1mongo -u testdb -p 123456 127.0.0.1:27017/testdb 2、数据库操作创建数据库12&gt; use newdbswitched to db newdb 检查当前选择的数据库12&gt; dbnewdb 检查数据库列表123&gt; show dbsadmin 0.000GBlocal 0.000GB 新创建的数据库(newdb)不在列表中。要显示数据库，需要至少插入一个文档，否则空的数据库是不显示出来的。123456&gt; db.items.insert(&#123;"name":"yiibai tutorials"&#125;)WriteResult(&#123; "nInserted" : 1 &#125;)&gt; show dbsadmin 0.000GBlocal 0.000GBnewdb 0.000GB 在 MongoDB 中默认数据库是：test。 如果您还没有创建过任何数据库，则集合/文档将存储在test数据库中。删除数据库MongoDB中的 db.dropDatabase()命令用于删除现有的数据库。123456789101112131415&gt; show dbsadmin 0.000GBlocal 0.000GBnewdb 0.000GB&gt; show dbsadmin 0.000GBlocal 0.000GBnewdb 0.000GB&gt; dbnewdb&gt; db.dropDatabase()&#123; "dropped" : "newdb", "ok" : 1 &#125;&gt; show dbsadmin 0.000GBlocal 0.000GB 以上过程已把数据库newdb删除 四、MongoDB集群1、MongoDB主从模式搭建（1）Master-Slave搭建两台服务器IP分别为：10.186.21.85（主）、10.186.21.84（从）关于mongodb的详细配置可以从配置文件看到主库配置文件1234567891011121314151617181920# cat /data/mongodb/conf/mongodb.conf dbpath=/data/mongodb/data #数据库路径logpath=/data/mongodb/log/mongodb.log #日志输出文件路径logappend=true #日志输出方式pidfilepath=/data/mongodb/data/mongodb.pid #pid文件路径#bind_ip=10.186.21.85bind_ip=0.0.0.0port=27017 #端口号rest=true #设置后打开28017网页端口httpinterface=truemaxConns=20000fork=true #设置后台运行shardsvr=true#directoryperdb=true#auth = true # 先关闭, 创建好用户在启动#nohttpinterface=falsejournal=truequiet=truemaster=true 从库配置文件123456789101112131415161718192021# cat /data/mongodb/conf/mongodb.conf dbpath=/data/mongodb/data #数据库路径logpath=/data/mongodb/log/mongodb.log #日志输出文件路径logappend=true #日志输出方式pidfilepath=/data/mongodb/data/mongodb.pid #pid文件路径#bind_ip=10.186.21.84bind_ip=0.0.0.0port=27017 #端口号rest=true #设置后打开28017网页端口httpinterface=truemaxConns=20000fork=true #设置后台运行shardsvr=true#directoryperdb=true#auth = true # 先关闭, 创建好用户在启动#nohttpinterface=falsejournal=truequiet=trueslave=truesource=10.186.21.85:27017 验证主库添加数据库12345678910111213&gt; show dbsadmin 0.000GBlocal 0.000GB&gt; use testdbswitched to db testdb&gt; db.items.insert(&#123;"name":"yiibai tutorials"&#125;)WriteResult(&#123; "nInserted" : 1 &#125;)&gt; use testdbswitched to db testdb&gt; show dbsadmin 0.000GBlocal 0.000GBtestdb 0.000GB 从库查看数据库验证12345&gt; rs.slaveOk()&gt; show dbsadmin 0.000GBlocal 0.000GBtestdb 0.000GB 登录从库后执行命令可能会报错1[thread1] Error: listDatabases failed:&#123; "ok" : 0, "errmsg" : "not master and slaveOk=false", "code" : 13435 &#125; : 解决方法为登录从库后执行rs.slaveOk()，如下123456789101112&gt; show dbs2018-06-08T05:25:43.065-0400 E QUERY [thread1] Error: listDatabases failed:&#123; "ok" : 0, "errmsg" : "not master and slaveOk=false", "code" : 13435 &#125; :_getErrorWithCode@src/mongo/shell/utils.js:25:13Mongo.prototype.getDBs@src/mongo/shell/mongo.js:62:1shellHelper.show@src/mongo/shell/utils.js:781:19shellHelper@src/mongo/shell/utils.js:671:15@(shellhelp2):1:1&gt; rs.slaveOk()&gt; show dbsadmin 0.000GBlocal 0.000GB （2）Master-Slave安全这个主从安全在 MongoDB官网说的很清楚。不能和普通的mongod权限验证那样。这里除了需要加入 —auth 还需要加入 —keyFile 的验证。首先，我们生成我们的keyFile，根据官网提供的说明，这个keyfile是可以任意内容的，只要保证所有集群中的机器都拥有同样的文件即可。在linux环境下，我们通过1openssl rand -base64 741 &gt; /data/mongodb/mongo-keyfile 这条命令来生成我们的keyFile。保证主从库上使用的配置文件相同，在配置文件中加入1keyFile=/data/mongodb/mongo-keyfile 重新启动monodb，报错1234# mongod -f /data/mongodb/conf/mongodb.confabout to fork child process, waiting until server is ready for connections.forked process: 16492ERROR: child process failed, exited with error number 1 查看日志12CONTROL [main] ***** SERVER RESTARTED *****ACCESS [main] permissions on /data/mongodb/mongo-keyfile are too open 可以看到是文件权限过大调整权限为400123456789101112# chmod 400 mongo-keyfile # lltotal 108drwxr-xr-x 2 root root 4096 Jun 7 04:16 bindrwxr-xr-x 2 root root 25 Jun 8 05:44 confdrwxr-xr-x 4 root root 4096 Jun 8 05:49 data-rw-r--r-- 1 root root 34520 May 8 18:08 GNU-AGPL-3.0drwxr-xr-x 2 root root 24 Jun 7 05:20 log-r-------- 1 root root 7 Jun 8 05:42 mongo-keyfile-rw-r--r-- 1 root root 16726 May 8 18:08 MPL-2-rw-r--r-- 1 root root 2262 May 8 18:08 README-rw-r--r-- 1 root root 35910 May 8 18:08 THIRD-PARTY-NOTICES 重新启动，即可启动成功]]></content>
      <categories>
        <category>DB</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>集群</tag>
        <tag>主从</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix安装]]></title>
    <url>%2F2018%2F12%2F11%2FZabbix%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[一、环境配置关闭selinux12vim /etc/sysconfig/selinuxSELINUX=disabled 二、Nginx安装Nginx在生产环境推荐使用编译方式安装 1、安装编译环境、gcc12yum -y install gcc gcc-c++ automake autoconf libtool makeyum install gcc gcc-c++ 一般我们都需要先装pcre, zlib，前者为了重写rewrite，后者为了gzip压缩。从ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/ 下载最新的 PCRE 源码包，使用下面命令下载编译和安装 PCRE 包： 2、安装pcre1234567cd /data/backupwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.42.tar.gztar -zxvf pcre-8.42.tar.gzcd pcre-8.42./configuremakemake install 3、安装zlib从http://zlib.net下载最新的 zlib 源码包，使用下面命令下载编译和安装 zlib包：1234567cd /data/backupwget http://zlib.net/zlib-1.2.11.tar.gz tar -zxvf zlib-1.2.11.tar.gzcd zlib-1.2.11./configuremakemake install 4、安装openssl123cd /data/backupwget https://www.openssl.org/source/openssl-1.1.0h.tar.gztar -zxvf openssl-1.1.0h.tar.gz 5、安装Nginx1234567cd /data/backupwget http://nginx.org/download/nginx-1.14.0.tar.gztar -zxvf nginx-1.14.0.tar.gz cd nginx-1.14.0./configure --prefix=/data/nginx/ --with-http_v2_module --with-http_ssl_module --with-http_flv_module --with-http_mp4_module --with-http_sub_module --with-http_stub_status_module --with-http_gzip_static_module --without-http-cache --with-http_realip_module --with-pcre=/data/backup/pcre-8.42 --with-zlib=/data/backup/zlib-1.2.11 --with-openssl=/data/backup/openssl-1.1.0hmakemake install 创建Nginx软连接到环境变量1ln -s /data/nginx/sbin/* /usr/local/sbin/ 三、php安装Zabbix界面需要支持的PHP组件可以从官网查看，如下图： 1、安装插件1yum install -y libxml2 libxml2-devel openssl openssl-devel bzip2 bzip2-devel libcurl libcurl-devel libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel gmp gmp-devel libmcrypt libmcrypt-devel readline readline-devel libxslt libxslt-devel libicu-devel 2、编译安装PHP123456wget http://cn2.php.net/distributions/php-7.2.8.tar.gztar -zxvf php-7.2.8.tar.gz cd php-7.2.8/./configure --prefix=/data/php --with-curl --with-freetype-dir --with-gd --with-gettext --with-iconv-dir --with-kerberos --with-libdir=lib64 --with-libxml-dir --with-mysqli --with-openssl --with-pcre-regex --with-pdo-mysql --with-pdo-sqlite --with-pear --with-png-dir --with-jpeg-dir --with-xmlrpc --with-xsl --with-zlib --with-bz2 --with-mhash --enable-fpm --enable-bcmath --enable-libxml --enable-inline-optimization --enable-mbregex --enable-mbstring --enable-opcache --enable-pcntl --enable-shmop --enable-soap --enable-sockets --enable-sysvsem --enable-sysvshm --enable-xml --enable-zipmakemake install 复制配置文件12cp php.ini-development /data/php/lib/php.inicp /data/php/etc/php-fpm.conf.default /data/php/etc/php-fpm.conf 启动1/data/php/sbin/php-fpm 三、Mysql安装1、yum安装123yum -y install libaiowget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpmyum localinstall mysql-community-release-el7-5.noarch.rpm 验证下是否添加成功1234yum repolist enabled | grep "mysql.*-community.*"yum install mysql-develyum install mysql-community-serversystemctl start mysqld 更改数据存放目录123mkdir /home/datamysqladmin -u root -p shutdownmv /var/lib/mysql /home/data 修改 /etc/my.cnf 文件12345[mysqld]datadir=/data/mysqldata/mysqlsocket=/data/mysqldata/mysql/mysql.sock[mysql]socket=/data/mysqldata/mysql/mysql.sock 授权1chown -R mysql:mysql /data/mysqldata/mysql 重启mysql服务配置开机自起123# systemctl is-enabled mysql.service;echo $?enabled0 如果是 enabled 则说明是开机自动，如果不是，执行1chkconfig --levels 235 mysqld on 修改 /etc/my.cnf 文件，添加字符集的设置1234[mysqld] character_set_server = utf8[mysql]default-character-set = utf8 创建数据库1create database zabbix default charset utf8; 2、源码包安装参考链接：mysql安装 四、Zabbix Server端安装创建用户12groupadd zabbixuseradd -g zabbix zabbix 安装zabbix server从官网查找最新稳定版本，当前为3.0.*，下载后解压123mkdir /data/zabbix./configure --prefix=/data/zabbix/ --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2 --enable-javamake install 启动server进程1/data/zabbix/sbin/zabbix_server -c /data/zabbix/etc/zabbix_server.conf 启动agent进程1/data/zabbix/sbin/zabbix_agentd -c /data/zabbix/etc/zabbix_agentd.conf 可能出现的报错：1234checking for mysql_config... noconfigure: error: MySQL library not found#解决方法yum -y install mysql-devel 123configure: error: Invalid Net-SNMP directory - unable to find net-snmp-config#解决方法yum -y install net-snmp net-snmp-devel 五、Zabbix Web安装12cd /data/backup/zabbix-3.0.8/frontends/phpcp -a . /data/watch01.sa.mtiancity.com/zabbix/ 配置nginx可以访问，略过修改php.ini12345post_max_size = 16Mmax_execution_time = 300date.timezone =Asia/Shanghaialways_populate_raw_post_data = -1max_input_time = 300 导入数据库1234cd /data/backup/zabbix-3.0.8/database/mysql/mysql -u root zabbix&lt;schema.sqlmysql -u root zabbix&lt;images.sqlmysql -u root zabbix&lt;data.sql 打开nginx配置的url访问，如下图：也可能出现报错此时按照提示，将配置文件放入相应目录即可初始化完成后，登陆zabbix web，默认用户名：Admin，密码：zabbix 六、Zabbix Agnet端安装安装方法二选一即可，推荐rpm安装 1、编译安装创建用户组和用户12groupadd zabbixuseradd -g zabbix zabbix yum安装组件1yum -y install mysql-devel libxml2-devel unixODBC-devel OpenIPMI-devel curl-devel net-snmp-devel 安装zabbix agent1234tar -zxvf zabbix-3.0.8.tar.gzcd zabbix-3.0.8/./configure --prefix=/data/zabbix/ --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2make &amp;&amp; make install 复制配置文件1cp /data/backup/zabbix_agentd.conf /data/zabbix/etc/ 启动agent1/data/zabbix/sbin/zabbix_agentd -c /data/zabbix/etc/zabbix_agentd.conf 2、rpm包安装12345yum -y install unixODBC#centos6rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/6/x86_64/zabbix-agent-3.0.1-1.el6.x86_64.rpm#centos7rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-agent-3.0.9-1.el7.x86_64.rpm 配置文件位置/etc/zabbix/zabbix_agentd.conf，可以根据实际场景修改启动客户端1zabbix_agentd]]></content>
      <categories>
        <category>Monitor</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS系统巡检]]></title>
    <url>%2F2018%2F12%2F11%2FCentOS%E7%B3%BB%E7%BB%9F%E5%B7%A1%E6%A3%80%2F</url>
    <content type="text"><![CDATA[1、巡检脚本首先编写单台系统巡检脚本，内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730# cat checkos.sh#!/bin/bash#################################################################### Functions: this script from polling system status# Info: be suitable for CentOS/RHEL 6/7 # Changelog:# 2016-09-15 shaon initial commit####################################################################set path env,if not set will some command not found in crontabexport PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binsource /etc/profilerm -f /data/scripts/*.csv# run this script use root[ $(id -u) -gt 0 ] &amp;&amp; echo "please use root run the script! " &amp;&amp; exit 1# check system versionOS_Version=$(awk '&#123;print $(NF-1)&#125;' /etc/redhat-release)# declare script version dateScript_Version="2018.10.30"# define polling log pathLOGPATH=/data/scripts[ -d $LOGPATH ] || mkdir -p $LOGPATHRESULTFILE="$LOGPATH/`hostname`-`date +%Y%m%d`.csv"# define globle variablereport_DateTime="" #日期 okreport_Hostname="" #主机名 okreport_OSRelease="" #发行版本 okreport_Kernel="" #内核 okreport_Language="" #语言/编码 okreport_LastReboot="" #最近启动时间 okreport_Uptime="" #运行时间（天） okreport_CPUs="" #CPU数量 okreport_CPUType="" #CPU类型 okreport_Arch="" #CPU架构 okreport_MemTotal="" #内存总容量(MB) okreport_MemFree="" #内存剩余(MB) okreport_MemUsedPercent="" #内存使用率% okreport_DiskTotal="" #硬盘总容量(GB) okreport_DiskFree="" #硬盘剩余(GB) okreport_DiskUsedPercent="" #硬盘使用率% okreport_InodeTotal="" #Inode总量 okreport_InodeFree="" #Inode剩余 okreport_InodeUsedPercent="" #Inode使用率 okreport_IP="" #IP地址 okreport_MAC="" #MAC地址 okreport_Gateway="" #默认网关 okreport_DNS="" #DNS okreport_Listen="" #监听 okreport_Selinux="" #Selinux okreport_Firewall="" #防火墙 okreport_USERs="" #用户 okreport_USEREmptyPassword="" #空密码用户 okreport_USERTheSameUID="" #相同ID的用户 ok report_PasswordExpiry="" #密码过期（天） okreport_RootUser="" #root用户 okreport_Sudoers="" #sudo授权 okreport_SSHAuthorized="" #SSH信任主机 okreport_SSHDProtocolVersion="" #SSH协议版本 okreport_SSHDPermitRootLogin="" #允许root远程登录 okreport_DefunctProsess="" #僵尸进程数量 okreport_SelfInitiatedService="" #自启动服务数量 okreport_SelfInitiatedProgram="" #自启动程序数量 okreport_RuningService="" #运行中服务数 okreport_Crontab="" #计划任务数 okreport_Syslog="" #日志服务 okreport_SNMP="" #SNMP OKreport_NTP="" #NTP okreport_JDK="" #JDK版本 okfunction version()&#123; echo "" echo "System Polling：Version $Script_Version " echo ""&#125;function getCpuStatus()&#123; echo "" echo "############################ Check CPU Status#############################" Physical_CPUs=$(grep "physical id" /proc/cpuinfo| sort | uniq | wc -l) Virt_CPUs=$(grep "processor" /proc/cpuinfo | wc -l) CPU_Kernels=$(grep "cores" /proc/cpuinfo|uniq| awk -F ': ' '&#123;print $2&#125;') CPU_Type=$(grep "model name" /proc/cpuinfo | awk -F ': ' '&#123;print $2&#125;' | sort | uniq) CPU_Arch=$(uname -m) echo "物理CPU个数:$Physical_CPUs" echo "逻辑CPU个数:$Virt_CPUs" echo "每CPU核心数:$CPU_Kernels" echo " CPU型号:$CPU_Type" echo " CPU架构:$CPU_Arch" # report information report_CPUs=$Virt_CPUs #CPU数量 report_CPUType=$CPU_Type #CPU类型 report_Arch=$CPU_Arch #CPU架构&#125;function getMemStatus()&#123; echo "" echo "############################ Check Memmory Usage ###########################" if [[ $OS_Version &lt; 7 ]];then free -mo else free -h fi # report information MemTotal=$(grep MemTotal /proc/meminfo| awk '&#123;print $2&#125;') #KB MemFree=$(grep MemFree /proc/meminfo| awk '&#123;print $2&#125;') #KB let MemUsed=MemTotal-MemFree MemPercent=$(awk "BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \"%.2f\",$MemUsed*100/$MemTotal&#125;&#125;") report_MemTotal="$((MemTotal/1024))""MB" #内存总容量(MB) report_MemFree="$((MemFree/1024))""MB" #内存剩余(MB) report_MemUsedPercent="$(awk "BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \"%.2f\",$MemUsed*100/$MemTotal&#125;&#125;")""%" #内存使用率%&#125;function getDiskStatus()&#123; echo "" echo "############################ Check Disk Status ############################" df -hiP | sed 's/Mounted on/Mounted/' &gt; /tmp/inode df -hTP | sed 's/Mounted on/Mounted/' &gt; /tmp/disk join /tmp/disk /tmp/inode | awk '&#123;print $1,$2,"|",$3,$4,$5,$6,"|",$8,$9,$10,$11,"|",$12&#125;'| column -t # report information diskdata=$(df -TP | sed '1d' | awk '$2!="tmpfs"&#123;print&#125;') #KB disktotal=$(echo "$diskdata" | awk '&#123;total+=$3&#125;END&#123;print total&#125;') #KB diskused=$(echo "$diskdata" | awk '&#123;total+=$4&#125;END&#123;print total&#125;') #KB diskfree=$((disktotal-diskused)) #KB diskusedpercent=$(echo $disktotal $diskused | awk '&#123;if($1==0)&#123;printf 100&#125;else&#123;printf "%.2f",$2*100/$1&#125;&#125;') inodedata=$(df -iTP | sed '1d' | awk '$2!="tmpfs"&#123;print&#125;') inodetotal=$(echo "$inodedata" | awk '&#123;total+=$3&#125;END&#123;print total&#125;') inodeused=$(echo "$inodedata" | awk '&#123;total+=$4&#125;END&#123;print total&#125;') inodefree=$((inodetotal-inodeused)) inodeusedpercent=$(echo $inodetotal $inodeused | awk '&#123;if($1==0)&#123;printf 100&#125;else&#123;printf "%.2f",$2*100/$1&#125;&#125;') report_DiskTotal=$((disktotal/1024/1024))"GB" #硬盘总容量(GB) report_DiskFree=$((diskfree/1024/1024))"GB" #硬盘剩余(GB) report_DiskUsedPercent="$diskusedpercent""%" #硬盘使用率% report_InodeTotal=$((inodetotal/1000))"K" #Inode总量 report_InodeFree=$((inodefree/1000))"K" #Inode剩余 report_InodeUsedPercent="$inodeusedpercent""%" #Inode使用率% echo ""&#125;function getSystemStatus()&#123; echo "" echo "############################ Check System Status ############################" if [ -e /etc/sysconfig/i18n ];then default_LANG="$(grep "LANG=" /etc/sysconfig/i18n | grep -v "^#" | awk -F '"' '&#123;print $2&#125;')" else default_LANG=$LANG fi export LANG="en_US.UTF-8" Release=$(cat /etc/redhat-release 2&gt;/dev/null) Kernel=$(uname -r) OS=$(uname -o) Hostname=$(uname -n) SELinux=$(/usr/sbin/sestatus | grep "SELinux status: " | awk '&#123;print $3&#125;') LastReboot=$(who -b | awk '&#123;print $3,$4&#125;') uptime=$(cat /proc/uptime| awk -F. '&#123;run_days=$1 / 86400;run_hour=($1 % 86400)/3600;run_minute=($1 % 3600)/60;run_second=$1 % 60;printf("%d天%d时%d分%d秒",run_days,run_hour,run_minute,run_second)&#125;') echo " 系统：$OS" echo " 发行版本：$Release" echo " 内核：$Kernel" echo " 主机名：$Hostname" echo " SELinux：$SELinux" echo "语言/编码：$default_LANG" echo " 当前时间：$(date +'%F %T')" echo " 最后启动：$LastReboot" echo " 运行时间：$uptime" # report information report_DateTime=$(date +"%F %T") #日期 report_Hostname="$Hostname" #主机名 report_OSRelease="$Release" #发行版本 report_Kernel="$Kernel" #内核 report_Language="$default_LANG" #语言/编码 report_LastReboot="$LastReboot" #最近启动时间 report_Uptime="$uptime" #运行时间（天） report_Selinux="$SELinux" export LANG="$default_LANG" echo ""&#125;function getServiceStatus()&#123; echo "" echo "############################ Check Service Status ############################" if [[ $OS_Version &gt; 7 ]];then conf=$(systemctl list-unit-files --type=service --state=enabled --no-pager | grep "enabled") process=$(systemctl list-units --type=service --state=running --no-pager | grep ".service") # report information report_SelfInitiatedService="$(echo "$conf" | wc -l)" #自启动服务数量 report_RuningService="$(echo "$process" | wc -l)" #运行中服务数量 else conf=$(/sbin/chkconfig | grep -E ":on|:启用") process=$(/sbin/service --status-all 2&gt;/dev/null | grep -E "is running|正在运行") # report information report_SelfInitiatedService="$(echo "$conf" | wc -l)" #自启动服务数量 report_RuningService="$(echo "$process" | wc -l)" #运行中服务数量 fi echo "Service Configure" echo "--------------------------------" echo "$conf" | column -t echo "" echo "The Running Services" echo "--------------------------------" echo "$process"&#125;function getAutoStartStatus()&#123; echo "" echo "############################ Check Self-starting Services ##########################" conf=$(grep -v "^#" /etc/rc.d/rc.local| sed '/^$/d') echo "$conf" # report information report_SelfInitiatedProgram="$(echo $conf | wc -l)" #自启动程序数量&#125;function getLoginStatus()&#123; echo "" echo "############################ Check Login In ############################" last | head&#125;function getNetworkStatus()&#123; echo "" echo "############################ Check Network ############################" if [[ $OS_Version &lt; 7 ]];then /sbin/ifconfig -a | grep -v packets | grep -v collisions | grep -v inet6 else #ip address for i in $(ip link | grep BROADCAST | awk -F: '&#123;print $2&#125;');do ip add show $i | grep -E "BROADCAST|global"| awk '&#123;print $2&#125;' | tr '\n' ' ' ;echo "" ;done fi GATEWAY=$(ip route | grep default | awk '&#123;print $3&#125;') DNS=$(grep nameserver /etc/resolv.conf| grep -v "#" | awk '&#123;print $2&#125;' | tr '\n' ',' | sed 's/,$//') echo "" echo "Gateway: $GATEWAY " echo " DNS: $DNS" # report information IP=$(ip -f inet addr | grep -v 127.0.0.1 | grep inet | awk '&#123;print $NF,$2&#125;' | tr '\n' ',' | sed 's/,$//') MAC=$(ip link | grep -v "LOOPBACK\|loopback" | awk '&#123;print $2&#125;' | sed 'N;s/\n//' | tr '\n' ',' | sed 's/,$//') report_IP="$IP" #IP地址 report_MAC=$MAC #MAC地址 report_Gateway="$GATEWAY" #默认网关 report_DNS="$DNS" #DNS&#125;function getListenStatus()&#123; echo "" echo "############################ Check Listen Status ############################"# TCPListen=$(ss -ntul | column -t) TCPListen=$(netstat -ntulp | column -t) AllConnect=$(ss -an | awk 'NR&gt;1 &#123;++s[$1]&#125; END &#123;for(k in s) print k,s[k]&#125;' | column -t) echo "$TCPListen" echo "$AllConnect" # report information report_Listen="$(echo "$TCPListen"| sed '1d' | awk '/tcp/ &#123;print $5&#125;' | awk -F: '&#123;print $NF&#125;' | sort | uniq | wc -l)"&#125;function getCronStatus()&#123; echo "" echo "############################ Check Crontab List ########################" Crontab=0 for shell in $(grep -v "/sbin/nologin" /etc/shells);do for user in $(grep "$shell" /etc/passwd | awk -F: '&#123;print $1&#125;');do crontab -l -u $user &gt;/dev/null 2&gt;&amp;1 status=$? if [ $status -eq 0 ];then echo "$user" echo "-------------" crontab -l -u $user let Crontab=Crontab+$(crontab -l -u $user | wc -l) echo "" fi done done # scheduled task find /etc/cron* -type f | xargs -i ls -l &#123;&#125; | column -t let Crontab=Crontab+$(find /etc/cron* -type f | wc -l) # report information report_Crontab="$Crontab" #计划任务数&#125;function getHowLongAgo()&#123; # 计算一个时间戳离现在有多久了 datetime="$*" [ -z "$datetime" ] &amp;&amp; echo "错误的参数：getHowLongAgo() $*" Timestamp=$(date +%s -d "$datetime") #转化为时间戳 Now_Timestamp=$(date +%s) Difference_Timestamp=$(($Now_Timestamp-$Timestamp)) days=0;hours=0;minutes=0; sec_in_day=$((60*60*24)); sec_in_hour=$((60*60)); sec_in_minute=60 while (( $(($Difference_Timestamp-$sec_in_day)) &gt; 1 )) do let Difference_Timestamp=Difference_Timestamp-sec_in_day let days++ done while (( $(($Difference_Timestamp-$sec_in_hour)) &gt; 1 )) do let Difference_Timestamp=Difference_Timestamp-sec_in_hour let hours++ done echo "$days 天 $hours 小时前"&#125;function getUserLastLogin()&#123; # 获取用户最近一次登录的时间，含年份 # 很遗憾last命令不支持显示年份，只有"last -t YYYYMMDDHHMMSS"表示某个时间之间的登录，我 # 们只能用最笨的方法了，对比今天之前和今年元旦之前（或者去年之前和前年之前……）某个用户 # 登录次数，如果登录统计次数有变化，则说明最近一次登录是今年。 username=$1 : $&#123;username:="`whoami`"&#125; thisYear=$(date +%Y) oldesYear=$(last | tail -n1 | awk '&#123;print $NF&#125;') while(( $thisYear &gt;= $oldesYear));do loginBeforeToday=$(last $username | grep $username | wc -l) loginBeforeNewYearsDayOfThisYear=$(last $username -t $thisYear"0101000000" | grep $username | wc -l) if [ $loginBeforeToday -eq 0 ];then echo "Never Login" break elif [ $loginBeforeToday -gt $loginBeforeNewYearsDayOfThisYear ];then lastDateTime=$(last -i $username | head -n1 | awk '&#123;for(i=4;i&lt;(NF-2);i++)printf"%s ",$i&#125;')" $thisYear" #格式如: Sat Nov 2 20:33 2015 lastDateTime=$(date "+%Y-%m-%d %H:%M:%S" -d "$lastDateTime") echo "$lastDateTime" break else thisYear=$((thisYear-1)) fi done&#125;function getUserStatus()&#123; echo "" echo "############################ Check User ############################" # /etc/passwd the last modification time pwdfile="$(cat /etc/passwd)" Modify=$(stat /etc/passwd | grep Modify | tr '.' ' ' | awk '&#123;print $2,$3&#125;') echo "/etc/passwd The last modification time：$Modify ($(getHowLongAgo $Modify))" echo "" echo "A privileged user" echo "-----------------" RootUser="" for user in $(echo "$pwdfile" | awk -F: '&#123;print $1&#125;');do if [ $(id -u $user) -eq 0 ];then echo "$user" RootUser="$RootUser,$user" fi done echo "" echo "User List" echo "--------" USERs=0 echo "$( echo "UserName UID GID HOME SHELL LasttimeLogin" for shell in $(grep -v "/sbin/nologin" /etc/shells);do for username in $(grep "$shell" /etc/passwd| awk -F: '&#123;print $1&#125;');do userLastLogin="$(getUserLastLogin $username)" echo "$pwdfile" | grep -w "$username" |grep -w "$shell"| awk -F: -v lastlogin="$(echo "$userLastLogin" | tr ' ' '_')" '&#123;print $1,$3,$4,$6,$7,lastlogin&#125;' done let USERs=USERs+$(echo "$pwdfile" | grep "$shell"| wc -l) done )" | column -t echo "" echo "Null Password User" echo "------------------" USEREmptyPassword="" for shell in $(grep -v "/sbin/nologin" /etc/shells);do for user in $(echo "$pwdfile" | grep "$shell" | cut -d: -f1);do r=$(awk -F: '$2=="!!"&#123;print $1&#125;' /etc/shadow | grep -w $user) if [ ! -z $r ];then echo $r USEREmptyPassword="$USEREmptyPassword,"$r fi done done echo "" echo "The Same UID User" echo "----------------" USERTheSameUID="" UIDs=$(cut -d: -f3 /etc/passwd | sort | uniq -c | awk '$1&gt;1&#123;print $2&#125;') for uid in $UIDs;do echo -n "$uid"; USERTheSameUID="$uid" r=$(awk -F: 'ORS="";$3=='"$uid"'&#123;print ":",$1&#125;' /etc/passwd) echo "$r" echo "" USERTheSameUID="$USERTheSameUID $r," done # report information report_USERs="$USERs" #用户 report_USEREmptyPassword=$(echo $USEREmptyPassword | sed 's/^,//') report_USERTheSameUID=$(echo $USERTheSameUID | sed 's/,$//') report_RootUser=$(echo $RootUser | sed 's/^,//') #特权用户&#125;function getPasswordStatus &#123; echo "" echo "############################ Check Password Status ############################" pwdfile="$(cat /etc/passwd)" echo "" echo "Password Expiration Check" echo "-------------------------" result="" for shell in $(grep -v "/sbin/nologin" /etc/shells);do for user in $(echo "$pwdfile" | grep "$shell" | cut -d: -f1);do get_expiry_date=$(/usr/bin/chage -l $user | grep 'Password expires' | cut -d: -f2) if [[ $get_expiry_date = ' never' || $get_expiry_date = 'never' ]];then printf "%-15s never expiration\n" $user result="$result,$user:never" else password_expiry_date=$(date -d "$get_expiry_date" "+%s") current_date=$(date "+%s") diff=$(($password_expiry_date-$current_date)) let DAYS=$(($diff/(60*60*24))) printf "%-15s %s expiration after days\n" $user $DAYS result="$result,$user:$DAYS days" fi done done report_PasswordExpiry=$(echo $result | sed 's/^,//') echo "" echo "Check The Password Policy" echo "------------" grep -v "#" /etc/login.defs | grep -E "PASS_MAX_DAYS|PASS_MIN_DAYS|PASS_MIN_LEN|PASS_WARN_AGE" echo ""&#125;function getSudoersStatus()&#123; echo "" echo "############################ Sudoers Check #########################" conf=$(grep -v "^#" /etc/sudoers| grep -v "^Defaults" | sed '/^$/d') echo "$conf" echo "" # report information report_Sudoers="$(echo $conf | wc -l)"&#125;function getInstalledStatus()&#123; echo "" echo "############################ Software Check ############################" rpm -qa --last | head | column -t &#125;function getProcessStatus()&#123; echo "" echo "############################ Process Check ############################" if [ $(ps -ef | grep defunct | grep -v grep | wc -l) -ge 1 ];then echo "" echo "zombie process"; echo "--------" ps -ef | head -n1 ps -ef | grep defunct | grep -v grep fi echo "" echo "Merory Usage TOP10" echo "-------------" echo -e "PID %MEM RSS COMMAND $(ps aux | awk '&#123;print $2, $4, $6, $11&#125;' | sort -k3rn | head -n 10 )"| column -t echo "" echo "CPU Usage TOP10" echo "------------" top b -n1 | head -17 | tail -11 # report information report_DefunctProsess="$(ps -ef | grep defunct | grep -v grep|wc -l)"&#125;function getJDKStatus()&#123; echo "" echo "############################ JDK Check #############################" java -version 2&gt;/dev/null if [ $? -eq 0 ];then java -version 2&gt;&amp;1 fi echo "JAVA_HOME=\"$JAVA_HOME\"" # report information report_JDK="$(java -version 2&gt;&amp;1 | grep version | awk '&#123;print $1,$3&#125;' | tr -d '"')"&#125;function getSyslogStatus()&#123; echo "" echo "############################ Syslog Check ##########################" echo "Service Status：$(getState rsyslog)" echo "" echo "/etc/rsyslog.conf" echo "-----------------" cat /etc/rsyslog.conf 2&gt;/dev/null | grep -v "^#" | grep -v "^\\$" | sed '/^$/d' | column -t #report information report_Syslog="$(getState rsyslog)"&#125;function getFirewallStatus()&#123; echo "" echo "############################ Firewall Check ##########################" # Firewall Status/Poilcy if [[ $OS_Version &lt; 7 ]];then /etc/init.d/iptables status &gt;/dev/null 2&gt;&amp;1 status=$? if [ $status -eq 0 ];then s="active" elif [ $status -eq 3 ];then s="inactive" elif [ $status -eq 4 ];then s="permission denied" else s="unknown" fi else s="$(getState iptables)" fi echo "iptables: $s" echo "" echo "/etc/sysconfig/iptables" echo "-----------------------" cat /etc/sysconfig/iptables 2&gt;/dev/null # report information report_Firewall="$s"&#125;function getSNMPStatus()&#123; #SNMP Service Status,Configure echo "" echo "############################ SNMP Check ############################" status="$(getState snmpd)" echo "Service Status：$status" echo "" if [ -e /etc/snmp/snmpd.conf ];then echo "/etc/snmp/snmpd.conf" echo "--------------------" cat /etc/snmp/snmpd.conf 2&gt;/dev/null | grep -v "^#" | sed '/^$/d' fi # report information report_SNMP="$(getState snmpd)"&#125;function getState()&#123; if [[ $OS_Version &lt; 7 ]];then if [ -e "/etc/init.d/$1" ];then if [ `/etc/init.d/$1 status 2&gt;/dev/null | grep -E "is running|正在运行" | wc -l` -ge 1 ];then r="active" else r="inactive" fi else r="unknown" fi else #CentOS 7+ r="$(systemctl is-active $1 2&gt;&amp;1)" fi echo "$r"&#125;function getSSHStatus()&#123; #SSHD Service Status,Configure echo "" echo "############################ SSH Check #############################" # Check the trusted host pwdfile="$(cat /etc/passwd)" echo "Service Status：$(getState sshd)" Protocol_Version=$(cat /etc/ssh/sshd_config | grep Protocol | awk '&#123;print $2&#125;') echo "SSH Protocol Version：$Protocol_Version" echo "" echo "Trusted Host" echo "------------" authorized=0 for user in $(echo "$pwdfile" | grep /bin/bash | awk -F: '&#123;print $1&#125;');do authorize_file=$(echo "$pwdfile" | grep -w $user | awk -F: '&#123;printf $6"/.ssh/authorized_keys"&#125;') authorized_host=$(cat $authorize_file 2&gt;/dev/null | awk '&#123;print $3&#125;' | tr '\n' ',' | sed 's/,$//') if [ ! -z $authorized_host ];then echo "$user authorization \"$authorized_host\" Password-less access" fi let authorized=authorized+$(cat $authorize_file 2&gt;/dev/null | awk '&#123;print $3&#125;'|wc -l) done echo "" echo "Whether to allow ROOT remote login" echo "----------------------------------" config=$(cat /etc/ssh/sshd_config | grep PermitRootLogin) firstChar=$&#123;config:0:1&#125; if [ $firstChar == "#" ];then PermitRootLogin="yes" #The default is to allow ROOT remote login else PermitRootLogin=$(echo $config | awk '&#123;print $2&#125;') fi echo "PermitRootLogin $PermitRootLogin" echo "" echo "/etc/ssh/sshd_config" echo "--------------------" cat /etc/ssh/sshd_config | grep -v "^#" | sed '/^$/d' # report information report_SSHAuthorized="$authorized" #SSH信任主机 report_SSHDProtocolVersion="$Protocol_Version" #SSH协议版本 report_SSHDPermitRootLogin="$PermitRootLogin" #允许root远程登录&#125;function getNTPStatus()&#123; # The NTP service status, the current time, configuration, etc echo "" echo "############################ NTP Check #############################" if [ -e /etc/ntp.conf ];then echo "Service Status：$(getState ntpd)" echo "" echo "/etc/ntp.conf" echo "-------------" cat /etc/ntp.conf 2&gt;/dev/null | grep -v "^#" | sed '/^$/d' fi # report information report_NTP="$(getState ntpd)"&#125;function getZabbixStatus()&#123; # Check Zabbix Serivce Status echo "" echo "######################### Zabbix Check ##############################" netstat -nltp | grep -v grep | grep zabbix &gt; /dev/null 2&gt;&amp;1 if [ $? -eq 0 ];then echo "Service Status": Zabbix is running! else echo "Service Status": Zabbix not running! fi # report information&#125;function uploadHostDailyCheckReport()&#123; json="&#123; \"DateTime\":\"$report_DateTime\", \"Hostname\":\"$report_Hostname\", \"OSRelease\":\"$report_OSRelease\", \"Kernel\":\"$report_Kernel\", \"Language\":\"$report_Language\", \"LastReboot\":\"$report_LastReboot\", \"Uptime\":\"$report_Uptime\", \"CPUs\":\"$report_CPUs\", \"CPUType\":\"$report_CPUType\", \"Arch\":\"$report_Arch\", \"MemTotal\":\"$report_MemTotal\", \"MemFree\":\"$report_MemFree\", \"MemUsedPercent\":\"$report_MemUsedPercent\", \"DiskTotal\":\"$report_DiskTotal\", \"DiskFree\":\"$report_DiskFree\", \"DiskUsedPercent\":\"$report_DiskUsedPercent\", \"InodeTotal\":\"$report_InodeTotal\", \"InodeFree\":\"$report_InodeFree\", \"InodeUsedPercent\":\"$report_InodeUsedPercent\", \"IP\":\"$report_IP\", \"MAC\":\"$report_MAC\", \"Gateway\":\"$report_Gateway\", \"DNS\":\"$report_DNS\", \"Listen\":\"$report_Listen\", \"Selinux\":\"$report_Selinux\", \"Firewall\":\"$report_Firewall\", \"USERs\":\"$report_USERs\", \"USEREmptyPassword\":\"$report_USEREmptyPassword\", \"USERTheSameUID\":\"$report_USERTheSameUID\", \"PasswordExpiry\":\"$report_PasswordExpiry\", \"RootUser\":\"$report_RootUser\", \"Sudoers\":\"$report_Sudoers\", \"SSHAuthorized\":\"$report_SSHAuthorized\", \"SSHDProtocolVersion\":\"$report_SSHDProtocolVersion\", \"SSHDPermitRootLogin\":\"$report_SSHDPermitRootLogin\", \"DefunctProsess\":\"$report_DefunctProsess\", \"SelfInitiatedService\":\"$report_SelfInitiatedService\", \"SelfInitiatedProgram\":\"$report_SelfInitiatedProgram\", \"RuningService\":\"$report_RuningService\", \"Crontab\":\"$report_Crontab\", \"Syslog\":\"$report_Syslog\", \"SNMP\":\"$report_SNMP\", \"NTP\":\"$report_NTP\", \"JDK\":\"$report_JDK\" &#125;" #echo "$json" curl -l -H "Content-type: application/json" -X POST -d "$json" "$uploadHostDailyCheckReportApi" 2&gt;/dev/null&#125;function check()&#123; version getSystemStatus getCpuStatus getMemStatus getDiskStatus getNetworkStatus getListenStatus getProcessStatus getServiceStatus getAutoStartStatus getLoginStatus getCronStatus getUserStatus getPasswordStatus getSudoersStatus getJDKStatus getFirewallStatus getSSHStatus getSyslogStatus getSNMPStatus getNTPStatus getZabbixStatus getInstalledStatus&#125;# Perform inspections and save the inspection results #执行检查并保存检查结果check &gt; $RESULTFILEecho "Check the result：$RESULTFILE"# Upload the result file #上传检查结果的文件#curl -F "filename=@$RESULTFILE" "$uploadHostDailyCheckApi" 2&gt;/dev/null#Upload inspection result report #上传检查结果的报表#uploadHostDailyCheckReport 1&gt;/dev/null 运行脚本后，会在脚本设定的目录：/data/scripts/checklog/下生成以csv为后缀的文件，文件格式也是在脚本中已经设定。 2、文件合并需要将多个csv文件合成为xlsx后缀的文件，将多台服务器的执行结果都保存在checklog目录下。脚本内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# cat toall_xlsx.py #!/usr/bin/python# coding=utf_8_sigimport osimport sysimport csvimport globimport timesys.path.append("/home/shdi/bin/pymodule")import xlsxwriterimport sysreload(sys)sys.setdefaultencoding('utf-8') def merge_csv2xlsx(csv_dir, xlsxfile): # Create a new workbook and add a worksheet workbook = xlsxwriter.Workbook(xlsxfile) fmt_plain = workbook.add_format(&#123; 'font_size': 12, 'font_name': "Arial Narrow", &#125;) for filename in glob.glob("%s/*.csv" % csv_dir): print " procsss %s" % filename (f_path, f_name) = os.path.split(filename) (f_short_name, f_extension) = os.path.splitext(f_name) sheet_name = f_short_name worksheet = workbook.add_worksheet(sheet_name) spamReader = csv.reader(open(filename, 'rb'), delimiter=',',quotechar='"') row_count = 0 for row in spamReader: for col in range(len(row)): #ws.write(row_count,col,row[col]) worksheet.write(row_count, col, row[col],fmt_plain) row_count +=1 workbook.close() print "xlsx file saved: %s" % xlsxfile returnif __name__ == "__main__": if len(sys.argv) != 2: print "Usage:" print "\t%s &lt;csvdir&gt;" % sys.argv[0] sys.exit(0) csvdir = sys.argv[1] savefile = time.strftime("/data/scripts/checklog/check_%Y%m%d.xlsx") merge_csv2xlsx(csvdir, savefile) print("\n\nCVS merged file saved to %s" % savefile) 此脚本放在checklog下，讲同目录下所有文件合并成xlsx文件。 3、定时任务添加多台服务器ip，并将脚本添加进定时任务脚本如下：123456789101112131415161718192021222324252627282930313233343536373839404142# pwd/data/scripts[root@gbw_manage scripts]# cat run_xunjian.sh #!/bin/bashHOSTLIST=("172.16.109.139 172.16.109.149172.16.109.145 172.16.109.146 172.16.109.150 172.16.109.140 172.16.109.151 172.16.109.147 172.16.109.141 172.16.109.137 172.16.109.138 172.16.109.144 172.16.109.148 172.16.109.143 172.16.109.142172.16.109.153")#echo "$HOSTLIST"COUNT=`echo "$HOSTLIST" |grep -v '^$'|wc -l`#echo $COUNTfor ip in $&#123;HOSTLIST[*]&#125;do /usr/bin/ssh root@$ip -C "/bin/bash" &lt; /data/scripts/checkos.sh echo $ipdonerm -f /data/scripts/checklog/*.csvfor ip in $&#123;HOSTLIST[*]&#125;do scp root@$ip:/data/scripts/*.csv /data/scripts/checklog/ echo $ipdone/usr/bin/python /data/scripts/checklog/toall_xlsx.py /data/scripts/checklog 最后的结果文档会保存在/data/scripts/checklog下，文件后缀为xlsx。将此脚本添加定时任务，每天1点执行一次，即可实现定时巡检系统。完善：可以在脚本内增加邮件发送功能，将最后的结果文件发送到对应的接收人员。]]></content>
      <categories>
        <category>Scripts</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Python</tag>
        <tag>巡检</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ应用文档]]></title>
    <url>%2F2018%2F12%2F10%2FRabbitMQ%E5%BA%94%E7%94%A8%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[一、Rabbitmq简介1、Rabbitmq介绍RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。AMQP，即Advanced message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 2、Rabbitmq系统概念 RabbitMQ Server 也叫broker server，是一种传输服务，负责维护一条从Producer到consumer的路线，保证数据能够按照指定的方式进行传输。 Producer 数据的发送方。 Consumer 数据的接收方。 Exchanges 接收消息，转发消息到绑定的队列。主要使用3种类型：direct， topic， fanout。 Queue RabbitMQ内部存储消息的对象。相同属性的queue可以重复定义，但只有第一次定义的有效。 Bindings 绑定Exchanges和Queue之间的路由。 Connection 就是一个TCP的连接。Producer和consumer都是通过TCP连接到RabbitMQ Server的。 Channel 虚拟连接。它建立在上述的TCP连接中。数据流动都是在Channel中进行的。也就是说，一般情况是程序起始建立TCP连接，第二步就是建立这个Channel。 3、AMQP协议简介AMQP在一致性客户端和消息中间件(也称为”brokers”)之间创建了全功能的互操作．为了完全实现消息中间件的互操作性，需要充分定义网络协议和消息代理服务的功能语义。因此，AMQP通过如下来定义了网络协议(AMQP是协议！)和服务端服务：1、一套确定的消息交换功能，也就是“高级消息交换协议模型”。AMQP模型包括一套用于路由和存储消息的功能模块，以及一套在这些模块之间交换消息的规则。2、 一个网络线级协议（数据传输格式），AMQP促使客户端可使用AMQ模型来与服务器交互。可以只实现AMQP协议规范中的的部分语义，但是我们相信这些明确的语义有助于理解这个协议。我们需要明确定义服务器语义，因为所有服务器实现都应该与这些语义保持一致性，否则就无法进行互操作. 因此AMQ 模型定义了一系列模块化组件和标准规则来进行协作. 有三种类型的组件可以连接服务器处理链来创建预期的功能:1、”交换器(exchange)” ：接收来自发布者应用程序的消息，并基于任意条件(通常是消息属性和内容）将这些消息路由到消息队列(message queues).2、”消息队列(message queue)”：存储消息直到它们可以被消费客户端应用程序(或多线程应用程序)安全处理。3、”绑定(binding)”:定义了消息队列与交换器之间的关系，并提供了消息路由条件．使用这些模型我们可以很容易地模拟经典的存储转发队列和面向消息中间件的主题订阅概念. 我们还可以表示更为复杂的概念，例如：基于内容的路由，工作负载分配和按需消息队列。大致上讲， AMQP 服务器类似与邮件服务器, 每个交换器都扮演了消息传送代理,每个消息队列都作为邮箱，而绑定则定义了每个传送代理中的路由表.发布者发送消息给独立的传送代理,然后传送代理再路由消息到邮箱中.消费者从邮箱中收取消息. 相比较而言，在AMQP之前的许多中间件系统中，发布者直接发送消息到独立收件箱(在存储转发队列的情况下),或者发布到邮件列表中 (在主题订阅的情况下)。区别就在于用户可以控制消息队列和交换器之间的绑定规则，这可以做很多有趣的事情，比如定义一条规则：“将所有包含这样消息头的消息都复制一份再发送到消息队列中”。AMQ模型是基于下面的需求来驱动设计的：1、支持与主要消息产品相媲美的语义。.2、 提供与主要消息产品相媲美的性能水平.3、允许通过应用程序使用服务器特定语义来编程.4、灵活性，可扩展性，简单性 二、安装Rabbitmq1、安装好系统运行12yum update -yreboot #一般情况不用重启 2、安装依赖文件12yum -y install gcc glibc-devel make ncurses-devel openssl-devel xmlto perl wget#部分依赖可能在安装其他服务时已安装 3、安装erlang语言环境官网地址：http://www.erlang.org/downloads，由于环境支持问题，建议下载最新版本123456wget http://erlang.org/download/otp_src_20.3.tar.gztar -zxvf otp_src_20.3.tar.gz cd otp_src_20.3./configure --prefix=/data/erlangmakemake install 配置erlang环境变量12345678vi /etc/profile #在底部添加以下内容 #set erlang environmentERL_HOME=/data/erlangPATH=$ERL_HOME/bin:$PATHexport ERL_HOME PATHsource /etc/profile #生效 在控制台输入命令erl如果进入erlang的shell则证明安装成功，退出即可。 4、安装rabbitmq官网地址：http://www.rabbitmq.com/install-generic-unix.html，下载最新稳定版本1234wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.4/rabbitmq-server-generic-unix-3.7.4.tar.xzxz -d rabbitmq-server-generic-unix-3.7.4.tar.xz tar -xvf rabbitmq-server-generic-unix-3.7.4.tar mv rabbitmq_server-3.7.4 /data/rabbitmq 配置rabbitmq环境变量123456vi /etc/profile #在底部添加以下内容 #set rabbitmq environmentexport PATH=$PATH:/data/rabbitmq/sbinsource /etc/profile #生效 启动服务1rabbitmq-server -detached #启动rabbitmq，-detached代表后台守护进程方式启动 出现以下界面此时rabbit-servery已经启动官网解释：http://www.rabbitmq.com/rabbitmq-server.8.html但是由于没有写入PID file文件，可能导致服务停止查看状态1rabbitmqctl status 如果显示如下截图说明安装成功其他相关命令 启动服务：rabbitmq-server -detached 或者/data/rabbitmq/sbin/rabbitmq-server -detached 查看状态：rabbitmqctl status 或者/usr/local/rabbitmq/sbin/rabbitmqctl status 关闭服务：rabbitmqctl stop 或者/usr/local/rabbitmq/sbin/rabbitmqctl stop 列出角色：rabbitmqctl list_users 或者/usr/local/rabbitmq/sbin/rabbitmqctl list_users 5、配置网页插件首先创建目录，否则可能报错1mkdir /etc/rabbitmq 启用web管理插件1rabbitmq-plugins enable rabbitmq_management 6、配置防火墙配置linux端口15672网页管理5672AMQP端口123firewall-cmd --permanent --add-port=15672/tcpfirewall-cmd --permanent --add-port=5672/tcpsystemctl restart firewalld.service 在浏览器输入http://ip:15672，可以看到RabbitMQ的WEB管理页面，如下 7、配置访问账号密码和权限默认网页是不允许访问的，需要增加一个用户修改一下权限123rabbitmqctl add_user action action #添加用户，后面两个参数分别是用户名和密码rabbitmqctl set_permissions -p / action ".*" ".*" ".*" #添加权限rabbitmqctl set_user_tags action administrator #修改用户角色 查看角色并确认123# rabbitmqctl list_usersListing users ...action [administrator] 然后就可以远程访问了，然后可直接配置用户权限等信息。登录：http://ip:15672 登录之后在admin里面把guest删除。 8、Rabbitmq配置RabbitMQ 提供了三种方式来定制服务器: 环境变量：定义端口，文件位置和名称(接受shell输入,或者在环境配置文件（rabbitmq-env.conf）中设置) 配置文件：为服务器组件设置权限,限制和集群，也可以定义插件设置. 运行时参数和策略：可在运行时进行修改集群设置 1）配置文件rabbitmq.config 文件rabbitmq.config配置文件允许配置RabbitMQ 核心程序， Erlang 服务和RabbitMQ 插件. 它是标准的Erlang 配置文件, 文档位于Erlang Config Man Page.最小化的样例配置文件如下:1[ &#123;rabbit, [&#123;tcp_listeners, [5673]&#125;]&#125; ]. 这个例子中将会修改RabbitMQ监听AMQP 0-9-1 客户端连接端口，5672修改为5673.配置文件不同于环境配置文件rabbitmq-env.conf这些文件的位置分布特定的. 默认情况下，这些文件是没有创建的,但每个平台上期望的位置如下：12345Generic UNIX - $RABBITMQ_HOME/etc/rabbitmq/Debian - /etc/rabbitmq/RPM - /etc/rabbitmq/Mac OS X (Homebrew) - $&#123;install_prefix&#125;/etc/rabbitmq/, the Homebrew prefix is usually/usr/localWindows - %APPDATA%\RabbitMQ\ 如果rabbitmq-env.conf不存在, 可在默认位置中手动创建.。它不能用于Windows系统.如果rabbitmq.config不存在，可以手动创建它. 如果你修改了位置，可设置RABBITMQ_CONFIG_FILE 环境变量来指定. Erlang 运行时会自动在此变量值后添加.config扩展名，重启服务器后生效。Windows 服务用户在删除配置文件后，需要重新安装服务。 2）rabbitmq.config中的变量配置大部分的RabbitMQ用户都会不会修改这些值，有些是相当模糊的。为了完整性，他们都在这里列出。 Key Documentation tcp_listeners 用于监听 AMQP连接的端口列表(无SSL). 可以包含整数 (即”监听所有接口”)或者元组如 {“127.0.0.1”, 5672} 用于监听一个或多个接口. Default: [5672] num_tcp_acceptors 接受TCP侦听器连接的Erlang进程数。 Default: 10 handshake_timeout AMQP 0-8/0-9/0-9-1 handshake (在 socket 连接和SSL 握手之后）的最大时间, 毫秒为单位. Default: 10000 ssl_listeners 如上所述，用于SSL连接。 Default: [] num_ssl_acceptors 接受SSL侦听器连接的Erlang进程数。 Default: 1 ssl_options SSL配置.参考SSL documentation. Default: [] ssl_handshake_timeout SSL handshake超时时间,毫秒为单位. Default: 5000 vm_memory_high_watermark 流程控制触发的内存阀值．相看memory-based flow control 文档. Default: 0.4 vm_memory_high_watermark_paging_ratio 高水位限制的分数，当达到阀值时，队列中消息消息会转移到磁盘上以释放内存. 参考memory-based flow control 文档. Default: 0.5 disk_free_limit RabbitMQ存储数据分区的可用磁盘空间限制．当可用空间值低于阀值时，流程控制将被触发. 此值可根据RAM的总大小来相对设置 (如.{mem_relative, 1.0}). 此值也可以设为整数(单位为bytes)或者使用数字单位(如．”50MB”). 默认情况下，可用磁盘空间必须超过50MB. 参考 Disk Alarms 文档. Default: 50000000 log_levels 控制日志的粒度.其值是日志事件类别(category)和日志级别(level)成对的列表． level 可以是 ‘none’ (不记录日志事件), ‘error’ (只记录错误), ‘warning’ (只记录错误和警告), ‘info’ (记录错误，警告和信息), or ‘debug’ (记录错误，警告，信息以及调试信息). 目前定义了４种日志类别. 它们是： channel -针对所有与AMQP channels相关的事件 connection - 针对所有与网络连接相关的事件 federation - 针对所有与federation相关的事件 mirroring -针对所有与 mirrored queues相关的事件 Default: [{connection, info}] frame_max 与客户端协商的允许最大frame大小. 设置为０表示无限制，但在某些QPid客户端会引发bug. 设置较大的值可以提高吞吐量;设置一个较小的值可能会提高延迟. Default: 131072 channel_max 与客户端协商的允许最大chanel大小. 设置为０表示无限制．该数值越大，则broker使用的内存就越高． Default: 0 channel_operation_timeout Channel 操作超时时间(毫秒为单位） (内部使用，因为消息协议的区别和限制，不暴露给客户端). Default: 5000 heartbeat 表示心跳延迟(单位为秒) ，服务器将在connection.tune frame中发送.如果设置为 0, 心跳将被禁用. 客户端可以不用遵循服务器的建议, 查看 AMQP reference 来了解详情. 禁用心跳可以在有大量连接的场景中提高性能，但可能会造成关闭了非活动连接的网络设备上的连接落下． Default: 60 (3.5.5之前的版本是580) default_vhost 当RabbitMQ从头开始创建数据库时创建的虚拟主机. amq.rabbitmq.log交换器会存在于这个虚拟主机中. Default: &lt;&lt;”/“&gt;&gt; default_user RabbitMQ从头开始创建数据库时，创建的用户名. Default: &lt;&lt;”guest”&gt;&gt; default_pass 默认用户的密码. Default: &lt;&lt;”guest”&gt;&gt; default_user_tags 默认用户的Tags. Default: [administrator] default_permissions 创建用户时分配给它的默认Permissions . Default: [&lt;&lt;”.“&gt;&gt;, &lt;&lt;”.“&gt;&gt;, &lt;&lt;”.*”&gt;&gt;] loopback_users 只能通过环回接口(即localhost)连接broker的用户列表 如果你希望默认的guest用户能远程连接,你必须将其修改为[]. Default: [&lt;&lt;”guest”&gt;&gt;] cluster_nodes 当节点第一次启动的时候，设置此选项会导致集群动作自动发生. 元组的第一个元素是其它节点想与其建立集群的节点. 第二个元素是节点的类型，要么是disc,要么是ram Default: {[], disc} server_properties 连接时向客户端声明的键值对列表 Default: [] collect_statistics 统计收集模式。主要与管理插件相关。选项： none (不发出统计事件) coarse (发出每个队列 /每个通道 /每个连接的统计事件) fine (也发出每个消息统计事件) 你自已可不用修改此选项. Default: none collect_statistics_interval 统计收集时间间隔(毫秒为单位)． 主要针对于 management plugin. Default: 5000 auth_mechanisms 提供给客户端的SASL authentication mechanisms. Default: [‘PLAIN’, ‘AMQPLAIN’] auth_backends 用于 authentication / authorisation backends 的列表. 此列表可包含模块的名称(在模块相同的情况下，将同时用于认证来授权)或像{ModN, ModZ}这样的元组，在这里ModN将用于认证，ModZ将用于授权. 在２元组的情况中, ModZ可由列表代替,列表中的所有元素必须通过每个授权的确认，如{ModN, [ModZ1, ModZ2]}. 这就允许授权插件进行组合提供额外的安全约束. 除rabbit_auth_backend_internal外，其它数据库可以通常 plugins来使用. Default: [rabbit_auth_backend_internal] reverse_dns_lookups 设置为true,可让客户端在连接时让RabbitMQ 执行一个反向DNS查找, 然后通过 rabbitmqctl 和 管理插件来展现信息. Default: false delegate_count 内部集群通信中，委派进程的数目. 在一个有非常多核的机器(集群的一部分)上,你可以增加此值. Default: 16 trace_vhosts tracer内部使用. 你不应该修改. Default: [] tcp_listen_options 默认socket选项. 你可能不想修改这个选项. Default: [{backlog, 128}, {nodelay, true}, {exit_on_close, false}] hipe_compile 将此选项设置为true,将会使用HiPE预编译部分RabbitMQ,Erlang的即时编译器. 这可以增加服务器吞吐量，但会增加服务器的启动时间． 你可以看到花费几分钟延迟启动的成本，就可以带来20-50% 更好性能.这些数字与高度依赖于工作负载和硬件． HiPE 支持可能没有编译进你的Erlang安装中.如果没有的话，启用这个选项,并启动RabbitMQ时，会看到警告消息． 例如, Debian / Ubuntu 用户需要安装erlang-base-hipe 包. HiPE并非在所有平台上都可用, 尤其是Windows. 在 Erlang/OTP 1７.５版本之前，HiPE有明显的问题 . 对于HiPE,使用最新的OTP版本是高度推荐的． Default: false cluster_partition_handling 如何处理网络分区.可用模式有: ignore pause_minority {pause_if_all_down, [nodes], ignore autoheal}where [nodes] is a list of node names (ex: [‘rabbit@node1’, ‘rabbit@node2’]) autoheal 参考documentation on partitions 来了解更多信息 Default: ignore cluster_keepalive_interval 节点向其它节点发送存活消息和频率(毫秒). 注意，这与 net_ticktime是不同的; 丢失存活消息不会引起节点掉线 Default: 10000 queue_index_embed_msgs_below 消息大小在此之下的会直接内嵌在队列索引中. 在修改此值时，建议你先阅读 persister tuning 文档. Default: 4096 msg_store_index_module 队列索引的实现模块. 在修改此值时，建议你先阅读 persister tuning 文档. Default: rabbit_msg_store_ets_index backing_queue_module 队列内容的实现模块. 你可能不想修改此值． Default: rabbit_variable_queue msg_store_file_size_limit Tunable value for the persister. 你几乎肯定不应该改变此值。 Default: 16777216 mnesia_table_loading_timeout 在集群中等待使用Mnesia表可用的超时时间。 Default: 30000 queue_index_max_ journal_entries Tunable value for the persister. 你几乎肯定不应该改变此值。 Default: 65536 queue_master_locator Queue master 位置策略. 可用策略有: &lt;&lt;”min-masters”&gt;&gt; &lt;&lt;”client-local”&gt;&gt; &lt;&lt;”random”&gt;&gt; 查看documentation on queue master location 来了解更多信息． Default: &lt;&lt;”client-local”&gt;&gt; 此外，许多插件也可以在配置文件中配置, 其名称是rabbitmq_plugin的形式. 我们的维护的插件被记录在以下位置： 123456rabbitmq_managementrabbitmq_management_agentrabbitmq_mochiwebrabbitmq_stomprabbitmq_shovelrabbitmq_auth_backend_ldap 3）文件位置 名称 描述 RABBITMQ_BASE 此基础目录包含了RabbitMQ server的数据库，日志文件的子目录. 另外，也可以独立设置RABBITMQ_MNESIA_BASE 和 RABBITMQ_LOG_BASE 目录. RABBITMQ_CONFIG_FILE 用于配置文件的路径，无.config扩展名. 如果 configuration file 存在，服务器将使用它来配置RabbitMQ组件. 参考 Configuration guide 来了解更多信息. RABBITMQ_MNESIA_BASE 包含RabbitMQ 服务器Mnesia数据库文件子目录的基本目录,除非明确设置了RABBITMQ_MNESIA_DIR目录，否则每个节点都应该配置一个. (除了Mnesia文件，这个位置还包含消息存储和索引文件以及模式和集群的细节．） RABBITMQ_MNESIA_DIR RabbitMQ节点Mnesia数据库文件安放的目录. (除了Mnesia文件，这个位置还包含消息存储和索引文件以及模式和集群的细节.) RABBITMQ_LOG_BASE 用于包含RabbitMQ 服务器日志文件的基本目录, 除非明确设置了RABBITMQ_LOGS 或 RABBITMQ_SASL_LOGS. RABBITMQ_LOGS RabbitMQ 服务器的Erlang日志文件路径.在Window上不能覆盖此变量． RABBITMQ_SASL_LOGS RabbitMQ服务器的Erlang SASL (System Application Support Libraries)日志文件路径. 在Window上不能覆盖此变量． RABBITMQ_PLUGINS_DIR 用于查找插件的目录 . RABBITMQ_PLUGINS_EXPAND_DIR 用于在启动服务器时扩展启用插件的工作目录。 RABBITMQ_ENABLED_PLUGINS_FILE 此文件记录了显式启用的插件。 RABBITMQ_PID_FILE 此文件中包含了rabbitmqctl所等待进程ID的信息． Unix默认位置在下面的表格中，${install_prefix}表示某个路径. Homebrew 安装时使用installation-prefix (Homebrew Cellar) . 默认是/usr/local.Deb / RPM 包安装使用空${install_prefix}. Name Location RABBITMQ_BASE (Not used) RABBITMQ_CONFIG_FILE ${install_prefix}/etc/rabbitmq/rabbitmq RABBITMQ_MNESIA_BASE ${install_prefix}/var/lib/rabbitmq/mnesia RABBITMQ_MNESIA_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME RABBITMQ_LOG_BASE ${install_prefix}/var/log/rabbitmq RABBITMQ_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME.log RABBITMQ_SASL_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME-sasl.log RABBITMQ_PLUGINS_DIR $RABBITMQ_HOME/plugins RABBITMQ_PLUGINS_EXPAND_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME-plugins-expand RABBITMQ_ENABLED_PLUGINS_FILE ${install_prefix}/etc/rabbitmq/enabled_plugins RABBITMQ_PID_FILE $RABBITMQ_MNESIA_DIR.pid Windows默认位置 Name Location RABBITMQ_BASE %APPDATA%\RabbitMQ RABBITMQ_CONFIG_FILE %RABBITMQ_BASE%\rabbitmq RABBITMQ_MNESIA_BASE %RABBITMQ_BASE%\db RABBITMQ_MNESIA_DIR %RABBITMQ_MNESIA_BASE%\%RABBITMQ_NODENAME% RABBITMQ_LOG_BASE %RABBITMQ_BASE%\log RABBITMQ_LOGS %RABBITMQ_LOG_BASE%\%RABBITMQ_NODENAME%.log RABBITMQ_SASL_LOGS %RABBITMQ_LOG_BASE%\%RABBITMQ_NODENAME%-sasl.log RABBITMQ_PLUGINS_DIR Installation-directory/plugins RABBITMQ_PLUGINS_EXPAND_DIR %RABBITMQ_MNESIA_BASE%\%RABBITMQ_NODENAME%-plugins-expand RABBITMQ_ENABLED_PLUGINS_FILE %RABBITMQ_BASE%\enabled_plugins RABBITMQ_PID_FILE (Not currently supported) 通用Unix默认位置（即本次测试使用Rabbitmq版本）当解压Generic Unix tar文件并运行时，由于默认获得到位置，不需要进行. 在下面的表格中，$RABBITMQ_HOME指的是rabbitmq_server-3.7.4解压后的目录。 Name Location RABBITMQ_BASE (Not used) RABBITMQ_CONFIG_FILE $RABBITMQ_HOME/etc/rabbitmq/rabbitmq RABBITMQ_MNESIA_BASE $RABBITMQ_HOME/var/lib/rabbitmq/mnesia RABBITMQ_MNESIA_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME RABBITMQ_LOG_BASE $RABBITMQ_HOME/var/log/rabbitmq RABBITMQ_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME.log RABBITMQ_SASL_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME-sasl.log RABBITMQ_PLUGINS_DIR $RABBITMQ_HOME/plugins RABBITMQ_PLUGINS_EXPAND_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME-plugins-expand RABBITMQ_ENABLED_PLUGINS_FILE $RABBITMQ_HOME/etc/rabbitmq/enabled_plugins RABBITMQ_PID_FILE $RABBITMQ_MNESIA_DIR.pid 4）持久化配置RabbitMQ持久层的目的是为了得到好的结果，在大多数情况下没有配置。然而，一些配置有时是有用的。首先，先讲一下背景: 持久化和短暂消息都可以写入磁盘。持久化消息一旦到达队列，就会写入磁盘,而短暂消息只在内存压力较大被赶出内存时才会写入磁盘。持久化消息在内存紧张释放内存时，依然也会存在内存中． 持久层指的是存储这两种类型消息到磁盘的机制。队列是指无镜像队列或master队列或slave队列。 队列镜像会发生以上的持久化。持久层有两个组件: 队列索引和消息存储.队列索引负责维护消息在队列的位置，以及是否被投递，是否应答的信息. 因此，每个队列都有一个队列索引。消息存储是消息的key-value存储, 由服务器中的所有队列共享.消息(消息体, 消息属性或消息头)可直接存储于队列索引，也可以写到消息存储中.在技术上有两个消息存储（一个暂时的和一个持久的消息），但他们通常一起被被认为是“消息存储”。内存成本在内存压力下，持久层试图尽可能多地写入磁盘，并尽可能的从内存中删除。然而有一些事情必须留在内存中：每个队列都会为每个未应答消息维护一些元数据．如果它的目的地是消息存储，则消息本身可以从内存中删除。消息存储需要索引. 默认消息存储索引对于存储中的每个消息会使用少量内存。队列索引中的消息将消息写入队列索引有优点也有缺点。优点:消息可在一个操作中(而不是两个）写入磁盘; 对于微小的消息，这可以是一个实质性的增益。写入队列索引的消息不需要消息存储索引中的条目，因此当页出(paged out)时，不需要花费内存成本。缺点:队列索引在内存中保有固定数量的记录块;如果写入队列索引中的消息不是小消息，那么内存占用也是巨大的。如果一个消息通过一个交换路由到多个队列，则消息将需要写入多个队列索引。如果这样的消息被写入消息存储区，则只有一个副本需要被写入。目的地是队列索引的未应答消息总会保存在内存中。将小消息存储在队列索引中目的是优化，所有其它消息将会写入消息存储.这可以配置项queue_index_embed_msgs_below来配置.默认情况下，序列后大小小于4096字节 (包括属性和头)会存储在队列索引中。当从磁盘中读取消息时，每个队列索引至少需要在内存中保留一个段文件(segment file). 段文件中包含了16,384个消息. 因此要谨慎如果增加queue_index_embed_msgs_below；小的增加会导致大量的内存使用。无意中有限的持久性能(Accidentally limited persister performance）持久化有可能表现不佳，因为持久化受限于文件句柄的数目或与它工作的异步线程.在这两种情况下，当您有大量需要同时访问磁盘的队列时，会发生这样的情况。.太少的文件句柄RabbitMQ 服务器通常受限于它能打开的文件句柄数量(在Unix上，无论如何). 每个运行的网络连接都需要一个文件句柄, 其余的可用于队列使用。如果磁盘访问队列比考虑到网络连接后文件句柄更多，那么磁盘访问队列将与文件句柄一起共享; 每个都会在它返回交给另一个队列之前，都会使用文件句柄一段时间。当有太多磁盘访问队列时，这可以防止服务器崩溃,但代价是昂贵的. 管理插件可以显示集群中每个节点的统计I/O统计信息，如读，写，查找的速率．同时它也会显示重新开始(reopens)的速率- 文件句柄通过这种方式来回收利用. 一个有太少文件句柄繁忙的服务器每秒可能会做几百次reopens - 在这种情况下，如果增加文件句柄，就有可能提高性能。太少的异步线程Erlang 虚拟机创建异步线程池来处理长时间运行的文件I/O操作. 这些线程池是所有队列所共享的.每个活跃的文件I/O操作都会使用一个异步线程. 太少的异步线程可以因此伤害性能。注意，异步线程的情况并不完全类似与文件句柄的情况. 如果一个队列按顺序来执行一定数量的I/O操作，假设它持有一个文件句柄来所理所有操作，其性能是最好的，否则，我们会占用ＣＰＵ来做更多的刷新，查找 操作. 然而,队列不能从持有一个异步线程执行一系列的操作中获益(事实上也做不到)。因此理论上应该要有足够的文件句柄来处理所有队列上的I/O流操作, 并且要有足够的线程来处理并发的 (simultaneous )的I/O操作。由异步线程缺乏造成的性能问题，不是太明显. (一般情况下都不太可能，可首先检查其它地方!) 。太少异步线程的典型症状是，当服务器忙于持久化时，在很短的时间内，每秒 I/O操作的数目将会下降到０(管理插件可报告) ,报告的每个 I/O操作的时间将会增加。Erlang虚拟主机的异步线程数目可通过+A 参数进行配置，这里有描述, 通常情况下，也可以通过环境变量RABBITMQ_SERVER_ERL_ARGS来配置. 默认值是 +A 30. 在修改之前，多进行几次尝试总是好主意。 三、Rabbitmq集群RabbitMQ是用erlang开发的，集群非常方便，因为erlang天生就是一门分布式语言,但其本身并不支持负载均衡。Rabbit模式大概分为以下三种：单一模式、普通模式、镜像模式单一模式：最简单的情况，非集群模式。普通模式：默认的集群模式。对于Queue来说，消息实体只存在于其中一个节点，A、B两个节点仅有相同的元数据，即队列结构。当消息进入A节点的Queue中后，consumer从B节点拉取时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连A或B，出口总在A，会产生瓶颈。该模式存在一个问题就是当A节点故障后，B节点无法取到A节点中还未消费的消息实体。如果做了消息持久化，那么得等A节点恢复，然后才可被消费；如果没有持久化的话，就会很容易发生故障。镜像模式：把需要的队列做成镜像队列，存在于多个节点，属于RabbitMQ的HA方案。该模式解决了上述问题，其实质和普通模式不同之处在于，消息实体会主动在镜像节点间同步，而不是在consumer取数据时临时拉取。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉，所以在对可靠性要求较高的场合中适用。 1、集群中的基本概念RabbitMQ的集群节点包括内存节点、磁盘节点。顾名思义内存节点就是将所有数据放在内存，磁盘节点将数据放在磁盘。不过，如前文所述，如果在投递消息时，打开了消息的持久化，那么即使是内存节点，数据还是安全的放在磁盘。一个rabbitmq集群中可以共享 user，vhost，queue，exchange等，所有的数据和状态都是必须在所有节点上复制的，一个例外是，那些当前只属于创建它的节点的消息队列，尽管它们可见且可被所有节点读取。rabbitmq节点可以动态的加入到集群中，一个节点它可以加入到集群中，也可以从集群环集群会进行一个基本的负载均衡。集群中有两种节点：1 内存节点：只保存状态到内存（一个例外的情况是：持久的queue的持久内容将被保存到disk）2 磁盘节点：保存状态到内存和磁盘。内存节点虽然不写入磁盘，但是它执行比磁盘节点要好。集群中，只需要一个磁盘节点来保存状态 就足够了如果集群中只有内存节点，那么不能停止它们，否则所有的状态，消息等都会丢失。 2、集群模式配置1）配置hosts在2台节点服务器中，分别修改/etc/hosts文件1210.186.21.84 10-186-21-8410.186.21.85 10-186-21-85 还有hostname文件也要正确，分别是10-186-21-84、10-186-21-85，如果修改hostname建议安装rabbitmq前修改。请注意RabbitMQ集群节点必须在同一个网段里，如果是跨广域网效果就差。 2）设置每个节点CookieRabbitmq的集群是依赖于erlang的集群来工作的，所以必须先构建起erlang的集群环境。Erlang的集群中各节点是通过一个magic cookie来实现的，这个cookie存放在 /var/lib/rabbitmq/.erlang.cookie 中，文件是400的权限。所以必须保证各节点cookie保持一致，否则节点之间就无法通信。将10-186-21-84中的cookie 复制到10-186-21-85中，先修改下10-186-21-84中的.erlang.cookie权限1chmod 777 /root/.erlang.cookie 将queue的/root/.erlang.cookie这个文件，拷贝到10-186-21-85的同一位置（反过来亦可），该文件是集群节点进行通信的验证密钥，所有节点必须一致。拷完后重启下RabbitMQ。复制好后别忘记还原.erlang.cookie的权限，否则可能会遇到错误chmod 400 /root/.erlang.cookie设置好cookie后先将三个节点的rabbitmq重启12rabbitmqctl stoprabbitmq-server start 3）重启所有节点停止所有节点RabbitMq服务，然后使用detached参数独立运行，尤其增加节点停止节点后再次启动遇到无法启动都可以参照这个顺序（此步骤很重要）12rabbitmqctl stoprabbitmq-server -detached 分别查看节点集群信息第一台1234567[root@10-186-21-84 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-30-84 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-30-84']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-30-84']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-30-84"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-30-84',[]&#125;]&#125;] 第二台1234567[root@10-186-21-85 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-21-85 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-21-85']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-21-85']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-21-85"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-21-85',[]&#125;]&#125;] 4）配置集群10-186-21-84作为内存节点，10-186-21-84作为磁盘节点创建集群。在10-186-21-84上操作加入集群rabbit@10-186-21-851234567[root@10-186-21-84 ~]# rabbitmqctl stop_appStopping rabbit application on node rabbit@10-186-30-84 ...[root@10-186-21-84 ~]# rabbitmqctl join_cluster --ram rabbit@10-186-21-85Clustering node rabbit@10-186-30-84 with rabbit@10-186-21-85[root@10-186-21-84 ~]# rabbitmqctl start_appStarting node rabbit@10-186-30-84 ... completed with 3 plugins. 此时重新查看节点上集群信息在10-186-21-84上查看1234567[root@10-186-21-84 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-21-84 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-21-85']&#125;,&#123;ram,['rabbit@10-186-21-84']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-21-85','rabbit@10-186-21-84']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-21-85"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-21-85',[]&#125;,&#123;'rabbit@10-186-21-84',[]&#125;]&#125;] 在10-186-21-85上查看1234567[root@10-186-21-85 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-21-85 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-21-85']&#125;,&#123;ram,['rabbit@10-186-21-84']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-21-84','rabbit@10-186-21-85']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-21-85"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-21-84',[]&#125;,&#123;'rabbit@10-186-21-85',[]&#125;]&#125;] disc代表磁盘模式ram代表内存模式cluster_name代表集群名称查看消息队列是否一致1rabbitmqctl list_queues -p hrsystem 5）节点相关操作change_cluster_node_type {disc | ram}修改集群节点的类型. 要成功执行此操作，必须首先停止节点，要将节点转换为RAM节点，则此节点不能是集群中的唯一disc节点。ram节点转换为disc节点亦然。例如:1rabbitmqctl change_cluster_node_type disc 此命令会将一个RAM节点转换为disc节点。 forget_cluster_node [–offline][–offline]允许节点从脱机节点中删除. 这只在所有节点都脱机且最后一个掉线节点不能再上线的情况下有用，从而防止整个集群从启动。它不能使用在其它情况下，因为这会导致不一致．远程删除一个集群节点.要删除的节点必须是脱机的, 而在删除节点期间节点必须是在线的，除非使用了–offline 标志.当使用–offline 标志时，rabbitmqctl不会尝试正常连接节点;相反，它会临时改变节点以作修改.如果节点不能正常启动的话，这是非常有用的.在这种情况下，节点将变成集群元数据的规范源（例如，队列的存在），即使它不是以前的。因此，如果有可能，你应该在最新的节点上使用这个命令来关闭。例如:1rabbitmqctl -n hare@mcnulty forget_cluster_node rabbit@stringer 此命令会从节点hare@mcnulty中删除rabbit@stringer节点.1rename_cluster_node &#123;oldnode1&#125; &#123;newnode1&#125; [oldnode2] [newnode2 ...] 支持在本地数据库中重命名集群节点.此子命令会促使rabbitmqctl临时改变节点以作出修改. 因此本地集群必须是停止的，其它节点可以是在线或离线的．这个子命令接偶数个参数，成对表示节点的旧名称和新名称.你必须指定节点的旧名称和新名称，因为其它停止的节点也可能在同一时间重命名.同时停止所有节点来重命名也是可以的(在这种情况下，每个节点都必须给出旧名称和新名称)或一次停止一个节点来重命名(在这种情况下，每个节点只需要被告知其名句是如何变化的).例如:1rabbitmqctl rename_cluster_node rabbit@misshelpful rabbit@cordelia 此命令来将节点名称rabbit@misshelpful 重命名为rabbit@cordelia.12update_cluster_nodes &#123;clusternode&#125;clusternode 用于咨询具有最新消息的节点.指示已集群的节点醒来时联系clusternode.这不同于join_cluster ，因为它不会加入任何集群 - 它会检查节点已经以clusternode的形式存在于集群中了．需要这个命令的动机是当节点离线时，集群可以变化.考虑这样的情况，节点Ａ和节点Ｂ都在集群里边，这里节点Ａ掉线了，Ｃ又和Ｂ集群了，然后Ｂ又离开了集群．当Ａ醒来的时候，它会尝试联系Ｂ，但这会失败，因为Ｂ已经不在集群中了.update_cluster_nodes -n A C 可解决这种场景．1force_boot 确保节点将在下一次启动，即使它不是最后一个关闭的。通常情况下，当你关闭整个RabbitMQ 集群时，你重启的第一个节点应该是最后一个下线的节点，因为它可以看到其它节点所看不到的事情. 但有时这是不可能的:例如，如果整个集群是失去了电力而所有节点都在想它不是最后一个关闭的．在这种节点掉线情况下，你可以调用rabbitmqctl force_boot ．这就告诉节点下一次无条件的启动节点.在此节点关闭后，集群的任何变化，它都会丢失．如果最后一个掉线的节点永久丢失了，那么你需要优先使用rabbitmqctl forget_cluster_node –offline, 因为它可以确保在丢失的节点上掌握的镜像队列得到提升。例如:1rabbitmqctl force_boot 这可以强制节点下次启动时不用等待其它节点．12sync_queue [-p vhost] &#123;queue&#125;queue 同步队列的名称指示未同步slaves上的镜像队列自行同步.同步发生时，队列会阻塞(所有出入队列的发布者和消费者都会阻塞).此命令成功执行后，队列必须是镜像的。注意，未同步队列中的消息被耗尽后，最终也会变成同步. 此命令主要用于未耗尽的队列。12cancel_sync_queue [-p vhost] &#123;queue&#125;queue 取消同步的队列名称.指示同步镜像队列停止同步.12purge_queue [-p vhost] &#123;queue&#125;queue 要清除队列的名称.清除队列(删除其中的所有消息).1set_cluster_name &#123;name&#125; 设置集群名称. 集群名称在client连接时，会通报给client,也可用于federation和shovel插件记录消息的来源地. 群集名称默认是来自在群集中的第一个节点的主机名，但可以改变。例如:1rabbitmqctl set_cluster_name london 设置集群名称为”london”. 3、镜像模式配置上面配置RabbitMQ默认集群模式，但并不保证队列的高可用性，尽管交换机、绑定这些可以复制到集群里的任何一个节点，但是队列内容不会复制，虽然该模式解决一部分节点压力，但队列节点宕机直接导致该队列无法使用，只能等待重启，所以要想在队列节点宕机或故障也能正常使用，就要复制队列内容到集群里的每个节点，需要创建镜像队列。下面配置镜像模式来解决复制的问题，从而提高可用性。 1）增加负载均衡器选择HAProxy作为RabbitMQ前端的LB安装haproxy1yum install haproxy 配置负载均衡，在/etc/haproxy/haproxy.cfg中加入以下内容12345listen rabbitmq_cluster 0.0.0.0:5672 mode tcp balance roundrobin server rqslave1 10.186.21.84:5672 check inter 2000 rise 2 fall 3# server rqslave2 10.186.21.85:5672 check inter 2000 rise 2 fall 3 负载均衡器会监听5672端口，轮询内存节点10.186.21.84的5672端口,由于资源问题，此处只配置一个内存节点，应该是配置多个才有意义。10.186.21.85为磁盘节点，只做备份不提供给生产者、消费者使用，当然如果我们服务器资源充足情况也可以配置多个磁盘节点，这样磁盘节点除了故障也不会影响，除非同时出故障。 2）配置策略使用Rabbit镜像功能，需要基于rabbitmq策略来实现，政策是用来控制和修改群集范围的某个vhost队列行为和Exchange行为。在cluster中任意节点启用策略，策略会自动同步到集群节点rabbitmqctl set_policy -p hrsystem ha-allqueue”^” ‘{“ha-mode”:”all”}’这行命令在vhost名称为hrsystem创建了一个策略，策略名称为ha-allqueue,策略模式为 all 即复制到所有节点，包含新增节点，策略正则表达式为 “^” 表示所有匹配所有队列名称。Set_policy语法参看官网：1set_policy [-p vhost] [--priority priority] [--apply-to apply-to] name pattern definition 用法12Usage:rabbitmqctl [-n &lt;node&gt;] [-t &lt;timeout&gt;] [-q] set_policy [-p &lt;vhost&gt;] [--priority &lt;priority&gt;] [--apply-to &lt;apply-to&gt;] &lt;name&gt; &lt;pattern&gt; &lt;definition&gt; 通过命令行添加，例如12[root@10-186-21-84 ~]# rabbitmqctl set_policy delete_ha "^delete" '&#123;"ha-mode":"all"&#125;'Setting policy "delete_ha" for pattern "^delete" to "&#123;"ha-mode":"all"&#125;" with priority "0" for vhost "/" .. 查看web界面从上图可以看到已添加成功。也可以通过rabbit控制台添加下图为以添加的两个policy下图可以看到在exchanges中已经可以看all_ha已经被应用 3）新加入队列创建队列时需要指定ha 参数，如果不指定x-ha-prolicy 的话将无法复制。 4、单机多节点集群配置在启动RabbitMQ节点之后，服务器默认的节点名称是Rabbit和监听端口5672，如果想在同一台机器上启动多个节点，那么其他的节点就会因为节点名称和端口与默认的冲突而导致启动失败，可以通过设置环境变量来实现，具体方法如下：配置三个rabbitmq节点，分别为rabbit1, rabbit2和rabbit3主要开启命令如下：123RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit1 rabbitmq-server -detachedRABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit2 rabbitmq-server -detachedRABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=rabbit3 rabbitmq-server -detached 结束命令如下：123rabbitmqctl -n rabbit1 stoprabbitmqctl -n rabbit2 stoprabbitmqctl -n rabbit3 stop rabbit1上配置集群1234rabbitmqctl -n rabbit1 stop_apprabbitmqctl -n rabbit1 resetrabbitmqctl -n rabbit1 cluster rabbitmqctl -n rabbit1 start_app rabbit2加入rabbit1集群1234rabbitmqctl -n rabbit2 stop_apprabbitmqctl -n rabbit2 resetrabbitmqctl -n rabbit2 cluster rabbit1@`hostname -s`rabbitmqctl -n rabbit2 start_app 查看集群状态1rabbitmqctl -n rabbit1 cluster_status 将rabbit3加入集群1234rabbitmqctl -n rabbit3 stop_apprabbitmqctl -n rabbit3 resetrabbitmqctl -n rabbit3 cluster rabbit1@`hostname -s`rabbitmqctl -n rabbit3 start_app 再查看集群状态1rabbitmqctl -n rabbit1 cluster_status 由于此种集群方案对于并无太大意思，所以只简单讲述方法。同理可以配置多机多节点集群。]]></content>
      <categories>
        <category>OS</category>
        <category>Service</category>
      </categories>
      <tags>
        <tag>集群</tag>
        <tag>erlang</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat基础文档]]></title>
    <url>%2F2018%2F12%2F10%2FTomcat%E5%9F%BA%E7%A1%80%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[一、 前言1、Tomcat是什么Tomcat 是由 Apache 开发的一个 Servlet 容器，实现了对 Servlet 和 JSP 的支持，并提供了作为Web服务器的一些特有功能，如Tomcat管理和控制平台、安全域管理和Tomcat阀等。由于 Tomcat 本身也内含了一个 HTTP 服务器，它也可以被视作一个单独的 Web 服务器。但是，不能将 Tomcat 和 Apache HTTP 服务器混淆，Apache HTTP 服务器是一个用 C 语言实现的 HTTP Web 服务器；这两个 HTTP web server 不是捆绑在一起的。Tomcat 包含了一个配置管理工具，也可以通过编辑XML格式的配置文件来进行配置。 2、Tomcat重要目录1234* /bin - Tomcat 脚本存放目录（如启动、关闭脚本）。 *.sh 文件用于 Unix 系统； *.bat 文件用于 Windows 系统。* /conf - Tomcat 配置文件目录。* /logs - Tomcat 默认日志目录。* /webapps - webapp 运行的目录。 3、web工程发布目录一般web项目路径结构123456789101112|-- webapp # 站点根目录 |-- META-INF # META-INF 目录 | `-- MANIFEST.MF # 配置清单文件 |-- WEB-INF # WEB-INF 目录 | |-- classes # class文件目录 | | |-- *.class # 程序需要的 class 文件 | | `-- *.xml # 程序需要的 xml 文件 | |-- lib # 库文件夹 | | `-- *.jar # 程序需要的 jar 包 | `-- web.xml # Web应用程序的部署描述文件 |-- &lt;userdir&gt; # 自定义的目录 |-- &lt;userfiles&gt; # 自定义的资源文件 webapp：工程发布文件夹。其实每个 war 包都可以视为 webapp 的压缩包。 META-INF：META-INF 目录用于存放工程自身相关的一些信息，元文件信息，通常由开发工具，环境自动生成。 WEB-INF：Java web应用的安全目录。所谓安全就是客户端无法访问，只有服务端可以访问的目录。 /WEB-INF/classes：存放程序所需要的所有 Java class 文件。 /WEB-INF/lib：存放程序所需要的所有 jar 文件。 /WEB-INF/web.xml：web 应用的部署配置文件。它是工程中最重要的配置文件，它描述了servlet和组成应用的其它组件，以及应用初始化参数、安全管理约束等。 二、安装Tomcat需要java环境支持，无论windows server还是linux server都需要先安装JAVA环境，本次安装tomcat8.5.29版本需要最低JAVA SE 7或以上版本支持。具体的JAVA版本支持可以从tomcat官网tomcat.apache.org查看。 1、 windwos server安装Tomcat由于windows server环境安装过于简单，以及实际使用较少，在这里只简述过程。 1）安装JDK下载JDK版本为1.8.0_161，windows版本可以双击直接安装，或者添加系统环境变量JAVA_HOME，环境变量的值为JDK的路径。 2）安装Tomcat下载zip压缩版本，下载后解压，可以直接双击bin目录下的startup.bat启动，也可以注册服务，以服务方式启动。 2、linux server安装Tomcat1）安装JDK检查系统是否已经安装jdk1java -version 如果没有显示java版本信息，则表示没有安装java12345678910#安装javatar -zxvf jdk-8u161-linux-x64.tar.gzmv jdk1.8.0_161 /data/jdk1.8#修改系统变量vi /etc/profile#在文本末尾添加以下内容：PATH=/data/jdk1.8/bin:$PATHexport PATH#使添加内容生效 source /etc/profile 再查看java版本 出现如下信息表示安装成功1234# java -versionjava version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 2）安装Tomcat12345678910111213141516171819202122232425#解压tar zxvf apache-tomcat-8.5.29.tar.gz#修改目录名并移动位置mv apache-tomcat-8.5.29 /data/tomcat#修改默认启动脚本cd /usr/local/tomcat/binvim catalina.sh#首先找到CLASSPATH=，改为CLASSPATH=/data/jdk1.8/lib/tools.jar:/data/jdk1.8/lib/dt.jar#然后在文件的第二行空行插入以下内容（带#号注释的那行也要）：#chkconfig: 35 85 15CATALINA_HOME=/data/tomcatJAVA_HOME=/data/jdk1.8JRE_HOME=/data/jdk1.8#复制脚本到/etc/init.d/cp catalina.sh /etc/init.d/tomcat #给脚本加上可可执行权限chmod +x /etc/init.d/tomcat#启动tomcatservice tomcat start#查看进程# netstat -lntp|grep javatcp6 0 0 :::8009 :::* LISTEN 19310/java tcp6 0 0 :::8080 :::* LISTEN 19310/java tcp6 0 0 127.0.0.1:8005 :::* LISTEN 19310/java 访问ip:8080就能看到欢迎页 三、配置详解本节将列举一些重要、常见的配置项。 1、ServerServer 元素表示整个 Catalina servlet 容器。因此，它必须是 conf/server.xml 配置文件中的根元素。它的属性代表了整个 servlet 容器的特性。属性 描述 备注className 这个类必须实现org.apache.catalina.Server接口。 默认 org.apache.catalina.core.StandardServeraddress 服务器等待关机命令的TCP / IP地址。如果没有指定地址，则使用localhost。port 服务器等待关机命令的TCP / IP端口号。设置为-1以禁用关闭端口。shutdown 必须通过TCP / IP连接接收到指定端口号的命令字符串，以关闭Tomcat。 2、ServiceService元素表示一个或多个连接器组件的组合，这些组件共享一个用于处理传入请求的引擎组件。Server 中可以有多个 Service。属性 描述 备注className 这个类必须实现org.apache.catalina.Service接口。 默认 org.apache.catalina.core.StandardServicename 此服务的显示名称，如果您使用标准 Catalina 组件，将包含在日志消息中。与特定服务器关联的每个服务的名称必须是唯一的。conf/server.xml配置文件示例：123456&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8080" shutdown="SHUTDOWN"&gt; &lt;Service name="xxx"&gt; ... &lt;/Service&gt;&lt;/Server&gt; 3、ExecutorExecutor表示可以在Tomcat中的组件之间共享的线程池。属性 描述 备注className 这个类必须实现org.apache.catalina.Executor接口。 默认 org.apache.catalina.core.StandardThreadExecutorname 线程池名称。 要求唯一, 供Connector元素的executor属性使用namePrefix 线程名称前缀。maxThreads 最大活跃线程数。 默认200minSpareThreads 最小活跃线程数。 默认25maxIdleTime 当前活跃线程大于minSpareThreads时,空闲线程关闭的等待最大时间。 默认60000msmaxQueueSize 线程池满情况下的请求排队大小。 默认Integer.MAX_VALUE示例：123&lt;Service name="xxx"&gt; &lt;Executor name="tomcatThreadPool" namePrefix="catalina-exec-" maxThreads="300" minSpareThreads="25"/&gt;&lt;/Service&gt; 4、ConnectorConnector代表连接组件。Tomcat 支持三种协议：HTTP/1.1、HTTP/2.0、AJP。属性 说明 备注asyncTimeout Servlet3.0规范中的异步请求超时 默认30sport 请求连接的TCP Port 设置为0,则会随机选取一个未占用的端口号protocol 协议. 一般情况下设置为 HTTP/1.1,这种情况下连接模型会在NIO和APR/native中自动根据配置选择URIEncoding 对URI的编码方式. 如果设置系统变量org.apache.catalina.STRICT_SERVLET_COMPLIANCE为true,使用 ISO-8859-1编码;如果未设置此系统变量且未设置此属性, 使用UTF-8编码useBodyEncodingForURI 是否采用指定的contentType而不是URIEncoding来编码URI中的请求参数以下属性在标准的Connector(NIO, NIO2 和 APR/native)中有效:属性 说明 备注acceptCount 当最大请求连接maxConnections满时的最大排队大小 默认100,注意此属性和Executor中属性maxQueueSize的区别.这个指的是请求连接满时的堆栈大小,Executor的maxQueueSize指的是处理线程满时的堆栈大小connectionTimeout 请求连接超时 默认60000msexecutor 指定配置的线程池名称keepAliveTimeout keeAlive超时时间 默认值为connectionTimeout配置值.-1表示不超时maxConnections 最大连接数 连接满时后续连接放入最大为acceptCount的队列中. 对 NIO和NIO2连接,默认值为10000;对 APR/native,默认值为8192maxThreads 如果指定了Executor, 此属性忽略;否则为Connector创建的内部线程池最大值 默认200minSpareThreads 如果指定了Executor, 此属性忽略;否则为Connector创建线程池的最小活跃线程数 默认10processorCache 协议处理器缓存Processor对象的大小 -1表示不限制.当不使用servlet3.0的异步处理情况下: 如果配置Executor,配置为Executor的maxThreads;否则配置为Connnector的maxThreads. 如果使用Serlvet3.0异步处理, 取maxThreads和maxConnections的最大值 5、ContextContext元素表示一个Web应用程序，它在特定的虚拟主机中运行。每个Web应用程序都基于Web应用程序存档（WAR）文件，或者包含相应的解包内容的相应目录，如Servlet规范中所述。属性 说明 备注altDDName web.xml部署描述符路径 默认 /WEB-INF/web.xmldocBase Context的Root路径 和Host的appBase相结合, 可确定web应用的实际目录failCtxIfServletStartFails 同Host中的failCtxIfServletStartFails, 只对当前Context有效 默认为falselogEffectiveWebXml 是否日志打印web.xml内容(web.xml由默认的web.xml和应用中的web.xml组成) 默认为falsepath web应用的context path 如果为根路径,则配置为空字符串(“”), 不能不配置privileged 是否使用Tomcat提供的manager servletreloadable /WEB-INF/classes/ 和/WEB-INF/lib/ 目录中class文件发生变化是否自动重新加载 默认为falseswallowOutput true情况下, System.out和System.err输出将被定向到web应用日志中 默认为false 6、EngineEngine元素表示与特定的Catalina服务相关联的整个请求处理机器。它接收并处理来自一个或多个连接器的所有请求，并将完成的响应返回给连接器，以便最终传输回客户端。属性 描述 备注defaultHost 默认主机名，用于标识将处理指向此服务器上主机名称但未在此配置文件中配置的请求的主机。 这个名字必须匹配其中一个嵌套的主机元素的名字属性。name 此引擎的逻辑名称，用于日志和错误消息。 在同一服务器中使用多个服务元素时，每个引擎必须分配一个唯一的名称。 7、HostHost元素表示一个虚拟主机，它是一个服务器的网络名称（如“www.mycompany.com”）与运行Tomcat的特定服务器的关联。属性 说明 备注name 名称 用于日志输出appBase 虚拟主机对应的应用基础路径 可以是个绝对路径, 或${CATALINA_BASE}相对路径xmlBase 虚拟主机XML基础路径,里面应该有Context xml配置文件 可以是个绝对路径, 或${CATALINA_BASE}相对路径createDirs 当appBase和xmlBase不存在时,是否创建目录 默认为trueautoDeploy 是否周期性的检查appBase和xmlBase并deploy web应用和context描述符 默认为truedeployIgnore 忽略deploy的正则deployOnStartup Tomcat启动时是否自动deploy 默认为truefailCtxIfServletStartFails 配置为true情况下,任何load-on-startup &gt;=0的servlet启动失败,则其对应的Contxt也启动失败 默认为false 8、ClusterTomcat集群配置。集群的配置比较复杂，默认的集群配置可以满足一般的开发需求。一个Cluster配置案例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120&lt;!-- Cluster(集群,族) 节点,如果你要配置tomcat集群,则需要使用此节点. className 表示tomcat集群时,之间相互传递信息使用那个类来实现信息之间的传递. channelSendOptions可以设置为2、4、8、10，每个数字代表一种方式 2 = Channel.SEND_OPTIONS_USE_ACK(确认发送) 4 = Channel.SEND_OPTIONS_SYNCHRONIZED_ACK(同步发送) 8 = Channel.SEND_OPTIONS_ASYNCHRONOUS(异步发送) 在异步模式下，可以通过加上确认发送(Acknowledge)来提高可靠性，此时channelSendOptions设为10--&gt;&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;!-- Manager决定如何管理集群的Session信息。Tomcat提供了两种Manager：BackupManager和DeltaManager BackupManager－集群下的所有Session，将放到一个备份节点。集群下的所有节点都可以访问此备份节点 DeltaManager－集群下某一节点生成、改动的Session，将复制到其他节点。 DeltaManager是Tomcat默认的集群Manager，能满足一般的开发需求 使用DeltaManager，每个节点部署的应用要一样；使用BackupManager，每个节点部署的应用可以不一样. className－指定实现org.apache.catalina.ha.ClusterManager接口的类,信息之间的管理. expireSessionsOnShutdown－设置为true时，一个节点关闭，将导致集群下的所有Session失效 notifyListenersOnReplication－集群下节点间的Session复制、删除操作，是否通知session listeners maxInactiveInterval－集群下Session的有效时间(单位:s)。 maxInactiveInterval内未活动的Session，将被Tomcat回收。默认值为1800(30min) --&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;!-- Channel是Tomcat节点之间进行通讯的工具。 Channel包括5个组件：Membership、Receiver、Sender、Transport、Interceptor --&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;!-- Membership维护集群的可用节点列表。它可以检查到新增的节点，也可以检查到没有心跳的节点 className－指定Membership使用的类 address－组播地址 port－组播端口 frequency－发送心跳(向组播地址发送UDP数据包)的时间间隔(单位:ms)。默认值为500 dropTime－Membership在dropTime(单位:ms)内未收到某一节点的心跳，则将该节点从可用节点列表删除。默认值为3000 注: 组播（Multicast）：一个发送者和多个接收者之间实现一对多的网络连接。 一个发送者同时给多个接收者传输相同的数据，只需复制一份相同的数据包。 它提高了数据传送效率，减少了骨干网络出现拥塞的可能性 相同组播地址、端口的Tomcat节点，可以组成集群下的子集群 --&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;!-- Receiver : 接收器，负责接收消息 接收器分为两种：BioReceiver(阻塞式)、NioReceiver(非阻塞式) className－指定Receiver使用的类 address－接收消息的地址 port－接收消息的端口 autoBind－端口的变化区间 如果port为4000，autoBind为100，接收器将在4000-4099间取一个端口，进行监听 selectorTimeout－NioReceiver内轮询的超时时间 maxThreads－线程池的最大线程数 --&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;!-- Sender : 发送器，负责发送消息 Sender内嵌了Transport组件，Transport真正负责发送消息 --&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;!-- Transport分为两种：bio.PooledMultiSender(阻塞式)、nio.PooledParallelSender(非阻塞式) --&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;!-- Interceptor : Cluster的拦截器 TcpFailureDetector－网络、系统比较繁忙时，Membership可能无法及时更新可用节点列表， 此时TcpFailureDetector可以拦截到某个节点关闭的信息， 并尝试通过TCP连接到此节点，以确保此节点真正关闭，从而更新集群可以用节点列表 --&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;!-- MessageDispatch15Interceptor－查看Cluster组件发送消息的方式是否设置为 Channel.SEND_OPTIONS_ASYNCHRONOUS(Cluster标签下的channelSendOptions为8时)。 设置为Channel.SEND_OPTIONS_ASYNCHRONOUS时， MessageDispatch15Interceptor先将等待发送的消息进行排队，然后将排好队的消息转给Sender --&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;!-- Valve : 可以理解为Tomcat的拦截器 ReplicationValve－在处理请求前后打日志；过滤不涉及Session变化的请求 vmRouteBinderValve－Apache的mod_jk发生错误时，保证同一客户端的请求发送到集群的同一个节点 --&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;!-- Deployer : 同步集群下所有节点的一致性。 --&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;!-- ClusterListener : 监听器，监听Cluster组件接收的消息 使用DeltaManager时，Cluster接收的信息通过ClusterSessionListener传递给DeltaManager --&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt;&lt;/Cluster&gt; 四、配置实例1、Tomcat配置使用manager管理项目Tomcat在部署新项目时，可以通过/manager/html来上传war包，来完成部署。部署完成的访问路径为：ip:8080/warname。首先配置tomcat可以访问manager和host-manager在conf/tomcat-users.xml中标签中添加以下配置信息：123456789&lt;role rolename="admin"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="admin-script"/&gt;&lt;role rolename="manager"/&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;role rolename="manager-jmx"/&gt; &lt;role rolename="manager-status"/&gt; &lt;user username="tomcat" password="tomcat" roles="admin,admin-gui,admin-script,manager,manager-gui,manager-script,manager-jmx,manager-status"/&gt; 相关配置注释：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157manager-gui #允许访问html接口(即URL路径为/manager/html/*)manager-script #允许访问纯文本接口(即URL路径为/manager/text/*)manager-jmx #允许访问JMX代理接口(即URL路径为/manager/jmxproxy/*)manager-status #允许访问Tomcat只读状态页面(即URL路径为/manager/status/*)特别需要说明的是：manager-gui、manager-script、manager-jmx均具备manager-status的权限，也就是说，manager-gui、manager-script、manager-jmx三种角色权限无需再额外添加manager-status权限，即可直接访问路径”/manager/status/*”。Tomcat8中还需要增加一段配置才能满足要求，在conf/Catalina/localhost中新建文件名manager.xml，内容为：&lt;Context privileged="true" antiResourceLocking="false" docBase="$&#123;catalina.home&#125;/webapps/manager"&gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="^.*$" /&gt; &lt;/Context&gt;在conf/Catalina/localhost中新建文件名host-manager.xml，内容为：&lt;Context privileged="true" antiResourceLocking="false" docBase="$&#123;catalina.home&#125;/webapps/host-manager"&gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="^.*$" /&gt; &lt;/Context&gt;``` 配置完成后，重启tomcat，即可以访问manager。### 2、Nginx+Tomcat配置+多Tomcat负载均衡关于Nginx的配置请查看文档《Nginx应用文档》，Nginx的配置文件如下：```bashuser nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream lvs &#123; #配置两台tomcat负载均衡，ip：port地址为tomcat地址。weight为权重，权重越大，访问概率越大， server 127.0.0.1:8081 weight=10; server 127.0.0.1:8082 weight=10; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; # access_log logs/host.access.log main; location ~ .*\.(gif|jpg|jpeg|bmp|png|ico|txt|js|css)$ &#123; root /data/nainx/html/; #expires定义用户浏览器缓存的时间为7天，如果静态页面不常更新，可以设置更长，这样可以节省带宽和缓解服务器的压力 expires 7d; &#125; location ~ (\.jsp)|(\.do)$ &#123; #root html; #index index.jsp index.htm; #lvs是 upstream 后面的名字 lvs proxy_pass http://lvs; #localhost是nginx服务器的主机地址，如果不写此句，会导致静态文件访问路径为http://lvs，导致找不到地址 proxy_set_header Host localhost; #forwarded信息，用于告诉后端服务器终端用户的ip地址，否则后端服务器只能获取前端代理服务器的ip地址。 proxy_set_header Forwarded $remote_addr; &#125; # / 表示匹配所有地址，默认最大前缀匹配，如果其他没有匹配的才会匹配 location /&#123; root /data/lvs; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html #错误页面地址，500 502 503 504错误的地址 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 路径转发配置（可以不用配置）：1234567891011121314151617181920server &#123; listen 80; server_name *.*.*.*;#本服务器ip地址 #charset koi8-r; #access_log logs/host.access.log main; location /&#123; #root html; #index index.html index.htm; proxy_pass http://10.8.0.66:8090/; #当地址最后加上 /时，匹配路径的 yanshi 不会加到转发路径中 proxy_set_header X-Forwarded-For $remote_addr; #当下面这句话不加，Host $host; 会导致post请求参数丢失 proxy_set_header Host $host; proxy_set_header X-Real-Ip $remote_addr; &#125;&#125; 以下是关于tomcat的配置：同一服务器部署多个tomcat时，存在端口号冲突的问题，所以需要修改tomcat配置文件server.xml：首先了解下tomcat的几个主要端口：12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="60000" redirectPort="8443" disableUploadTimeout="false" executor="tomcatThreadPool" URIEncoding="UTF-8"/&gt;其中8080为HTTP端口，8443为HTTPS端口&lt;Server port="8005" shutdown="SHUTDOWN"&gt; 8005为远程停服务端口&lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt;``` 8009为AJP端口，APACHE能过AJP协议访问TOMCAT的8009端口。部署多个tomcat主要修改三个端口：第一个tomcat配置server.xml如下：```bash&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8006" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8081" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8010" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="/data/lvs " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8006、8081、8010第二个tomcat配置server.xml如下：123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8007" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8082" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8011" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="/data/lvs " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8007、8082、8011如果需要更多的tomcat做负载，端口号依次增加即可。nginx与tomcat的结合，主要用的是nginx中的upstream,后端可包括有多台tomcat来处ginx的upstream目前支持5种方式的分配 1）轮询（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 2）weight指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如：1234 upstream bakend &#123; server 192.168.0.14 weight=10; server 192.168.0.15 weight=10;&#125; 3）ip_hash每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session 的问题。例如：12345upstreambakend &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80; &#125; 4）fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。12345upstream backend &#123; server server1; server server2; fair;&#125; 5）url_hash（第三方）按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法123456upstream backend &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_methodcrc32;&#125; 示例：1234567upstream bakend&#123;#定义负载均衡设备的Ip及设备状态 ip_hash; server127.0.0.1:9090 down; server127.0.0.1:8080 weight=2; server127.0.0.1:6060; server127.0.0.1:7070 backup;&#125; 在需要使用负载均衡的server中增加1proxy_pass http://bakend/; 每个设备的状态设置为:1.down 表示单前的server暂时不参与负载2.weight 默认为1.weight越大，负载的权重就越大。3.max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误4.fail_timeout:max_fails次失败后，暂停的时间。5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 nginx支持同时设置多组的负载均衡，用来给不用的server来使用。client_body_in_file_only 设置为On 可以讲clientpost过来的数据记录到文件中用来做debugclient_body_temp_path 设置记录文件的目录 可以设置最多3层目录location 对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡 3、Apache+Tomcat集群配置1）集群简述集群是一组协同工作的服务实体，用以提供比单一服务实体更具扩展性与可用性的服务平台。在客户端看来，一个集群就象是一个服务实体，但 事实上集群由一组服务实体组成。与单一服务实体相比较，集群提供了以下两个关键特性：·可扩展性－－集群的性能不限于单一的服务实体，新的服 务实体可以动态地加入到集群，从而增强集群的性能。·高可用性－－集群通过服务实体冗余使客户端免于轻易遇到out of service的警告。在集群中，同样的服务可以由多个服务实体提供。如果一个服务实体失败了，另一个服务实体会接管失败的服务实体。集群提供的从一个出 错的服务实体恢复到另一个服务实体的功能增强了应用的可用性。为了具有可扩展性和高可用性特点，集群的必须具备以下两大能力： 负载均衡－－负载均衡能把任务比较均衡地分布到集群环境下的计算和网络资源。 错误恢复－－由于某种原因，执行某个任务的资源出现故障，另一服 务实体中执行同一任务的资源接着完成任务。这种由于一个实体中的资源不能工作，另一个实体中的资源透明的继续完成任务的过程叫错误恢复。负载均衡 和错误恢复都要求各服务实体中有执行同一任务的资源存在，而且对于同一任务的各个资源来说，执行任务所需的信息视图（信息上下文）必须是一样的。 集群主要分成三大类：高可用集群(High Availability Cluster/HA)， 负载均衡集群(Load Balance Cluster)，高性能计算集群(High Performance Computing Cluster/HPC) 高可用集群(High Availability Cluster/HA)：一般是指当集群中有某个节点失效的情况下，其上的任务会自动转移到其他正常的节点上。还指可以将集群中的某节点进行离线维护再上线，该过程并不影响整个集群的运行。常见的就是2个节点做 成的HA集群，有很多通俗的不科学的名称，比如”双机热备”, “双机互备”, “双机”，高可用集群解决的是保障用户的应用程序持续对外提供服 务的能力。 负载均衡集群(Load Balance Cluster)：负载均衡集群运行时一般通过一个或者多个前端负载均衡器将工作负载分发到后端的一组服务器上，从而达到将工作负载分发。这样的计算机集群有时也被称为服务器群（Server Farm）。一般web服务器集群、数据库集群 和应用服务器集群都属于这种类型。这种集群可以在接到请求时，检查接受请求较少，不繁忙的服务器，并把请求转到这些服务器 上。从检查其他服务器状态这一点上 看，负载均衡和容错集群很接近，不同之处是数量上更多。 高性能计算集群(High Performance Computing Cluster/HPC)：高性能计算集群采用将计算任务分配到集群的不同计算节点而提高计算能力，因而主要应用在科学计算领域。这类集群致力于提供单个计算机所不能提供的强大的计算能力 Tomcat集群配置的优缺点：通常配置tomcat集群有三种方式：使用DNS轮询，使用apache r-proxy代理方式，使用apache mod_jk方式。（1）DNS轮询的缺点：当集群中某台服务器停止之后，用户由于dns缓存的缘故，便无法访问服务，必 须等到dns解析更新，或者这台服务器重新启动。还有就是必须把集群中的所有服务端口暴露给外界，没有用apache做前置代理的方式安全，并 且占用大量公网IP地址，而且tomcat还要负责处理静态网页资源，影响效率。优点是集群配置最简单，dns设置也非常简单。（2）R- proxy的缺点：当其中一台tomcat停止运行的时候，apache仍然会转发请求过去，导致502网关错误。但是只要服务器再启动就不存 在这个问题。（3）mod_jk方式的优点是，Apache 会自动检测到停止掉的tomcat，然后不再发请求过去。缺点就是，当停 止掉的tomcat服务器再次启动的时候，Apache检测不到，仍然不会转发请求过去。R-proxy和mod_jk的共同优点是.可 以只将Apache置于公网，节省公网IP地址资源。可以通过设置来实现Apache专门负责处理静态网页，让Tomcat专门负责处理jsp和 servlet等动态请求。共同缺点是：如果前置Apache代理服务器停止运行，所有集群服务将无法对外提供。R-proxy和 mod_jk对静态页面请求的处理，都可以通设置来选取一个尽可能优化的效果。这三种方式对实现最佳负载均衡都有一定不足，mod_jk相对好些，可以通过设置lbfactor参数来分配请求任务。2）Apache安装12345678910111213141516171819202122232425#下载安装包wget http://mirrors.hust.edu.cn/apache//httpd/httpd-2.4.33.tar.gzwget http://archive.apache.org/dist/apr/apr-1.4.5.tar.gzwget http://archive.apache.org/dist/apr/apr-util-1.3.12.tar.gzwget http://jaist.dl.sourceforge.net/project/pcre/pcre/8.10/pcre-8.42.zip#apr安装tar -zxf apr-1.4.5.tar.gz cd apr-1.4.5 ./configure --prefix=/usr/local/apr make &amp;&amp; make install #apr-util安装tar -zxf apr-util-1.3.12.tar.gz cd apr-util-1.3.12 ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr/bin/apr-1-config make &amp;&amp; make install#pcre安装unzip -o pcre-8.42.zip cd pcre-8.42./configure --prefix=/usr/local/pcre make &amp;&amp; make install #apache安装tar -zxvf httpd-2.4.33.tar.gzcd httpd-2.4.33./configure --prefix=/data/apache --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util --with-pcre=/usr/local/pcremake &amp;&amp; make install 在apache安装过程中会有报错：差找不到文件apr_escape.h由于centos7默认是使用的是xfs的硬盘格式，在安装apr的时候由于automake编译根据硬盘格式会默认系统不需要这个文件，如果是其他硬盘格式，比如：ext3、ext4，则不会出现这个问题。解决方法：从apache官网上查找该文件源码，并放入apr的include/apr-1内，本次环境apr的目录为：/usr/local/apr/include/apr-1以下为apr_escape.h文件的源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374/* Licensed to the Apache Software Foundation (ASF) under one or more* contributor license agreements. See the NOTICE file distributed with* this work for additional information regarding copyright ownership.* The ASF licenses this file to You under the Apache License, Version 2.0* (the "License"); you may not use this file except in compliance with* the License. You may obtain a copy of the License at** http://www.apache.org/licenses/LICENSE-2.0** Unless required by applicable law or agreed to in writing, software* distributed under the License is distributed on an "AS IS" BASIS,* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.* See the License for the specific language governing permissions and* limitations under the License.*//*** @file apr_escape.h* @brief APR-UTIL Escaping*/#ifndef APR_ESCAPE_H#define APR_ESCAPE_H#include "apr.h"#include "apr_general.h"#ifdef __cplusplusextern "C" &#123;#endif/*** @defgroup APR_Util_Escaping Escape functions* @ingroup APR* @&#123;*//* Simple escape/unescape functions.**//*** When passing a string to one of the escape functions, this value can be* passed to indicate a string-valued key, and have the length computed* automatically.*/#define APR_ESCAPE_STRING (-1)/*** Perform shell escaping on the provided string.** Shell escaping causes characters to be prefixed with a '\' character.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_shell(char *escaped, const char *str,apr_ssize_t slen, apr_size_t *len);/*** Perform shell escaping on the provided string, returning the result* from the pool.** Shell escaping causes characters to be prefixed with a '\' character.** If no characters were escaped, the original string is returned.* @param p Pool to allocate from* @param str The original string* @return the encoded string, allocated from the pool, or the original* string if no escaping took place or the string was NULL.*/APR_DECLARE(const char *) apr_pescape_shell(apr_pool_t *p, const char *str)__attribute__((nonnull(1)));/*** Unescapes a URL, leaving reserved characters intact.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param url String to be unescaped* @param slen The length of the original url, or APR_ESCAPE_STRING* @param forbid Optional list of forbidden characters, in addition to* 0x00* @param reserved Optional list of reserved characters that will be* left unescaped* @param plus If non zero, '+' is converted to ' ' as per* application/x-www-form-urlencoded encoding* @param len If set, the length of the escaped string will be returned* @return APR_SUCCESS on success, APR_NOTFOUND if no characters are* decoded or the string is NULL, APR_EINVAL if a bad escape sequence is* found, APR_BADCH if a character on the forbid list is found.*/APR_DECLARE(apr_status_t) apr_unescape_url(char *escaped, const char *url,apr_ssize_t slen, const char *forbid, const char *reserved, int plus,apr_size_t *len);/*** Unescapes a URL, leaving reserved characters intact, returning the* result from a pool.* @param p Pool to allocate from* @param url String to be unescaped in place* @param forbid Optional list of forbidden characters, in addition to* 0x00* @param reserved Optional list of reserved characters that will be* left unescaped* @param plus If non zero, '+' is converted to ' ' as per* application/x-www-form-urlencoded encoding* @return A string allocated from the pool on success, the original string* if no characters are decoded, or NULL if a bad escape sequence is found* or if a character on the forbid list is found, or if the original string* was NULL.*/APR_DECLARE(const char *) apr_punescape_url(apr_pool_t *p, const char *url,const char *forbid, const char *reserved, int plus)__attribute__((nonnull(1)));/*** Escape a path segment, as defined in RFC1808.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_path_segment(char *escaped,const char *str, apr_ssize_t slen, apr_size_t *len);/*** Escape a path segment, as defined in RFC1808, returning the result from a* pool.* @param p Pool to allocate from* @param str String to be escaped* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_pescape_path_segment(apr_pool_t *p,const char *str) __attribute__((nonnull(1)));/*** Converts an OS path to a URL, in an OS dependent way, as defined in RFC1808.* In all cases if a ':' occurs before the first '/' in the URL, the URL should* be prefixed with "./" (or the ':' escaped). In the case of Unix, this means* leaving '/' alone, but otherwise doing what escape_path_segment() does. For* efficiency reasons, we don't use escape_path_segment(), which is provided for* reference. Again, RFC 1808 is where this stuff is defined.** If partial is set, os_escape_path() assumes that the path will be appended to* something with a '/' in it (and thus does not prefix "./").* @param escaped Optional buffer to write the encoded string, can be* NULL* @param path The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param partial If non zero, suppresses the prepending of "./"* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or if the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_path(char *escaped, const char *path,apr_ssize_t slen, int partial, apr_size_t *len);/*** Converts an OS path to a URL, in an OS dependent way, as defined in RFC1808,* returning the result from a pool.** In all cases if a ':' occurs before the first '/' in the URL, the URL should* be prefixed with "./" (or the ':' escaped). In the case of Unix, this means* leaving '/' alone, but otherwise doing what escape_path_segment() does. For* efficiency reasons, we don't use escape_path_segment(), which is provided for* reference. Again, RFC 1808 is where this stuff is defined.** If partial is set, os_escape_path() assumes that the path will be appended to* something with a '/' in it (and thus does not prefix "./").* @param p Pool to allocate from* @param str The original string* @param partial If non zero, suppresses the prepending of "./"* @return A string allocated from the pool on success, the original string* if no characters are encoded or if the string was NULL.*/APR_DECLARE(const char *) apr_pescape_path(apr_pool_t *p, const char *str,int partial) __attribute__((nonnull(1)));/*** Urlencode a string, as defined in* http://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.1.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or if the stirng was NULL*/APR_DECLARE(apr_status_t) apr_escape_urlencoded(char *escaped, const char *str,apr_ssize_t slen, apr_size_t *len);/*** Urlencode a string, as defined in* http://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.1, returning* the result from a pool.* @param p Pool to allocate from* @param str String to be escaped* @return A string allocated from the pool on success, the original string* if no characters are encoded or if the string was NULL.*/APR_DECLARE(const char *) apr_pescape_urlencoded(apr_pool_t *p,const char *str) __attribute__((nonnull(1)));/*** Apply entity encoding to a string. Characters are replaced as follows:* '&lt;' becomes '&amp;lt;', '&gt;' becomes '&amp;gt;', '&amp;' becomes '&amp;amp;', the* double quote becomes '&amp;quot;" and the single quote becomes '&amp;apos;'.** If toasc is not zero, any non ascii character will be encoded as* '%\#ddd;', where ddd is the decimal code of the character.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param toasc If non zero, encode non ascii characters* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_entity(char *escaped, const char *str,apr_ssize_t slen, int toasc, apr_size_t *len);/*** Apply entity encoding to a string, returning the result from a pool.* Characters are replaced as follows: '&lt;' becomes '&amp;lt;', '&gt;' becomes* '&amp;gt;', '&amp;' becomes '&amp;amp;', the double quote becomes '&amp;quot;" and the* single quote becomes '&amp;apos;'.* @param p Pool to allocate from* @param str The original string* @param toasc If non zero, encode non ascii characters* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_pescape_entity(apr_pool_t *p, const char *str,int toasc) __attribute__((nonnull(1)));/*** Decodes html entities or numeric character references in a string. If* the string to be unescaped is syntactically incorrect, then the* following fixups will be made:* unknown entities will be left undecoded;* references to unused numeric characters will be deleted.* In particular, &amp;#00; will not be decoded, but will be deleted.* @param unescaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_unescape_entity(char *unescaped, const char *str,apr_ssize_t slen, apr_size_t *len);/*** Decodes html entities or numeric character references in a string. If* the string to be unescaped is syntactically incorrect, then the* following fixups will be made:* unknown entities will be left undecoded;* references to unused numeric characters will be deleted.* In particular, &amp;#00; will not be decoded, but will be deleted.* @param p Pool to allocate from* @param str The original string* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_punescape_entity(apr_pool_t *p, const char *str)__attribute__((nonnull(1)));/*** Escape control characters in a string, as performed by the shell's* 'echo' command. Characters are replaced as follows:* \\a alert (bell), \\b backspace, \\f form feed, \\n new line, \\r carriage* return, \\t horizontal tab, \\v vertical tab, \\ backslash.** Any non ascii character will be encoded as '\\xHH', where HH is the hex* code of the character.** If quote is not zero, the double quote character will also be escaped.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param quote If non zero, encode double quotes* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_echo(char *escaped, const char *str,apr_ssize_t slen, int quote, apr_size_t *len);/*** Escape control characters in a string, as performed by the shell's* 'echo' command, and return the results from a pool. Characters are* replaced as follows: \\a alert (bell), \\b backspace, \\f form feed,* \\n new line, \\r carriage return, \\t horizontal tab, \\v vertical tab,* \\ backslash.** Any non ascii character will be encoded as '\\xHH', where HH is the hex* code of the character.** If quote is not zero, the double quote character will also be escaped.* @param p Pool to allocate from* @param str The original string* @param quote If non zero, encode double quotes* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_pescape_echo(apr_pool_t *p, const char *str,int quote);/*** Convert binary data to a hex encoding.* @param dest The destination buffer, can be NULL* @param src The original buffer* @param srclen The length of the original buffer* @param colon If not zero, insert colon characters between hex digits.* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_hex(char *dest, const void *src,apr_size_t srclen, int colon, apr_size_t *len);/*** Convert binary data to a hex encoding, and return the results from a* pool.* @param p Pool to allocate from* @param src The original buffer* @param slen The length of the original buffer* @param colon If not zero, insert colon characters between hex digits.* @return A zero padded buffer allocated from the pool on success, or* NULL if src was NULL.*/APR_DECLARE(const char *) apr_pescape_hex(apr_pool_t *p, const void *src,apr_size_t slen, int colon) __attribute__((nonnull(1)));/*** Convert hex encoded string to binary data.* @param dest The destination buffer, can be NULL* @param str The original buffer* @param slen The length of the original buffer* @param colon If not zero, ignore colon characters between hex digits.* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if the string was NULL, or APR_BADCH* if a non hex character is present.*/APR_DECLARE(apr_status_t) apr_unescape_hex(void *dest, const char *str,apr_ssize_t slen, int colon, apr_size_t *len);/*** Convert hex encoding to binary data, and return the results from a pool.* If the colon character appears between pairs of hex digits, it will be* ignored.* @param p Pool to allocate from* @param str The original string* @param colon If not zero, ignore colon characters between hex digits.* @param len If present, returns the length of the final buffer* @return A buffer allocated from the pool on success, or NULL if src was* NULL, or a bad character was present.*/APR_DECLARE(const void *) apr_punescape_hex(apr_pool_t *p, const char *str,int colon, apr_size_t *len);/** @&#125; */#ifdef __cplusplus&#125;#endif#endif /* !APR_ESCAPE_H */ 由于Apache和Nginx同台安装，所以修改Apache的端口为88，配置ServerName启动apache1./bin/apachectl start 访问apache服务器：http://ip:88响应结果：It works！ #apache服务器安装成功 3）Tomcat安装配置同一服务器部署多个tomcat时，存在端口号冲突的问题，所以需要修改tomcat配置文件server.xml：首先了解下tomcat的几个主要端口：123456&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="60000" redirectPort="8443" disableUploadTimeout="false" executor="tomcatThreadPool" URIEncoding="UTF-8"/&gt;#其中8080为HTTP端口，8443为HTTPS端口&lt;Server port="8005" shutdown="SHUTDOWN"&gt; #8005为远程停服务端口&lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; #8009为AJP端口，APACHE能过AJP协议访问TOMCAT的8009端口。 部署多个tomcat主要修改三个端口：第一个tomcat配置server.xml如下：123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8006" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8081" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8010" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat1"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8006、8081、8010第二个tomcat配置server.xml如下：123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8007" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8082" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8011" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat2"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8007、8082、8011如果需要更多的tomcat做负载，端口号依次增加即可。tomcat1测试http://ip:8081tomcat2 测试http://ip:8082结果：显示tomcat首页 4）集群配置创建mod_jk.so文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142#下载wget http://archive.apache.org/dist/tomcat/tomcat-connectors/jk/tomcat-connectors-1.2.41-src.tar.gztar -zxvf tomcat-connectors-1.2.41-src.tar.gz cd tomcat-connectors-1.2.41-srccd native/#进行编译，生成文件，但是不需要make install./configure --with-apxs=/data/apache/bin/apxsmakecd apache-2.0/#拷贝到apache目录下cp mod_jk.so /data/apache/modules//data/apache/modules/在httpd.conf中加入配置Include conf/mod_jk.conf/data/apache/conf下创建mod_jk.conf文件，文件内容为#mod_jk 配置mod_jk包 LoadModule jk_module modules/mod_jk.so #workers 配置工作负责文件 JkWorkersFile conf/workers.properties #jk log 配置jk日志文件 JkLogFile logs/mod_jk.log #jk log leve 配置日志级别 JkLogLevel info #配置jk日志内存共享 JkShmFile logs/mod_jk.shm #balancer 配置负载均衡模式 JkMount /*.jsp balancer 在/data/apache/conf下创建workers.properties文件，文件内容为#tomcat1的配置 worker.tomcat1.port=8010worker.tomcat1.host=127.0.0.1worker.tomcat1.reference=worker.template worker.tomcat1.activation=A #worker.tomcat1.lbfactor=1 #tomcat2 的配置 worker.tomcat2.port=8011 worker.tomcat2.host=127.0.0.1worker.tomcat2.reference=worker.template worker.tomcat2.activation=A #worker.tomcat2.lbfactor=1 worker.list=balancer #balancer 负载配置 worker.balancer.type=lb worker.balancer.balance_workers=tomcat1,tomcat2 worker.balancer.sticky_session=1 #tempalte 负载模板配置 worker.template.type=ajp13``` 重启apache、tomcat1、tomcat2验证，可以访问apache地址http://ip:88/testjsp.jsp，可以看到不同的客户端或刷新后显示的可以是tomcat1，也可以是tomcat2，验证成功。#### 5）Session复制在Tomcat集群中实现session同步，可以通过session共享和复制来实现，下面以session复制来实现session同步。Session复制需要修改server.xml配置Tomcat1中在&lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat1"&gt;后面加上以下配置```bash&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" #默认为auto，改为自己的IP port="4001" #同一台服务器上的tomcat必须修改为不同的端口，tomcat1修改为4001，tomcat2修改为4002。 autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt;``` Tomcat2中在&lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat1"&gt;后面加上以下配置```bash &lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" #默认为auto，改为自己的IP port="4002" #同一台服务器上的tomcat必须修改为不同的端口，tomcat1修改为4001，tomcat2修改为4002。 autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt; ``` 在集群中所有tomcat的应用项目中web.xml中的配置 ：在WEB-INF/web.xml中加入以下内容```bash&lt;!--此应用将与群集服务器复制Session--&gt; &lt;distributable/&gt;]]></content>
      <categories>
        <category>OS</category>
        <category>Service</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx+lua组建基础waf防火墙]]></title>
    <url>%2F2018%2F12%2F10%2Fnginx-lua%E7%BB%84%E5%BB%BA%E5%9F%BA%E7%A1%80waf%E9%98%B2%E7%81%AB%E5%A2%99%2F</url>
    <content type="text"><![CDATA[一、nginx+Lua环境部署1、系统基础信息123456# ifconfig eth0|grep 'inet addr'|awk -F ":" '&#123;print $2&#125;'|awk '&#123;print $1&#125;'192.168.83.129# cat /etc/redhat-releaseCentOS release 6.5 (Final)# uname -r2.6.32-431.el6.x86_64 2、安装基础库12yum -y install gcc gcc-c++yum -y install openssl openssl-devel 3、创建Nginx运行的普通用户1useradd -s /sbin/nologin -M www 4、下载需要的程序并安装123456789cd /usr/local/src/wget http://nginx.org/download/nginx-1.9.4.tar.gzwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.38.tar.gzwget -c http://luajit.org/download/LuaJIT-2.0.4.tar.gzwget https://github.com/simpl/ngx_devel_kit/archive/v0.2.19.tar.gzwget https://github.com/openresty/lua-nginx-module/archive/v0.9.16.tar.gztar zxvf ngx_devel_kit-0.2.19.tar.gztar zxvf lua-nginx-module-0.9.16.tar.gztar zxvf pcre-8.38.tar.gz 5、安装LuaJIT Luajit是Lua即时编译器123tar zxvf LuaJIT-2.0.4.tar.gzcd /usr/local/src/LuaJIT-2.0.4make &amp;&amp; make install 6、安装nginx并加载模块123456cd nginx-1.9.4/export LUAJIT_LIB=/usr/local/libexport LUAJIT_INC=/usr/local/include/luajit-2.0/./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-http_stub_status_module --with-file-aio --with-http_dav_module --add-module=../ngx_devel_kit-0.2.19/ --add-module=../lua-nginx-module-0.9.16/ --with-pcre=/usr/local/src/pcre-8.38/make -j2 &amp;&amp; make installln -s /usr/local/lib/libluajit-5.1.so.2 /lib64/libluajit-5.1.so.2 安装完毕后，下面可以测试安装了，修改nginx.conf 增加第一个配置123456789101112131415161718 server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location /hello &#123; default_type 'text/plain'; content_by_lua 'ngx.say("hello,lua")'; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 启动nginx1234/usr/local/nginx/sbin/nginx -t nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful/usr/local/nginx/sbin/nginx 7、测试看lua环境是否正常 二、openresty实现WAF功能1、系统基础信息123456# ifconfig eth0|grep 'inet addr'|awk -F ":" '&#123;print $2&#125;'|awk '&#123;print $1&#125;'192.168.83.129# cat /etc/redhat-releaseCentOS release 6.5 (Final)# uname -r2.6.32-431.el6.x86_64 2、安装基础依赖包1yum install -y readline-devel pcre-devel openssl-devel 3、下载并编译安装openresty1234567cd /usr/local/src/wget https://openresty.org/download/ngx_openresty-1.9.3.2.tar.gztar zxvf ngx_openresty-1.9.3.2.tar.gzcd ngx_openresty-1.9.3.2./configure --prefix=/usr/local/openresty-1.9.3.2 --with-luajit --with-http_stub_status_module --with-pcre --with-pcre-jitgmake &amp;&amp; gmake installln -s /usr/local/openresty-1.9.3.2/ /usr/local/openresty 4、测试openresty安装12345678910111213# vim /usr/local/openresty/nginx/conf/nginx.conf server &#123; location /hello &#123; default_type text/html; content_by_lua_block &#123; ngx.say("HelloWorld") &#125; &#125; &#125;# /usr/local/openresty/nginx/sbin/nginx -t nginx: the configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf test is successful# /usr/local/openresty/nginx/sbin/nginx 5、WAF部署：在github上克隆下代码123yum -y install gitcd /usr/local/openresty/nginx/conf/git clone https://github.com/unixhot/waf.git 6、修改Nginx的配置文件，加入（http字段）以下配置。注意路径，同时WAF日志默认存放在/tmp/日期_waf.log12345678910111213# vim /usr/local/openresty/nginx/conf/nginx.conf http &#123; include mime.types; default_type application/octet-stream; #WAF lua_shared_dict limit 50m; lua_package_path "/usr/local/openresty/nginx/conf/waf/?.lua"; init_by_lua_file "/usr/local/openresty/nginx/conf/waf/init.lua"; access_by_lua_file "/usr/local/openresty/nginx/conf/waf/access.lua";# /usr/local/openresty/nginx/sbin/nginx -t nginx: the configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf test is successful# /usr/local/openresty/nginx/sbin/nginx -s reload 7、根据日志记录位置，创建日志目录12# mkdir /tmp/waf_logs# chown www.www /tmp/waf_logs 8、配置信息与注释1234567891011121314151617181920212223242526272829303132333435363738394041424344# cat /usr/local/openresty/nginx/conf/waf/config.lua--WAF config file,enable = "on",disable = "off" --waf status config_waf_enable = "on" #是否开启配置 --log dir config_log_dir = "/tmp/waf_logs" #日志记录地址 --rule setting config_rule_dir = "/usr/local/nginx/conf/waf/rule-config" #匹配规则缩放地址 --enable/disable white url config_white_url_check = "on" #是否开启url检测 --enable/disable white ip config_white_ip_check = "on" #是否开启IP白名单检测 --enable/disable block ip config_black_ip_check = "on" #是否开启ip黑名单检测 --enable/disable url filtering config_url_check = "on" #是否开启url过滤 --enalbe/disable url args filtering config_url_args_check = "on" #是否开启参数检测 --enable/disable user agent filtering config_user_agent_check = "on" #是否开启ua检测 --enable/disable cookie deny filtering config_cookie_check = "on" #是否开启cookie检测 --enable/disable cc filtering config_cc_check = "on" #是否开启防cc攻击 --cc rate the xxx of xxx seconds config_cc_rate = "10/60" #允许一个ip60秒内只能访问10此 --enable/disable post filtering config_post_check = "on" #是否开启post检测 --config waf output redirect/html config_waf_output = "html" #action一个html页面，也可以选择跳转 --if config_waf_output ,setting url config_waf_redirect_url = "http://www.baidu.com" config_output_html=[[ #下面是html的内容 &lt;html&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt; &lt;meta http-equiv="Content-Language" content="zh-cn" /&gt; &lt;title&gt;网站防火墙&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1 align="center"&gt; # 您的行为已违反本网站相关规定，注意操作规范。 &lt;/body&gt; &lt;/html&gt; ]] 三、启用waf并做测试1、模拟sql注入即url攻击日志显示如下,记录了UA，匹配规则，URL，客户端类型，攻击的类型，请求的数据12# tail -f /tmp/2018-07-30_waf.log&#123;"user_agent":"Mozilla\/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/67.0.3396.99 Safari\/537.36","rule_tag":"\\.(bak|inc|old|mdb|sql|backup|java|class|tgz|gz|tar|zip)$","req_url":"\/eastmonet.sql","client_ip":"192.168.83.1","local_time":"2018-07-30 10:46:52","attack_method":"Deny_URL","req_data":"-","server_name":"localhost"&#125; 2、使用ab压力测试工具模拟防CC攻击12# ifconfig eth0|grep 'inet addr'|awk -F ":" '&#123;print $2&#125;'|awk '&#123;print $1&#125;'192.168.83.131 将对方IP放入黑名单12# echo 192.168.83.131 &gt;&gt; /usr/local/openresty/nginx/conf/waf/rule-config/blackip.rule# /usr/local/openresty/nginx/sbin/nginx -s reload 再拿192.168.83.131访问的时候就提示403了将对方IP放入白名单12[root@tiejiang-src1 ~]# echo 192.168.83.131 &gt;&gt; /usr/local/openresty/nginx/conf/waf/rule-config/whiteip.rule[root@tiejiang-src1 ~]# /usr/local/openresty/nginx/sbin/nginx -s reload 此时将不对此ip进行任何防护措施，所以sql注入时应该返回404目录： waf目录：/usr/local/openresty/nginx/conf/waf 配置文件：/usr/local/openresty/nginx/conf/waf/config.lua Waf的ip黑名单：/usr/local/openresty/nginx/conf/waf/rule-config/blackip.rule Waf的ip白名单：/usr/local/openresty/nginx/conf/waf/rule-config/whiteip.rule]]></content>
      <categories>
        <category>OS</category>
        <category>Service</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Nginx</tag>
        <tag>lua</tag>
        <tag>waf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7升级python版本]]></title>
    <url>%2F2018%2F12%2F10%2FCentOS7%E5%8D%87%E7%BA%A7python%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[centos7.4中默认python默认安装版本为2.7.*。12345# pythonPython 2.7.5 (default, Oct 30 2018, 23:45:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux2Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; quit() 但是随着python3的成熟，生产需要需要使用python3版本进行支持，以下升级安装3.*版本python。 1、python3安装python官网地址：https://www.python.org/查看python的各个支持版本的最新版，本次开发需求为python3.6版本，官网最新3.6版本为3.6.6版本。首先安装编译模块支持yum -y install zlib*其他在安装过程中提示需要的模块请自行安装。下载、安装1234567wget https://www.python.org/ftp/python/3.6.6/Python-3.6.6.tgztar -zxvf Python-3.6.6.tgzmkdir /data/pythoncd Python-3.6.6./configure --prefix=/data/pythonmakemake install 安装检查1234567# /data/python/bin/python3Python 3.6.6 (default, Aug 10 2018, 16:26:38) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; quit()# /data/python/bin/pip3 -Vpip 10.0.1 from /data/python/lib/python3.6/site-packages/pip (python 3.6) 可以看到安装的python版本为3.6.6，pip版本为10.0.1。 2、环境配置为了符合代码习惯制作软连接12ln -s /data/python/bin/python3.6 /usr/bin/python3ln -s /data/python/bin/pip3 /usr/bin/pip3 再次验证1234567891011# python3Python 3.6.6 (default, Aug 10 2018, 16:26:38) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; print("hello world")hello world&gt;&gt;&gt; quit()# pip3 -Vpip 10.0.1 from /data/python/lib/python3.6/site-packages/pip (python 3.6)# whereis python3python3: /usr/bin/python3 查看/usr/bin/下python版本123456# ll /usr/bin/py*-rwxr-xr-x. 1 root root 78 Aug 4 2017 /usr/bin/pydoclrwxrwxrwx 1 root root 24 Aug 10 16:55 /usr/bin/python -&gt; /data/python/bin/python3lrwxrwxrwx. 1 root root 9 Oct 15 2017 /usr/bin/python2 -&gt; python2.7-rwxr-xr-x. 1 root root 7136 Aug 4 2017 /usr/bin/python2.7lrwxrwxrwx 1 root root 26 Aug 10 16:33 /usr/bin/python3 -&gt; /data/python/bin/python3.6 可以看到同时存在两个版本，python2.7和python3.6。不建议将python3直接软连接到/usr/bin/python，因为可能影响yum使用。可以在代码中头文件中说明调用/usr/bin/python3。 3、单版本配置同上述步骤，在配置软连接1ln -s /data/python/bin/python3.6 /usr/bin/python 查看/usr/bin/1234567ll /usr/bin/py*-rwxr-xr-x. 1 root root 78 Aug 4 2017 /usr/bin/pydoclrwxrwxrwx 1 root root 30 Aug 6 18:24 /usr/bin/python -&gt; /data/python/bin/python3lrwxrwxrwx. 1 root root 9 Oct 15 2017 /usr/bin/python2 -&gt; python2.7-rwxr-xr-x. 1 root root 7136 Aug 4 2017 /usr/bin/python2.7lrwxrwxrwx 1 root root 26 Aug 6 14:01 /usr/bin/python3 -&gt; /data/python/bin/python3.6lrwxrwxrwx. 1 root root 7 Oct 15 2017 /usr/bin/python.bak -&gt; python2 此时，系统默认python版本即为python3.6.6。需要注意的是，由于系统默认python版本更换，需要更改之前使用python2的应用配置，比如yum等。]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK6.3+head插件安装配置]]></title>
    <url>%2F2018%2F12%2F10%2FELK6-3-head%E6%8F%92%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[一、前言1、为什么用ELK一般我们需要进行日志分析场景：直接在日志文件中 grep、awk 就可以获得自己想要的信息。但在规模较大的场景中，此方法效率低下，面临问题包括日志量太大如何归档、文本搜索太慢怎么办、如何多维度查询。需要集中化的日志管理，所有服务器上的日志收集汇总。常见解决思路是建立集中式日志收集系统，将所有节点上的日志统一收集，管理，访问。一般大型系统是一个分布式部署的架构，不同的服务模块部署在不同的服务器上，问题出现时，大部分情况需要根据问题暴露的关键信息，定位到具体的服务器和服务模块，构建一套集中式日志系统，可以提高定位问题的效率。一个完整的集中式日志系统，需要包含以下几个主要特点： * 收集－能够采集多种来源的日志数据 * 传输－能够稳定的把日志数据传输到中央系统 * 存储－如何存储日志数据 * 分析－可以支持 UI 分析 * 警告－能够提供错误报告，监控机制 ELK提供了一整套解决方案，并且都是开源软件，之间互相配合使用，完美衔接，高效的满足了很多场合的应用。目前主流的一种日志系统。 2、ELK简介ELK是三个开源软件的缩写，分别表示：Elasticsearch , Logstash, Kibana , 它们都是开源软件。新增了一个FileBeat，它是一个轻量级的日志收集处理工具(Agent)，Filebeat占用资源少，适合于在各个服务器上搜集日志后传输给Logstash，官方也推荐此工具。Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。Logstash 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。Filebeat隶属于Beats。目前Beats包含四种工具：（1）Packetbeat（搜集网络流量数据）（2）Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）（3）Filebeat（搜集文件数据）（4）Winlogbeat（搜集 Windows 事件日志数据） 3、设计架构1）简单架构一般最简单的架构只用elasticsearch、logstash、kibana组成即可，如下图：logstash收集处理数据，并输出到elasticsearchelasticsearch存储日志数据kibana用于数据的检索、查询、web展示2）高可用架构随着业务、性能、稳定性等需求的增加，架构中引进filebeat和缓存机制，如下图filebeat：用于收集数据，替代logstash，在每台agent端需要部署，相比于logstash，filebeat占用更少的系统资源缓存集群：可以使用kafka或者redis，使日志的汇总处理更快速logstash集群：提高日志管道的传输速度和系统性能elasticsearch集群：存储日志数据kibana集群：提高web的访问负载能力，前端使用nginx代替这种架构中各节点使用集群替代，具有更大的负载能力和数据处理能力。 二、 安装1、环境准备修改/etc/sysctl.conf，并使之生效12345678910111213141516171819# cat /etc/sysctl.conf |grep vm.maxvm.max_map_count=262144[root@izuf63k1rfnrzs6zc1g95qz elasticsearch-head]# sysctl -p /etc/sysctl.conf net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1net.ipv6.conf.lo.disable_ipv6 = 1vm.swappiness = 0net.ipv4.neigh.default.gc_stale_time = 120net.ipv4.conf.all.rp_filter = 0net.ipv4.conf.default.rp_filter = 0net.ipv4.conf.default.arp_announce = 2net.ipv4.conf.lo.arp_announce = 2net.ipv4.conf.all.arp_announce = 2net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_syn_backlog = 1024net.ipv4.tcp_synack_retries = 2kernel.sysrq = 1vm.max_map_count = 262144 修改/etc/security/limits.conf，添加以下两行123# cat /etc/security/limits.conf |grep elasticsearchelasticsearch soft nofile 65536elasticsearch hard nofile 65536 关于网络设置和端口开放部分不再描述，使用端口可以根据自己需求修改。 2、elasticsearch安装ELK官网地址：https://www.elastic.co/Elasticsearch需要java环境支持，请自行安装。需要的安装文件自行下载，不再给予下载地址。12345678910111213141516171819# tar -zxvf elasticsearch-6.3.2.tar.gz# mv elasticsearch-6.3.2 /data/elasticsearch创建用户和用户组groupadd elasticsearch #新建elsearch组useradd elasticsearch -g elasticsearch -p elasticsearch #新建一个elsearch用户chown -R elasticsearch. elasticsearch /data/elasticsearch #对文件夹授权配置elasticsearch# cd /data/elasticsearch# cat config/elasticsearch.yml |grep -v '^#'|grep -v '^$'path.data: /data/elasticsearch/datapath.logs: /data/elasticsearch/logsbootstrap.memory_lock: falsenetwork.host: 0.0.0.0http.port: 9200http.cors.enabled: truehttp.cors.allow-origin: "*"切换用户，启动elasticsearch# su elasticsearch$ /data/elasticsearch/bin/elasticsearch -d -d是以后台进程方式启动浏览器访问，如下图表示安装成功，也可以使用curl方式访问。 3、logstash安装Logstash安装可以切换到root用户进行安装1234567891011121314151617181920212223242526# tar -zxvf logstash-6.3.2.tar.gz# mv logstash-6.3.2 /data/logstash配置logstash# cd /data/logstash/# mkdir conf.d# cat config/logstash.yml |grep -v '^$'|grep -v '^#'path.config: /data/logstash/conf.dpath.logs: /data/logstash/logs# cat conf.d/logstash_test.confinput&#123; file&#123; path =&gt;"/data/work/logs/MsgService.log" start_position=&gt;"beginning" &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "MsgService-%&#123;+YYYY.MM.dd&#125;" &#125; stdout&#123; codec=&gt;rubydebug &#125;&#125; 启动并验证1# /data/logstash/bin/logstash -f /data/logstash/conf.d/logstash_test.conf --path.data=/data/logstash/data/002 出现以下格式信息表示启动成功1234567&#123; "message" =&gt; "2018-07-19 10:18:23.431 INFO 21554 --- [tbeatExecutor-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_MSGSERVICE/172.19.254.54:23000/msgService - registration status: 204", "path" =&gt; "/data/work/logs/MsgService.log", "@timestamp" =&gt; 2018-07-26T08:43:43.081Z, "host" =&gt; "izuf63k1rfnrzs6zc1g95qz", "@version" =&gt; "1"&#125; logstash中input表示读取日志文件，filter表示过滤，output表示输出具体的语法，根据不同的日志文件配置。input、filter、output其实都是logstash的插件，根据需求我们可以安装检查和卸载插件。通过1# ./bin/logstash-plugin list 查看插件管理的命令帮助。常用的命令有1234bin/logstash-plugin list #查看已安装插件列表bin/logstash-plugin install plugin_name #安装插件bin/logstash-plugin update plugin_name #卸载插件bin/logstash-plugin uninstall plugin_name #卸载插件 通过list命令查看插件列表时候，无非下列四种类型的插件： * logstash-codec-* #编码解码插件 * logstash-filter-* #数据处理插件 * logstash-input-* #输入插件 * logstash-output-* #输出插件 此处需要完善一个概念：Logstash 不只是一个input | filter | output 的数据流，而是一个 input | decode | filter | encode | output 的数据流！上面插件中的codec 就是用来 decode、encode 事件的。启动语句中–path.data表示指定目录，为了实现多实例启动，在配置文件中可以不配置path.data参数，在启动时候加上。以后台方式启动1# nohup /data/logstash/bin/logstash -f /data/logstash/conf.d/logstash_test.conf --path.data=/data/logstash/data/002 &amp; 4、安装elasticsearch-headelasticsearch-head从5.x版本以后不再依附于elasticsearch安装，作为独立进程安装。elasticsearch-head项目地址：https://github.com/mobz/elasticsearch-head#connecting-to-elasticsearchelasticsearch-head需要node环境，首先安装node，这里不贴出详细步骤。验证node版本12# node -vv8.11.3 下载安装123456789101112131415161718192021# wget https://github.com/mobz/elasticsearch-head/archive/master.zip为了后续安装phantomjs，使用bzip2解压，需要安装bzip2# yum install bzip2 -y解压到/data目录# cd /data/elasticsearch-head# npm -v5.6.0# npm install --registry=https://registry.npm.taobao.org --unsafe-perm安装过程会有点慢--registry=https://registry.npm.taobao.org表示使用国内镜像资源--unsafe-perm表示取消秘钥验证验证安装# ll ./node_modules/grunttotal 32drwxr-xr-x 2 root root 4096 Jul 26 14:03 bin-rw-r--r-- 1 root root 7111 Apr 6 2016 CHANGELOGdrwxr-xr-x 4 root root 4096 Jul 26 14:03 lib-rw-r--r-- 1 root root 1592 Mar 23 2016 LICENSEdrwxr-xr-x 4 root root 4096 Jul 26 14:03 node_modules-rw-r--r-- 1 root root 2442 Jul 26 14:03 package.json-rw-r--r-- 1 root root 878 Feb 12 2016 README.md 修改配置Gruntfile.js，增加hostname，如下图所示启动1npm run start 浏览器访问比如我们在服务器上配置，但是在本地通过外网访问elasticsearch-head，那么elasticsearch的地址不应该是elasticsearch所在服务器的内网地址，而应该是外网地址，注意对应使用的端口应该打开。elasticsearch-head是一个查看集群信息的工具，我们现在只配置一台elasticsearch，如果是多台，也可以用于查看集群内其他elasticsearch信息。查看页面表示安装成功。以后台方式运行1# nohup npm run start &amp; 5、kibana安装1234567891011解压配置# tar -zxvf kibana-6.3.2-linux-x86_64^C# mv kibana-6.3.2-linux-x86_64 /data/kibana^C# cd /data/kibana/# cat config/kibana.yml |grep -v '^#'|grep -v '^$'server.port: 80server.host: "0.0.0.0"elasticsearch.url: "http://localhost:9200"kibana.index: ".kibana"后台启动nohup /data/kibana/bin/kibana &amp; 浏览器访问后，配置index pattern，根据日志index标识不同，自己灵活掌握。 6、kibana汉化对于习惯使用英文界面的也可以不用汉化。 1）官网汉化方式ELK6.x版本提供国际化的标准，可以自己翻译汉化1、复制src/core_plugins/kibana/translations/en.json的内容，创建一个新的json文件，比如ch.json。2、翻译并修改ch.json中对应的文字。3、 在src/core_plugins/kibana/index.js文件中，找到translations，然后添加对应的内容。4、 最后在配置文件config/kibana.yml（开发模式下，创建并使用配置文件kibana.dev.yml）中，加入默认的语言设置：i18n.defaultLocale: “ch”5、 等kibana服务器重启之后，刷新页面就可以看见效果了。 2）github个人项目翻译方式项目地址：https://github.com/anbai-inc/Kibana_Hanization具体的使用方法也有介绍，但是非官方方法，具体的效果不太理想。个人认为6.x版本使用此方法汉化后会影响系统启动。 三、高级配置1、filebeat安装12345678910111213141516171819202122下载地址https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-linux-x86_64.tar.gz解压包到对应目录# tar -zxvf filebeat-6.3.2-linux-x86_64.tar.gz# mv filebeat-6.3.2-linux-x86_64 /data/filebeat修改配置文件# cat filebeat.yml |grep -v '#'|grep -v '^$'filebeat.inputs:- type: log enabled: true paths: - /data/work/logs/*.logfilebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 3setup.kibana: host: "localhost:80"#output.elasticsearch:# hosts: ["localhost:9200"]output.logstash: hosts: ["localhost:5044"] 6.x版本中filebeat，只支持一个output输出，如果把日志输出到elasticsearch，则需要把输出到logstash段配置注释。一般情况下输出到logstash，进行过滤，再由logstash输出到elasticsearch。启动1nohup ./filebeat -c filebeat.yml &amp; 同一台服务器上可以启动多个filebeat，但是需要指定不同的配置文件。 2、logstash相关配置主要配置如下123456789101112131415161718# cat /data/logstash/conf.d/logstash_test.conf input&#123; beats &#123; port =&gt; 5044 &#125; &#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "MsgService-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; Index定义日志头Logstash可以根据conf和path.data的不同启动多个进程 3、filter配置filter主要对日志进行过滤和筛选，以剔除不必要的日志，使用的方法为grok。grok中配置macth来匹配日志，使用正则表达式。相关正则表达式字段可以查看github：https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns匹配的验证测试可以使用以下地址：https://grokconstructor.appspot.com/do/matchhttp://grokdebug.herokuapp.com/个人体验，推荐使用第一个地址，需要使用科学上网。实例： 1、匹配nginx access的日志nginx中access日志的模式配置为123log_format main '$remote_addr $remote_user $time_local $request ' '$http_referer $status $body_bytes_sent $request_body ' '"$http_user_agent" "$http_x_forwarded_for"'; 验证匹配字段其中第一个框内为nginx access的日志第二个框内为匹配准则，准则的大写字段是从github地址上查找得到，小写字段为自定义执行，得到如下所示可以看到匹配完成，match即为匹配准则，日志中不重要的部分可以不进行匹配。将match写入logstash配置文件1234567891011121314151617181920212223242526272829303132# cat conf.d/nginx_access_log.conf input&#123; beats &#123; port =&gt; 5055 &#125; &#125;filter &#123; grok &#123; match =&gt; ["message","%&#123;IP:clientip&#125; %&#123;USER:user&#125; %&#123;HTTPDATE:timestamp&#125; %&#123;WORD:request_method&#125; %&#123;URIPATHPARAM:uri&#125; HTTP/%&#123;NUMBER:httpversion&#125; (?:%&#123;URI:referrer&#125;|-) %&#123;NUMBER:status:int&#125; %&#123;NUMBER:body_bytes_sent:int&#125; "] &#125; # if [loglevel] == "DEBUG" &#123;# drop &#123;&#125;# &#125; if [uri] == "/" &#123; drop &#123;&#125; &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "nginx_access_log-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; drop是跟字段匹配进行过滤，过滤掉的日志将不会再进行output。此处drop掉的是slb的检测访问的日志，即非业务的日志。需要注意的是：对message进行匹配，后面的准测内不允许使用多个””，所以在nginx的配置文件内需要修改日志格式的相关字段，不要加双引号。 2、匹配nodejs的日志验证执行，查看结果关于每条日志的记录的行为的相应时间是没有进行匹配的，所以出现在after match处。写入logstash配置1234567891011121314151617181920212223242526272829303132# cat conf.d/nodejs_log.conf input&#123; beats &#123; port =&gt; 5077 &#125; &#125;filter &#123; grok &#123; match =&gt; ["message","logger: %&#123;TIMESTAMP_ISO8601:time&#125; %&#123;WORD:request_method&#125; %&#123;URIPATHPARAM:uri&#125; %&#123;NUMBER:status:int&#125; %&#123;NUMBER:body_bytes_sent:int&#125; "] &#125; # if [loglevel] == "DEBUG" &#123;# drop &#123;&#125;# &#125;# if [uri] == "/" &#123;# drop &#123;&#125;# &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "nodejs_log-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; 以上配置是没有对日志进行drop操作的，日志是否需要进行drop根据实际情况操作。 3、匹配java的日志java是世界上最不友好的语言，反正我就是这么认为！java的日志格式不像web应用暴露的日志一样格式规范，所以很难匹配。如下所示after match部分毫无规律，不知道这是什么玩意儿，就不匹配了，够用就行。添加logstash配置123456789101112131415161718192021222324252627282930313233# cat conf.d/springcloud_log.conf input&#123; beats &#123; port =&gt; 5044 &#125; &#125;filter &#123; grok &#123; match =&gt; ["message","%&#123;TIMESTAMP_ISO8601:datestamp&#125; *%&#123;LOGLEVEL:loglevel&#125; %&#123;INT:digital&#125; *"] &#125; # if [loglevel] == "DEBUG" &#123;# drop &#123;&#125;# &#125; if [loglevel] == "INFO" &#123; drop &#123;&#125; &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "springcloud_log-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; 此处drop的为类型是INFO的日志。 4、其他配置关于elasticsearch和kibana的配置不用调整。]]></content>
      <categories>
        <category>Monitor</category>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>日志</tag>
        <tag>head</tag>
        <tag>ELK</tag>
        <tag>Elasticsearch</tag>
        <tag>Logstash</tag>
        <tag>Kibana</tag>
        <tag>FileBeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python购物车程序]]></title>
    <url>%2F2018%2F12%2F07%2Fshopping%2F</url>
    <content type="text"><![CDATA[程序：购物车程序需求 1、启动程序后，让用户输入工资，然后打开商品列表 2、允许用户根据商品编号购买商品 3、用户选择商品后，检测余额是否够，够就直接扣款，不够就提醒 4、可随时退出，退出时，打印已购商品和余额 code123456789101112131415161718192021222324252627282930313233343536373839# -*- coding:utf-8 -*-#Author:Francisproduct_list = [ ('Iphone',5800), ('Mac Pro',9800), ('Bike',800), ('Watch',10600), ('Coffee',31), ('Alex Python',120),]shopping_list = []salary = input("Input your salary:")if salary.isdigit(): salary = int(salary) while True: for index,item in enumerate(product_list): #print(product_list.index(item),item) print(index,item) user_choice = input("选择要买嘛？&gt;&gt;&gt;:") if user_choice.isdigit(): user_choice = int(user_choice) if user_choice &lt; len(product_list) and user_choice &gt;=0: p_item = product_list[user_choice] if p_item[1] &lt;= salary: #买的起 shopping_list.append(p_item) salary -= p_item[1] print("Added %s into shopping cart,your current balance is \033[31;1m%s\033[0m" %(p_item,salary) ) else: print("\033[41;1m你的余额只剩[%s]啦，还买个毛线\033[0m" % salary) else: print("product code [%s] is not exist!"% user_choice) elif user_choice == 'q': print("--------shopping list------") for p in shopping_list: print(p) print("Your current balance:",salary) exit() else: print("invalid option")]]></content>
      <categories>
        <category>Scripts</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix监控redis]]></title>
    <url>%2F2018%2F12%2F06%2FZabbix%E7%9B%91%E6%8E%A7Redis%2F</url>
    <content type="text"><![CDATA[zabbix监控redis实例有个不方便的地方是只能监控固定的6379端口，如果是非6379端口的话，需要修改模板，如果主机有多个redis实例的话，需要具有不同的redis模板，然后在管理监控，很是麻烦，为了解决这个问题，我使用lld（low level discovery）方式监控redis，只需要你在正则表达式里把需要监控的端口标上，就可以监控redis多实例。 一、agent端配置agent端脚本，获取正在运行的redis实例端口1234567891011121314151617181920212223242526# pwd/etc/zabbix/scripts# cat redis_low_discovery.sh #!/bin/bash#Script_name redis_low_discovery.shredis() &#123;# port=($(sudo netstat -tpln | awk -F "[ :]+" '/redis/ &amp;&amp; /0.0.0.0/ &#123;print $5&#125;')) port=($(netstat -tpln | awk -F "[ :]+" '/redis/ &amp;&amp; /0.0.0.0/ &#123;print $5&#125;')) printf '&#123;\n' printf '\t"data":[\n' for key in $&#123;!port[@]&#125; do if [[ "$&#123;#port[@]&#125;" -gt 1 &amp;&amp; "$&#123;key&#125;" -ne "$(($&#123;#port[@]&#125;-1))" ]];then socket=`ps aux|grep $&#123;port[$&#123;key&#125;]&#125;|grep -v grep|awk -F '=' '&#123;print $10&#125;'|cut -d ' ' -f 1` printf '\t &#123;\n' printf "\t\t\t\"&#123;#REDISPORT&#125;\":\"$&#123;port[$&#123;key&#125;]&#125;\"&#125;,\n" else [[ "$&#123;key&#125;" -eq "(($&#123;#port[@]&#125;-1))" ]] socket=`ps aux|grep $&#123;port[$&#123;key&#125;]&#125;|grep -v grep|awk -F '=' '&#123;print $10&#125;'|cut -d ' ' -f 1` printf '\t &#123;\n' printf "\t\t\t\"&#123;#REDISPORT&#125;\":\"$&#123;port[$&#123;key&#125;]&#125;\"&#125;\n" fi done printf '\t ]\n' printf '&#125;\n'&#125;$1 验证脚本是否正常监控redis实例的json展示12345678910# ./redis_low_discovery.sh redis&#123; "data":[ &#123; "&#123;#REDISPORT&#125;":"6379"&#125; ] &#123; "&#123;#REDISPORT&#125;":"6380"&#125; ]&#125; 添加UserParameter12345# pwd/etc/zabbix/zabbix_agentd.d# cat userparameter_redis.conf UserParameter=zabbix_low_discovery[*],/bin/bash /etc/zabbix/scripts/redis_low_discovery.sh $1UserParameter=redis_stats[*],(/bin/echo info; sleep 1) | telnet 127.0.0.1 $1 2&gt;&amp;1 |grep $2|cut -d : -f2 注：zabbix_agentd.conf配置文件中吧UnsafeUserParameters=1设置为1并打开注释即可，这里我的redis示例没有设置密码，如果有密码就加上-a password，telnet对空密码可以。有密码的话telnet换成$(which redis-cli)。12UserParameter=zabbix_low_discovery[*],/bin/bash /etc/zabbix/scripts/redis/redis_low_discovery.sh $1UserParameter=redis_stats[*],(/bin/echo info; sleep 1) | /data/redis/bin/redis-cli -h 172.16.109.138 -p $1 -a 5U7pp/pQLbdGLA 2&gt;&amp;1 |grep $2|cut -d : -f2 然后重启agent即可把redis_low_discovery.sh文件存放到/etc/zabbix/scripts/目录下，然后给与755权限，并修改用户与组为zabbix，同时允许zabbix用户无密码运行1echo "zabbix ALL=(root) NOPASSWD:/bin/netstat"&gt;&gt;/etc/sudoers 关闭requiretty1sed -i 's/^Defaults.*.requiretty/#Defaults requiretty/' /etc/sudoers 二、server端配置使用zabbix_get获取redis键值123456789# zabbix_get -s 172.19.231.227 -p 10050 -k zabbix_low_discovery[redis]&#123;"data":[ &#123;"&#123;#REDISPORT&#125;":"6379"&#125;, &#123;"&#123;#REDISPORT&#125;":"6380"&#125; ]&#125; redis每秒更新时间12# zabbix_get -s 172.19.231.227 -p 10050 -k redis_stats[6381,uptime_in_seconds]8 三、web界面配置导入模板以及主机连接模板，还需要设置正则等模板在此处下载，然后导入模板，并且关联对应的主机。设置正则表达式name：Redis regexResult TRUE = ^(6380|6381)$正则表达式根据端口配置，可以增加最后把主机连接到模板上即可，默认间隔时间1小时，方便测试我改成60s，数据收集后然后改过了即可检查思路如下： 1：agent端可以使用脚步获取json化的信息 2：server端可以zabbix_get获取json化信息以及item的值注：基于以上2步骤，按理说可以获取到相应的item值了。 3：打开agent端debug模式获取更多的日志信息，日志无问题，显示过程中没有显示json化的item 4：检查redis多实例模板中自动发现规则的键值与agent端中UnsafeUserParameters中定义键值不一样，修改与模板中对应的键值一样即可，重启agent即可]]></content>
      <categories>
        <category>Monitor</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云ECS漏洞修复]]></title>
    <url>%2F2018%2F12%2F05%2F%E9%98%BF%E9%87%8C%E4%BA%91ECS%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[一、关于glibc的报警1、问题确认关于glibc的报警，具体如下所示：此处报警我们可以根据漏洞编号进行查询，可以看到是因为glibc的版本太低，具有以下上图所示两个漏洞。阿里云进行的报警的依据是根据探测ECS相关软件的版本，如下图所示： 2、解决方案上图可以看到我们需要升级的软件一共有5个，分别是glibc、glibc-common、glibc-headers、glibc-devel、nscd。rpm包可从此处下载，选择稳定版本即可。 3、升级脚本将下载、安装过程脚本话12345678910111213141516171819#!/bin/sh#Francis#切换到下载目录cd /data/backup# update glibc to 2.22 for CentOS 7wget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-common-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-headers-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-devel-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/nscd-2.22.90-21.el7.x86_64.rpmrpm -Uvh glibc-2.22.90-21.el7.x86_64.rpm \ glibc-common-2.22.90-21.el7.x86_64.rpm \ glibc-devel-2.22.90-21.el7.x86_64.rpm \ glibc-headers-2.22.90-21.el7.x86_64.rpm \ nscd-2.22.90-21.el7.x86_64.rpm \ --force --nodeps 二、关于curl的报警1、问题确认关于glibc的报警，具体如下所示：此处报警我们可以根据漏洞编号进行查询，可以看到是因为curl的版本太低，具有以下上图所示四个漏洞。阿里云进行的报警的依据是根据探测ECS相关软件的版本，如下图所示： 2、解决方案上图可以看到curl版本7.12到7.58都有漏洞，所以我们选择安装7.60以后的版本 1、编译安装123456wget https://curl.haxx.se/download/curl-7.62.0.tar.gztar -zxvf curl-7.62.0.tar.gz cd curl-7.62.0./configure --prefix=/usrmakemake install 查看curl版本1234567# curl --versioncurl 7.62.0 (x86_64-pc-linux-gnu) libcurl/7.47.1 NSS/3.21.3 Basic ECC zlib/1.2.7 libidn/1.28 libssh2/1.4.3Release-Date: 2018-10-31Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp Features: AsynchDNS IDN IPv6 Largefile GSS-API Kerberos SPNEGO NTLM NTLM_WB SSL libz UnixSockets # curl-config --versionlibcurl 7.62.0 2、yum安装查看已安装版本1234# curl --versioncurl 7.29.0 (x86_64-redhat-linux-gnu) libcurl/7.29.0 NSS/3.34 zlib/1.2.7 libidn/1.28 libssh2/1.4.3Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smtp smtps telnet tftp Features: AsynchDNS GSS-Negotiate IDN IPv6 Largefile NTLM NTLM_WB SSL libz unix-sockets 安装repo1rpm -Uvh http://www.city-fan.org/ftp/contrib/yum-repo/rhel6/x86_64/city-fan.org-release-2-1.rhel6.noarch.rpm 查看该 repo 包含的 curl 版本12345678910# yum --showduplicates list curl --disablerepo="*" --enablerepo="city*"Loaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * city-fan.org: cityfan.mirror.digitalpacific.com.au * city-fan.org-debuginfo: cityfan.mirror.digitalpacific.com.au * city-fan.org-source: cityfan.mirror.digitalpacific.com.auInstalled Packagescurl.x86_64 7.29.0-51.el7 @base Available Packagescurl.x86_64 7.62.0-1.7.cf.rhel7 city-fan.org 修改该repo的enable为1123456789101112131415vi /etc/yum.repos.d/city-fan.org.repo[city-fan.org]name=city-fan.org repository for Red Hat Enterprise Linux (and clones) $releasever ($basearch)#baseurl=http://mirror.city-fan.org/ftp/contrib/yum-repo/rhel$releasever/$basearchmirrorlist=http://mirror.city-fan.org/ftp/contrib/yum-repo/mirrorlist-rhel$releaseverenabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-city-fan.org 升级最新的curl1yum upgrade curl -y 查看版本12345# curl -Vcurl 7.62.0 (x86_64-redhat-linux-gnu) libcurl/7.62.0 NSS/3.36 zlib/1.2.7 libpsl/0.7.0 (+libicu/50.1.2) libssh2/1.8.0 nghttp2/1.31.1Release-Date: 2018-10-31Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp Features: AsynchDNS IPv6 Largefile GSS-API Kerberos SPNEGO NTLM NTLM_WB SSL libz HTTP2 UnixSockets HTTPS-proxy PSL Metalink 升级完成]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
        <tag>软件漏洞修复</tag>
        <tag>glibc</tag>
        <tag>curl</tag>
        <tag>nss-pem</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql安装]]></title>
    <url>%2F2018%2F11%2F29%2FMysql%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[一、软件部署1、MySQL安装123456789101112131415161718192021222324252627282930313233343536373839## 安装软件依赖shell&gt; yum install libaio -y## 创建用户和组shell&gt; groupadd mysqlshell&gt; useradd -r -g mysql -s /bin/false mysql## 解压软件包并创建软连接shell&gt; tar xzvf mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz -C /usr/local/shell&gt; cd /usr/local/shell&gt; ln -s mysql-5.7.22-linux-glibc2.12-x86_64 mysql## 修改软件目录权限为mysql用户shell&gt; cd /usr/local/mysqlshell&gt; chown -R mysql:mysql .## 创建数据目录权限并修改权限为mysql用户shell&gt; mkdir -p /data/mysql/&#123;data,tmp&#125;shell&gt; chown -R mysql:mysql /data/mysql/## 拷贝启动脚本至系统启动目录shell&gt; cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld## 执行数据库初始化操作shell&gt; cd /usr/local/mysqlshell&gt; bin/mysqld --initialize --user=mysql## 启动MySQLshell&gt; systemctl enable mysqldshell&gt; systemctl start mysqldshell&gt; systemctl status mysqldshell&gt; systemctl disable mysqldshell&gt; cat /data/mysql/data/mysql-error.log |grep passshell&gt; /usr/local/mysql/bin/mysql -S /data/mysql/data/mysql_3306.sock -p## 输入查看到的随机密码## 登录数据库后需先修改密码mysql&gt; set password='emhlbnhpbmcxMDA0';mysql&gt; exit; 2、配置环境变量12345shell&gt; vim ~/.bash_profile MYSQL_HOME=/usr/local/mysql PATH=$PATH:$HOME/bin:$MYSQL_HOME/binshell&gt; source ~/.bash_profileshell&gt; mysql -V 从库的搭建方式为在从库所在服务器重复步骤一和步骤二全部操作 二、复制配置1、复制用户创建12## 主库创建复制用户mysql&gt; grant replication slave on *.* to 'repl'@'%' identified by 'cmVwbGRiYQ=='; 2、配置复制同步123456789101112## 从库配置复制同步mysql&gt; change master to master_host='172.16.109.144',master_user='repl',master_password='cmVwbGRiYQ==',master_port=3306,master_auto_position=1;## 从库启动复制mysql&gt; start slave;mysql&gt; show slave status\G;mysql&gt; show processlist; 三、备份配置1、部署xtrabackup主从都需要部署，文件上传操作：略1234567891011## 解压percona-xtrabackupcd /opt/for_gongbao_mysql/tar xzvf percona-xtrabackup-2.4.9-Linux-x86_64.tar.gz## 拷贝命令至系统可执行目录cp percona-xtrabackup-2.4.9-Linux-x86_64/bin/* /usr/local/bin/rm percona-xtrabackup-2.4.9-Linux-x86_64 -rf## 拷贝qpress解压缩命令至系统可执行目录cd /opt/for_gongbao_mysql/cp qpress /usr/local/bin/ 2、配置自动化备份脚本脚本模板已上传，暂未配置 四、慢查询配置1、日志轮换脚本配置脚本模板已上传，暂未配置 2、日志格式化脚本配置脚本模板已上传，暂未配置]]></content>
      <categories>
        <category>DB</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
</search>
