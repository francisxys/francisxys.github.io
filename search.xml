<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[上传文件到Seafile]]></title>
    <url>%2Fposts%2Ffe431f56.html</url>
    <content type="text"><![CDATA[需求场景业务系统需要每天巡检，之前的方案是巡检系统生成word格式的巡检报告，并发送到邮箱。但是随着各地业务节点服务器增多，邮件也增多，每天接收很多邮件很困扰，而且邮件收到后，也需要将附件(即生成的巡检报告)上传至Seafile，所以简化化成，将巡检报告直接上传至Seafile。 具体实现生成巡检报告参考：Python系统巡检脚本 如何将文件上传至Seafile，参考Seafiel api文档首先确定Seafile上目标目录的最上层目录的repo-id，可以通过网页端在地址栏查看。本次需要上传到运维巡检目录下，repo-id为8599d561-f818-4e86-93b3-1da91d920145。查看目录的所有者，使用目录所有者账号获取Token，也可以使用自己账户新建目录，并上传。 获取Token12# curl --data-urlencode username=****** -d password=****** https://seafile.******.com/api2/auth-token/&#123;"token":"e2acc3630c05c88a9546073ae5bac6ed8aa7e980"&#125; 验证12# curl -H 'Authorization: Token e2acc3630c05c88a9546073ae5bac6ed8aa7e980' https://seafile.******.com/api2/auth/ping/"pong" 出现pong，表示使用curl方式登录验证通过。每个账户的token是不变的。示例中账号密码及seafile地址隐藏了，在使用中根据实际情况填写。 获取上传链接12# curl -H 'Authorization: Token e2acc3630c05c88a9546073ae5bac6ed8aa7e980' https://seafile.******.com/api2/repos/8599d561-f818-4e86-93b3-1da91d920145/upload-link/"https://seafile.******.com/seafhttp/upload-api/d6d70117-2124-484e-8fde-316cb6a7c30a" 此处8599d561-f818-4e86-93b3-1da91d920145即为上面提到的目标目录的repo-id。需要主要的是： 返回的url并非是不变的，在不同的服务器上返回的url不同； 并且具有时效性，即过了一段时间之后，这个url就不能用了，但是具体多少时间没有测试出来。 上传脚本12345678910111213141516171819202122232425#!/usr/bin/python# coding:utf-8#Author:Francisimport osimport subprocessimport timeimport reimport requestsdef main(): filename = "gbj_ls_checkos_" + session000 + ".docx" cmd = " curl -s -H 'Authorization: Token e2acc3630c05c88a9546073ae5bac6ed8aa7e980' https://seafile.******.com/api2/repos/8599d561-f818-4e86-93b3-1da91d920145/upload-link/ " getuploadlink = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT) uploadlinktmp = getuploadlink.stdout.read() uploadlink = eval(uploadlinktmp) output = os.popen(" curl -s -H 'Authorization: Token e2acc3630c05c88a9546073ae5bac6ed8aa7e980' -F file=@%s -F parent_dir=/test01/ls/ -F replace=1 %s " % (filename,uploadlink)) print(output.read()) print(datetime.datetime.now()) if __name__ == '__main__': main() 脚本中获取系统指标的代码已经省略，其中变量filename代表生成的具有日期标识的巡检报告，uploadlink是脚本执行时获取的上传链接，- s表示curl以静默方式运行，不显示进度条。]]></content>
      <categories>
        <category>Scripts</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Seafile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Storm集群搭建]]></title>
    <url>%2Fposts%2F48352a80.html</url>
    <content type="text"><![CDATA[Apache Storm简介Apache Storm是一个分布式实时大数据处理系统。Storm设计用于在容错和水平可扩展方法中处理大量数据。它是一个流数据框架，具有最高的摄取率。虽然Storm是无状态的，它通过Apache ZooKeeper管理分布式环境和集群状态。它很简单，您可以并行地对实时数据执行各种操作。Apache Storm继续成为实时数据分析的领导者。Storm易于设置和操作，并且它保证每个消息将通过拓扑至少处理一次。 Apache Storm vs Hadoop基本上Hadoop和Storm框架用于分析大数据。两者互补，在某些方面有所不同。Apache Storm执行除持久性之外的所有操作，而Hadoop在所有方面都很好，但滞后于实时计算。下表比较了Storm和Hadoop的属性。 Storm Hadoop 实时流处理 批量处理 无状态 有状态 主/从架构与基于ZooKeeper的协调。主节点称为nimbus，从属节点是主管。 具有/不具有基于ZooKeeper的协调的主 - 从结构。主节点是作业跟踪器，从节点是任务跟踪器。 Storm流过程在集群上每秒可以访问数万条消息。 Hadoop分布式文件系统（HDFS）使用MapReduce框架来处理大量的数据，需要几分钟或几小时。 Storm拓扑运行直到用户关闭或意外的不可恢复故障。 MapReduce作业按顺序执行并最终完成。 两者都是分布式和容错的 如果nimbus / supervisor死机，重新启动使它从它停止的地方继续，因此没有什么受到影响。 如果JobTracker死机，所有正在运行的作业都会丢失。 使用Apache Storm的例子Apache Storm对于实时大数据流处理非常有名。因此，大多数公司都将Storm用作其系统的一个组成部分。一些值得注意的例子如下 -Twitter - Twitter正在使用Apache Storm作为其“发布商分析产品”。 “发布商分析产品”处理Twitter平台中的每个tweets和点击。 Apache Storm与Twitter基础架构深度集成。NaviSite - NaviSite正在使用Storm进行事件日志监控/审计系统。系统中生成的每个日志都将通过Storm。Storm将根据配置的正则表达式集检查消息，如果存在匹配，那么该特定消息将保存到数据库。Wego - Wego是位于新加坡的旅行元搜索引擎。旅行相关数据来自世界各地的许多来源，时间不同。Storm帮助Wego搜索实时数据，解决并发问题，并为最终用户找到最佳匹配。 Apache Storm优势下面是Apache Storm提供的好处列表： Storm是开源的，强大的，用户友好的。它可以用于小公司和大公司。 Storm是容错的，灵活的，可靠的，并且支持任何编程语言。 Storm允许实时流处理。 Storm是令人难以置信的快，因为它具有巨大的处理数据的力量。 Storm可以通过线性增加资源来保持性能，即使在负载增加的情况下。它是高度可扩展的。 Storm在几秒钟或几分钟内执行数据刷新和端到端传送响应取决于问题。它具有非常低的延迟。 Storm有操作智能。 Storm提供保证的数据处理，即使群集中的任何连接的节点死或消息丢失。 Apache Storm核心概念Apache Storm从一端读取​​实时数据的原始流，并将其传递通过一系列小处理单元，并在另一端输出处理/有用的信息。下图描述了Apache Storm的核心概念：Apache Storm的组件： 组件 描述 Tuple Tuple是Storm中的主要数据结构。它是有序元素的列表。默认情况下，Tuple支持所有数据类型。通常，它被建模为一组逗号分隔的值，并传递到Storm集群。 Stream 流是元组的无序序列。 Spouts 流的源。通常，Storm从原始数据源（如Twitter Streaming API，Apache Kafka队列，Kestrel队列等）接受输入数据。否则，您可以编写spouts以从数据源读取数据。“ISpout”是实现spouts的核心接口，一些特定的接口是IRichSpout，BaseRichSpout，KafkaSpout等。 Bolts Bolts是逻辑处理单元。Spouts将数据传递到Bolts和Bolts过程，并产生新的输出流。Bolts可以执行过滤，聚合，加入，与数据源和数据库交互的操作。Bolts接收数据并发射到一个或多个Bolts。 “IBolt”是实现Bolts的核心接口。一些常见的接口是IRichBolt，IBasicBolt等。 下图描述了一个“Twitter分析”的实时示例，看看如何在Apache Storm中建模：“Twitter分析”的输入来自Twitter Streaming API。Spout将使用Twitter Streaming API读取用户的tweets，并作为元组流输出。来自spout的单个元组将具有twitter用户名和单个tweet作为逗号分隔值。然后，这个元组的蒸汽将被转发到Bolt，并且Bolt将tweet拆分成单个字，计算字数，并将信息保存到配置的数据源。现在，我们可以通过查询数据源轻松获得结果。 拓扑Spouts和Bolts连接在一起，形成拓扑结构。实时应用程序逻辑在Storm拓扑中指定。简单地说，拓扑是有向图，其中顶点是计算，边缘是数据流。简单拓扑从spouts开始。Spouts将数据发射到一个或多个Bolts。Bolt表示拓扑中具有最小处理逻辑的节点，并且Bolts的输出可以发射到另一个Bolts作为输入。Storm保持拓扑始终运行，直到您终止拓扑。Apache Storm的主要工作是运行拓扑，并在给定时间运行任意数量的拓扑。 任务现在你有一个关于Spouts和Bolts的基本想法。它们是拓扑的最小逻辑单元，并且使用单个Spout和Bolt阵列构建拓扑。应以特定顺序正确执行它们，以使拓扑成功运行。Storm执行的每个Spout和Bolt称为“任务”。简单来说，任务是Spouts或Bolts的执行。在给定时间，每个Spout和Bolt可以具有在多个单独的螺纹中运行的多个实例。 进程拓扑在多个工作节点上以分布式方式运行。Storm将所有工作节点上的任务均匀分布。工作节点的角色是监听作业，并在新作业到达时启动或停止进程。 流分组数据流从Spouts流到Bolts，或从一个Bolts流到另一个Bolts。流分组控制元组在拓扑中的路由方式，并帮助我们了解拓扑中的元组流。有四个内置分组，如下所述： 随机分组在随机分组中，相等数量的元组随机分布在执行Bolts的所有工人中。如下图所示： 字段分组元组中具有相同值的字段组合在一起，其余的元组保存在外部。然后，具有相同字段值的元组被向前发送到执行Bolts的同一进程。例如，如果流由字段“字”分组，则具有相同字符串“Hello”的元组将移动到相同的工作者。下图显示了字段分组的工作原理。 全局分组所有流可以分组并向前到一个Bolts。此分组将源的所有实例生成的元组发送到单个目标实例（具体来说，选择具有最低ID的工作程序）。 所有分组所有分组将每个元组的单个副本发送到接收Bolts的所有实例。这种分组用于向Bolts发送信号。所有分组对于连接操作都很有用。 Apache Storm集群架构Apache Storm的主要亮点是，它是一个容错，快速，没有“单点故障”（SPOF）分布式应用程序。我们可以根据需要在多个系统中安装Apache Storm，以增加应用程序的容量。如下图所示：Apache Storm有两种类型的节点，Nimbus（主节点）和Supervisor（工作节点）。Nimbus是Apache Storm的核心组件。Nimbus的主要工作是运行Storm拓扑。Nimbus分析拓扑并收集要执行的任务。然后，它将任务分配给可用的supervisor。Supervisor将有一个或多个工作进程。Supervisor将任务委派给工作进程。工作进程将根据需要产生尽可能多的执行器并运行任务。Apache Storm使用内部分布式消息传递系统来进行Nimbus和管理程序之间的通信。 组件 描述 Nimbus（主节点） Nimbus是Storm集群的主节点。集群中的所有其他节点称为工作节点。主节点负责在所有工作节点之间分发数据，向工作节点分配任务和监视故障。 Supervisor（工作节点） 遵循指令的节点被称为Supervisors。Supervisor有多个工作进程，它管理工作进程以完成由nimbus分配的任务。 Worker process（工作进程） 工作进程将执行与特定拓扑相关的任务。工作进程不会自己运行任务，而是创建执行器并要求他们执行特定的任务。工作进程将有多个执行器。 Executor（执行者） 执行器只是工作进程产生的单个线程。执行器运行一个或多个任务，但仅用于特定的spout或bolt。 Task（任务） 任务执行实际的数据处理。所以，它是一个spout或bolt。 ZooKeeper framework（ZooKeeper框架） Apache的ZooKeeper的是使用群集（节点组）自己和维护具有强大的同步技术共享数据之间进行协调的服务。Nimbus是无状态的，所以它依赖于ZooKeeper来监视工作节点的状态。ZooKeeper的帮助supervisor与nimbus交互。它负责维持nimbus，supervisor的状态。 Storm是无状态的。即使无状态性质有它自己的缺点，它实际上帮助Storm以最好的可能和最快的方式处理实时数据。Storm虽然不是完全无状态的。它将其状态存储在Apache ZooKeeper中。由于状态在Apache ZooKeeper中可用，故障的网络可以重新启动，并从它离开的地方工作。通常，像monit这样的服务监视工具将监视Nimbus，并在出现任何故障时重新启动它。Apache Storm还有一个称为Trident拓扑的高级拓扑，它具有状态维护，并且还提供了一个高级API，如Pig。 Apache Storm工作流程一个工作的Storm集群应该有一个Nimbus和一个或多个supervisors。另一个重要的节点是Apache ZooKeeper，它将用于nimbus和supervisors之间的协调。Apache Storm的工作流程： 最初，nimbus将等待“Storm拓扑”提交给它。 一旦提交拓扑，它将处理拓扑并收集要执行的所有任务和任务将被执行的顺序。 然后，nimbus将任务均匀分配给所有可用的supervisors。 在特定的时间间隔，所有supervisor将向nimbus发送心跳以通知它们仍然运行着。 当supervisor终止并且不向心跳发送心跳时，则nimbus将任务分配给另一个supervisor。 当nimbus本身终止时，supervisor将在没有任何问题的情况下对已经分配的任务进行工作。 一旦所有的任务都完成后，supervisor将等待新的任务进去。 同时，终止nimbus将由服务监控工具自动重新启动。 重新启动的网络将从停止的地方继续。同样，终止supervisor也可以自动重新启动。由于网络管理程序和supervisor都可以自动重新启动，并且两者将像以前一样继续，因此Storm保证至少处理所有任务一次。 一旦处理了所有拓扑，则网络管理器等待新的拓扑到达，并且类似地，管理器等待新的任务。 默认情况下，Storm集群中有两种模式： 本地模式：此模式用于开发，测试和调试，因为它是查看所有拓扑组件协同工作的最简单方法。在这种模式下，我们可以调整参数，使我们能够看到我们的拓扑如何在不同的Storm配置环境中运行。在本地模式下，storm拓扑在本地机器上在单个JVM中运行。 生产模式：在这种模式下，我们将拓扑提交到工作Storm集群，该集群由许多进程组成，通常运行在不同的机器上。如在storm的工作流中所讨论的，工作集群将无限地运行，直到它被关闭。 Apache Storm分布式消息系统Apache Storm处理实时数据，并且输入通常来自消息排队系统。外部分布式消息系统将提供实时计算所需的输入。Spout将从消息系统读取数据，并将其转换为元组并输入到Apache Storm中。有趣的是，Apache Storm在内部使用其自己的分布式消息传递系统，用于其nimbus和主管之间的通信。 分布式消息系统分布式消息传递基于可靠消息队列的概念。消息在客户端应用程序和消息系统之间异步排队。分布式消息传递系统提供可靠性，可扩展性和持久性的好处。大多数消息模式遵循发布 - 订阅模型（简称发布 - 订阅），其中消息的发送者称为发布者，而想要接收消息的那些被称为订阅者。一旦消息已经被发​​送者发布，订阅者可以在过滤选项的帮助下接收所选择的消息。通常我们有两种类型的过滤，一种是基于主题的过滤，另一种是基于内容的过滤。需要注意的是，pub-sub模型只能通过消息进行通信。它是一个非常松散耦合的架构;甚至发件人不知道他们的订阅者是谁。许多消息模式使消息代理能够交换发布消息以便由许多订户及时访问。一个现实生活的例子是Dish电视，它发布不同的渠道，如运动，电影，音乐等，任何人都可以订阅自己的频道集，并获得他们订阅的频道时可用。一些流行的高吞吐量消息传递系统： 分布式消息系统 描述 Apache Kafka Kafka是在LinkedIn公司开发的，后来它成为Apache的一个子项目。 Apache Kafka基于brokerenabled的，持久的，分布式的发布订阅模型。 Kafka是快速，可扩展和高效的。 RabbitMQ RabbitMQ是一个开源的分布式鲁棒消息应用程序。它易于使用并在所有平台上运行。 JMS(Java Message Service) JMS是一个开源API，支持创建，读取和从一个应用程序向另一个应用程序发送消息。它提供有保证的消息传递并遵循发布 - 订阅模型。 ActiveMQ ActiveMQ消息系统是JMS的开源API。 ZeroMQ ZeroMQ是无代理的对等体消息处理。它提供推拉，路由器 - 经销商消息模式。 Kestrel Kestrel是一个快速，可靠，简单的分布式消息队列。 Apache Storm安装服务器规划 主机名 IP Zookeeper Nimbus Supbervisor node01 10.186.63.112 是 是 是 node02 10.186.63.119 是 否 是 node03 10.186.63.122 是 否 是 安装Java环境所有节点都需要安装Java环境。123tar -zxvf jdk-8u161-linux-x64.tar.gz -C /datamv /data/jdk1.8.0_161 /data/jdk1.8vim /etc/profile 修改环境变量，末尾加入以下内容1234#set java environmentJAVA_HOME=/data/jdk1.8PATH=$JAVA_HOME/bin:$PATHexport JAVA_HOME PATH 执行以下命令，使环境变量生效1source /etc/profile 验证1234# java -versionjava version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 搭建Zookeeper集群下载、解压1234wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gztar -zxvf apache-zookeeper-3.4.14.tar.gz -C /data/cd /datamv zookeeper-3.4.14 zookeeper 修改文件/etc/profile，添加环境变量123#set zookeeper environmentexport ZOOKEEPER_HOME=/data/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf 配置1234cd zookeepermkdir data dataLogcp conf/zoo_sample.cfg conf/zoo.cfgvim conf/zoo.cfg 内容如下：123456789tickTime=2000initLimit=10syncLimit=5dataDir=/data/zookeeper/datadataLogDir=/data/zookeeper/dataLogclientPort=2181server.1=node01:2888:3888server.2=node02:2888:3888server.3=node03:2888:3888 创建id文件12touch data/myidecho 1 &gt; data/myid 注意此处id值分别为1、2、3，每台服务器不一样。启动1./bin/zkServer.sh start 在当前目录，即/data/zookeeper会生成日志文件zookeeper.out，查看日志中是否有报错。Zookeeper集群安装完成。 安装Storm集群官方下载地址 下载1234567wget http://mirror.bit.edu.cn/apache/storm/apache-storm-1.2.2/apache-storm-1.2.2.tar.gztar -zxvf apache-storm-1.2.2.tar.gz -C /datacd /datamv apache-storm-1.2.2 storm #重新命名文件夹cd stormmkdir data #创建数据目录vim conf/storm.yaml #修改配置文件 配置配置文件内容如下：123456789101112131415storm.zookeeper.servers: - &quot;node01&quot; - &quot;node02&quot; - &quot;node03&quot;storm.zookeeper.port: 2181torm.local.dir: &quot;/data/storm/data&quot; nimbus.seeds: [&quot;node01&quot;]supervisor.slots.ports: - 6700 - 6701 - 6702 - 6703storm.health.check.dir: &quot;healthchecks&quot;storm.health.check.timeout.ms: 5000 修改/etc/profile,添加环境变量123#set storm environmentexport STORM_HOME=/data/stormexport PATH=$PATH:$STORM_HOME/bin 同步storm以及环境配置1234scp -r storm root@10.186.63.119:/datascp -r storm root@10.186.63.122:/datascp /etc/profile root@10.186.63.119:/etcscp /etc/profile root@10.186.63.122:/etc 三台服务器执行source /etc/profile,使环境变量生效。 启动storm集群node01上启动启动storm nimbus1storm nimbus 启动ui(再复制一个窗口)1storm ui node02和node03上启动1storm supervisor 上述启动方式中，进程并没有以后台方式运行，如果断开远程连接窗口，则进程关闭。也可以使用以下命令123nohup /data/storm/bin/storm nimbus &gt;/dev/null 2&gt;&amp;1 &amp;nohup /data/storm/bin/storm ui &gt;/dev/null 2&gt;&amp;1 &amp;nohup /data/storm/bin/storm supervisor &gt;/dev/null 2&gt;&amp;1 &amp; 也可以使用supervisor(和storm中的supervisor节点不是同一个东西)，使用方法参考：Supervisor的作用与配置实例打开node01上8080端口，浏览器访问，即可看到以下截图内容Nimbus Summary和Supervisor Summary运行正常，storm集群已安装完成。]]></content>
      <categories>
        <category>BigData</category>
        <category>Storm</category>
      </categories>
      <tags>
        <tag>集群</tag>
        <tag>Zookeeper</tag>
        <tag>Storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装Ambari搭建大数据集群平台]]></title>
    <url>%2Fposts%2Fbfbe0eca.html</url>
    <content type="text"><![CDATA[简介Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的供应、管理和监控。Ambari已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeper、Sqoop和Hcatalog等。Apache Ambari 支持HDFS、MapReduce、Hive、Pig、Hbase、Zookeper、Sqoop和Hcatalog等的集中管理。也是5个顶级hadoop管理工具之一。Ambari能够安装安全的（基于Kerberos）Hadoop集群，以此实现了对Hadoop 安全的支持，提供了基于角色的用户认证、授权和审计功能，并为用户管理集成了LDAP和Active Directory。Apache Ambari 是开源的。 本次安装的Ambari的版本为2.7.3.0，官方参考文档。Ambari 2.7.3 supports only HDP-3.1.0 and HDF-3.2.0Ambari只能管理一个集群。 环境准备节点准备本次准备4个节点 名称 IP 系统 CPU 内存 磁盘 master 10.186.63.57 centos7.5 4 8G 60G node01 10.186.63.112 centos7.5 4 8G 60G node02 10.186.63.119 centos7.5 4 8G 60G node03 10.186.63.174 centos7.5 4 8G 60G 系统初始化(所有节点)初始化系统安装更新及常用软件12yum update -yyum install wget zip unzip gcc* openssl ntpdate lrzsz vim -y 安装Ambari需要的应用有：yum、rpm、scp、curl、unzip、tar、wget、gcc*、openssl、python。部分应用系统已经自带不用安装。 修改打开最大文件数(所有节点)建议的最大文件数配置为大于等于10000，运行命令检查12ulimit -Snulimit -Hn 如果数值小于10000，运行以下命令配置1ulimit -n 10000 配置主机名和hosts解析(所有节点)配置主机名1hostnamectl set-hostname master 其他节点命令相同修改hosts解析，编辑文件/etc/hosts，增加如下内容。123410.186.63.57 master10.186.63.112 node0110.186.63.119 node0210.186.63.174 node03 时间同步(所有节点)添加定时任务1echo "0 */1 * * * /usr/sbin/ntpdate 10.186.61.39" &gt;&gt; /var/spool/cron/root 10.186.61.39为内网中一台时间服务器，也可以使用其他地址。修改时区12mv /etc/localtime /etc/localtime.bakln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime SSH免密登录在master节点上安装ambari server，在其他节点安装ambari agent，server端控制agent端通过ssh，所以在此处配置ssh免密登录。server端执行1ssh-keygen 在根目录会生成以下两个文件12.ssh/id_rsa.ssh/id_rsa.pub 添加公钥到所有的节点授权12chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys 连接测试1ssh root@node01 修改网络配置1vim /etc/sysconfig/network 增加以下两行12NETWORKING=yesHOSTNAME=&lt;fully.qualified.domain.name&gt; 个人认为第二行不用加 关闭防火墙(所有节点)12systemctl stop firewalld.servicesystemctl disable firewalld.service 关闭SELinux(所有节点)12sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/configsetenforce 0 安装MySQL JDBC驱动(所有节点)1234wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gztar -zxvf mysql-connector-java-5.1.46.tar.gzmkdir -p /usr/share/java/cp mysql-connector-java-5.1.46/mysql-connector-java-5.1.46-bin.jar /usr/share/java/mysql-connector-java.jar 或者1yum install mysql-connector-java -y 配置JDK(所有节点)1rpm -ivh jdk-8u211-linux-x64.rpm 也可以不用安装，参考步骤配置ambari server。 安装Mysql在master节点上安装，也可以在其他节点。版本要求：5.5及其以后版本。数据库使用mysql数据库，具体安装步骤参考：Mysql自动安装脚本Mysql安装创建需要用到的数据库及数据库用户并配置赋权12345CREATE DATABASE ambari DEFAULT CHARACTER SET utf8;CREATE USER &apos;ambari&apos;@&apos;%&apos; IDENTIFIED BY &apos;francis&apos;;GRANT ALL PRIVILEGES ON ambari.* TO &apos;ambari&apos;@&apos;%&apos; WITH GRANT OPTION;commit;flush privileges; 暂时只创建ambari的数据库，其他数据库根据需求自行创建。 配置本地源网络情况比较好，我就是不配置！因为ambari 和 hdp 安装文件比较大，如果在线安装的话会很慢，所以最好选择本地源。（可以在集群可以访问的任何机器上制作本地源） 安装制作本地源工具1yum install yum-utils createrepo 创建一个HTTP服务器12yum install httpd -ysystemctl enable httpd &amp;&amp; systemctl start httpd 为Web服务器创建目录1mkdir -p /var/www/html/hdp/HDP-UTILS 下载系统对应的最新版相关安装包其中包括Ambari、HDP、HDP-UTILS,由于HDP-GPL较小只有几百k，所以没有配置为本地源。 下载123wget http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.7.3.0/ambari-2.7.3.0-centos7.tar.gzwget http://public-repo-1.hortonworks.com/HDP/centos7/3.x/updates/3.1.0.0/HDP-3.1.0.0-centos7-rpm.tar.gzwget http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7/HDP-UTILS-1.1.0.22-centos7.tar.gz 下载地址见官方文档：https://docs.hortonworks.com/HDPDocuments/Ambari-2.7.3.0/bk_ambari-installation/content/ch_using-local-repos.html123tar -zxvf ambari-2.7.3.0-centos7.tar.gz -C /var/www/htmltar -zxvf HDP-3.1.0.0-centos7-rpm.tar.gz -C /var/www/html/hdp/tar -zxvf HDP-UTILS-1.1.0.22-centos7.tar.gz -C /var/www/html/hdp/HDP-UTILS/ 解决在浏览器访问http://10.186.63.57/hdp/HDP/centos7/2.7.3.0 为空白原因：该目录下index.xml使用了 https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js 国内访问不了谷歌，将index.xml注释掉即可12cd /var/www/html/hdp/HDP/centos7/3.1.0.0-91mv index.xml index.xml.bak 此时应该可以在浏览器访问下面的地址了,可以验证一下http://10.186.63.57/ambari/centos7/2.7.3.0-3http://10.186.63.57/hdp/HDP/centos7/3.1.0.0-91http://10.186.63.57/hdp/HDP-UTILS 配置ambari、HDP、HDP-UTILS的本地源12cp /var/www/html/ambari/centos7/2.7.3.0-3/ambari.repo /etc/yum.repos.d/cp /var/www/html/hdp/HDP/centos7/3.1.0.0-91/hdp.repo /etc/yum.repos.d/ 将每个repo里的baseurl和gpgkey的地址修改为本地的1vim /etc/yum.repos.d/ambari.repo 12345678#VERSION_NUMBER=2.7.3.0-3[ambari-2.7.3.0]name=ambari Version - ambari-2.7.3.0baseurl=http://10.186.63.57/ambari/centos7/2.7.3.0-3gpgcheck=1gpgkey=http://10.186.63.57/ambari/centos7/2.7.3.0-3/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinsenabled=1priority=1 1vim /etc/yum.repos.d/hdp.repo 12345678910111213141516#VERSION_NUMBER=3.1.0.0-91[HDP-3.1.0.0]name=HDP Version - HDP-3.1.0.0baseurl=http://10.186.63.57/hdp/HDP/centos7/3.1.0.0-91gpgcheck=1gpgkey=http://10.186.63.57/hdp/HDP/centos7/3.1.0.0-91/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinsenabled=1priority=1[HDP-UTILS-1.1.0.22]name=HDP-UTILS Version - HDP-UTILS-1.1.0.22baseurl=http://10.186.63.57/hdp/HDP-UTILSgpgcheck=1gpgkey=http://10.186.63.57/hdp/HDP/centos7/3.1.0.0-91/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinsenabled=1priority=1 1234yum clean allyum list updateyum makecacheyum repolist （可选）如果您的环境中配置了多个存储库，请在集群中的所有节点上部署以下插件12yum install yum-plugin-priorities -yvim /etc/yum/pluginconf.d/priorities.conf 123[main]enabled = 1gpgcheck=0 安装Ambari配置yum源(所有节点)12wget -nv http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.7.3.0/ambari.repo -O /etc/yum.repos.d/ambari.repoyum repolist 安装ambari servermaster节点操作1yum install ambari-server -y 配置ambari server1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# ambari-server setupUsing python /usr/bin/pythonSetup ambari-serverChecking SELinux...SELinux status is 'disabled'Customize user account for ambari-server daemon [y/n] (n)? yEnter user account for ambari-server daemon (root):ambariAdjusting ambari-server permissions and ownership...Checking firewall status...Checking JDK...[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8[2] Custom JDK==============================================================================Enter choice (1): 2WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.Path to JAVA_HOME: /usr/java/jdk1.8.0_211-amd64Validating JDK on Ambari Server...done.Check JDK version for Ambari Server...JDK version found: 8Minimum JDK version is 8 for Ambari. Skipping to setup different JDK for Ambari Server.Checking GPL software agreement...GPL License for LZO: https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.htmlEnable Ambari Server to download and install GPL Licensed LZO packages [y/n] (n)? yCompleting setup...Configuring database...Enter advanced database configuration [y/n] (n)? yConfiguring database...==============================================================================Choose one of the following options:[1] - PostgreSQL (Embedded)[2] - Oracle[3] - MySQL / MariaDB[4] - PostgreSQL[5] - Microsoft SQL Server (Tech Preview)[6] - SQL Anywhere[7] - BDB==============================================================================Enter choice (1): 3Hostname (localhost): Port (3306): Database name (ambari): Username (ambari): Enter Database Password (bigdata): Re-enter password: Configuring ambari database...Should ambari use existing default jdbc /usr/share/java/mysql-connector-java.jar [y/n] (y)? yConfiguring remote database connection properties...WARNING: Before starting Ambari Server, you must run the following DDL directly from the database shell to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sqlProceed with configuring remote database connection properties [y/n] (y)? yExtracting system views...ambari-admin-2.7.3.0.139.jar....Ambari repo file contains latest json url http://public-repo-1.hortonworks.com/HDP/hdp_urlinfo.json, updating stacks repoinfos with it...Adjusting ambari-server permissions and ownership...Ambari Server 'setup' completed successfully. 选择JDK步骤，因为我们已经安装了JDK环境，可以选择2。配置的结果保存在/etc/ambari-server/conf，主要是文件/etc/ambari-server/conf/ambari.properties,可以打开文件去验证。 启动ambari server1234567891011121314# ambari-server startUsing python /usr/bin/pythonStarting ambari-serverAmbari Server running with administrator privileges.Organizing resource files at /var/lib/ambari-server/resources...Ambari database consistency check started...Server PID at: /var/run/ambari-server/ambari-server.pidServer out at: /var/log/ambari-server/ambari-server.outServer log at: /var/log/ambari-server/ambari-server.logWaiting for server start..............................Server started listening on 8080DB configs consistency check: no errors and warnings were found.Ambari Server 'start' completed successfully. 访问http://10.186.63.57:8080，默认用户admin，密码为admin。 安装大数据库平台过程进入web页面，一切按照提示进行即可，以下截图为提示步骤！此处如果没有配置本地源，可以直接NEXT，如果配置了本地源可以选择使用Use Local Repository。此处选择添加节点，已经配置过hosts，所以可以直接写hostname。密钥即为在master生成的id_rsa文件。此处选择要安装的服务，根据自己的需求安装即可。其中SmartSense为必选项，其他需要添加服务根据提示。写文档时中选择了HDFS、Zookeeper、Ambari Metrics、Smart Sense服务。以下截图为安装完成后，整个界面的概览。到此，安装Ambari过程已结束。]]></content>
      <categories>
        <category>BigData</category>
        <category>Ambari</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>集群</tag>
        <tag>Ambari</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis为什么快]]></title>
    <url>%2Fposts%2F9febb6fd.html</url>
    <content type="text"><![CDATA[前言 Redis是一种基于键值对(Key-Value)的NoSQL数据库，Redis的Value可以由String，hash，list，set，zset，Bitmaps，HyperLogLog等多种数据结构和算法组成。Redis还提供了键过期，发布订阅，事务，Lua脚本，哨兵，Cluster等功能。Redis执行命令的速度非常快，根据官方给的性能可以达到10w+qps。那么本文主要介绍到底Redis快在哪里，主要有以下几点： 开发语言现在我们都用高级语言来编程，比如Java、python等。也许你会觉得C语言很古老，但是它真的很有用，毕竟unix系统就是用C实现的，所以C语言是非常贴近操作系统的语言。Redis就是用C语言开发的，所以执行会比较快。 纯内存访问Redis将所有数据放在内存中，非数据同步正常工作中，是不需要从磁盘读取数据的，0次IO。内存响应时间大约为100纳秒，这是Redis速度快的重要基础。先看看CPU的速度：借了一张《深入理解计算机系统》的图，展示了一个典型的存储器层次结构，在L0层，CPU可以在一个时钟周期访问到，基于SRAM的高速缓存春续期，可以在几个CPU时钟周期访问到，然后是基于DRAM的主存，可以在几十到几百个时钟周期访问到他们。 单线程第一，单线程简化算法的实现，并发的数据结构实现不但困难且测试也麻烦。第二，单线程避免了线程切换以及加锁释放锁带来的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手。当然了，单线程也会有它的缺点，也是Redis的噩梦：阻塞。如果执行一个命令过长，那么会造成其他命令的阻塞，对于Redis是十分致命的，所以Redis是面向快速执行场景的数据库。 除了Redis之外，Node.js也是单线程，Nginx也是单线程，但他们都是服务器高性能的典范。 非阻塞多路I/O复用机制在这之前先要说一下传统的阻塞I/O是如何工作的：当使用read或者write对某一文件描述符（File Descriptor FD）进行读写的时候，如果数据没有收到，那么该线程会被挂起，直到收到数据。阻塞模型虽然易于理解，但是在需要处理多个客户端任务的时候，不会使用阻塞模型。 I/O多路复用实际上是指多个连接的管理可以在同一进程。多路是指网络连接，复用只是同一个线程。在网络服务中，I/O多路复用起的作用是一次性把多个连接的事件通知业务代码处理，处理的方式由业务代码来决定。在I/O多路复用模型中，最重要的函数调用就是I/O 多路复用函数，该方法能同时监控多个文件描述符（fd）的读写情况，当其中的某些fd可读/写时，该方法就会返回可读/写的fd个数。 Redis使用epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll的read、write、close等都转换成事件，不在网络I/O上浪费过多的时间。实现对多个FD读写的监控，提高性能。举个形象的例子吧。比如一个tcp服务器处理20个客户端socket。A方案：顺序处理，如果第一个socket因为网卡读数据处理慢了，一阻塞后面都玩蛋去。B方案：每个socket请求都创建一个分身子进程来处理，不说每个进程消耗大量系统资源，光是进程切换就够操作系统累的了。C方案（I/O复用模型，epoll）：将用户socket对应的fd注册进epoll（实际上服务器和操作系统之间传递的不是socket的fd而是fd_set的数据结构），然后epoll只告诉哪些需要读/写的socket，只需要处理那些活跃的、有变化的socket fd的就好了。这样，整个过程只在调用epoll的时候才会阻塞，收发客户消息是不会阻塞的。]]></content>
      <categories>
        <category>DB</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用正则表达式]]></title>
    <url>%2Fposts%2F81d5af05.html</url>
    <content type="text"><![CDATA[校验数字的表达式12345678910111213141516171819数字：^[0-9]*$n位的数字：^\d&#123;n&#125;$至少n位的数字：^\d&#123;n,&#125;$m-n位的数字：^\d&#123;m,n&#125;$零和非零开头的数字：^(0|[1-9][0-9]*)$非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(.[0-9]&#123;1,2&#125;)?$带1-2位小数的正数或负数：^(\-)?\d+(\.\d&#123;1,2&#125;)?$正数、负数、和小数：^(\-|\+)?\d+(\.\d+)?$有两位小数的正实数：^[0-9]+(.[0-9]&#123;2&#125;)?$有1~3位小数的正实数：^[0-9]+(.[0-9]&#123;1,3&#125;)?$非零的正整数：^[1-9]\d*$ 或 ^([1-9][0-9]*)&#123;1,3&#125;$ 或 ^\+?[1-9][0-9]*$非零的负整数：^\-[1-9][]0-9&quot;*$ 或 ^-[1-9]\d*$非负整数：^\d+$ 或 ^[1-9]\d*|0$非正整数：^-[1-9]\d*|0$ 或 ^((-\d+)|(0+))$非负浮点数：^\d+(\.\d+)?$ 或 ^[1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0$非正浮点数：^((-\d+(\.\d+)?)|(0+(\.0+)?))$ 或 ^(-([1-9]\d*\.\d*|0\.\d*[1-9]\d*))|0?\.0+|0$正浮点数：^[1-9]\d*\.\d*|0\.\d*[1-9]\d*$ 或 ^(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*))$负浮点数：^-([1-9]\d*\.\d*|0\.\d*[1-9]\d*)$ 或 ^(-(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*)))$浮点数：^(-?\d+)(\.\d+)?$ 或 ^-?([1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0)$ 校验字符的表达式123456789101112汉字：^[\u4e00-\u9fa5]&#123;0,&#125;$英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]&#123;4,40&#125;$长度为3-20的所有字符：^.&#123;3,20&#125;$由26个英文字母组成的字符串：^[A-Za-z]+$由26个大写英文字母组成的字符串：^[A-Z]+$由26个小写英文字母组成的字符串：^[a-z]+$由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$由数字、26个英文字母或者下划线组成的字符串：^\w+$ 或 ^\w&#123;3,20&#125;$中文、英文、数字包括下划线：^[\u4E00-\u9FA5A-Za-z0-9_]+$中文、英文、数字但不包括下划线等符号：^[\u4E00-\u9FA5A-Za-z0-9]+$ 或 ^[\u4E00-\u9FA5A-Za-z0-9]&#123;2,20&#125;$可以输入含有^%&amp;&apos;,;=?$\&quot;等字符：[^%&amp;&apos;,;=?$\x22]+禁止输入含有~的字符：[^~\x22]+ 特殊需求表达式123456789101112131415161718192021222324252627282930313233Email地址：^\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$域名：[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;(/.[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;)+/.?InternetURL：[a-zA-z]+://[^\s]* 或 ^http://([\w-]+\.)+[\w-]+(/[\w-./?%&amp;=]*)?$手机号码：^(13[0-9]|14[0-9]|15[0-9]|16[0-9]|17[0-9]|18[0-9]|19[0-9])\d&#123;8&#125;$ (由于工信部放号段不定时，所以建议使用泛解析 ^([1][3,4,5,6,7,8,9])\d&#123;9&#125;$)电话号码(&quot;XXX-XXXXXXX&quot;、&quot;XXXX-XXXXXXXX&quot;、&quot;XXX-XXXXXXX&quot;、&quot;XXX-XXXXXXXX&quot;、&quot;XXXXXXX&quot;和&quot;XXXXXXXX)：^(\(\d&#123;3,4&#125;-)|\d&#123;3.4&#125;-)?\d&#123;7,8&#125;$ 国内电话号码(0511-4405222、021-87888822)：\d&#123;3&#125;-\d&#123;8&#125;|\d&#123;4&#125;-\d&#123;7&#125; 18位身份证号码(数字、字母x结尾)：^((\d&#123;18&#125;)|([0-9x]&#123;18&#125;)|([0-9X]&#123;18&#125;))$帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]&#123;4,15&#125;$密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\w&#123;5,17&#125;$强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间)：^(?=.*\d)(?=.*[a-z])(?=.*[A-Z]).&#123;8,10&#125;$ 日期格式：^\d&#123;4&#125;-\d&#123;1,2&#125;-\d&#123;1,2&#125;一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$ 钱的输入格式： 1.有四种钱的表示形式我们可以接受:&quot;10000.00&quot; 和 &quot;10,000.00&quot;, 和没有 &quot;分&quot; 的 &quot;10000&quot; 和 &quot;10,000&quot;：^[1-9][0-9]*$ 2.这表示任意一个不以0开头的数字,但是,这也意味着一个字符&quot;0&quot;不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$ 3.一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$ 4.这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧.下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$ 5.必须说明的是,小数点后面至少应该有1位数,所以&quot;10.&quot;是不通过的,但是 &quot;10&quot; 和 &quot;10.2&quot; 是通过的：^[0-9]+(.[0-9]&#123;2&#125;)?$ 6.这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]&#123;1,2&#125;)?$ 7.这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]&#123;1,3&#125;(,[0-9]&#123;3&#125;)*(.[0-9]&#123;1,2&#125;)?$ 8.1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]&#123;1,3&#125;(,[0-9]&#123;3&#125;)*)(.[0-9]&#123;1,2&#125;)?$ 备注：这就是最终结果了,别忘了&quot;+&quot;可以用&quot;*&quot;替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\.[x|X][m|M][l|L]$中文字符的正则表达式：[\u4e00-\u9fa5]双字节字符：[^\x00-\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1))空白行的正则表达式：\n\s*\r (可以用来删除空白行)HTML标记的正则表达式：&lt;(\S*?)[^&gt;]*&gt;.*?&lt;/\1&gt;|&lt;.*? /&gt; (网上流传的版本太糟糕，上面这个也仅仅能部分，对于复杂的嵌套标记依旧无能为力)首尾空白字符的正则表达式：^\s*|\s*$或(^\s*)|(\s*$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式)腾讯QQ号：[1-9][0-9]&#123;4,&#125; (腾讯QQ号从10000开始)中国邮政编码：[1-9]\d&#123;5&#125;(?!\d) (中国邮政编码为6位数字)IP地址：\d+\.\d+\.\d+\.\d+ (提取IP地址时有用)IP地址：((?:(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d)\\.)&#123;3&#125;(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d))]]></content>
      <categories>
        <category>OS</category>
        <category>Command&amp;Tool</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql命令行工具Mycli使用]]></title>
    <url>%2Fposts%2F73ee1a5a.html</url>
    <content type="text"><![CDATA[简介MyCli 是一个 MySQL 命令行工具，支持自动补全和语法高亮。也可用于 MariaDB 和 Percona。官网介绍Mycli is tested on macOS and Linux. It runs on Python 2.7 and 3.4+. Works well with unicode input/output. NOTE: Python 2.6 support was dropped in mycli 1.9.0. If you&#39;re running Python 2.6, you&#39;ll want to install mycli 1.8.1.Mycli就是说支持Python 2.7和Python 3.4+版本。如果系统Python版本是2.6，那么安装后的Mycli 版本为1.8.1。 安装在 CentOS 上使用pip安装，其他系统版本参考官网。如果没有安装pip，则先安装pip。安装如下：12345678910# yum list |grep python2-pippython2-pip.noarch 8.1.2-8.el7 epel # yum install python2-pip -y# pip -Vpip 8.1.2 from /usr/lib/python2.7/site-packages (python 2.7)# pip install mycli# which mycli/usr/bin/mycli# mycli -VVersion: 1.19.0 使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# mycli --helpUsage: mycli [OPTIONS] [DATABASE] A MySQL terminal client with auto-completion and syntax highlighting. Examples: - mycli my_database - mycli -u my_user -h my_host.com my_database - mycli mysql://my_user@my_host.com:3306/my_databaseOptions: -h, --host TEXT Host address of the database. -P, --port INTEGER Port number to use for connection. Honors $MYSQL_TCP_PORT. -u, --user TEXT User name to connect to the database. -S, --socket TEXT The socket file to use for connection. -p, --password TEXT Password to connect to the database. --pass TEXT Password to connect to the database. --ssh-user TEXT User name to connect to ssh server. --ssh-host TEXT Host name to connect to ssh server. --ssh-port INTEGER Port to connect to ssh server. --ssh-password TEXT Password to connect to ssh server. --ssh-key-filename TEXT Private key filename (identify file) for the ssh connection. --ssl-ca PATH CA file in PEM format. --ssl-capath TEXT CA directory. --ssl-cert PATH X509 cert in PEM format. --ssl-key PATH X509 key in PEM format. --ssl-cipher TEXT SSL cipher to use. --ssl-verify-server-cert Verify server's "Common Name" in its cert against hostname used when connecting. This option is disabled by default. -V, --version Output mycli's version. -v, --verbose Verbose output. -D, --database TEXT Database to use. -d, --dsn TEXT Use DSN configured into the [alias_dsn] section of myclirc file. --list-dsn list of DSN configured into the [alias_dsn] section of myclirc file. -R, --prompt TEXT Prompt format (Default: "\t \u@\h:\d&gt; "). -l, --logfile FILENAME Log every query and its results to a file. --defaults-group-suffix TEXT Read MySQL config groups with the specified suffix. --defaults-file PATH Only read MySQL options from the given file. --myclirc PATH Location of myclirc file. --auto-vertical-output Automatically switch to vertical output mode if the result is wider than the terminal width. -t, --table Display batch output in table format. --csv Display batch output in CSV format. --warn / --no-warn Warn before running a destructive query. --local-infile BOOLEAN Enable/disable LOAD DATA LOCAL INFILE. --login-path TEXT Read this path from the login file. -e, --execute TEXT Execute command and quit. --help Show this message and exit. 连接 Mysql 使用：简单截个图，可以自行体验。]]></content>
      <categories>
        <category>OS</category>
        <category>Command&amp;Tool</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>Mycli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CDH集群安装]]></title>
    <url>%2Fposts%2Fffd68ac0.html</url>
    <content type="text"><![CDATA[概念介绍CDH 概览CDH是Apache Hadoop和相关项目的最完整、最受测试和最流行的发行版。CDH提供Hadoop的核心元素-可伸缩存储和分布式计算-以及基于web的用户界面和重要的企业功能。CDH是Apache许可的开放源码，是唯一提供统一批处理、交互式SQL和交互式搜索以及基于角色的访问控制的Hadoop解决方案。CDH 提供以下特性： 灵活性：存储任何类型的数据并使用各种不同的计算框架进行操作，包括批处理、交互式SQL、免费文本搜索、机器学习和统计计算。 集成：在一个完整的Hadoop平台上快速启动和运行，该平台与广泛的硬件和软件解决方案一起工作。 安全：处理和控制敏感数据。 可伸缩性：启用广泛的应用程序和规模，并扩展它们以满足您的需求。 高可用性：满怀信心地执行任务关键的业务任务。 兼容性：利用您现有的IT基础设施和投资。 CDH 组件如下图： Cloudera Manager 概览Cloudera Manager 是用于管理cdh集群的端到端应用程序。Cloudera Manager通过向CDH集群的每个部分提供细粒度的可见性并对其进行控制来设置企业部署标准-授权运营商提高性能、提高服务质量、提高遵从性和降低管理成本。使用Cloudera Manager，您可以轻松地部署和集中操作完整的CDH堆栈和其他托管服务。应用程序自动化安装过程，将部署时间从数周减少到分钟；为您提供在集群范围内运行主机和服务的实时视图；提供一个单一的中央控制台来执行整个集群的配置更改；并集成各种报告和诊断工具，以帮助您进行操作。Cloudera Manager 的架构如上图所示（cs结构），主要由如下几部分组成： 服务端/Server：Cloudera Manager 的核心。主要用于管理 web server 和应用逻辑。它用于安装软件，配置，开始和停止服务，以及管理服务运行的集群。 代理/agent：安装在每台主机上。它负责启动和停止的进程，部署配置，触发安装和监控主机。 数据库/Database：存储配置和监控信息。通常可以在一个或多个数据库服务器上运行的多个逻辑数据库。例如，所述的 Cloudera 管理器服务和监视，后台程序使用不同的逻辑数据库。 Cloudera Repository：由cloudera manager 提供的软件分发库。 客户端/Clients：提供了一个与 Server 交互的接口。 Cloudera Manager包括server端和agent；server端主要作用是监控集群分发配置集群等，agent端主管集群各节点。CDH是CM的安装包，本地或者云端，其中包括hadoop的生态系统需要的所有组件，通过Cloudera Manager统一管理和安装。CDH除了可以通过cm安装也可以通过yum,tar,rpm安装。 环境准备软件版本选择 类目 版本 下载地址 操作系统 CentOS 7.6 使用阿里云镜像下载 数据库 5.7.25-Mysql 二进制安装 JDK jdk-8u211-linux-x64.rpm Oracle 官网下载 Cloudera Manager Cloudera Manager 6.2.0 官方仓库 CDH CDH 6.2.0 使用parcels安装 节点准备必须准备4个以上节点 名称 IP CM管理软件 master 10.186.63.57 Cloudera Manager Server&amp;Agent ，Mysql node01 10.186.63.112 Cloudera Manager Agent node02 10.186.63.135 Cloudera Manager Agent node03 10.186.63.136 Cloudera Manager Agent 内存要求大于8GB，master的磁盘要求多余50G。 系统初始化(所有节点)初始化系统安装更新及常用软件12yum upadte -yyum install wget ntpdate lrzsz vim -y 配置主机名和hosts解析(所有节点)配置主机名1hostnamectl set-hostname master 其他节点命令相同修改hosts解析，编辑文件/etc/hosts，增加如下内容。123410.186.63.57 master10.186.63.112 node0110.186.63.135 node0210.186.63.136 node03 关闭防火墙(所有节点)12systemctl stop firewalld.servicesystemctl disable firewalld.service 关闭SELinux(所有节点)12sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/configsetenforce 0 时间同步(所有节点)添加定时任务1echo "0 */1 * * * /usr/sbin/ntpdate 10.186.61.39" &gt;&gt; /var/spool/cron/root 10.186.61.39为内网中一台时间服务器，也可以使用其他地址。修改时区12mv /etc/localtime /etc/localtime.bakln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 禁用透明大页面压缩(所有节点)CDH配置需要12echo never &gt; /sys/kernel/mm/transparent_hugepage/defragecho never &gt; /sys/kernel/mm/transparent_hugepage/enabled 并将上面的两条命令写入开机自启动/etc/rc.local。 优化交换分区(所有节点)12echo "vm.swappiness = 10" &gt;&gt; /etc/sysctl.confsysctl -p 配置 JDK (所有节点)1rpm -ivh jdk-8u211-linux-x64.rpm 安装 CM 和 CDH配置 Cloudera Manager 仓库(所有节点)123wget https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/cloudera-manager.repo -P /etc/yum.repos.d/或者rpm --import https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/RPM-GPG-KEY-cloudera 使用仓库安装会比较慢，建议先把需要的rpm下载下来，进行离线安装或者建私有仓库，主要下面的三个软件包：cloudera-manager-agent-6.2.0-968826.el7.x86_64.rpmcloudera-manager-daemons-6.2.0-968826.el7.x86_64.rpmcloudera-manager-server-6.2.0-968826.el7.x86_64.rpmcloudera-manager-daemons 是 server 和 agent 必须安装的。 安装 CM Server 和 Agent建议离线安装，把rpm包下载到服务器上面，传到其他节点一份，再本地安装，速度会快很多。master：1yum install cloudera-manager-daemons cloudera-manager-agent cloudera-manager-server node0[1-3]：1yum install cloudera-manager-daemons cloudera-manager-agent 安装数据库(master)数据库使用mysql数据库，具体安装步骤参考：Mysql自动安装脚本Mysql安装注意：Mysql需要关闭GTID，否则在后面进行初始化步骤会出错！以下为：官网推荐示例配置文件：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.socktransaction-isolation = READ-COMMITTED# Disabling symbolic-links is recommended to prevent assorted security risks;# to do so, uncomment this line:symbolic-links = 0key_buffer_size = 32Mmax_allowed_packet = 32Mthread_stack = 256Kthread_cache_size = 64query_cache_limit = 8Mquery_cache_size = 64Mquery_cache_type = 1max_connections = 550#expire_logs_days = 10#max_binlog_size = 100M#log_bin should be on a disk with enough free space.#Replace '/var/lib/mysql/mysql_binary_log' with an appropriate path for your#system and chown the specified folder to the mysql user.log_bin=/var/lib/mysql/mysql_binary_log#In later versions of MySQL, if you enable the binary log and do not set#a server_id, MySQL will not start. The server_id must be unique within#the replicating group.server_id=1binlog_format = mixedread_buffer_size = 2Mread_rnd_buffer_size = 16Msort_buffer_size = 8Mjoin_buffer_size = 8M# InnoDB settingsinnodb_file_per_table = 1innodb_flush_log_at_trx_commit = 2innodb_log_buffer_size = 64Minnodb_buffer_pool_size = 4Ginnodb_thread_concurrency = 8innodb_flush_method = O_DIRECTinnodb_log_file_size = 512M[mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pidsql_mode=STRICT_ALL_TABLES 为 Cloudera 各软件创建数据库使用root登陆数据库，创建以下数据库和账号。 Service Database User Cloudera Manager Server scm scm Activity Monitor amon amon Reports Manager rman rman Hue hue hue Hive Metastore Server metastore hive Sentry Server sentry sentry Cloudera Navigator Audit Server nav nav Cloudera Navigator Metadata Server navms navms Oozie oozie oozie sql语句如下：123456789101112131415161718192021create database scm DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database amon DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database rman DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database metastore DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database sentry DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database nav DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database navms DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci;GRANT ALL ON scm.* TO 'scm'@'%' identified by 'francis';GRANT ALL ON amon.* TO 'amon'@'%' identified by 'francis';GRANT ALL ON rman.* TO 'rman'@'%' identified by 'francis';GRANT ALL ON hue.* TO 'hue'@'%' identified by 'francis';GRANT ALL ON metastore.* TO 'hive'@'%' identified by 'francis';GRANT ALL ON sentry.* TO 'sentry'@'%' identified by 'francis';GRANT ALL ON nav.* TO 'nav'@'%' identified by 'francis';GRANT ALL ON navms.* TO 'navms'@'%' identified by 'francis';GRANT ALL ON oozie.* TO 'oozie'@'%' identified by 'francis';flush privileges; 安装 MySQL JDBC 驱动(所有节点)1234wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gztar -zxvf mysql-connector-java-5.1.46.tar.gzmkdir -p /usr/share/java/cp mysql-connector-java-5.1.46/mysql-connector-java-5.1.46-bin.jar /usr/share/java/mysql-connector-java.jar 注意：最后的jar包名称mysql-connector-java.jar中，不能包含版本号。 设置 Cloudera Manager 数据库初始化数据库(master节点操作)123456789[root@master ~]# /opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scmEnter SCM password: JAVA_HOME=/usr/java/jdk1.8.0_211Verifying that we can write to /etc/cloudera-scm-serverCreating SCM configuration file in /etc/cloudera-scm-serverExecuting: /usr/java/jdk1.8.0_162/bin/java -cp /usr/share/java/mysql-connector-java.jar:/usr/share/java/oracle-connector-java.jar:/usr/share/java/postgresql-connector-java.jar:/opt/cloudera/cm/schema/../lib/* com.cloudera.enterprise.dbutil.DbCommandExecutor /etc/cloudera-scm-server/db.properties com.cloudera.cmf.db.[ main] DbCommandExecutor INFO Successfully connected to database.All done, your SCM database is configured correctly! 安装 CDH配置CDH的软件包 parcels(master)CM安装成功之后，接下来我们就可以通过CM安装CDH的方式构建企业大数据平台。所以首先需要把CDH的parcels包下载到CM主服务器上。同样的，我们为了加速我们的安装，我们可以把需要下载的软件包提前下载下来，也可以创建CDH私有仓库。123[root@namenode01 ~]# cd /opt/cloudera/parcel-repowget https://archive.cloudera.com/cdh6/6.2.0/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcelwget https://archive.cloudera.com/cdh6/6.2.0/parcels/manifest.json 在manifest.json文件中，找到对应版本的秘钥，复制到.sha文件中。1echo "2e650f1f1ea020a3efc98a231b85c2df1a50b030" &gt; CDH-6.0.1-1.cdh6.0.1.p0.590678-el7.parcel.sha 修改属主属组。1chown cloudera-scm.cloudera-scm /opt/cloudera/parcel-repo/* 启动 Cloudera Manager Server1[root@namenode01 ~]# systemctl start cloudera-scm-server 如果启动中有什么问题，可以查看日志。1tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log 在最后显示的日志中，有显示启动监听的端口。12Started ServerConnector@da518cb&#123;SSL,[ssl, http/1.1]&#125;&#123;0.0.0.0:7183&#125;Started ServerConnector@a77165b&#123;HTTP/1.1,[http/1.1]&#125;&#123;0.0.0.0:7180&#125; 初始化 Cloudera Manager启动 server 和 agent12systemctl start cloudera-scm-serversystemctl start cloudera-scm-agent CDH中各个服务的端口，如下图：浏览器打开 http://10.186.63.57:7180 用户名和密码默认都是admin。已安装过JDK，不用勾选，继续。此处需要使用我们创建过的数据库。由于安装过程角色分配不合理，所以截图中有很多红色报警，属于内存不足。至此，CDH集群安装完成。]]></content>
      <categories>
        <category>BigData</category>
        <category>CDH</category>
      </categories>
      <tags>
        <tag>CDH</tag>
        <tag>cloudera</tag>
        <tag>大数据</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx编译安装及JDK环境安装脚本]]></title>
    <url>%2Fposts%2F4a48582.html</url>
    <content type="text"><![CDATA[在生产环境中需要安装多台web服务器及JDK环境，所以通过脚本实现自动化。脚本实现功能： 更新系统 nginx编译安装 安装JDK环境 使用方法：将安装包及脚本放在同级目录，执行脚本即可。目录类型如下：123456789# pwd/data/backup[root@localhost backup]# ll-rwxr-xr-x 1 root root 1624 Apr 26 09:01 deploy_nginx.sh-rw-r--r-- 1 root root 189756259 Mar 7 07:58 jdk-8u161-linux-x64.tar.gz-rw-r--r-- 1 root root 981687 Mar 7 07:52 nginx-1.12.2.tar.gz-rw-r--r-- 1 root root 5422717 Mar 7 07:51 openssl-1.1.0h.tar.gz-rw-r--r-- 1 root root 2081413 Mar 7 07:51 pcre-8.42.tar.gz-rw-r--r-- 1 root root 607698 Mar 7 07:51 zlib-1.2.11.tar.gz 脚本内容如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# cat deploy_nginx.sh #!/bin/bashhome=$(cd `dirname $0`; pwd)#read -p "请输入Java环境安装目录:" JAVA_HOME#read -p "请输入Nginx安装目录:" NGINX_HOME#read -p "请输入Mysql数据目录:" MYSQL_DATA#echo $hoem $JAVA_HOME $NGINX_HOME $MYSQL_DATA#mkdir -p $JAVA_HOME $NGINX_HOME $MYSQL_DATAmkdir -p /data/work/&#123;service_jar,shell,logs&#125;os_update()&#123; yum update -y yum install -y wget lrzsz telnet &#125;jdk_install()&#123; echo "安装java环境......" tar -zxvf jdk-8u161-linux-x64.tar.gz mv jdk1.8.0_161/ /data/jdk1.8 echo "#set java environment" &gt;&gt; /etc/profile echo "JAVA_HOME=/data/jdk1.8" &gt;&gt; /etc/profile echo "PATH=/data/jdk1.8/bin:\$PATH" &gt;&gt; /etc/profile echo "export PATH" &gt;&gt; /etc/profile source /etc/profile&#125;nginx_install()&#123; yum -y install gcc gcc-c++ automake autoconf libtool make tar -zxvf zlib-1.2.11.tar.gz tar -zxvf openssl-1.1.0h.tar.gz tar -zxvf pcre-8.42.tar.gz tar -zxvf nginx-1.12.2.tar.gz cd pcre-8.42 ./configure make &amp;&amp; make install cd $home cd zlib-1.2.11 ./configure make &amp;&amp; make install cd $home cd nginx-1.12.2 cfg="--prefix=/data/nginx --with-http_v2_module --with-http_ssl_module --with-http_sub_module --with-http_stub_status_module --with-http_gzip_static_module --without-http-cache --with-http_realip_module --with-pcre=/data/backup/pcre-8.42 --with-zlib=/data/backup/zlib-1.2.11 --with-openssl=/data/backup/openssl-1.1.0h" ./configure $cfg make &amp;&amp; make install ln -s /data/nginx/sbin/* /usr/sbin/ cd $home&#125;main()&#123; os_update jdk_install nginx_install&#125;main 待优化！]]></content>
      <categories>
        <category>Scripts</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
        <tag>Nginx</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql自动安装脚本]]></title>
    <url>%2Fposts%2F5229cf63.html</url>
    <content type="text"><![CDATA[在生产环境中需要安装多台mysql实例，单台操作太麻烦所以写一个脚本实现自动化。脚本实现功能： 安装mysql实例并进行初始化 自动编写配置文件 安装xtrabackup 安装qpress 修改备份脚本 添加定时任务 修改mysql实例root密码，创建数据库名，并新建多类型账户并授权 将mysql用户及密码输出到同目录文件password.txt 使用方法：将安装包及脚本放在同级目录，执行脚本即可。目录类型如下：123456789101112# pwd/data/backup# ll -atotal 913696drwxr-xr-x 7 root root 4096 Apr 29 06:12 .drwxr-xr-x 7 root root 72 Apr 29 05:49 ..-rwxr-xr-x 1 root root 7367 Apr 29 05:58 deploy_mysql.sh-rw-r--r-- 1 root root 644862820 Apr 28 02:05 mysql-5.7.25-linux-glibc2.12-x86_64.tar.gz-rw-r--r-- 1 root root 285 Apr 29 05:49 password.txt-rw-r--r-- 1 root root 90282874 Apr 28 02:02 percona-xtrabackup-2.4.9-Linux-x86_64.tar.gz-rw-r--r-- 1 root root 75684 Apr 28 02:01 qpress-rw-r--r-- 1 root root 3706 Apr 28 02:01 scripts.tar.gz 脚本内容为：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227# cat deploy_mysql.sh #!/bin/bashread -p "请输入新建数据库名:" dbnamehome=$(cd `dirname $0`; pwd)function generate_random()&#123; openssl rand -base64 14 | cut -c 1-16&#125;password1=$(generate_random)echo "root : $password1" &gt;&gt; password.txtpassword2=$(generate_random)echo "repl : $password2" &gt;&gt; password.txtpassword3=$(generate_random)echo "appuser : $password3" &gt;&gt; password.txtpassword4=$(generate_random)echo "readuser : $password4" &gt;&gt; password.txtecho "zbx : zabbix" &gt;&gt; password.txtpassword5=$(generate_random)echo "backup : $password5" &gt;&gt; password.txtmysql_install()&#123;#编写配置文件cat &gt; /etc/my.cnf &lt;&lt; EOF [client]port = 3306user = rootsocket = /data/mysql/data/mysql_3306.sockpassword =[mysql]prompt ='[\c][Conn:\C][\R:\\m:\\s][\U][\d]&gt; 'default-character-set = utf8mb4#prompt ='\U[\d]&gt; 'tee = /data/mysql/mysql_operation.log[mysqld]# Base Configserver_id = 108basedir = /usr/local/mysqldatadir = /data/mysql/datatmpdir = /data/mysql/tmpsecure_file_priv = /data/mysql/tmppid-file = mysqld.pidsocket = /data/mysql/data/mysql_3306.sockuser = mysqlport = 3306default_storage_engine = InnoDBcharacter_set_server = utf8mb4skip_slave_start = 1skip-name-resolve = 1skip-external-locking = 1lower_case_table_names = 1query_cache_type = 0query_cache_size = 0max_connections = 1000default-time-zone = '+8:00'log_timestamps = SYSTEM# InnoDB configinnodb_strict_mode = 1innodb_file_per_table = 1innodb_stats_on_metadata = 0innodb_flush_method = O_DIRECTinnodb_log_files_in_group = 3innodb_data_file_path = ibdata1:1G:autoextendinnodb_buffer_pool_size = 2Ginnodb_log_file_size = 512Minnodb_log_buffer_size = 64Minnodb_max_dirty_pages_pct = 60innodb_io_capacity = 400innodb_buffer_pool_instances = 8innodb_buffer_pool_load_at_startup = 1innodb_buffer_pool_dump_at_shutdown = 1innodb_undo_logs = 128innodb_undo_tablespaces = 3innodb_flush_neighbors = 1# Cache configkey_buffer_size = 8Mtmp_table_size = 64Mmax_heap_table_size = 64Mthread_cache_size = 1000table_open_cache = 2048open_files_limit = 65535max_allowed_packet = 64M# Log configlog_error = mysql-error.logslow_query_log_file = mysql-slow.logrelay-log = mysql-relaylog-bin = mysql-binslow_query_log = 1long_query_time = 0.2#log_slow_admin_statements = 1#log_slow_slave_statements = 1# Semisync configplugin-load = "rpl_semi_sync_master=semisync_master.so;rpl_semi_sync_slave=semisync_slave.so"rpl_semi_sync_master_enabled = 1rpl_semi_sync_slave_enabled = 1# Replication configslave-parallel-type = LOGICAL_CLOCKslave-parallel-workers = 8expire_logs_days = 14binlog_format = rowlog_slave_updates = ONbinlog_checksum = NONEmax_binlog_size = 250Mbinlog_cache_size = 2Msync_binlog = 1innodb_flush_log_at_trx_commit = 1relay-log-info-repository = TABLEmaster_info_repository = TABLErelay_log_recovery = 1binlog_rows_query_log_events = 1log_bin_trust_function_creators = 1# GTIDgtid-mode = ONenforce-gtid-consistency = 1# Performance Schemaperformance-schema-instrument = 'wait/lock/metadata/sql/mdl=ON'EOF## 安装软件依赖yum install libaio -y## 创建用户和组groupadd mysqluseradd -r -g mysql -s /bin/false mysql## 解压软件包并创建软连接tar -zxvf mysql-*-linux-glibc2.12-x86_64.tar.gz -C /usr/local/cd /usr/local/ln -s mysql-*-linux-glibc2.12-x86_64 mysql## 修改软件目录权限为mysql用户cd /usr/local/mysqlchown -R mysql:mysql .## 创建数据目录权限并修改权限为mysql用户mkdir -p /data/mysql/&#123;data,tmp,backup,slowlog_format&#125;chown -R mysql:mysql /data/mysql/## 拷贝启动脚本至系统启动目录cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld## 执行数据库初始化操作cd /usr/local/mysqlbin/mysqld --initialize --user=mysql## 启动MySQLsystemctl enable mysqldsystemctl start mysqldsystemctl status mysqld#systemctl disable mysqld/etc/init.d/mysqld start#数据库账户配置tempassword=`grep 'A temporary password' /data/mysql/data/mysql-error.log | awk -F"root@localhost: " '&#123; print $2&#125;' `mysql -S /data/mysql/data/mysql_3306.sock -uroot -p$&#123;tempassword&#125; --connect-expired-password &lt;&lt;EOFset password='$&#123;password1&#125;';exitEOFecho "***********************************************8"#创建数据库及账户mysql -S /data/mysql/data/mysql_3306.sock -uroot -p$&#123;password1&#125; --connect-expired-password &lt;&lt;EOFgrant REPLICATION CLIENT,replication slave on *.* to 'repl'@'%' identified by '$&#123;password2&#125;';create database $&#123;dbname&#125;;create user 'appuser'@'%' identified by '$&#123;password3&#125;';grant select,update,delete,insert on $&#123;dbname&#125;.* to 'appuser'@'%';create user 'readuser'@'%' identified by '$&#123;password4&#125;';grant select on $dbname.* to 'readuser'@'%';GRANT SELECT,SHOW VIEW,EVENT,TRIGGER,LOCK TABLES,RELOAD, PROCESS, SUPER, REPLICATION CLIENT ON *.* TO 'backup'@'127.0.0.1' identified by '$&#123;password5&#125;';GRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO 'zbx'@'127.0.0.1' identified by 'zabbix';exitEOF#重启mysql#/etc/init.d/mysqld restart#配置环境变量echo "#set mysql environment" &gt;&gt; ~/.bash_profileecho "export MYSQL_HOME=/usr/local/mysql" &gt;&gt; ~/.bash_profileecho "export PATH=\$PATH:\$HOME/bin:\$MYSQL_HOME/bin" &gt;&gt; ~/.bash_profilesource ~/.bash_profile#安装percona-xtrabackupcd $hometar -zxvf percona-xtrabackup-*-Linux-x86_64.tar.gzcp percona-xtrabackup-*-Linux-x86_64/bin/* /usr/local/bin/rm percona-xtrabackup-*-Linux-x86_64 -rfcp qpress /usr/local/bin/tar -zxvf scripts.tar.gzcp -r scripts /usr/local/mysql/#修改全备和增备的脚本文件中备份用户的端口和密码即可使用sed -i "1,10s|^MYSQL_BACKUP_PASS.*|MYSQL_BACKUP_PASS='$&#123;password5&#125;'|" /usr/local/mysql/scripts/mysqldump_schema_backup.shsed -i "1,10s|^MYSQL_BACKUP_PASS.*|MYSQL_BACKUP_PASS='$&#123;password5&#125;'|" /usr/local/mysql/scripts/slow_log_format.shsed -i "1,10s|^MYSQL_BACKUP_PASS.*|MYSQL_BACKUP_PASS='$&#123;password5&#125;'|" /usr/local/mysql/scripts/xtrabackup_checksum.shsed -i "1,10s|^MYSQL_BACKUP_PASS.*|MYSQL_BACKUP_PASS='$&#123;password5&#125;'|" /usr/local/mysql/scripts/xtrabackup_full_backup.shsed -i "1,10s|^MYSQL_BACKUP_PASS.*|MYSQL_BACKUP_PASS='$&#123;password5&#125;'|" /usr/local/mysql/scripts/xtrabackup_incr_backup.shsed -i "1,10s|^MYSQL_BACKUP_PASS.*|MYSQL_BACKUP_PASS='$&#123;password5&#125;'|" /usr/local/mysql/scripts/xtrabackup_recovery_prepare.sh#添加定时任务echo "0 0 * * 0 /usr/local/mysql/scripts/xtrabackup_full_backup.sh" &gt;&gt; /var/spool/cron/rootecho "0 0 * * 1-6 /usr/local/mysql/scripts/xtrabackup_incr_backup.sh" &gt;&gt; /var/spool/cron/rootecho "0 3 * * * /usr/local/mysql/scripts/slow_log_format.sh" &gt;&gt; /var/spool/cron/rootecho "0 4 * * * /usr/local/mysql/scripts/mysqldump_backup.sh" &gt;&gt; /var/spool/cron/root&#125;main()&#123; mysql_install&#125;main 生成的密码文件如下：1234567# cat password.txt root : o/FpOMHcM2YHt8GQrepl : TqOeLuFy1NO5zHLnappuser : 5GQzCFH6Qvc8VJ91readuser : NqMHHw0CZHsk5MzKzbx : zabbixbackup : DClBRGqCfg8MF26L 待优化！]]></content>
      <categories>
        <category>Scripts</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix监控JVM（微服务进程）]]></title>
    <url>%2Fposts%2F748ad64f.html</url>
    <content type="text"><![CDATA[ZabbixServer端配置Zabbix服务器需安装java，编译需添加启动参数–enable-java本次安装的编译参数为：1./configure --prefix=/data/zabbix/ --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2 --enable-java ZabbixAgent端配置ZabbixAgent端不仅需要安装zabbix_agentd，还需要安装zabbix_sender，可以通过地址http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/ 选择合适的版本。安装1rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-sender-3.0.9-1.el7.x86_64.rpm 监控原理微服务的特性： 每个进程是直接以java-jar service.jar的方式启动，并没有依赖于tomcat或者其他web应用。 每台服务器上的微服务并没有固定的数量，可以灵活的增加或者减少。 每个微服务的启动参数已有配置端口很多。 鉴于此种情况，传统的监控方法监控微服务，会造成经常的手动去增加删减web页面配置，服务器内的端口管理也会很混乱。所以使用discovery自动发现的方式去监控微服务。并将每个微服务的信息通过zabbix_sender发送到ZabbixServer端。首先java版本为jdk1.81234# java -versionjava version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 关于微服务的信息主要通过jstat获取，如下12345678910111213141516# ps -ef|grep javaroot 1891 1 0 Apr02 ? 00:09:38 java -Xms500M -Xmx500M -Xmn400M -XX:+PrintGCDetails -jar /data/work/service_jar/orderService.jar --server.port=14000 --management.port=14001 --config.profile=testroot 17860 1 0 Mar26 ? 00:27:17 java -Xms500M -Xmx500M -Xmn400M -XX:+PrintGCDetails -jar /data/work/service_jar/systemService.jar --server.port=21000 --management.port=21001 --config.profile=testroot 18444 1 0 Mar26 ? 00:39:28 java -Xms500M -Xmx500M -Xmn400M -XX:+PrintGCDetails -jar /data/work/service_jar/resourceService.jar --server.port=18000 --management.port=18001 --config.profile=testroot 18619 1 0 Mar26 ? 00:27:06 java -Xms500M -Xmx500M -Xmn400M -XX:+PrintGCDetails -jar /data/work/service_jar/userService.jar --server.port=13000 --management.port=13001 --config.profile=testroot 19601 1 0 Mar26 ? 00:22:37 java -Xms1000M -Xmx1000M -Xmn800M -jar /data/work/service_jar/manageMiddle.jar --server.port=20000 --management.port=20001 --config.profile=testroot 31282 17046 0 17:00 pts/3 00:00:00 grep --color=auto java# jstat -gc 1891 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 9216.0 8704.0 4320.0 0.0 391680.0 246746.7 102400.0 77473.4 83112.0 80407.4 9896.0 9400.6 94 1.742 3 0.762 2.504# jstat -gcutil 1891 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 46.88 0.00 63.00 75.66 96.75 94.99 94 1.742 3 0.762 2.504# jstat -gccapacity 1891 NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC 409600.0 409600.0 409600.0 9216.0 8704.0 391680.0 102400.0 102400.0 102400.0 102400.0 0.0 1122304.0 83112.0 0.0 1048576.0 9896.0 94 3 Jdk1.8中取消了永久区Perm 监控脚本脚本很多调试内容已注释，请忽略，脚本路径及内容：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209# pwd/etc/zabbix/scripts/java[root@gbw_test_app03 java]# cat jstat.py #!/usr/bin/env python#coding=utf-8'''功能: 调用jstat获取JVM的各项指标说明: 用于zabbix自动发现告警版本: V1.0 2019-04-01特性: 1. 线程功能，提高脚本执行速度'''import datetimeimport timeimport sysimport osimport commandsimport subprocessimport jsonimport argparseimport socketimport threadingjstat_cmd = commands.getoutput("which jstat")jstack_cmd = commands.getoutput("which jstack")jvmname_cmd = "jps|grep -Ev 'Jps|JStack|Jstat'|awk '&#123;print $2,$1&#125;'"jvmport_cmd = "netstat -tpnl|grep -oP '(?&lt;=:)\d+.*\d+(?=/java)'|awk '&#123;print $1,$NF&#125;'"hostname = socket.gethostname()zbx_sender='/usr/bin/zabbix_sender'zbx_cfg='/etc/zabbix/zabbix_agentd.conf'zbx_tmp_file='/etc/zabbix/scripts/java/.zabbix_jvm_status''''output=sys.stdoutoutputfile=open("/etc/zabbix/scripts/java/log.txt","a")sys.stdout=outputfilenow = time.time()t = time.localtime(int(now))dt = time.strftime("%Y%m%d%H%M%S", t)print dt'''jvm_threads = []def get_status(cmd,opts,pid): value = commands.getoutput('%s -%s %s' % (cmd,opts,pid)).strip().split('\n') #print value[0].split(' ') #print value[1].split(' ') #print filter(None, value[0].split(' ')) #print filter(None, value[1].split(' ')) if filter(None, value[0].split(' ')): if filter(None, value[1].split(' ')): kv = [] for i in filter(None, value[0].split(' ')): if i != '': kv.append(i) vv = [] for i in filter(None, value[1].split(' ')): if i != '': vv.append(i) data = dict(zip(kv,vv)) return data else: pass else: pass''' kv = [] for i in filter(None, value[0].split(' ')): if i != '': kv.append(i) vv = [] for i in filter(None, value[1].split(' ')): if i != '': vv.append(i) data = dict(zip(kv,vv)) return data'''def get_thread(cmd,pid): value = commands.getoutput('sudo %s %s|grep http|wc -l' % (cmd,pid)) data = &#123;"Thread":value&#125; return datadef get_jvm(jport,jprocess): ''' 使用jstat获取Java的性能指标 ''' file_truncate() # 清空zabbix_data_tmp gcutil_data = get_status(jstat_cmd,"gcutil",jprocess) gccapacity_data = get_status(jstat_cmd,"gccapacity",jprocess) gc_data = get_status(jstat_cmd,"gc",jprocess) thread_data = get_thread(jstack_cmd,jprocess) data_dict = dict(gcutil_data.items()+gccapacity_data.items()+gc_data.items()+thread_data.items()) for jvmkey in data_dict.keys(): zbx_data = "%s jvm[%s,%s] %s" %(hostname,jport,jvmkey,data_dict[jvmkey]) with open(zbx_tmp_file,'a') as file_obj: file_obj.write(zbx_data + '\n')def jvm_name_discovery(): output = subprocess.Popen(jvmname_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT) jvm_name_lists = output.stdout.readlines() jvm_name_proce = [] for jvm_name_tmp in jvm_name_lists: jvm_name_proce.append(jvm_name_tmp.split()) return jvm_name_procedef jvm_port_discovery(): output = subprocess.Popen(jvmport_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT) jvm_port_lists = output.stdout.readlines() jvm_port_proce = [] for jvm_port_tmp in jvm_port_lists: jvm_port_proce.append(jvm_port_tmp.split()) return jvm_port_proce def file_truncate(): ''' 用于清空zabbix_sender使用的临时文件 ''' with open(zbx_tmp_file,'w') as fn: fn.truncate()def zbx_tmp_file_create(): ''' 创建zabbix_sender发送的文件内容 ''' jvmname_list = jvm_name_discovery() for jvm_name_tmp in jvmname_list: jvmname = jvm_name_tmp[0] jvmprocess = jvm_name_tmp[1] th = threading.Thread(target=get_jvm,args=(jvmname,jvmprocess)) th.start() jvm_threads.append(th)def send_data_zabbix(): ''' 调用zabbix_sender命令，将收集的key和value发送至zabbix server ''' zbx_tmp_file_create() for get_jvmdata in jvm_threads: get_jvmdata.join() zbx_sender_cmd = "%s -c %s -i %s" %(zbx_sender,zbx_cfg,zbx_tmp_file) print zbx_sender_cmd zbx_sender_status,zbx_sender_result = commands.getstatusoutput(zbx_sender_cmd) #print zbx_sender_status print zbx_sender_resultdef zbx_name_discovery(): ''' 用于zabbix自动发现JVM名称 ''' jvm_zabbix = [] jvmname_list = jvm_name_discovery() for jvm_tmp in jvmname_list: jvm_zabbix.append(&#123;'&#123;#JNAME&#125;' : jvm_tmp[0], '&#123;#JPROCESS&#125;' : jvm_tmp[1], &#125;) return json.dumps(&#123;'data': jvm_zabbix&#125;, sort_keys=True, indent=7,separators=(',', ':'))def zbx_port_discovery(): ''' 用于zabbix自动发现JVM端口 ''' jvm_zabbix = [] jvmport_list = jvm_port_discovery() for jvm_tmp in jvmport_list: jvm_zabbix.append(&#123;'&#123;#JPORT&#125;' : jvm_tmp[0], '&#123;#JPROCESS&#125;' : jvm_tmp[1], &#125;) return json.dumps(&#123;'data': jvm_zabbix&#125;, sort_keys=True, indent=7,separators=(',', ':'))def cmd_line_opts(arg=None): class ParseHelpFormat(argparse.HelpFormatter): def __init__(self, prog, indent_increment=5, max_help_position=50, width=200): super(ParseHelpFormat, self).__init__(prog, indent_increment, max_help_position, width) parse = argparse.ArgumentParser(description='JVM监控"', formatter_class=ParseHelpFormat) parse.add_argument('--version', '-v', action='version', version="1.0", help='查看版本') parse.add_argument('--jvmname', action='store_true', help='获取JVM名称') parse.add_argument('--jvmport', action='store_true', help='获取JVM端口') parse.add_argument('--data', action='store_true', help='发送JVM指标数据至zabbix') if arg: return parse.parse_args(arg) if not sys.argv[1:]: return parse.parse_args(['-h']) else: return parse.parse_args()if __name__ == '__main__': opts = cmd_line_opts() if opts.jvmname: print zbx_name_discovery() elif opts.jvmport: print zbx_port_discovery() elif opts.data: send_data_zabbix() else: cmd_line_opts(arg=['-h']) 脚本使用方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# ./jstat.py -husage: jstat.py [-h] [--version] [--jvmname] [--jvmport] [--data]JVM监控"optional arguments: -h, --help show this help message and exit --version, -v 查看版本 --jvmname 获取JVM名称 --jvmport 获取JVM端口 --data 发送JVM指标数据至zabbix# ./jstat.py --version1.0# ./jstat.py --jvmname&#123; "data":[ &#123; "&#123;#JNAME&#125;":"manageMiddle.jar", "&#123;#JPROCESS&#125;":"19601" &#125;, &#123; "&#123;#JNAME&#125;":"orderService.jar", "&#123;#JPROCESS&#125;":"1891" &#125;, &#123; "&#123;#JNAME&#125;":"systemService.jar", "&#123;#JPROCESS&#125;":"17860" &#125;, &#123; "&#123;#JNAME&#125;":"userService.jar", "&#123;#JPROCESS&#125;":"18619" &#125;, &#123; "&#123;#JNAME&#125;":"resourceService.jar", "&#123;#JPROCESS&#125;":"18444" &#125; ]&#125;# ./jstat.py --jvmport&#123; "data":[ &#123; "&#123;#JPORT&#125;":"14000", "&#123;#JPROCESS&#125;":"1891" &#125;, &#123; "&#123;#JPORT&#125;":"18000", "&#123;#JPROCESS&#125;":"18444" &#125;, &#123; "&#123;#JPORT&#125;":"14001", "&#123;#JPROCESS&#125;":"1891" &#125;, &#123; "&#123;#JPORT&#125;":"18001", "&#123;#JPROCESS&#125;":"18444" &#125;, &#123; "&#123;#JPORT&#125;":"20000", "&#123;#JPROCESS&#125;":"19601" &#125;, &#123; "&#123;#JPORT&#125;":"20001", "&#123;#JPROCESS&#125;":"19601" &#125;, &#123; "&#123;#JPORT&#125;":"13000", "&#123;#JPROCESS&#125;":"18619" &#125;, &#123; "&#123;#JPORT&#125;":"21000", "&#123;#JPROCESS&#125;":"17860" &#125;, &#123; "&#123;#JPORT&#125;":"13001", "&#123;#JPROCESS&#125;":"18619" &#125;, &#123; "&#123;#JPORT&#125;":"21001", "&#123;#JPROCESS&#125;":"17860" &#125; ]&#125;# ./jstat.py --data/usr/bin/zabbix_sender -c /etc/zabbix/zabbix_agentd.conf -i /etc/zabbix/scripts/java/.zabbix_jvm_statusinfo from server: "processed: 170; failed: 0; total: 170; seconds spent: 0.001286"sent: 170; skipped: 0; total: 170 .zabbix_jvm_status文件中存储要发送到server端的值，文件的权限为：12# ll .zabbix_jvm_status -rw-r--rw- 1 root root 686 Apr 4 15:15 .zabbix_jvm_status 如果文件权限不是646，最好重新授权。文件内key值的解释为： NGCMN：新生代最小容量 NGCMX：新生代最大容量 NGC：当前新生代容量 OGCMN：老年代最小容量 OGCMX：老年代最大容量 OGC：当前老年代大小 MCMN：最小元数据容量 MCMX：最大元数据容量 MC：元数据空间大小 MU：元数据空间使用大小 M：元数据空间使用百分比 EC：Eden区大小 EU：Eden区使用大小 E：Eden区使用百分比 S0C：第一个幸存区大小 S0U：第一个幸存区使用大小 S0：第一个幸存区使用百分比 S1C：第二个幸存区大小 S1U：第二个幸存区使用大小 S1：第二个幸存区使用百分比 OC：老年代大小 OU：老年代使用大小 O：老年代使用百分比 CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：压缩类空间大小 CCSU：压缩类空间使用大小 CCS：压缩类空间使用百分比 YGCT：年轻代GC消耗时间 YGC：年轻代GC次数 FGCT：老年代GC消耗时间 FGC：老年代GC次数 GCT：GC消耗总时间 Thread：线程数 userparameter配置路径及内容如下12345# pwd/etc/zabbix/zabbix_agentd.d# cat userparameter_java_discovery_status.conf UserParameter=jvmname,/usr/bin/python /etc/zabbix/scripts/java/jstat.py --jvmnameUserParameter=jvmdata,/usr/bin/python /etc/zabbix/scripts/java/jstat.py --data zabbix_agentd.conf配置如下1234567891011# cat zabbix_agentd.conf |grep -Ev '^$|^#'PidFile=/var/run/zabbix/zabbix_agentd.pidLogFile=/var/log/zabbix/zabbix_agentd.logLogFileSize=0Server=172.19.138.53ListenPort=10050ServerActive=172.19.138.53Hostname=gbw_test_app03Timeout=10AllowRoot=1Include=/etc/zabbix/zabbix_agentd.d/ 为了防止脚本执行超时，出现报错ZBX_NOTSUPPORTED，修改默认Timeout=3为Timeout=10。AllowRoot=1是给Agent服务提升权限，并且会以root用户启动（默认为zabbix用户），这样是不安全的。在生产环境中不建议配置AllowRoot=1，使用以下方式替代：12345678ll /etc/sudoers-r--r----- 1 root root 3938 Sep 6 2017 /etc/sudoers# chmod 640 /etc/sudoers #修改可写权限# vim /etc/sudoers #添加下面这一句zabbix ALL=(ALL) NOPASSWD: ALL# chmod 440 /etc/sudoers #恢复权限# ll /etc/sudoers-r--r----- 1 root root 3937 Apr 3 17:20 /etc/sudoers 配置完成后重启agent客户端，确保是以zabbix用户启动。 模板配置模板地址：github地址Templates目录下 Template Jvm Process Dicovery.xml。导入模板关联主机即可。不再截图展示。最后可以通过命令获取值计算结果与zabbix获取结果进行校准。]]></content>
      <categories>
        <category>Monitor</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
        <tag>JVM</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervisor的作用与配置实例]]></title>
    <url>%2Fposts%2Ff0ff2220.html</url>
    <content type="text"><![CDATA[supervisor简介supervisor管理进程，是通过fork/exec的方式将这些被管理的进程当作supervisor的子进程来启动，所以我们只需要将要管理进程的可执行文件的路径添加到supervisor的配置文件中就好了。此时被管理进程被视为supervisor的子进程，若该子进程异常中断，则父进程可以准确的获取子进程异常中断的信息，通过在配置文件中设置autostart=ture，可以实现对异常中断的子进程的自动重启。 安装supervisorpip安装supervisord1pip install supervisor 生成配置文件1echo_supervisord_conf &gt; /etc/supervisord.conf 修改配置文件（分号;表示注释）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495[unix_http_server]file=/tmp/supervisor.sock ; the path to the socket filechmod=0700 ; sockef file mode (default 0700)# 开启web界面[inet_http_server] ; inet (TCP) server disabled by defaultport=*:9001 ; ip_address:port specifier, *:port for all ifaceusername=admin ; default is no username (open server)password=123456 ; default is no password (open server)[supervisord]logfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.loglogfile_maxbytes=50MB ; max main logfile bytes b4 rotation; default 50MBlogfile_backups=10 ; # of main logfile backups; 0 means none, default 10loglevel=info ; log level; default info; others: debug,warn,tracepidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pidnodaemon=false ; start in foreground if true; default falseminfds=1024 ; min. avail startup file descriptors; default 1024minprocs=200 ; min. avail process descriptors;default 200[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket[program:zookeeper]command=/data/confluent/bin/zookeeper-server-start /data/confluent/etc/kafka/zookeeper.properties ; 管理命令，supervisor不支持后台进程process_name=%(program_name)suser=root ;进程启动用户autostart=true ;是否随supervisor启动autorestart=true ;是否在挂了之后重启，意外关闭后会重启，比如kill掉！startretries=3 ;启动尝试次数stderr_logfile=/tmp/tail1.err.log ;标准输出的位置stdout_logfile=/tmp/tail1.out.log ;标准错误输出的位置loglevel=info ;日志的级别[program:kafka]command=/data/confluent/bin/kafka-server-start /data/confluent/etc/kafka/server.properties ;管理命令，supervisor不支持后台进程process_name=%(program_name)suser=root ;进程启动用户autostart=true ;是否随supervisor启动autorestart=true ;是否在挂了之后重启，意外关闭后会重启，比如kill掉！startretries=3 ;启动尝试次数stderr_logfile=/tmp/tail2.err.log ;标准输出的位置stdout_logfile=/tmp/tail2.out.log ;标准错误输出的位置loglevel=info ;日志的级别[program:schema-registry]command=/data/confluent/bin/schema-registry-start /data/confluent/etc/schema-registry/schema-registry.properties ;管理命令，supervisor不支持后台进程process_name=%(program_name)suser=root ;进程启动用户autostart=true ;是否随supervisor启动autorestart=true ;是否在挂了之后重启，意外关闭后会重启，比如kill掉！startretries=3 ;启动尝试次数stderr_logfile=/tmp/tail3.err.log ;标准输出的位置stdout_logfile=/tmp/tail3.out.log ;标准错误输出的位置loglevel=info ;日志的级别[program:kafka-rest]command=/data/confluent/bin/kafka-rest-start /data/confluent/etc/kafka-rest/kafka-rest.properties ;管理命令，supervisor不支持后台进程process_name=%(program_name)suser=root ;进程启动用户autostart=true ;是否随supervisor启动autorestart=true ;是否在挂了之后重启，意外关闭后会重启，比如kill掉！startretries=3 ;启动尝试次数stderr_logfile=/tmp/tail4.err.log ;标准输出的位置stdout_logfile=/tmp/tail4.out.log ;标准错误输出的位置loglevel=info ;日志的级别[program:connect]command=/data/confluent/bin/connect-distributed /data/confluent/etc/schema-registry/connect-avro-distributed.properties ;管理命令，supervisor不支持后台进程 process_name=%(program_name)suser=root ;进程启动用户autostart=true ;是否随supervisor启动autorestart=true ;是否在挂了之后重启，意外关闭后会重启，比如kill掉！startretries=3 ;启动尝试次数stderr_logfile=/tmp/tail5.err.log ;标准输出的位置stdout_logfile=/tmp/tail5.out.log ;标准错误输出的位置loglevel=info ;日志的级别[program:ksql-server]command=/data/confluent/bin/ksql-server-start /data/confluent/etc/ksql/ksql-server.properties ;管理命令，supervisor不支持后台进程process_name=%(program_name)suser=root ;进程启动用户autostart=true ;是否随supervisor启动autorestart=true ;是否在挂了之后重启，意外关闭后会重启，比如kill掉！startretries=3 ;启动尝试次数stderr_logfile=/tmp/tail6.err.log ;标准输出的位置stdout_logfile=/tmp/tail6.out.log ;标准错误输出的位置loglevel=info ;日志的级别[program:control-center]command=/data/confluent/bin/control-center-start /data/confluent/etc/confluent-control-center/control-center-dev.properties ;管理命令，supervisor不支持后台进程 process_name=%(program_name)suser=root ;进程启动用户autostart=true ;是否随supervisor启动autorestart=true ;是否在挂了之后重启，意外关闭后会重启，比如kill掉！startretries=3 ;启动尝试次数stderr_logfile=/tmp/tail7.err.log ;标准输出的位置stdout_logfile=/tmp/tail7.out.log ;标准错误输出的位置loglevel=info ;日志的级别[include]files=/etc/supervisor/conf.d/*.conf 以上配置文件用到几个部分：[unix_http_server]：这部分设置HTTP服务器监听的UNIX domain socket file：指向UNIX domain socket，即file=/tmp/supervisor.sock chmod：启动时改变supervisor.sock的权限 [supervisord]：与supervisord有关的全局配置需要在这部分设置 logfile: 指向记录supervisord进程的log文件 pidfile：pidfile保存子进程的路径 childlogdir：子进程log目录设为AUTO的log目录 [supervisorctl]： serverurl：进入supervisord的URL， 对于UNIX domain sockets, 应设为unix:///tmp/supervisor.sock [include]：如果配置文件包含该部分，则该部分必须包含一个files键： files：包含一个或多个文件，这里包含了/etc/supervisor/conf.d/ 目录下所有的.conf文件，可以在该目录下增加我们自己的配置文件，在该配置文件中增加[program:x]部分，用来运行我们自己的程序，如下：[program:x]：配置文件必须包括至少一个program，x是program名称，必须写上，不能为空 command：包含一个命令，当这个program启动时执行 directory：执行子进程时supervisord暂时切换到该目录 user：账户名 startsecs：进程从STARING状态转换到RUNNING状态program所需要保持运行的时间（单位：秒） redirect_stderr：如果是true，则进程的stderr输出被发送回其stdout文件描述符上的supervisord stdout_logfile：将进程stdout输出到指定文件 stdout_logfile_maxbytes：stdout_logfile指定日志文件最大字节数，默认为50MB，可以加KB、MB或GB等单位 stdout_logfile_backups：要保存的stdout_logfile备份的数量 为了方便查看，在此配置文件中直接将[program:x]写在主配置文件，示例中几个服务为confluent kafka的启动进程。启动1supervisord -c /etc/supervisord.conf 启动完成后验证服务、进程、端口是否正常。关闭:1supervisorctl shutdown 管理命令（”-c /etc/supervisord.conf”可以省略）123456789101112supervisorctl -c /etc/supervisord.conf status #查看状态supervisorctl -c /etc/supervisord.conf reload #重新载入配置文件supervisorctl -c /etc/supervisord.conf start [all]|[x] #启动所有/指定的程序进程supervisorctl -c /etc/supervisord.conf stop [all]|[x] #关闭所有/指定的程序进程 supervisorctl stop program_name # 停止某一个进程，program_name 为 [program:x] 里的 xsupervisorctl start program_name # 启动某个进程supervisorctl restart program_name # 重启某个进程supervisorctl stop groupworker: # 结束所有属于名为 groupworker 这个分组的进程 (start，restart 同理)supervisorctl stop groupworker:name1 # 结束 groupworker:name1 这个进程 (start，restart 同理)supervisorctl stop all # 停止全部进程，注：start、restartUnlinking stale socket /tmp/supervisor.sock、stop 都不会载入最新的配置文件supervisorctl reload # 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程supervisorctl update # 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启 安装supervisord-monitor（可选）supervisord-monitor是对supervisord的一个集中化管理工具，可以对supervisor统一化操作。12345#下载git clone https://github.com/mlazarov/supervisord-monitor.git# 生成配置文件cd supervisord-monitor/cp application/config/supervisor.php.example application/config/supervisor.php 修改配置文件，添加supervisord主机展示名url服务器地址port端口12345678$config['supervisor_servers'] = array( 'host103' =&gt; array( 'url' =&gt; 'http://localhost/RPC2', 'port' =&gt; '9001', 'username' =&gt; 'admin', 'password' =&gt; '123456' ),); 添加nginx对supervisord-monitor的支持1234567891011121314151617181920server &#123; listen 82; server_name localhost; set $web_root /data/supervisord-monitor/public_html; root $web_root; index index.php index.html index.htm; location / &#123; try_files $uri $uri/ /index.php; &#125; location ~ \.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $web_root$fastcgi_script_name; fastcgi_param SCHEME $scheme; &#125; &#125; 重启nginx后，访问即可。]]></content>
      <categories>
        <category>Service</category>
        <category>Supervisor</category>
      </categories>
      <tags>
        <tag>Supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rsync搭配inotify实现服务器之间数据实时同步]]></title>
    <url>%2Fposts%2F68c5ac4c.html</url>
    <content type="text"><![CDATA[简介rsync如果你man一下sync的话，就会发现：sync-flush file system buffers，它是一个把缓冲区中的数据同步到文件系统中的一个命令；而rsync其实就是remote rsync，它是一个远程同步工具，兼具cp和scp的功能，rsync命令的使用几乎和scp是一样一样的。rsync是通过超级守护进程xinetd进行触发同步的。 优点：与cp和scp相比来说，rsync更快，更安全，支持增量备份。rsync在数据同步的过程中，不像cp一样全部都拷贝，而是先去比对特征码，只有不一样的才会去拷贝，如果一样了，就不需再做多余操作。通过使用rsync+crontab可以解决对实时性要求不是太高的场景。 缺点：在这个大数据年代，如果你的数据量非常大，你每做一次任务计划，rsync都会先去遍历目标目录，把所有数据做一次特征码比对，然后进行差量传输，这个过程会是很漫长的，对于那些要求实时性更新比较高的企业来说，无疑是一场噩梦。但是如果能够出现一个工具能够实时的去监控我们的文件系统，只有在数据改变时才会触发它去同步，那该有多好啊！为了满足广大需求者的心声rsync+inotify组合就出现了 inotifyInotify 是一种强大的、细粒度的、异步的文件系统事件监控机制，linux内核从2.6.13起，加入了Inotify支持，通过Inotify可以监控文件系统中添加、删除，修改、移动等各种细微事件，利用这个内核接口，第三方软件就可以监控文件系统下文件的各种变化情况，而inotify-tools就是这样的一个第三方软件。 rsync+inotify之推荐理由服务器性能：rsync+crontab会定时去检查是否有文件更新，这势必会造成服务器性能下降；而rsync+inotify组合是触发式更新，只有在数据文件有变化时，才会去更新，因此相对前者而言，是提高了服务器性能 数据实时性：rsync+crontab是周期性任务计划，不能保证数据的实时性；rsync+inotify组合是触发式更新，只要有数据变化，就立刻同步更新 搭建环境配置 服务器 系统 IP 软件 服务端 CnetOS7.6 172.18.19.47 rsync 客户端 CentOS7.6 172.18.19.46 rsync、inotify 服务端配置安装1yum -y install rsync 配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# cat /etc/rsyncd.conf |grep -Ev '^$|^#'uid = rootgid = rootuse chroot = yesmax connections = 5pid file = /var/run/rsyncd.pidlockfile = /var/run/rsyncd.locklog file = /var/log/rsyncd.logtimeout = 900[nginx_ssl]path = /data/nginx/ssl ignore errors = yes read only = no write only = no hosts allow = 172.18.19.46 hosts deny = * list = yes uid = root gid = rootauth users = sg01 secrets file = /etc/sg01.passwd [nginx_conf]path = /data/nginx/conf ignore errors = yes read only = no write only = no hosts allow = 172.18.19.46 hosts deny = * list = yes uid = root gid = rootauth users = sg01 secrets file = /etc/sg01.passwd [work_html_sg]path = /data/work/html_sg ignore errors = yes read only = no write only = no hosts allow = 172.18.19.46 hosts deny = * list = yes uid = root gid = rootauth users = sg01 secrets file = /etc/sg01.passwd [work_service_jar]path = /data/work/service_jar ignore errors = yes read only = no write only = no hosts allow = 172.18.19.46 hosts deny = * list = yes uid = root gid = rootauth users = sg01 secrets file = /etc/sg01.passwd [work_shell]path = /data/work/shell ignore errors = yes read only = no write only = no hosts allow = 172.18.19.46 hosts deny = * list = yes uid = root gid = rootauth users = sg01 secrets file = /etc/sg01.passwd 配置rsync认证文件/etc/web.passwd123# echo "sg01:123456" &gt; /etc/sg01.passwd# cat /etc/sg01.passwdsg01:123456 在实际过程中用户可以自定义，并提高密码复杂度。修改/etc/sg01.passwd的权限为600123# chmod 600 /etc/sg01.passwd# ll /etc/sg01.passwd-rw------- 1 root root 12 Mar 27 15:25 /etc/sg01.passwd 启动1234567891011# systemctl start rsyncd #启动服务# ps -ef | grep rsync #检查进程root 28008 1 0 14:13 ? 00:00:00 /usr/bin/rsync --daemon --no-detachroot 28115 4478 0 14:15 pts/0 00:00:00 grep --color=auto rsync# netstat -tnpl #检查873端口Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 21265/sshd tcp 0 0 0.0.0.0:873 0.0.0.0:* LISTEN 28008/rsync tcp6 0 0 :::873 :::* LISTEN 28008/rsync tcp6 0 0 :::3306 :::* LISTEN 15971/mysqld 客户端配置安装rsync、inotify1yum install rsync inotify-tools -y 设置rsync客户端的密码文件，客户端只需要设置rsync同步的密码即可，不用设置用户名。123# echo 123456 &gt; /etc/sg01.passwd# cat /etc/sg01.passwd123456 修改/etc/sg01.passwd的权限为600123# chmod 600 /etc/sg01.passwd# ll /etc/sg01.passwd-rw------- 1 root root 7 Mar 27 15:26 /etc/sg01.passwd 在客户端上测试能否同步文件1234rsync --password-file=/etc/sg01.passwd /etc/fstab sg01@172.18.19.47::work_shell#将客户端文件上传到服务端 rsync --password-file=/etc/sg01.passwd sg01@172.18.19.47::work_shell/fstab /data/backup/#将服务端的文件下载到客户端 可以查看服务端work_shell模块即目录/data/work/shell和本地/data/backup目录中是否有文件fstab。客户端同步脚本内容123456789101112131415161718192021222324252627282930313233343536373839# cat /data/scripts/autorsync.sh #!/bin/bash#Author:Francislist=(1 2 3 4 5)array_src=(1 2 3 4 5)array_src[1]=/data/nginx/ssl/array_src[2]=/data/nginx/conf/array_src[3]=/data/work/html_sg/array_src[4]=/data/work/service_jar/array_src[5]=/data/work/shell/array_des=(1 2 3 4 5)array_des[1]=nginx_sslarray_des[2]=nginx_confarray_des[3]=work_html_sgarray_des[4]=work_service_jararray_des[5]=work_shellhost=172.18.19.47user=sg01:&lt;&lt;'for i in $&#123;list[*]&#125;;do /usr/bin/rsync -vzrtopg --delete --progress $&#123;array_src[$i]&#125; $user@$host::$&#123;array_des[$i]&#125; --password-file=/etc/sg01.passwddone'for i in $&#123;list[*]&#125;;do&#123; /usr/bin/inotifywait -mrq --timefmt '%d/%m/%y %H:%M' --format '%T %w %f' -e modify,delete,create,attrib $&#123;array_src[$i]&#125; | while read file DATE TIME DIR; do /usr/bin/rsync -vzrtopg --delete --progress $&#123;array_src[$i]&#125; $user@$host::$&#123;array_des[$i]&#125; --password-file=/etc/sg01.passwd #echo " $&#123;file&#125; was rsynced" &gt;&gt;/tmp/autorsync.log 2&gt;&amp;1 done&#125; &amp;donewait 将脚本以后台方式启动1nohup sh autorsync.sh &amp; 脚本使用多进程方式，批量停止1ps -ef|grep autorsync|grep -v grep | awk '&#123;print $2&#125;'| xargs kill -9 测试在客户端目录/data/nginx/ssl/、/data/nginx/conf/、/data/work/html_sg/、/data/work/service_jar/、/data/work/shell/中进行文件修改、创建、删除等操作，来查看服务端对应的目录文件是否同步成功。]]></content>
      <categories>
        <category>OS</category>
        <category>Command&amp;Tool</category>
      </categories>
      <tags>
        <tag>rsync</tag>
        <tag>inotify</tag>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装配置Kubernetes集群]]></title>
    <url>%2Fposts%2Faba522df.html</url>
    <content type="text"><![CDATA[Kubernetes集群组件: etcd：一个高可用的K/V键值对存储和服务发现系统 flannel：实现夸主机的容器网络的通信 kube-apiserver：提供kubernetes集群的API调用 kube-controller-manager：确保集群服务 kube-scheduler：调度容器，分配到Node kubelet：在Node节点上按照配置文件中定义的容器规格启动容器 kube-proxy：提供网络代理服务 节点信息 节点 IP 服务 master 10.186.61.103 etcd、apiserver、controller-manager、scheduler、config node01 10.186.60.60 etcd、flannel、docker、kubelet、kube-proxy node02 10.186.65.43 etcd、flannel、docker、kubelet、kube-proxy 准备工作以下步骤所有节点服务器都需要执行 关闭SELINUX关闭SELINUX，可以解决程序安装然后不执行的问题。12345#修改配置文件vim /etc/selinux/config#设定不可用SELINUX=disabled 关闭防火墙测试安装时候可以关闭防火墙，以防止因防火墙问题出现的故障，正式环境如果启用，根据需求配置。12345systemctl stop firewalld.servicesystemctl disable firewalld.service#查看防火墙状态systemctl status firewalld 修改hostname更改hostname为master、node1、node2，配置所有测试机的/etc/hosts文件12345# cat /etc/hosts10.186.61.103 master10.186.60.60 node0110.186.65.43 node02 安装epel源1yum -y install epel-release 软件升级1yum update 时间校对1234yum install ntpsystemctl start ntpd;systemctl enable ntpdntpdate ntp1.aliyun.comhwclock 时间同步的地址可以选择其他地址，本次使用阿里云的时间服务器地址，更多配置请参考：搭建内网NTP时间服务器。 master节点安装安装flannel123456789101112#安装yum install -y flannel#配置# cat flanneld |grep -Ev '^#|^$'FLANNEL_ETCD_ENDPOINTS="http://10.186.61.103:2379"FLANNEL_ETCD_PREFIX="/atomic.io/network"FLANNEL_OPTIONS="--logtostderr=false --log_dir=/var/log/k8s/flannel/ --etcd-prefix=/atomic.io/network --etcd-endpoints=http://10.186.61.103:2379 --iface=eth0" #查看网络ifconfig#信息较长，此处不再展示 安装etcd1234567891011121314151617181920212223242526272829303132#安装yum install etcd #启动服务 systemctl start etcd #开机启动systemctl enable etcd#获取节点数据，看自身是否可用，然后再进行下一步，配置ETCD的操作（很重要，不进行这步，容易发生错误，不知道是那个地方的问题） etcdctl get /#配置etcdvim /etc/etcd/etcd.conf#配置文件#[Member]ETCD_DATA_DIR="/var/lib/etcd/default.etcd"ETCD_LISTEN_PEER_URLS="http://0.0.0.0:2380"ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"ETCD_NAME="default"#[Clustering]ETCD_ADVERTISE_CLIENT_URLS="http://10.186.61.103:2379"ETCD_INITIAL_CLUSTER="default=http://10.186.61.103:2380"ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"ETCD_INITIAL_CLUSTER_STATE="new"#重启服务systemctl restart etcd #设定容器网络etcdctl set /atomic.io/network/config '&#123;"Network":"172.17.11.1/16"&#125;' 其中网络号172.17.11.1/16与docker中的docker0网络一致（若不一致，可修改docker0网络或者配置上述etcd网络）;atomic.io与下面的Flannel配置中的FLANNEL_ETCD_PREFIX对应。12# etcdctl get /atomic.io/network/config&#123;"Network":"172.17.11.1/16"&#125; 安装kubernetes-master1yum install kubernetes-master 配置apiserver配置文件/etc/kubernetes/apiserver，内容包括：绑定主机的IP地址、端口号、etcd服务地址、Service所需的Cluster IP池、一系列admission控制策略等。 -insecure-bind-address参数默认为127.0.0.1，即API-server绑定的安全IP只有127.0.0.1，相当于一个白名单，修改成-insecure-bind-address=0.0.0.0后，表示运行所有节点进行访问。 去掉SecurityContextDeny,ServiceAccount，这是权限相关的,测试时候不需要添加。 123456# cat /etc/kubernetes/apiserver |grep -Ev '^#|^$'KUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"KUBE_ETCD_SERVERS="--etcd-servers=http://10.186.61.103:2379"KUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=10.254.0.0/16"KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"KUBE_API_ARGS="" 配置Kubernate全局配置文件/etc/kubernetes/config，文件的内容为所有服务都需要的参数。12345# cat /etc/kubernetes/config |grep -Ev '^#|^$'KUBE_LOGTOSTDERR="--logtostderr=true"KUBE_LOG_LEVEL="--v=0"KUBE_ALLOW_PRIV="--allow-privileged=false"KUBE_MASTER="--master=http://10.186.61.103:8080" 配置kube-controller-manager配置文件12# grep -Ev '^#|^$' /etc/kubernetes/controller-managerKUBE_CONTROLLER_MANAGER_ARGS="" 配置kube-scheduler配置文件12# grep -Ev '^#|^$' /etc/kubernetes/scheduler KUBE_SCHEDULER_ARGS="--address=0.0.0.0" 启动服务1234567891011121314151617#让配置生效systemctl daemon-reload#启动服务systemctl start etcd kube-apiserver.service kube-controller-manager kube-scheduler#重启服务systemctl restart etcd kube-apiserver.service kube-controller-manager kube-scheduler#设定开机启动systemctl enable etcd kube-apiserver.service kube-controller-manager kube-scheduler#通过systemctl status 来验证服务启动的状态。#日志查看cat /var/log/messages |grep kube 测试master123456789101112131415161718192021222324252627282930313233343536373839# curl 127.0.0.1:8080&#123; "paths": [ "/api", "/api/v1", "/apis", "/apis/apps", "/apis/apps/v1beta1", "/apis/authentication.k8s.io", "/apis/authentication.k8s.io/v1beta1", "/apis/authorization.k8s.io", "/apis/authorization.k8s.io/v1beta1", "/apis/autoscaling", "/apis/autoscaling/v1", "/apis/batch", "/apis/batch/v1", "/apis/batch/v2alpha1", "/apis/certificates.k8s.io", "/apis/certificates.k8s.io/v1alpha1", "/apis/extensions", "/apis/extensions/v1beta1", "/apis/policy", "/apis/policy/v1beta1", "/apis/rbac.authorization.k8s.io", "/apis/rbac.authorization.k8s.io/v1alpha1", "/apis/storage.k8s.io", "/apis/storage.k8s.io/v1beta1", "/healthz", "/healthz/ping", "/healthz/poststarthook/bootstrap-controller", "/healthz/poststarthook/extensions/third-party-resources", "/healthz/poststarthook/rbac/bootstrap-roles", "/logs", "/metrics", "/swaggerapi/", "/ui/", "/version" ]&#125; node节点安装以下安装操作node01和node02一样，涉及ip地址的请根据实际修改，以node01为例。 docker安装12345678910yum install docker #查看版本好，看docker是否安装成功docker version#设定开机启动systemctl enable docker #启动docker服务systemctl start docker 安装Flannel安装配置123456789101112131415161718192021222324252627#安装yum install flannel#具体配置vim /etc/sysconfig/flanneld#设定etcd的服务地址FLANNEL_ETCD_ENDPOINTS=&quot;http://10.186.61.103:2379&quot;#设置etcd设定的网络信息FLANNEL_ETCD_PREFIX=&quot;/atomic.io/network&quot;#这个是设定flanneld的启动参数FLANNEL_OPTIONS=&quot;--logtostderr=false --log_dir=/var/log/k8s/flannel/ --etcd-prefix=/atomic.io/network --etcd-endpoints=http://10.186.61.103:2379 --iface=eth0&quot;#配置完成后需要重启flanneldsystemctl start flanneld#设定开机启动systemctl enable flanneld#重启docker，这样就可以引用flanneld的网桥配置了systemctl restart docker#ifconfig 查看flannel0 是否出来了，配置是否正确ifconfig 验证网络验证是需要在master节点上执行123456789101112[root@master ~]# etcdctl get /atomic.io/network/config &#123;"Network":"172.17.11.1/16"&#125;[root@master ~]# etcdctl ls /atomic.io/network/subnets/atomic.io/network/subnets/172.17.102.0-24/atomic.io/network/subnets/172.17.11.0-24/atomic.io/network/subnets/172.17.55.0-24[root@master ~]# etcdctl get /atomic.io/network/subnets/172.17.11.0-24&#123;"PublicIP":"10.186.61.103"&#125;[root@master ~]# etcdctl get /atomic.io/network/subnets/172.17.55.0-24&#123;"PublicIP":"10.186.60.60"&#125;[root@master ~]# etcdctl get /atomic.io/network/subnets/172.17.102.0-24&#123;"PublicIP":"10.186.65.43"&#125; 10.186.60.60为node01地址，10.186.65.43为node02地址，网络验证通过。 安装kubernetes-node安装1yum install kubernetes-node 配置kubernetes12345# cat /etc/kubernetes/config |grep -Ev '^#|^$'KUBE_LOGTOSTDERR="--logtostderr=true"KUBE_LOG_LEVEL="--v=0"KUBE_ALLOW_PRIV="--allow-privileged=false"KUBE_MASTER="--master=http://10.186.61.103:8080" 配置kubelet组件12345678910111213141516vim /etc/kubernetes/kubeletKUBELET_ADDRESS="--address=0.0.0.0"# 配置本机的地址KUBELET_HOSTNAME="--hostname-override=10.186.60.60"# 配置apiserver api-server服务地址KUBELET_API_SERVER="--api-servers=http://10.186.61.103:8080"# 配置pod infrastructure container地址#KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest"KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=10.186.61.103:5000/pod-infrastructure:latest"# Add your own!KUBELET_ARGS="" 其中KUBELET_POD_INFRA_CONTAINER配置由于使用原来的地址，下载速度太慢，所以配置实用集群内仓库地址，搭建集群内仓库地址请参考：为Kubernetes集群部署本地镜像仓库。此处如果使用本地仓库地址，需要加本地仓库地址加入docker配置，如下：1234567891011# cat /etc/docker/daemon.json &#123;"registry-mirrors": [ "https://2lqq34jg.mirror.aliyuncs.com", "https://pee6w651.mirror.aliyuncs.com", "https://registry.docker-cn.com", "http://hub-mirror.c.163.com"], "dns": ["8.8.8.8","8.8.4.4"], "insecure-registries":["10.186.61.103:5000"]&#125; 配置proxy12# cat /etc/kubernetes/proxy |grep -Ev '^$|^#'KUBE_PROXY_ARGS="--bind=address=0.0.0.0" 启动服务12345#启动服务systemctl start kubelet kube-proxy#设定开机启动systemctl enable kubelet kube-proxy 测试集群在master节点运行12345678# kubectl get nodesNAME STATUS AGE10.186.60.60 Ready 8d10.186.65.43 Ready 8d# kubectl -s http://10.186.61.103:8080 get nodesNAME STATUS AGE10.186.60.60 Ready 8d10.186.65.43 Ready 8d 如上信息表示节点正常。]]></content>
      <categories>
        <category>VT</category>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>集群</tag>
        <tag>CentOS7</tag>
        <tag>etcd</tag>
        <tag>flannel</tag>
        <tag>kube-apiserver</tag>
        <tag>kube-controller-manager</tag>
        <tag>kube-scheduler</tag>
        <tag>kubelet</tag>
        <tag>kube-proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为Kubernetes集群部署本地镜像仓库]]></title>
    <url>%2Fposts%2F1b893487.html</url>
    <content type="text"><![CDATA[在搭建Kubernetes集群的时候，为了方便部署，可以搭建一个集群内的私有镜像仓库。 安装docker123yum install dockersystemctl enable dockersystemctl start docker 拉取registry镜像1234567891011121314# docker pull docker.io/registry Using default tag: latestTrying to pull repository docker.io/library/registry ... sha256:0e40793ad06ac099ba63b5a8fae7a83288e64b50fe2eafa2b59741de85fd3b97: Pulling from docker.io/library/registryb7f33cc0b48e: Pull complete 46730e1e05c9: Pull complete 458210699647: Pull complete 0cf045fea0fd: Pull complete b78a03aa98b7: Pull complete Digest: sha256:0e40793ad06ac099ba63b5a8fae7a83288e64b50fe2eafa2b59741de85fd3b97Status: Downloaded newer image for docker.io/registry:latest# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/registry latest d1e32b95d8e8 4 weeks ago 33.17 MB 启动registry1docker run -d -p 5000:5000 --name=registry --restart=always --privileged=true --log-driver=none -v /data/registrydata:/var/lib/registry registry 其中/data/registrydata为本地目录，/var/lib/registry为镜像内目录。不确定镜像中对应的目录可以使用docker inspect registry查看images的具体信息。Volumes字段确定镜像内的具体目录。 更改名称并推送12345678910docker search pod-infrastructuredocker search kubernetes-dashboard-amd64docker pull docker.io/zengshaoyong/pod-infrastructuredocker pull docker.io/siriuszg/kubernetes-dashboard-amd64docker imagesdocker tag docker.io/zengshaoyong/pod-infrastructure 10.186.61.103:5000/pod-infrastructuredocker tag docker.io/siriuszg/kubernetes-dashboard-amd64 10.186.61.103:5000/kubernetes-dashboard-amd64docker imagesdocker push 10.186.61.103:5000/pod-infrastructuredocker push 10.186.61.103:5000/kubernetes-dashboard-amd64 push完镜像后可以从本机的挂载目录查看镜像仓库：123456# pwd/data/registrydata# ll docker/registry/v2/repositories/total 0drwxr-xr-x 5 root root 55 Mar 20 11:02 kubernetes-dashboard-amd64drwxr-xr-x 5 root root 55 Mar 20 11:01 pod-infrastructure 可以看到上述信息。 更改镜像地址pod-infrastructure是在node的kubelet配置文件中定义的，要更改每个node中/etc/kubernetes/kubelet中对应的KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot;为KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=10.186.61.103:5000/pod-infrastructure:latest&quot;。更改之后需要重启kubelet服务。Dashboard是在yaml中定义的，要更改dashboard.yaml中对应的image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.5.1为image: 0.186.61.103:5000/kubernetes-dashboard-amd64:latest。]]></content>
      <categories>
        <category>VT</category>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Kubernetes</tag>
        <tag>仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Crontab安装和使用实例]]></title>
    <url>%2Fposts%2F1ca10132.html</url>
    <content type="text"><![CDATA[简介Linux crontab和Windows task schedules非常的相似。Crontab可以用来在系统中定期的执行任务。比如：写了一个爬虫需要每天早上八点执行，就可以用到Crontab;安装的Tomcat服务器需要每天凌晨重启一次，也可以使用到Crontab。总之，几乎所有的定时任务，我们都可以通过Crontab这个工具来完成。crontab命令常见于Unix和Linux的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行。通常，crontab储存的指令被守护进程激活。crond 常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。 安装12yum -y install vixie-cronyum -y install crontabs 说明： vixie-cron 软件包是 cron 的主程序； crontabs 软件包是用来安装、卸装、或列举用来驱动 cron 守护进程的表格的程序。 配置cron是linux的内置服务，但它不自动起来，可以用以下的方法启动、关闭这个服务：12345service crond start //启动服务service crond stop //关闭服务service crond restart //重启服务service crond reload //重新载入配置service crond status //查看crontab服务状态 在CentOS系统中加入开机自动启动:1chkconfig --level 345 crond on 限制对cron的使用/etc/cron.allow和/etc/cron.deny文件被用来限制对 cron 的使用。 这两个使用控制文件的格式都是每行一个用户。 两个文件都不允许空格。 如果使用控制文件被修改了，cron守护进程（crond）不必被重启。 使用控制文件在每次用户添加或删除一项 cron 任务时都会被读取。 无论使用控制文件中的规定如何root都总是可以使用cron。 如果cron.allow文件存在，只有其中列出的用户才被允许使用cron，并且cron.deny文件会被忽略。 如果cron.allow文件不存在，所有在cron.deny中列出的用户都被禁止使用cron。 crontab命令功能：设置计时器。语法：crontab[-u &lt;用户名称&gt;][配置文件] 或 crontab [-u &lt;用户名称&gt;][-elr]解释：cron 是一个常驻服务，它提供计时器的功能，让用户在特定的时间得以执行预设的指令或程序。只要用户会编辑计时器的配置文件，就可以使 用计时器的功能。其配置文件格式如下：Minute Hour Day Month DayOFWeek Command参数：-e 编辑该用户的计时器设置。-l 列出该用户的计时器设置。-r 删除该用户的计时器设置。-u &lt;用户名称&gt; 指定要设定计时器的用户名称。查看当前系统登录用户的Crontab命令集合1crontab -l 查看其他用户的Crontab命令集合1crontab -u username -l 格式：12* * * * * command分 时 日 月 周 命令 123456第1列表示分钟1～59 每分钟用*或者 */1表示第2列表示小时1～23（0表示0点）第3列表示日期1～31第4列表示月份1～12第5列标识号星期0～6（0表示星期天）第6列要运行的命令 实例每天02:00执行任务10 2 * * * /bin/sh backup.sh 每天5:00和17:00执行任务10 5,17 * * * /scripts/script.sh 每分钟执行一次任务通常情况下，我们并没有每分钟都需要执行的脚本(春运抢票需要…)1* * * * * /scripts/script.sh 每周日17:00执行任务10 17 * * sun /scripts/script.sh 每10min执行一次任务1*/10 * * * * /scripts/monitor.sh 在特定的某几个月执行任务1* * * jan,may,aug * /script/script.sh 在特定的某几天执行任务在每周五、每周日的17点执行10 17 * * sun,fri /script/scripy.sh 在每个月的第一个周日执行任务在每个月第一个周日的2点执行10 2 * * sun [ $(date +%d) -le 07 ] &amp;&amp; /script/script.sh 每四个小时执行一个任务10 */4 * * * /scripts/script.sh 每周一、周日执行任务10 4,17 * * sun,mon /scripts/script.sh 每个30秒执行一次任务我们没有办法直接通过上诉类似的例子去执行，因为最小的是1min。但是我们可以通过如下的方法。12* * * * * /scripts/script.sh* * * * * sleep 30; /scripts/script.sh ###多个任务在一条命令中配置1* * * * * /scripts/script.sh; /scripts/scrit2.sh 每年执行一次任务1@yearly /scripts/script.sh @yearly类似于“0 0 1 1 *”。它会在每年的第一分钟内执行，通常我们可以用这个发送新年的问候。 每月执行一次任务1@monthly /scripts/script.sh 每周执行一次任务1@weekly /scripts/script.sh 每天执行一次任务1@daily /scripts/script.sh 每分钟执行一次任务1@hourly /scripts/script.sh 系统重启时执行1@reboot /scripts/script.sh 将cron结果重定向的特定的账户默认情况下，cron只会将结果详情发送给cron被制定的用户。如果需要发送给其他用户，可以通过如下的方式：123# crontab -lMAIL=userabc0 2 * * * /script/backup.sh cron备份和恢复这是一个当我们丢失了cron命令后方便快速的一个恢复方式。下面是利用这个方式恢复cron的一个小例子。（看看就行~）首先：检查当前的cron123# crontab -lMAIL=userabc0 2 * * * /script/backup.sh 然后：备份cron到文件中1234# crontab -l &gt; cron-backup.txt# cat cron-backup.txtMAIL=userabc0 2 * * * /script/backup.sh 接着：移除当前的cron123# crontab -r# crontab -lno crontab for root 恢复：从text file中恢复1234# crontab cron-backup.txt# crontab -lMAIL=userabc0 2 * * * /script/backup.sh]]></content>
      <categories>
        <category>Service</category>
        <category>Crontab</category>
      </categories>
      <tags>
        <tag>Crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka手动设置offset]]></title>
    <url>%2Fposts%2F4c3ba58e.html</url>
    <content type="text"><![CDATA[在实际生产环境中，我们可能遇到这种情况：1、topic中有大量的消息需要消费；2、消费服务由于负载问题不能在短时间内消费掉topic内的消息；3、由此造成了消费服务负载过高，甚至服务进程阻塞；在这种情况下，我们应该需要手动去调整某消费者组对应的topic的offset，使整个系统进入平稳。 前提条件相关所有消费服务必须停止只有相关所有的消费服务停止，才能修改对应topic的offset。 当前环境当前kafka的安装是使用confluent kafka安装，所以在实际命令中根据不同环境使用对应的工具。 修改过程执行如下命令即可：查看消费者组12345# kafka-consumer-groups --bootstrap-server localhost:9092 --list1_confluent-controlcenter-5-1-2-1-command_confluent-controlcenter-5-1-2-1 此次我们要修改的消费者组就是1。查看消费者组订阅的topic以及topic信息1234567# kafka-consumer-groups --bootstrap-server localhost:9092 --group 1 --describeTOPIC PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG CONSUMER-ID HOST CLIENT-IDdiscovery1.test.goods_info 0 1250 1250 0 1-9b463cba-e36d-4d4c-ae2b-660831449796 /172.19.138.54 1discovery1.test.risk_control_info 0 161 161 0 1-9b463cba-e36d-4d4c-ae2b-660831449796 /172.19.138.54 1discovery1.test.calculate_user 0 56 56 0 1-9b463cba-e36d-4d4c-ae2b-660831449796 /172.19.138.54 1discovery1.test.order_info 0 7322 7322 0 1-9b463cba-e36d-4d4c-ae2b-660831449796 /172.19.138.54 1 注意看current-offset和log-end-offset还有lag，分别为当前偏移量，结束的偏移量，落后的偏移量。以topics：discovery1.test.order_info为例，当前已消费完成。此处修改current-offset，让消费服务再重新消费最后几条消息。1234# kafka-consumer-groups --bootstrap-server localhost:9092 --group 1 --topic discovery1.test.order_info --execute --reset-offsets --to-offset 7312TOPIC PARTITION NEW-OFFSET discovery1.test.order_info 0 7312 修改成功，再查看topic信息12345678# kafka-consumer-groups --bootstrap-server localhost:9092 --group 1 --describeConsumer group '1' has no active members.TOPIC PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG CONSUMER-ID HOST CLIENT-IDdiscovery1.test.goods_info 0 1250 1250 0 - - -discovery1.test.risk_control_info 0 161 161 0 - - -discovery1.test.calculate_user 0 56 56 0 - - -discovery1.test.order_info 0 7312 7322 10 - - - 现在明显是lag=10，current-offset=7312，log-end-offset=7322，告诉我们有10条未消费。current-offset当前已经消费到偏移量为7312,可以理解为已经消费7312条。log-end-offset可以理解为总共7322条记录。lag可以理解为未消费记录条数。现在可以重新启动消费服务，可以从日志中看到会重新消费最后10条消息。]]></content>
      <categories>
        <category>Service</category>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>offset</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka彻底删除topics及数据]]></title>
    <url>%2Fposts%2F315f23f4.html</url>
    <content type="text"><![CDATA[前言删除kafka topic及其数据，严格来说并不是很难的操作。但是，往往给kafka 使用者带来诸多问题。本文总结多个删除kafka topic的应用场景，总结一套删除kafka topic的标准操作方法。 方法step1如果需要被删除topic此时正在被程序produce和consume使用，则这些生产和消费程序需要停止。因为如果有程序正在生产或者消费该topic，则该topic的offset信息一致会在broker更新。调用kafka delete命令则无法删除该topic。同时，需要设置auto.create.topics.enable = false，默认设置为true。如果设置为true，则produce或者fetch 不存在的topic也会自动创建这个topic。这样会给删除topic带来很多意向不到的问题。所以，这一步很重要，必须设置auto.create.topics.enable = false，并认真把生产和消费程序彻底全部停止。 step2kafka配置文件server.properties设置delete.topic.enable=true，如果没有设置delete.topic.enable=true，则调用kafka 的delete命令无法真正将topic删除，而是显示（marked for deletion）。 step3当前使用的kafka版本为confluent5.1.2，以下命令请根据实际情况调整。调用命令删除topic1kafka-topics --delete --zookeeper [zookeeper server:port] --topic [topic name] 此处命令中topic name支持通配符*。 step4删除kafka存储目录（server.properties文件log.dirs配置，默认为”/data/kafka-logs”）相关topic的数据目录。confluent的目录为/tmp/confluent.*/kafka/data。注意：如果kafka 有多个 broker，且每个broker 配置了多个数据盘（比如 /data/kafka-logs,/data1/kafka-logs …），且topic也有多个分区和replica，则需要对所有broker的所有数据盘进行扫描，删除该topic的所有分区数据。一般而言，经过上面4步就可以正常删除掉topic和topic的数据。但是，如果经过上面四步，还是无法正常删除topic，则需要对kafka在zookeeer的存储信息进行删除。具体操作如下：（注意：以下步骤里面，kafka在zk里面的节点信息是采用默认值，如果你的系统修改过kafka在zk里面的节点信息，则需要根据系统的实际情况找到准确位置进行操作） step5找一台部署了zk的服务器，使用命令1zookeeper-shell [zookeeper server:port] 登录到zk shell，然后找到topic所在的目录：ls /brokers/topics，找到要删除的topic，然后执行命令1rmr /brokers/topics/[topic name] 即可，此时topic被彻底删除。如果topic 是被标记为 marked for deletion，则通过命令ls /admin/delete_topics，找到要删除的topic，然后执行命令1rmr /admin/delete_topics/[topic name] 备注：其他方法说需要删除topic在zk上面的消费节点记录、配置节点记录，比如12rmr /consumers/[consumer-group]rmr /config/topics/[topic name] 其实正常情况是不需要进行这两个操作的，如果需要，那都是由于操作不当导致的。比如step1停止生产和消费程序没有做，step2没有正确配置。也就是说，正常情况下严格按照step1 – step5 的步骤，是一定能够正常删除topic的。 step6完成之后，调用命令1kafka-topics --list --zookeeper [zookeeper server:port] 查看现在kafka的topic信息。正常情况下删除的topic就不会再显示，如果还能够查询到删除的topic，则重启zk和kafka即可。]]></content>
      <categories>
        <category>Service</category>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>Confluent</tag>
        <tag>topic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Confluent捕获Mysql实时数据变更事件]]></title>
    <url>%2Fposts%2Fe7a3462e.html</url>
    <content type="text"><![CDATA[简介如果后端应用数据存储使用的MySQL，项目中如果有这样的业务场景,我们会怎么做呢？ 分库分表数据拆分和迁移 历史数据同步分析 异步处理 多个应用之间数据同步和共享 建立elasticsearch搜索 对于最简单最直接的做法就是修改原有应用的代码，在数据发生改变的同时通知下游系统，或者数据改变发送MQ，下游系统消费消息。这样的设计虽然看似简单，但是实现真的很麻烦，数据库表多、业务复杂，各种业务代码里面到处是增删改，这样的设计后期难以维护，也难以保证数据一致性和可靠性。试想有没有可靠的替代方案，无需代码侵入，当数据库发生改变的时候，这些改变都是一个一个的data change事件发布到相应的中间件，下游系统订阅消息，这个设计就不得不提大名鼎鼎的kafka confluent了。Kafka connect是Confluent公司(当时开发出Apache Kafka的核心团队成员出来创立的新公司)开发的confluent platform的核心功能.大家都知道现在数据的ETL过程经常会选择kafka作为消息中间件应用在离线和实时的使用场景中,而kafka的数据上游和下游一直没有一个无缝衔接的pipeline来实现统一,比如会选择flume或者logstash采集数据到kafka,然后kafka又通过其他方式pull或者push数据到目标存储.而kafka connect旨在围绕kafka构建一个可伸缩的，可靠的数据流通道，通过kafka connect可以快速实现大量数据进出kafka从而和其他源数据源或者目标数据源进行交互构造一个低延迟的数据pipeline。 虽然kafka confluent提供了JDBC Connector使用JDBC的方式去获取数据源，这种方式kafka connector追踪每个表中检索到的组继续记录，可以在下一次迭代或者崩溃的情况下寻找到正确的位置，这里存在几种实现模式，具体可以参考官网说明JDBC Source Connector。但是我这里推荐使用debezium，这种方式基于MySQL binlog的特性，首先你需要了解什么是debezium。debezium是一个开源的分布式CDC（变更数据捕获）系统，支持对接各种数据源，将上游已持久化的数据变更捕获后写入消息队列，其特性查看官网How it works，类似的CDC系统还有Canal。 debezium安装使用部署kafka confluent如何部署kafka confluent这里不再描述，可以参考Confluent安装部署这篇文章。 安装debezium插件下载官网地址debezium。 安装插件Debezium把解压后的debezium复制到conlfuent安装目录share/java文件中，如1/data/confluent/share/java/debezium-connector-mysql 再次启动confluent即可 debezium使用使用debezium之前必须先开启mysql得binlog，这里不再叙述。接下来构建一个kafka connect来使用debezium插件，confluent提供了restful api可快速创建kafka connect。创建kafka connect连接123456789101112131415161718curl -i -X POST -H &quot;Accept:application/json&quot; -H &quot;Content-Type:application/json&quot; http://localhost:8083/connectors/ -d &apos;&#123; &quot;name&quot;: &quot;mysql-connector&quot;, &quot;config&quot;: &#123; &quot;connector.class&quot;: &quot;io.debezium.connector.mysql.MySqlConnector&quot;, &quot;database.hostname&quot;: &quot;ip/hostname&quot;, &quot;database.port&quot;: &quot;port&quot;, &quot;database.user&quot;: &quot;user&quot;, &quot;database.password&quot;: &quot;******&quot;, &quot;database.server.id&quot;: &quot;1&quot;, &quot;database.server.name&quot;: &quot;dbname&quot;, &quot;database.history.kafka.bootstrap.servers&quot;: &quot;localhost:9092&quot;, &quot;database.history.kafka.topic&quot;: &quot;dbhistory.inventory&quot;, &quot;include.schema.changes&quot;: &quot;true&quot; &quot;decimal.handling.mode&quot;: &quot;string&quot; &#125;&#125;&apos; 这里的脚本其实是一行，我为了方便查看展开了json。复制可用的脚本：1curl -i -X POST -H &quot;Accept:application/json&quot; -H &quot;Content-Type:application/json&quot; http://localhost:8083/connectors/ -d &apos;&#123;&quot;name&quot;:&quot;mysql-connector&quot;,&quot;config&quot;: &#123; &quot;connector.class&quot;: &quot;io.debezium.connector.mysql.MySqlConnector&quot;, &quot;database.hostname&quot;: &quot;ip/hostname&quot;, &quot;database.port&quot;: &quot;port&quot;, &quot;database.user&quot;: &quot;user&quot;, &quot;database.password&quot;: &quot;******&quot;, &quot;database.server.id&quot;: &quot;1&quot;, &quot;database.server.name&quot;: &quot;dbname&quot;, &quot;database.history.kafka.bootstrap.servers&quot;: &quot;localhost:9092&quot;, &quot;database.history.kafka.topic&quot;: &quot;dbhistory.inventory&quot; , &quot;include.schema.changes&quot;: &quot;true&quot;, &quot;decimal.handling.mode&quot;: &quot;string&quot; &#125;&#125;&apos; Debezium mysql 连接器属性 属性 默认值 属性含义 name 连接器的名字，不能和其他连接器的名字重复，如果用已经存在的连接器名字去注册会失败。这个属性也是所有Kafka Connect连接器都需要的属性 connector.class 连接器的java类，对于MySQL连接器来说，总是io.debezium.connector.mysql.MySqlConnector tasks.max 1 连接器创建的最大的任务数，MySQL连接器总是使用单任务，所以用不到这个值，默认的就可以了。 database.hostname MySQL数据库服务器的IP地址或者主机名 database.port 3306 MySQL数据库服务器的端口号 database.user 连接数据库的用户名 database.password 连接数据库的密码 database.server.name host:port debezium监控的MySQL服务器/集群的逻辑名。这个逻辑名应该在所有连接器中唯一，因为这个会用在Kafka topic的前缀，默认是’host:port’这样，host就是上面的database.hostname属性值，port就是上面的database.port属性值。但是我们推荐使用明确的、有意义的名字。 database.server.id random 数据库客户端(debezium连接器)数字id，在数据库集群中应该唯一。其实连接器用这个id，以一个数据库服务器的身份加入数据库集群，这样才能够读取binlog文件。默认情况下，随机数在5400到6400之间，推荐显示设置一个值。 database.history.kafka.topic kafka topic的全名，连接器将把数据库的schema历史信息存入这个topic中。 database.history.kafka.topic.bootstrap.servers 用于连接Kafka集群的host/port对。这个连接将用于获取连接器此前存放的数据库schema历史，并且把从源数据库（被监控的数据库）中读取到的DDL语句写入到这个Kafka集群中。这个连接参数应该和Kafka Connect用的集群一致。 database.whitelist 空字符串 用逗号隔开的正则表达式列表，可以匹配多个被监控的数据库名称，不在白名单中的数据库不会被debezium连接器监控。默认情况下，所有的数据库都会被监控。不能和database.blacklist同时使用。 database.blacklist 空字符串 用逗号隔开的正则表达式列表，用来匹配不想监控的数据库。任何不在黑名单中的数据库都会被监控。不能和database.whitelist同时使用。 table.whitelist 空字符串 逗号分割的正则表达式列表，用于匹配要监控的表的全名（数据库名.表名）。不同和table.blacklist同时使用经过实践，发现表白名单和数据库白名单也不能同时使用。 table.blacklist 空字符串 逗号分割的正则表达式列表，用于匹配不要监控的表的全名（数据库名.表名）。不能和table.whitelist同时使用。经过实践，发现表黑名单和数据库黑名单也不能同时使用。 column.blacklist 空字符串 逗号分割的正则表达式列表，用于匹配不想要监控的列，在事件消息中不会包含的列值。应该是databaseName.tableName.columnName或者databaseName.schemaName.tableName.columnName这样的全限定名。 column.truncate.to.length.chars n/a 逗号分割的正则表达式列表，用于匹配需要在事件消息中截短的列名。一个配置列表中可以配置多个不同的长度。列名应该是databaseName.tableName.columnName或者databaseName.schemaName.tableName.columnName这样的全限定名。 更多连接器属性参考：原文链接注意： 如果对topics的消费者是java语言的连接方式一定要加上`&quot;decimal.handling.mode&quot;: &quot;string&quot;` 示例中的关于地址、用户、密码等设置已经隐藏，需要根据实际情况自行替换 可以通过命令查看已创建成功的connect，如下12# curl -H &quot;Accept:application/json&quot; localhost:8083/&#123;&quot;version&quot;:&quot;2.1.1-cp1&quot;,&quot;commit&quot;:&quot;f5b753880d5460f1&quot;,&quot;kafka_cluster_id&quot;:&quot;__SovfFYR5WfKrZ1xuBlaw&quot;&#125; 如果一切正常，可以通过Confluent Control Center看到kafka集群上多了一些和表名相关的topic，topic命名规则为debezium mysql connector配置文件中配置的serverName.databaseName.tableName。 验证debezium会读取MySQL binlog产生数据改变事件，将事件发送到kafka队列，最简单的验证办法就是监听这些队列（这些队列按照表名区分）具体参考代码请查看github.com/moxingwang/…。这里我们观察数据库的order_info表，监听*.*.order_info队列。首先在数据库中将order_info表字段内容update。此时，应用消费者会立马收到一条消费消息，具体的信息不再展示。 命令使用打印出所有的topics1kafka-topics --list --zookeeper localhost:2181 创建一个名为test的topic1kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 更改tioic分区1kafka-topics --zookeeper localhost:2181 --topic test --alter --partitions 4 查看指定topic信息1kafka-topics --zookeeper localhost:2181 --topic test --describe 创建一个消息消费者1kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning 创建一个消息生产者1kafka-console-producer --broker-list localhost:9092 --topic test 应用消费者对topics的消费，对数据格式有一定的需求，也需要查看数据的内容，此时我们通过以下命令：1kafka-console-consumer --bootstrap-server localhost:9092 --topic topics_name --from-beginning 此命令打印出消息过长，一般不需要使用。]]></content>
      <categories>
        <category>BigData</category>
        <category>Confluent</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>Confluent</tag>
        <tag>Mysql</tag>
        <tag>Debezium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Confluent安装部署]]></title>
    <url>%2Fposts%2F502a07f.html</url>
    <content type="text"><![CDATA[confluent简介LinkedIn有个三人小组出来创业了—正是当时开发出Apache Kafka实时信息列队技术的团队成员，基于这项技术Jay Kreps带头创立了新公司Confluent。Confluent的产品围绕着Kafka做的。 Confluent PlatformConfluent Platform 是一个流数据平台，能够组织管理来自不同数据源的数据，拥有稳定高效的系统。Confluent Platform不仅提供数据传输的系统，还提供所有的工具：连接数据源的工具，应用，以及数据接收。 Confluent Platform组件Confluent Platform 很容易的建立实时数据管道和流应用。通过将多个来源和位置的数据集成到公司一个中央数据流平台，Confluent Platform使您可以专注于如何从数据中获得商业价值而不是担心底层机制，如数据是如何被运输或不同系统间摩擦。具体来说，Confluent Platform简化了连接数据源到Kafka，用Kafka构建应用程序，以及安全，监控和管理您的Kafka的基础设施。Kafka 是最流行的开源即时通讯系统，Confluent Platform 基于Kafka. Kafka 是低延迟，高可扩展，分布式消息系统。它被数百家企业用于许多不同的场景，包括收集用户活动数据，系统日志，应用程序指标，股票行情数据和设备仪器的信号。Kafka开源项目包括一些关键组件： Kafka Brokers(开源）。构成Kafka的消息，数据持久性和存储层。 Kafka Java Clients(开源)。Java 库，写消息到kafka 或者从kafka 读消息。 Kafka Streams（开源）。Kafka Streams是一个库使kafka转换成功能齐全的流处理系统。 Kafka Connect（开源）。一种可扩展的和可靠的连接Kafka框架与外部系统（如数据库，键值存储，搜索索引和文件系统）的框架。 除了Kafka以外， Confluent Platform 包括更多的工具和服务，使构建和管理数据流平台更加容易。 Confluent Control Center（闭源）。管理和监控Kafka最全面的GUI驱动系统。 Confluent Kafka Connectors（开源）。连接SQL数据库/Hadoop/Hive Confluent Kafka Clients（开源）。对于其他编程语言，包括C/C++,Python Confluent Kafka REST Proxy（开源）。允许一些系统通过HTTP和kafka之间发送和接收消息。 Confluent Schema Registry（开源）。帮助确定每一个应用使用正确的schema当写数据或者读数据到kafka中。 总的来说，Confluent Platform平台的组件给你的团队朝着建立统一而灵活的方式建立一个企业范围的数据流平台。 confluent单节点安装部署confluent的安装部署相对比较简单，confluent为我们提供了Confluent Platform,我们即可以快速启动整个confluent平台，也可以单独启动想要的组件。 java环境安装confluent启动需要java环境，java环境安装参考：CentOS上安装Java环境 confluent platform下载下载地址，下载最新版本12345678910111213cd /data/backupwget http://packages.confluent.io/archive/5.1/confluent-5.1.2-2.11.tar.gztar -zxvf confluent-5.1.2-2.11.tar.gzmv confluent-5.1.2 /data/confluentcd /data/confluentll total 12 drwxr-xr-x 3 1000 1000 4096 Feb 18 19:49 bin drwxr-xr-x 23 1000 1000 4096 Feb 18 19:49 etc drwxr-xr-x 3 1000 1000 21 Feb 18 19:26 lib -rw-r--r-- 1 1000 1000 871 Feb 18 20:24 README drwxr-xr-x 7 1000 1000 106 Feb 18 19:49 share drwxr-xr-x 2 1000 1000 179 Feb 18 20:24 src 添加环境变量1234567# vim /etc/profile #末尾添加以下内容 #set confluent environment PATH=/data/confluent/bin:$PATH export PATH# source /etc/profile #使环境变量生效 现在bin目录下的所有命令我们可以直接使用。首先看看如何快速启动confluent platform全家桶ZooKeeper,Kafka,Schema Registry,Control Center,Kafka Connect,Kafka REST Proxy,KSQL。 快速启动特别说明：我们的命令执行目录都是在confluent目录下。启动123456789101112131415# confluent startStarting zookeeperzookeeper is [UP]Starting kafkakafka is [UP]Starting schema-registryschema-registry is [UP]Starting kafka-restkafka-rest is [UP]Starting connectconnect is [UP]Starting ksql-serverksql-server is [UP]Starting control-centercontrol-center is [UP] 看到如下信息，说明我们的confluent platform中的多个组件都启动成功。confluent平台各组件的默认端口号 Component Default Port Zookeeper 2181 Apache Kafka brokers (plain text) 9092 Schema Registry REST API 8081 REST Proxy 8082 Kafka Connect REST API 8083 Confluent Control Center 9021 访问测试通过使用http://ip:9021来访问Control Center，如图： 集群搭建这里我们使用两台机器模拟集群10.186.61.103,10.186.60.60,10.186.65.43分别编排为node01,node02,node03。修改三台机器对应的hosts文件。分别添加如下配置12345678910110.0.0.0 localhost node0110.186.60.60 localhost node0210.186.65.43 localhost node0310.186.61.103 localhost node010.0.0.0 localhost node0210.186.65.43 localhost node0310.186.61.103 localhost node0110.186.60.60 localhost node020.0.0.0 localhost node03 分别为每台机器创建myid文件,没个myid保存要给唯一的数字即可，我这里三个host分别指定为1，2，3。12mkdir /var/lib/zookeepervim /var/lib/zookeeper/myid 每台机器分别指定如下配置 zookeeper配置和启动1234567891011# vim etc/kafka/zookeeper.properties #添加如下配置tickTime=2000dataDir=/var/lib/zookeeper/clientPort=2181initLimit=5syncLimit=2server.1=node01:2888:3888server.2=node02:2888:3888server.3=node03:2888:3888autopurge.snapRetainCount=3autopurge.purgeInterval=24 启动1zookeeper-server-start etc/kafka/zookeeper.properties kafka配置和启动修改配置12# vim etc/kafka/server.propertieszookeeper.connect=node01:2181,node02:2181,node03:2181 设置broker.id=0这里我们可以使用broker.id.generation.enable=true自动生成替代。123#broker.id=0broker.id.generation.enable=trueadvertised.listeners=PLAINTEXT://本机IP:9092 启动1kafka-server-start etc/kafka/server.properties Schema Registry配置和启动(可选)配置12# vim etc/schema-registry/schema-registry.propertieskafkastore.connection.url=node01:2181,node02:2181,node03:2181 启动1schema-registry-start etc/schema-registry/schema-registry.properties 这里我们不使用官方模式的avro序列化方式，所有不启动组件schema-registry。 kafka connect配置和启动配置1cp etc/schema-registry/connect-avro-distributed.properties etc/schema-registry/connect-distributed.properties 修改123456# vim etc/schema-registry/connect-distributed.propertiesbootstrap.servers=node01:9092,node02:9092,node03:9092key.converter=org.apache.kafka.connect.json.JsonConverter#key.converter.schema.registry.url=http://node01:8081value.converter=org.apache.kafka.connect.json.JsonConverter#value.converter.schema.registry.url=http://node01:8081 启动1./bin/connect-distributed etc/schema-registry/connect-distributed.properties Control Center配置和启动配置12345# vim etc/confluent-control-center/control-center-dev.propertiesbootstrap.servers=node01:9092,node02:9092,node03:9092zookeeper.connect=node01:2181,node02:2181:node03:2181#confluent.controlcenter.schema.registry.url=http://node01:8081,http://node02:8081,http://node03:8081confluent.controlcenter.connect.cluster=http://node01:8083 启动1control-center-start etc/confluent-control-center/control-center-dev.properties 到此为止kafka confluent集群搭建成功。]]></content>
      <categories>
        <category>BigData</category>
        <category>Confluent</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Kafka</tag>
        <tag>Confluent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Puppet部署与使用]]></title>
    <url>%2Fposts%2Fd9660bea.html</url>
    <content type="text"><![CDATA[puppet简介puppet是一种基于ruby语言开发的Lnux、Unix、windows平台的集中配置管理系统。它使用自有的puppet描述语言，可管理配置文件file、用户user、cron任务、软件包、系统服务等系统实体。 puppet依赖于C/S（客户端/服务器）的部署架构。它需要在puppet服务器上安装puppet-server软件包（以下简称master），在需要管理的目标主机上安装puppet客户端软件（以下简称client）。 为了保证安全，master和client之间是基于SSL和证书的，只有经过master证书认证的client才可以与master通信。 puppet是一个IT基础设施自动化管理工具，它能够帮助系统管理员管理基础设施的整个生命周期： 供应(provisioning)、配置(configuration)、联动(orchestration)及报告(reporting)。 基于puppet ，可实现自动化重复任务、快速部署关键性应用以及在本地或云端完成主动管理变更和快速扩展架构规模等。 遵循GPL 协议(2.7.0-), 基于ruby语言开发。 2.7.0 以后使用(Apache 2.0 license) 对于系统管理员是抽象的，只依赖于ruby与facter。 能管理多达40 多种资源，例如：file、user、group、host、package、service、cron、exec、yum repo等。 puppet工作机制工作模型puppet 通过声明性、基于模型的方法进行IT自动化管理。 定义：通过puppet 的声明性配置语言定义基础设置配置的目标状态； 模拟：强制应用改变的配置之前先进行模拟性应用； 强制：自动、强制部署达成目标状态，纠正任何偏离的配置； 报告：报告当下状态及目标状态的不同，以及达成目标状态所进行的任何强制性改变； puppet三层模型如下： 工作流程 使用模型puppet的使用模型分为单机使用模型和master/agent模型，下面我们来看看这两个模型的原理图。 单机使用模型实现定义多个manifests –&gt; complier –&gt; catalog –&gt; apply master/agent模型master/agent模型实现的是集中式管理，即 agent 端周期性向 master 端发起请求，请求自己需要的数据。然后在自己的机器上运行，并将结果返回给 master 端。架构和工作原理如下：工作原理 1、客户端puppet调用fast探测出主机的一些变量，如主机名、内存大小、IP地址等。Puppet把这些信息使用SSL连接发送给服务器端; 2、服务器端的puppetmaster通过fast工具分析检测客户端的主机名，然后找到项目的主配置文件manifest里面对应的node配置，并对该部分内容进行解析，fast发送过来的信息可以作为变量处理，node牵扯到的代码才被解析，没牵扯到的不解析，解析分为语法检查，如果语法没错，继续解析，解析结果生成一个结果‘伪代码’，然后把‘伪代码’发给客户端; 3、客户端收到‘伪代码’并且执行，客户端把执行结果发给服务器; 4、服务器端把客户端的执行结果写入日志。 在实际使用中多使用master/agent模型。 安装部署配置4台服务器在同一局域网中123410.186.61.39 ntpserver10.186.61.103 master10.186.60.60 node0110.186.65.43 node01 并修改相应的主机名 安装NTP Server由于Puppet需要使用SSL证书，依赖时间同步，所有需要搭建NTP服务器。关闭所有服务器的防火墙和安全性策略123systemctl stop firewalld.service systemctl disable firewalld.service setenforce 0 安装NTP Server参考：搭建内网NTP时间服务器然后master、node01、node02进行时间同步操作 修改hosts文件master、node01、node02都进行此操作1234vim /etc/hosts #添加10.186.61.103 master10.186.60.60 node0110.186.65.43 node01 安装master端12yum install -y epel-replease #安装epel源yum install -y puppet-server #yum安装puppet服务端 启动master程序12systemctl enable puppetmaster.servicesystemctl start puppetmaster.service 安装client端node01、node02进行一样的操作12yum install -y epel-replease #安装epel源yum install -y puppet #yum安装puppet控制端 编辑puppet配置文件1234vim /etc/puppet/puppet.conf[main]server = master #main中添加...... 启动123systemctl enable puppetsystemctl start puppetsystemctl status puppet client端申请证书12345678puppet agent --server=master --no-daemonize --verbose #两个client端执行命令一样 #执行完会有如下提示：Info: Creating a new SSL key for nide01Info: Caching certificate for caInfo: csr_attributes file loading from /etc/puppet/csr_attributes.yamlInfo: Creating a new SSL certificate request for node01Info: Certificate Request fingerprint (SHA256): 9E:E6:4D:3F:5B:03:D2:72:08:FF:0B:E7:92:48:45:FA:B7:2C:89:B5:12:CB:EC:8F:2E:50:B4:02:5F:4C:DF:17Info: Caching certificate for ca 等待一会儿按ctrl+c组合键结束 授权在master段查看申请证书的客户端123# puppet cert list "node01" (SHA256) 19:C7:34:73:78:4C:6E:FA:5D:1D:BE:84:05:50:2F:B4:F1:13:8C:75:E2:DA:0C:3A:9D:46:89:2F:53:86:AB:BC "node02" (SHA256) 07:48:B5:06:53:D7:A5:70:EF:06:A0:0D:D5:FA:8A:53:94:FB:69:07:E1:C2:59:18:8E:52:80:4D:B5:66:FC:90 将未申请的客户端进行授权单个签署1puppet cert sign clientname 全部签署12345# puppet cert sign --allNotice: Signed certificate request for node01Notice: Removing file Puppet::SSL::CertificateRequest node01 at '/var/lib/puppet/ssl/ca/requests/node01.pem'Notice: Signed certificate request for node02Notice: Removing file Puppet::SSL::CertificateRequest node02 at '/var/lib/puppet/ssl/ca/requests/node02.pem' 查看已经申请注册的客户端12345# ll /var/lib/puppet/ssl/ca/signed/ total 12-rw-r--r-- 1 puppet puppet 1927 Feb 27 15:31 master.pem-rw-r--r-- 1 puppet puppet 1927 Feb 27 15:41 node01.pem-rw-r--r-- 1 puppet puppet 1927 Feb 27 15:41 node02.pem 可以看到已注册的包括master本身，一共三台服务器至此Puppet部署已完成。 puppet使用方法puppet 名词解释 资源：是puppet的核心，通过资源申报，定义在资源清单中。相当于ansible中的模块，只是抽象的更加彻底。 类：一组资源清单。 模块：包含多个类。相当于ansible中的角色。 站点清单：以主机为核心，应用哪些模块。 定义资源puppet从以下三个维度来都资源完成抽象: 1、相似的资源被抽象成同一种资源“类型，”如程序包资源、用户资源及服务资源等 2、将资源属性或状态的描述与其实现方式剥离开来，如仅说明安装一个程序包而不用关系其具体是yum、pkgadd、prots或其他方式实现 3、仅描述资源的目标状态，也即期望其实现的结果，而不是其具体过程，如“确定nginx运行起来”，而不是具体描述为“运行nginx命令将启动起来” 这三个也被称为puppet的资源抽象层（RAL）。RAL由type（类型）和provide（提供者，即不同的OS上的特定实现）组成。资源是puppet用于模型化系统配置的基础单元，每个资源都从某个角度描述了系统属性，如某程序包必须安装或某用户必须移除等，在puppet，用于完成此类功能的代码也即“资源申报”12345type &#123; ‘title’： atttibue1 =&gt; value1, atttibue2 =&gt; value2, ...... &#125; 注意： 资源的文件统一以.pp结尾。 type必须使用小写字符；title是一个字符串，在同一类型中必须惟一；每一个属性之间需要用“,”隔开，最后一个“,”可省略。 例如，可以同时有名为nginx 的“service”资源和“package”资源，但在“package” 类型的资源中只能有一个名为“nginx”的资源。资源属性中的三个特殊属性 Namevar：可简称为name； ensure：资源的目标状态； Provider：指明资源的管理接口； 常见资源介绍查看资源我们可以使用puppet describe来打印有关Puppet资源类型，提供者和元参数的帮助。使用语法如下：123USAGE-----puppet describe [-h|--help] [-s|--short] [-p|--providers] [-l|--list] [-m|--meta] group：管理系统上的用户组。查看使用帮助信息：1puppet describe group -s -m 属性： name：组名，可以省略，如果省略，将继承title的值； gid：GID； system：是否为系统组，true OR false； ensure：目标状态，present/absent； members：成员用户; 简单举例如下：123456vim group.pp group&#123;&apos;mygrp&apos;: name =&gt; &apos;mygrp&apos;, ensure =&gt; present, gid =&gt; 2000, &#125; 运行：12345678910111213# puppet apply -v --noop group.pp ##试运行Notice: Compiled catalog for master in environment production in 0.13 secondsInfo: Applying configuration version '1551340533'Notice: /Stage[main]/Main/Group[mygrp]/ensure: current_value absent, should be present (noop)Notice: Class[Main]: Would have triggered 'refresh' from 1 eventsNotice: Stage[main]: Would have triggered 'refresh' from 1 eventsInfo: Creating state file /var/lib/puppet/state/state.yamlNotice: Finished catalog run in 0.04 seconds# puppet apply -v group.pp ##运行Notice: Compiled catalog for master in environment production in 0.12 secondsInfo: Applying configuration version '1551340577'Notice: /Stage[main]/Main/Group[mygrp]/ensure: createdNotice: Finished catalog run in 0.08 seconds user：管理系统上的用户。查看使用帮助信息：1puppet describe user -s -m 属性： name：用户名，可以省略，如果省略，将继承title的值； uid: UID; gid：基本组ID； groups：附加组，不能包含基本组； comment：注释； expiry：过期时间 ； home：用户的家目录； shell：默认shell类型； system：是否为系统用户 ； ensure：present/absent； password：加密后的密码串； 简单举例如下：1234567891011vim user.pp user&#123;&apos;francis&apos;: ensure =&gt; present, system =&gt; false, comment =&gt; &apos;Test User&apos;, shell =&gt; &apos;/bin/bash&apos;, home =&gt; &apos;/data/francis&apos;, managehome =&gt; true, groups =&gt; &apos;mygrp&apos;, uid =&gt; 3000, &#125; 运行123456789101112# puppet apply -v --noop user.pp Notice: Compiled catalog for master in environment production in 0.17 secondsInfo: Applying configuration version '1551341447'Notice: /Stage[main]/Main/User[francis]/ensure: current_value absent, should be present (noop)Notice: Class[Main]: Would have triggered 'refresh' from 1 eventsNotice: Stage[main]: Would have triggered 'refresh' from 1 eventsNotice: Finished catalog run in 0.04 seconds# puppet apply -v user.pp Notice: Compiled catalog for master in environment production in 0.18 secondsInfo: Applying configuration version '1551341455'Notice: /Stage[main]/Main/User[francis]/ensure: createdNotice: Finished catalog run in 0.09 seconds package：puppet管理软件包查看使用帮助信息：1puppet describe package -s -m 属性： ensure：installed, present, latest, absent, any version string (implies present) name：包名，可以省略，如果省略，将继承title的值； source：程序包来源，仅对不会自动下载相关程序包的provider有用，例如rpm或dpkg； provider:指明安装方式； 简单举例如下：12345vim package.pp package&#123;&apos;httpd&apos;: ensure =&gt; installed, procider =&gt; yum &#125; service：定义服务的状态查看使用帮助信息：1puppet describe service -s -m 属性： ensure：服务的目标状态，值有true（running）和false（stopped） enable：是否开机自动启动，值有true和false name：服务名称，可以省略，如果省略，将继承title的值 path：服务脚本路径，默认为/etc/init.d/下 start：定制启动命令 stop：定制关闭命令 restart：定制重启命令 status：定制状态 file：管理文件、目录、软链接查看使用帮助信息：1puppet describe file -s -m 属性： ensure：目标状态，值有absent,present,file,directory和link file：类型为普通文件，其内容由content属性生成或复制由source属性指向的文件路径来创建； link：类型为符号链接文件，必须由target属性指明其链接的目标文件； directory：类型为目录，可通过source指向的路径复制生成，recurse属性指明是否递归复制； path：文件路径； source：源文件； content：文件内容； target：符号链接的目标文件； owner：定义文件的属主； group：定义文件的属组； mode：定义文件的权限； atime/ctime/mtime：时间戳； exec：执行命令慎用，通常用来执行外部命令查看使用帮助信息：1puppet describe exec -s -m 属性： command(namevar)：要运行的命令； cwd：指定运行该命令的目录； creates：文件路径，仅此路径表示的文件不存在时，command方才执行； user/group：运行命令的用户身份； path：指定命令执行的搜索路径； onlyif：此属性指定一个命令，此命令正常（退出码为0）运行时，当前command才会运行； unless：此属性指定一个命令，此命令非正常（退出码为非0）运行时，当前command才会运行； refresh：重新执行当前command的替代命令； refreshonly：仅接收到订阅的资源的通知时方才运行； 简单举例如下：123456vim exec.pp exec&#123;'cmd': command =&gt; 'mkdir /data/testdir', path =&gt; ['/bin','/sbin','/usr/bin','/usr/sbin'], # path =&gt; '/bin:/sbin:/usr/bin:/usr/sbin', &#125; cron：定义周期性任务查看使用帮助信息：1puppet describe cron -s -m 属性： command：要执行的任务（命令或脚本）； ensure：目标状态，present/absent； hour：时； minute：分； monthday：日； month：月； weekday：周； user：以哪个用户的身份运行命令（默认为root）； target：添加为哪个用户的任务； name：cron job的名称； 简单举例如下：1234567vim cron.pp cron&#123;&apos;timesync&apos;: command =&gt; &apos;/usr/sbin/ntpdata 10.186.61.39&apos;, ensure =&gt; present, minute =&gt; &apos;*/3&apos;, user =&gt; &apos;root&apos;, &#125; 运行：1234567891011121314# puppet apply -v --noop cron.pp Notice: Compiled catalog for master in environment production in 0.08 secondsInfo: Applying configuration version '1551344167'Notice: /Stage[main]/Main/Cron[timesync]/ensure: current_value absent, should be present (noop)Notice: Class[Main]: Would have triggered 'refresh' from 1 eventsNotice: Stage[main]: Would have triggered 'refresh' from 1 eventsNotice: Finished catalog run in 0.10 seconds# puppet apply -v cron.pp Notice: Compiled catalog for master in environment production in 0.08 secondsInfo: Applying configuration version '1551344175'Notice: /Stage[main]/Main/Cron[timesync]/ensure: createdNotice: Finished catalog run in 0.08 seconds[root@master manifests]# crontab -l*/3 * * * * /usr/sbin/ntpdata 10.186.61.39 notify：调试输出查看使用帮助信息：1puppet describe notify -s -m 属性： message：记录的信息 name：信息名称 该选项一般用于master/agent模式中，来记录一些操作的时间，比如重新安装了一个程序呀，或者重启了应用等等。会直接输出到代理机的运行日志中。 资源的特殊属性puppet中也提供了before、require、notify和subscribe四个参数来定义资源之间的依赖关系和通知关系。 before：表示需要依赖于某个资源 require：表示应该先执行本资源，在执行别的资源 notify：A notify B：B依赖于A，且A发生改变后会通知B； subscribe：B subscribe A：B依赖于A，且B监控A资源的变化产生的事件； 同时，依赖关系还可以使用-&gt;和～&gt;来表示： -&gt; 表示后资源需要依赖前资源 ~&gt; 表示前资源变动通知后资源调用tag 标签 如同 ansible 一样，puppet 也可以定义“标签”——tag，打了标签以后，我们在运行资源的时候就可以只运行某个打过标签的部分，而非全部。这样就更方便于我们的操作。一个资源中，可以有一个tag也可以有多个。具体使用语法如下：123456789type&#123;&apos;title&apos;: ... tag =&gt; &apos;TAG1&apos;,&#125; type&#123;&apos;title&apos;: ... tag =&gt; [&apos;TAG1&apos;,&apos;TAG2&apos;,...],&#125; 调用时的语法如下：1puppet apply --tags TAG1,TAG2,... puppet 变量puppet 变量以“$”开头，赋值操作符为“=”，语法为$variable_name=value。数据类型： 字符型：引号可有可无；但单引号为强引用，双引号为弱引用；支持转义符； 数值型：默认均识别为字符串，仅在数值上下文才以数值对待； 数组：[]中以逗号分隔元素列表； 布尔型值：true, false；不能加引号； hash：{}中以逗号分隔k/v数据列表； 键为字符型，值为任意puppet支持的类型；{ ‘mon’ =&gt; ‘Monday’, ‘tue’ =&gt; ‘Tuesday’, }； undef：从未被声明的变量的值类型； 正则表达式： (?&lt;ENABLED OPTION&gt;:&lt;PATTERN&gt;) (?-&lt;DISABLED OPTION&gt;:&lt;PATTERN&gt;) OPTIONS： i：忽略字符大小写； m：把.当换行符； x：忽略&lt;PATTERN&gt;中的空白字符； (?i-mx:PATTERN） 注意：不能赋值给变量，仅能用在接受=~或!~操作符的位置； puppet的变量种类puppet 种类有三种，为facts，内建变量和用户自定义变量。12345678910facts： 由facter提供；top scope；内建变量： master端变量 $servername, $serverip, $serverversion agent端变量 $clientcert, $clientversion, $environment parser变量 $module_name用户自定义变量 变量的作用域不同的变量也有其不同的作用域。我们称之为Scope。作用域有三种，top scope，node scope，class scope。其生效范围排序为：top scope &gt; node scope &gt; class scope其优先级排序为：top scope &lt; node scope &lt; class scope puppet 流程控制语句puppet 支持if 语句，case 语句和selector 语句。 if 语句if语句支持单分支，双分支和多分支。具体语法如下：单分支：1234if CONDITION &#123; statement ……&#125; 双分支：12345678if CONDITION &#123; statement ……&#125;else&#123; statement …… &#125; 多分支：123456789101112if CONDITION &#123; statement ……&#125;elsif CONDITION&#123; statement ……&#125;else&#123; statement …… &#125; 其中，CONDITION的给定方式有如下三种： 变量 比较表达式 有返回值的函数 case 语句类似 if 语句，case 语句会从多个代码块中选择一个分支执行，这跟其它编程语言中的 case 语句功能一致。case 语句会接受一个控制表达式和一组 case 代码块，并执行第一个匹配到控制表达式的块。使用语法如下：1234567case CONTROL_EXPRESSION &#123; case1: &#123; ... &#125; case2: &#123; ... &#125; case3: &#123; ... &#125; …… default: &#123; ... &#125;&#125; 其中，CONTROL_EXPRESSION的给定方式有如下三种: 变量 表达式 有返回值的函数 各case的给定方式有如下五种： 直接字串； 变量 有返回值的函数 正则表达式模式； default selector语句Selector 只能用于期望出现直接值(plain value) 的地方，这包括变量赋值、资源属性、函数参数、资源标题、其它 selector。selector 不能用于一个已经嵌套于于selector 的case 中，也不能用于一个已经嵌套于case 的case 语句中。具体语法如下：123456CONTROL_VARIABLE ? &#123; case1 =&gt; value1, case2 =&gt; value2, ... default =&gt; valueN,&#125; 其中，CONTROL_EXPRESSION的给定方式有如下三种: 变量 表达式 有返回值的函数 各case的给定方式有如下五种： 直接子串； 变量； 有返回值的函数； 正则表达式模式； default selectors 使用要点： 整个selector 语句会被当作一个单独的值，puppet 会将控制变量按列出的次序与每个case 进行比较，并在遇到一个匹配的 case 后，将其值作为整个语句的值进行返回，并忽略后面的其它 case。 控制变量与各 case 比较的方式与 case 语句相同，但如果没有任何一个 case 与控制变量匹配时，puppet 在编译时将会返回一个错误，因此，实践中，其必须提供default case。 selector 的控制变量只能是变量或有返回值的函数，切记不能使用表达式。 其各 case 可以是直接值(需要加引号) 、变量、能调用返回值的函数、正则表达式模式或 default。 但与 case 语句所不同的是，selector 的各 case 不能使用列表。 selector 的各 case 的值可以是一个除了 hash 以外的直接值、变量、能调用返回值的函数或其它的 selector。 puppet的类Class是用于通用目标或目的的一组资源，因此，它是命令的代码块，在某位置创建之后可在puppet全局使用。类似于其他编程语言中的类的功能，puppet的类可以继承，也可以包含子类，定义类的语法如下所示123class my_class &#123; ...puppet code ...&#125; 例如：定义一个名为nginx的类牟其中包含两类资源，一个是package类型的nginx，一个是service的nginx1234567891011class nginx &#123; package &#123; &apos;nginx&apos;: ensure =&gt; installed, name =&gt; nginx, &#125; service &#123; &apos;nginx&apos;: ensure =&gt; true, enable =&gt; true, subscribe =&gt; Package[&apos;nginx&apos;], &#125;&#125; 以上是类的定义，类似于函数。需要使用的话，要调用。调用时，使用关键在include即可。类的继承：类可以基于父类调用，在调用时，应该指定通过inherits关键字调用父类。例如：1234567891011121314class nginx &#123; package &#123; &apos;nginx&apos;: ensure =&gt; installed, name =&gt; nginx, &#125;&#125; class nignx::web inherits nginx &#123; service &#123; &apos;nginx&apos;: ensure =&gt; true, enable =&gt; true, &#125;&#125;include nignx::web 也支持类的覆盖和重写：12=&gt;:在子类中覆盖父类中的资源+&gt;:在子类中为父类中的资源新增额外的属性 模板puppet模块：为了实现某种完备功能而组织成的一个独立的、自我包含的目录结构模块名：目录名1234567891011121314151617181920目录结构：Module_name: manifests init.pp: 必须声明一个类，类名与模块名相同; *.pp: MODULE_NAME::[SUBDIR_NAME]::MANIFESTS_FILE_NAME files:静态文件 puppet url:puppet:///modules/MODULE_NAME/[SUBDIR_NAME]/FILE_NAME file&#123;&apos;nginx.conf&apos;: source =&gt; puppet:///modules/nginx/nginx.conf &#125; templates: 模板文件：*.erb template(&apos;MODULE_NAME/TEMPLATE_FILE_NAME&apos;); file&#123;&apos;nginx.conf&apos;: content =&gt; template(&apos;模板文件&apos;), &#125; lib: 插件 tests: 模块使用说明文档 spec: lib目录下的插件使用说明文档 使用范例使用maste/agent模式，安装nginxmaster端modules下文件路径和目录如下：12345678910# pwd/etc/puppet/modules/nginx[root@master nginx]# tree.├── files│ └── nginx.conf└── manifests └── init.pp2 directories, 2 files 文件内容：123456789101112131415161718192021# cat manifests/init.pp class nginx &#123; package&#123;'nginx': ensure =&gt; installed, allow_virtual =&gt; false, &#125; file&#123;'nginx.conf': ensure =&gt; file, source =&gt; 'puppet:///modules/nginx/nginx.conf', require =&gt; Package['nginx'], path =&gt; '/etc/nginx/nginx.conf', &#125; service&#123;'nginx': ensure =&gt; true, enable =&gt; true, require =&gt; Package['nginx'], subscribe =&gt; File['nginx.conf'], &#125; &#125; nginx.conf的内容为nginx的配置文件注意:puppet:///modules/nginx/nginx.conf #不需要写files目录，指定模块文件后puppet默认回去files目录下找对应的文件。manifests下目录和内容：12345678# pwd/etc/puppet/manifests# cat site.pp import "server/*.pp"# cat server/node01.pp node 'node01' &#123; include nginx&#125; agent端测试：123456# puppet agent -t --server=masterInfo: Retrieving pluginfactsInfo: Retrieving pluginInfo: Caching catalog for node02Info: Applying configuration version '1551431554'Notice: Finished catalog run in 0.18 seconds 12345678# ps -ef|grep nginxroot 863 1 0 17:12 ? 00:00:00 nginx: master process /usr/sbin/nginxnginx 865 863 0 17:12 ? 00:00:00 nginx: worker processroot 1094 29974 0 17:14 pts/0 00:00:00 grep --color=auto nginx# netstat -tnpl|grep 80tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 3801/sshd tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 863/nginx: master p tcp6 0 0 :::22 不需要重启agent端，master端每隔30秒会自动推送。可以看到nginx已经安装成功并启动，端口监听正常。写到最后我不推荐大家用puppet！]]></content>
      <categories>
        <category>Automation</category>
        <category>Puppet</category>
      </categories>
      <tags>
        <tag>Puppet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建内网NTP时间服务器]]></title>
    <url>%2Fposts%2Faec0db0.html</url>
    <content type="text"><![CDATA[时间服务器作用大数据产生与处理系统是各种计算设备集群的，计算设备将统一、同步的标准时间用于记录各种事件发生时序，如E-MAIL信息、文件创建和访问时间、数据库处理时间等。大数据系统内不同计算设备之间控制、计算、处理、应用等数据或操作都具有时序性，若计算机时间不同步，这些应用或操作或将无法正常进行。大数据系统是对时间敏感的计算处理系统，时间同步是大数据能够得到正确处理的基础保障，是大数据得以发挥作用的技术支撑。大数据时代，整个处理计算系统内的大数据通信都是通过网络进行。时间同步也是如此，利用大数据的互联网络传送标准时间信息，实现大数据系统内时间同步。网络时间同步协议(NTP)是时间同步的技术基础。 ntp安装确认是否已安装ntp1rpm –qa | grep ntp 若只有ntpdate而未见ntp，则需删除原有ntpdate。如：123ntpdate-4.2.6p5-22.el7_0.x86_64fontpackages-filesystem-1.44-8.el7.noarchpython-ntplib-0.3.2-1.el7.noarch 删除已安装ntp1yum –y remove ntpdate-4.2.6p5-22.el7.x86_64 重新安装ntp安装ntp1yum –y install ntp 配置开机自启1systemctl enable ntpd.service 配置ntp服务国家授时中心NTP服务器地址1ntp.ntsc.ac.cn 阿里云时间同步服务器地址12ntp1.aliyun.comtime1.aliyun.com 修改配置文件1vim /etc/ntp.conf 修改前123456789101112# cat /etc/ntp.conf |grep -Ev &apos;^#|^$&apos;driftfile /var/lib/ntp/driftrestrict default nomodify notrap nopeer noqueryrestrict 127.0.0.1 restrict ::1server 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburstincludefile /etc/ntp/crypto/pwkeys /etc/ntp/keysdisable monitor 修改后123456789101112131415161718192021# cat /etc/ntp.conf |grep -Ev &apos;^#|^$&apos;driftfile /var/lib/ntp/driftrestrict default nomodify notrap nopeer noqueryrestrict 127.0.0.1 restrict ::1#允许内网其他服务器同步时间restrict 10.186.1.0 mask 255.255.255.0 nomodify notrap#定义使用的上游ntp服务器，将原来的注释server ntp.ntsc.ac.cnserver ntp1.aliyun.comserver time1.aliyun.com#允许上层时间服务器主动修改本机时间，也可以注释#restrict ntp.ntsc.ac.cn nomodify notrap nopeer noquery#restrict ntp1.aliyun.com nomodify notrap nopeer noquery#restrict ntp1.aliyun.com nomodify notrap nopeer noquery#外部时间服务器不可用时，以本地时间作为时间服务server 127.127.1.0fudge 127.127.1.0 stratum 10includefile /etc/ntp/crypto/pwkeys /etc/ntp/keysdisable monitor 启动服务1systemctl start ntpd.service 检查时间服务器是否正确同步，列出本NTP服务器与上游服务器的连接状态1234567# ntpq -p remote refid st t when poll reach delay offset jitter==============================================================================+114.118.7.163 210.72.145.18 2 u 230 512 377 27.560 -8.168 0.719+120.25.115.20 10.137.53.7 2 u 269 512 377 32.112 -8.144 1.597*203.107.6.88 10.165.84.13 2 u 329 512 377 14.344 -8.753 1.291 LOCAL(0) .LOCL. 10 l 164m 64 0 0.000 0.000 0.000 ntpq -p可以列出目前我们的NTP与相关的上层NTP的状态，以上的几个字段的意义如下： remote：即remote - 本机和上层ntp的ip或主机名，“+”表示优先，“*”表示次优先。 refid：参考的上一层NTP主机的地址 st：即stratum阶层 poll：下次更新在几秒之后 offset：时间补偿的结果 列出是否与上游服务器连接，需要过5分钟1234# ntpstatsynchronised to NTP server (203.107.6.88) at stratum 3 time correct to within 41 ms polling server every 512 s 如果没有连接，则需要检查UDP端口，端口号1231234567# netstat -ln|grep 123udp 0 0 10.186.61.39:123 0.0.0.0:* udp 0 0 127.0.0.1:123 0.0.0.0:* udp 0 0 0.0.0.0:123 0.0.0.0:* udp6 0 0 fe80::aff:feba:3d27:123 :::* udp6 0 0 ::1:123 :::* udp6 0 0 :::123 :::* 客户端测试先修改成一个错误时间12# date -s date -s "2018-12-23 11:23:34"Sun Dec 23 11:23:34 CST 2018 进行时间同步12# ntpdate 10.186.61.3927 Feb 14:33:46 ntpdate[23929]: step time server 10.186.61.39 offset 5713761.244970 sec 10.186.61.39即位搭建的内网时间服务器的地址可以看到时间已经同步成功。 修改时区当前系统版本为centos7时间同步后可以查看搭建的时间服务器的本机时间12# dateWed Feb 27 06:23:10 UTC 2019 UTC是世界统一时间，我们可以更改为东八区北京时间CST更改前12# dateWed Feb 27 06:25:59 UTC 2019 更改12mv /etc/localtime /etc/localtime.bakln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 更改后12# dateWed Feb 27 14:26:29 CST 2019]]></content>
      <categories>
        <category>Service</category>
        <category>NTP</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>ntp</tag>
        <tag>内网</tag>
        <tag>时间同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx文档]]></title>
    <url>%2Fposts%2F8dddf073.html</url>
    <content type="text"><![CDATA[前言Nginx作用Nginx 是一个高性能的 Web 和反向代理服务器, 它具有有很多非常优越的特性:作为 Web 服务器：相比 Apache，Nginx 使用更少的资源，支持更多的并发连接，体现更高的效率，这点使 Nginx 尤其受到虚拟主机提供商的欢迎。能够支持高达 50,000 个并发连接数的响应，感谢 Nginx 为我们选择了 epoll and kqueue 作为开发模型.作为负载均衡服务器：Nginx 既可以在内部直接支持 Rails 和 PHP，也可以支持作为 HTTP代理服务器 对外进行服务。Nginx 用 C 编写, 不论是系统资源开销还是 CPU 使用效率都比 Perlbal 要好的多。作为邮件代理服务器: Nginx 同时也是一个非常优秀的邮件代理服务器（最早开发这个产品的目的之一也是作为邮件代理服务器），Last.fm 描述了成功并且美妙的使用经验。Nginx 安装非常的简单，配置文件 非常简洁（还能够支持perl语法），Bugs非常少的服务器: Nginx 启动特别容易，并且几乎可以做到7x24不间断运行，即使运行数个月也不需要重新启动。你还能够在 不间断服务的情况下进行软件版本的升级。 Nginx版本选择Nginx官方网站为： nginx.orgNginx的版本有： Mainline version：Mainline 是 Nginx 目前主力在做的版本，可以说是开发版。 Stable version：最新稳定版，生产环境上建议使用的版本。 Legacy versions：遗留的老版本的稳定版。 一般就选最新版本，Stable version：最新稳定版。 Nginx安装、升级、卸载windows server环境安装下载解压后 修改配置文件Nginx的配置文件在./conf/nginx.conf具体的相关配置请查看后续内容 启动Nginx注意不要直接双击nginx.exe，这样会导致修改配置后重启、停止nginx无效，需要手动关闭任务管理器内的所有nginx进程在nginx.exe目录，打开命令行工具，用命令 启动/关闭/重启nginx启动nginx：nginx -s reload ：修改配置后重新加载生效nginx -s reopen ：重新打开日志文件nginx -t -c /path/to/nginx.conf 测试nginx配置文件是否正确关闭nginx：nginx -s stop :快速停止nginxnginx -s quit ：完整有序的停止nginx linux server安装NginxLinux server环境以centos7作为环境示例，文档着重讲述linux server环境下Nginx的使用配置等操作。 yum安装方式CentOS 7 中的 yum 没法直接使用 yum install nginx 这个指令去安装nginx，因为nginx这个服务不是yum库中自带的。首先添加yum源：1rpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm 可以通过yum search nginx查看yum源是否安装成功，如果安装成功，则可以使用以下命令安装nginx1yum install -y nginx 启动Nginx并设置开机自动运行12systemctl start nginx.servicesystemctl enable nginx.service 编译安装方式安装编译环境、gcc12yum -y install gcc gcc-c++ automake autoconf libtool makeyum install gcc gcc-c++ 一般我们都需要先装pcre, zlib，前者为了重写rewrite，后者为了gzip压缩。从ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/ 下载最新的 PCRE 源码包，使用下面命令下载编译和安装 PCRE 包：1234567cd /data/backupwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.42.tar.gztar -zxvf pcre-8.42.tar.gzcd pcre-8.42./configuremakemake install 从http://zlib.net下载最新的 zlib 源码包，使用下面命令下载编译和安装 zlib包：1234567cd /data/backupwget http://zlib.net/zlib-1.2.11.tar.gz tar -zxvf zlib-1.2.11.tar.gzcd zlib-1.2.11./configuremakemake install 安装openssl123cd /data/backupwget https://www.openssl.org/source/openssl-1.1.0h.tar.gztar -zxvf openssl-1.1.0h.tar.gz 安装Nginx1234567cd /data/backupwget http://nginx.org/download/nginx-1.14.0.tar.gztar -zxvf nginx-1.14.0.tar.gz cd nginx-1.14.0./configure --prefix=/data/nginx/ --with-http_v2_module --with-http_ssl_module --with-http_sub_module --with-http_stub_status_module --with-http_gzip_static_module --without-http-cache --with-http_realip_module --with-pcre=/data/backup/pcre-8.42 --with-zlib=/data/backup/zlib-1.2.11 --with-openssl=/data/backup/openssl-1.1.0hmakemake install 创建Nginx软连接到环境变量1ln -s /data/nginx/sbin/* /usr/sbin/ 至此Nginx的安装已经结束。 Nginx升级、添加模块如果要对当前的Nginx服务器进行版本升级，应用新模块，最简单的办法是停止当前Nginx服务，然后开启新的Nginx服务，但这样就会导致在一段时间内，用户无法访问服务器。为了解决这个问题，Nginx服务器提供平滑升级的功能。平滑升级的过程是这样的，Nginx服务接收到USR2信号后首先将旧的nginx.pid文件(如果在配置文件中更改过这个文件的名字，也是相同的过程)添加.oldbin，变为nginx.pid.oldbin文件；然后执行新版本Nginx服务器的二进制文件启动服务。如果新的服务启动成功，系统中将由新旧两个Nginx服务公用提供Web服务。如果新的服务启动成功，系统中将有新旧两个Nginx服务共同提供Web服务。之后，需要向旧的Nginx服务进程发送WINCH信号，使旧的Nginx服务平滑停止，并删除nginx.pid.oldbin文件。在发送WINCH信号之前，可以随时停止新的Nginx服务。注意：为了实现Nginx服务器的平滑升级，新的服务器安装路径应该和旧的保持一致。因此建议用户在安装新服务器之前先备份旧服务器。当前Nginx版本为1.12.2，官网提供最新版本为1.13.10（非稳定版本），本次升级到1.13.10。和安装一样，首先下载解压，但是不要make install，编译参数中可以添加新的模块，以达到添加模块的目的，如下：123456cd /data/backupwget http://nginx.org/download/nginx-1.13.10.tar.gztar -zxvf nginx-1.13.10.tar.gz cd nginx-1.13.10./configure --prefix=/data/nginx/ --with-http_v2_module --with-http_ssl_module --with-http_sub_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre=/data/backup/pcre-8.42 --with-zlib=/data/backup/zlib-1.2.11 --with-openssl=/data/backup/openssl-1.1.0hmake 此时会在当前目录的objs文件夹内生成新版本的Nginx二进制文件。平滑升级，先移走现有的Nginx二进制文件。1mv /data/nginx/sbin/nginx /data/nginx/sbin/nginx.old 拷贝新生成的二进制文件到指定目录。1cp objs/nginx /data/nginx/sbin 执行升级1make upgrade 完成后再查看Nginx版本以及编译的参数123456# nginx -Vnginx version: nginx/1.13.10built by gcc 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC) built with OpenSSL 1.1.0h 27 Mar 2018TLS SNI support enabledconfigure arguments: --prefix=/data/nginx/ --with-http_v2_module --with-http_ssl_module --with-http_sub_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre=/data/backup/pcre-8.42 --with-zlib=/data/backup/zlib-1.2.11 --with-openssl=/data/backup/openssl-1.1.0h 可以看到Nginx已升级完成，且模块也编译成功。 Nginx卸载Nginx在windows server比较容易删除，直接删除文件即可。Nginx在linux server上卸载的话，如果编译时的路径如果指定了–prefix /xxx/nginx 直接rm -rf /xxx/nginx即可。如果没指定路径，那就到源码路径执行make uninstall。如果源码已经删除，安装时也没有指定路径，则需要到/usr/bin /etc /usr/sbin /usr/lib找到相关文件手动删除。 Nginx常用命令12345678910#检查配置文件nginx -t#指定其他配置文件启动Nginxnginx -c /data/nginx/conf/nginx.conf.default#启动Nginxnginx#停止Nginxnginx -s stop#重启Nginxnginx -s reload 参数解释 -s stop 快速停止nginx -s quit 平滑停止nginx -s reopen 重新打开日志文件 -s reload 平滑重载所有配置 Nginx模块介绍核心模块主模块包含一些Nginx的基本控制功能指令1234daemon语法：daemon on | off默认值：ondaemon off; 123456789env语法：env VAR|VAR=VALUE默认值：TZ使用字段：main这个命令允许其限定一些环境变量的值，在以下的情况下会创建或修改变量的值：在不停机情况下升级、增加或删除一些模块时继承的变量使用嵌入式perl模块使用工作中的进程，必须记住，某些类似系统库的行为管理仅在变量初始化时频繁地使用库文件，即仍然可以用之前给定的命令设置。如果没有明确的定义TZ的值,默认情况下它总是继承的，并且内置的Perl模块总是可以使用TZ的值。 12345debug_points语法：debug_points [stop | abort] 默认值：none（无）debug_points stop;在Nginx内部有很多断言，如果debug_points的值设为stop时，那么触发断言时将停止Nginx并附加调试器。如果debug_point的值设为abort,那么触发断言时将创建内核文件。 123456789101112error_log语法：error_log file [ debug | info | notice | warn | error | crit ] 默认值：$&#123;prefix&#125;/logs/error.log指定Nginx服务（与FastCGI）错误日志文件位置。每个字段的错误日志等级默认值：1、main字段 - error2、HTTP字段 - crit3、server字段 - critNginx支持为每个虚拟主机设置不同的错误日志文件，这一点要好于lighttpd，如果你在编译安装Nginx时加入了--with-debug参数，你可以使用以下配置：error_log LOGFILE [debug_core | debug_alloc | debug_mutex | debug_event | debug_http | debug_imap];注意error_log off并不能关闭日志记录功能，而会将日志文件写入一个文件名为off的文件中，如果你想关闭错误日志记录功能，应使用以下配置：error_log /dev/null crit; 12345678log_not_found语法：log_not_found on | off 默认值：on 使用字段：location 这个参数指定了是否记录客户端的请求出现404错误的日志，通常用于不存在的robots.txt和favicon.ico文件，例如：location = /robots.txt &#123; log_not_found off;&#125; 1234567include语法：include file | * 默认值：none 你可以包含一些其他的配置文件来完成你想要的功能。0.4.4版本以后，include指令已经能够支持文件通配符：include vhosts/*.conf;注意：直到0.6.7版本，这个参数包含的文件相对路径随你在编译时指定的--prefix=PATH目录而决定，默认是/usr/local/nginx，如果你不想指定这个目录下的文件，请写绝对路径。 12345lock_file语法：lock_file file 默认值：编译时指定 lock_file /var/log/lock_file;Nginx使用连接互斥锁进行顺序的accept()系统调用，如果Nginx在i386,amd64,sparc64,与ppc64环境下使用gcc,Intel C++,或SunPro C++进行编译，Nginx将采用异步互斥进行访问控制，在其他情况下锁文件会被使用。 12345master_process语法：master_process on | off 默认值：on master_process off;生产环境中不要使用"daemon"和"master_process"指令，这些选项仅用于开发调试。 12345pid语法：pid file 默认值：编译时指定 pid /var/log/nginx.pid;指定pid文件，可以使用kill命令来发送相关信号，例如你如果想重新读取配置文件，则可以使用：kill -HUP `cat /var/log/nginx.pid` 123456789ssl_engine语法：ssl_engine engine 默认值：依赖于系统环境 这里可以指定你想使用的OpenSSL引擎，你可以使用这个命令找出哪个是可用的：openssl engine -t$ openssl engine -t(cryptodev) BSD cryptodev engine [ 可用 ] (dynamic) Dynamic engine loading support [ 不可用 ] 123456timer_resolution语法：timer_resolution t 默认值：none timer_resolution 100ms;这个参数允许缩短gettimeofday()系统调用的时间，默认情况下gettimeofday()在下列都调用完成后才会被调用：kevent(), epoll, /dev/poll, select(), poll()。如果你需要一个比较准确的时间来记录$upstream_response_time或者$msec变量，你可能会用到timer_resolution 123try_files语法：try_files path1 [ path2] uri 默认值：none 1234user语法：user user [group] 默认值：nobody nobody 如果主进程以root运行，Nginx将会调用setuid()/setgid()来设置用户/组，如果没有指定组，那么将使用与用户名相同的组，默认情况下会使用nobody用户与nobody组（或者nogroup），或者在编译时指定的--user=USER和--group=GROUP的值。 1234567891011worker_cpu_affinity语法：worker_cpu_affinity cpumask [cpumask...] 默认值：none 仅支持linux系统。这个参数允许将工作进程指定到cpu，它调用sched_setaffinity()函数worker_processes 4;worker_cpu_affinity 0001 0010 0100 1000;指定每个进程到一个CPU：worker_processes 2;worker_cpu_affinity 0101 1010;指定第一个进程到CPU0/CPU2，指定第二个进程到CPU1/CPU3，对于HTT处理器来说是一个不错的选择。 1234worker_priority语法：worker_priority [-] number 默认值：on 这个选项可以用来设置所有工作进程的优先级（即linux系统中的nice），它调用setpriority()。 123456789worker_processes语法：worker_processes number 默认值：1 worker_processes 5;由于以下几点原因，Nginx可能需要运行不止一个进程1、使用了SMP（对称多处理技术）。2、当服务器在磁盘I/O出现瓶颈时为了减少响应时间。3、当使用select()/poll()限制了每个进程的最大连接数时。max_clients = worker_processes * worker_connections 1234worker_rlimit_core语法：worker_rlimit_core size 默认值： 允许的每个进程核心文件最大值。 1234worker_rlimit_nofile语法：worker_rlimit_nofile limit 默认值： 进程能够打开的最多文件描述符数 1234worker_rlimit_sigpending语法：worker_rlimit_sigpending limit 默认值： linux内核2.6.8以后，限制调用的进程中真实用户队列可能使用的信号数量。 1234working_directory语法：working_directory path 默认值：--prefix 程序的工作目录，一般只用来指定核心文件位置，Nginx仅使用绝对路径，所有在配置文件中的相对路径会转移到--prefix==PATH 变量123$pid进程ID号$realpath_root 事件模块控制Nginx处理连接的方式指令1234accept_mutex语法：accept_mutex [ on | off ] 默认值：on Nginx使用连接互斥锁进行顺序的accept()系统调用 1234accept_mutex_delay语法：accept_mutex_delay Nms; 默认值：500ms如果一个进程没有互斥锁，它将至少在这个值的时间后被回收，默认是500ms 123debug_connection语法：debug_connection [ip | CIDR] 默认值：none 12345678devpoll_changesdevpoll_events kqueue_changeskqueue_events epoll_events语法：devpoll_changes 默认值：这些参数指定了按照规定方式传递到或者来自内核的事件数，默认devpoll的值为32，其余为512。 1234multi_accept语法：multi_accept [ on | off ] 默认值：off multi_accept在Nginx接到一个新连接通知后调用accept()来接受尽量多的连接 12345rtsig_signo语法：rtsig_signo 默认值：Nginx在rtsig模式启用后使用两个信号，该指令指定第一个信号编号，第二个信号编号为第一个加1默认rtsig_signo的值为SIGRTMIN+10 (40) 标准HTTP模块HTTP核心模块Nginx处理HTTP的核心功能模块指令1234alias语法：alias file-path|directory-path; 默认值：no使用字段：location 这个指令指定一个路径使用某个某个，注意它可能类似于root，但是document root没有改变，请求只是使用了别名目录的文件。123location /i/ &#123; alias /spool/w3/images/;&#125; 上个例子中，请求”/i/top.gif”将返回这个文件: “/spool/w3/images/top.gif”。Alias同样可以用于带正则表达式的location，如：123location ~ ^/download/(.*)$ &#123; alias /home/website/files/$1;&#125; 请求”/download/book.pdf”将返回”/home/website/files/book.pdf”。同样，也可以在别名目录字段中使用变量。1234client_body_in_file_only语法：client_body_in_file_only on|off 默认值：off 使用字段：http, server, location 这个指令始终存储一个连接请求实体到一个文件即使它只有0字节。注意：如果这个指令打开，那么一个连接请求完成后，所存储的文件并不会删除。这个指令可以用于debug调试和嵌入式Perl模块中的$r-&gt;request_body_file。1234client_body_in_single_buffer语法：client_body_in_single_buffer 默认值：off 使用字段：http, server, location 1234client_body_buffer_size语法：client_body_buffer_size the_size 默认值：8k/16k 使用字段：http, server, location 这个指令可以指定连接请求实体的缓冲区大小。如果连接请求超过缓存区指定的值，那么这些请求实体的整体或部分将尝试写入一个临时文件。默认值为两个内存分页大小值，根据平台的不同，可能是8k或16k。1234client_body_temp_path语法：client_body_temp_path dir-path [ level1 [ level2 [ level3 ] 默认值：client_body_temp 使用字段：http, server, location 指令指定连接请求实体试图写入的临时文件路径。可以指定三级目录结构，如：1client_body_temp_path /spool/nginx/client_temp 1 2; 那么它的目录结构可能是这样：1/spool/nginx/client_temp/7/45/00000123457 123456client_body_timeout语法：client_body_timeout time默认值：60 使用字段：http, server, location 指令指定读取请求实体的超时时间。这里的超时是指一个请求实体没有进入读取步骤，如果连接超过这个时间而客户端没有任何响应，Nginx将返回一个"Request time out" (408)错误 1234567client_header_buffer_size语法：client_header_buffer_size size 默认值：1k 使用字段：http, server 指令指定客户端请求头部的缓冲区大小绝大多数情况下一个请求头不会大于1k不过如果有来自于wap客户端的较大的cookie它可能会大于1k，Nginx将分配给它一个更大的缓冲区，这个值可以在large_client_header_buffers里面设置。 123456client_header_timeout语法：client_header_timeout time 默认值：60 使用字段：http, server 指令指定读取客户端请求头标题的超时时间。这里的超时是指一个请求头没有进入读取步骤，如果连接超过这个时间而客户端没有任何响应，Nginx将返回一个"Request time out" (408)错误。 1234567client_max_body_size语法：client_max_body_size size 默认值：client_max_body_size 1m 使用字段：http, server, location 指令指定允许客户端连接的最大请求实体大小，它出现在请求头部的Content-Length字段。如果请求大于指定的值，客户端将收到一个"Request Entity Too Large" (413)错误。记住，浏览器并不知道怎样显示这个错误。 12345678910111213default_type语法： default_type MIME-type 默认值：default_type text/plain 使用字段：http, server, location 某个文件在标准MIME视图没有指定的情况下的默认MIME类型。参考typeslocation = /proxy.pac &#123; default_type application/x-ns-proxy-autoconfig;&#125;location = /wpad.dat &#123; rewrite . /proxy.pac; default_type application/x-ns-proxy-autoconfig;&#125; 123456directio语法：directio [size|off] 默认值：directio off 使用字段：http, server, location 这个参数指定在读取文件大小大于指定值的文件时使用O_DIRECT（FreeBSD, Linux），F_NOCACHE（Mac OS X）或者调用directio()函数（Solaris），当一个请求用到这个参数时会禁用sendfile，通常这个参数用于大文件。directio 4m; 1234567891011121314151617181920error_page语法：error_page code [ code... ] [ = | =answer-code ] uri | @named_location 默认值：no 使用字段：http, server, location, location 中的if字段 这个参数可以为错误代码指定相应的错误页面error_page 404 /404.html;error_page 502 503 504 /50x.html;error_page 403 http://example.com/forbidden.html;error_page 404 = @fetch;同样，你也可以修改返回的错误代码：error_page 404 =200 /.empty.gif;如果一个错误的响应经过代理或者FastCGI服务器并且这个服务器可以返回不同的响应码，如200, 302, 401或404，那么可以指定响应码返回：error_page 404 = /404.php;如果在重定向时不需要改变URI，可以将错误页面重定向到一个命名的location字段中：location / ( error_page 404 = @fallback;)location @fallback ( proxy_pass http://backend;) 1234if_modified_since语法：if_modified_since [off|exact|before]默认值：if_modified_since exact 使用字段：http, server, location 1234567891011121314internal语法：internal 默认值：no 使用字段： location internal指令指定某个location只能被“内部的”请求调用，外部的调用请求会返回"Not found" (404)“内部的”是指下列类型：·指令error_page重定向的请求。·ngx_http_ssi_module模块中使用include virtual指令创建的某些子请求。·ngx_http_rewrite_module模块中使用rewrite指令修改的请求。一个防止错误页面被用户直接访问的例子：error_page 404 /404.html;location /404.html &#123; internal;&#125; 123456keepalive_timeout语法：keepalive_timeout [ time ] [ time ]默认值：keepalive_timeout 75 使用字段：http, server, location 参数的第一个值指定了客户端与服务器长连接的超时时间，超过这个时间，服务器将关闭连接。参数的第二个值（可选）指定了应答头中Keep-Alive: timeout=time的time值，这个值可以使一些浏览器知道什么时候关闭连接，以便服务器不用重复关闭，如果不指定这个参数，nginx不会在应答头中发送Keep-Alive信息。（但这并不是指怎样将一个连接“Keep-Alive”） 参数的这两个值可以不相同下面列出了一些服务器如何处理包含Keep-Alive的应答头： ·MSIE和Opera将Keep-Alive: timeout=N头忽略。 ·MSIE保持一个连接大约60-65秒，然后发送一个TCP RST。 ·Opera将一直保持一个连接处于活动状态。 ·Mozilla将一个连接在N的基础上增加大约1-10秒。 ·Konqueror保持一个连接大约N秒。 12345keepalive_requests语法：keepalive_requests n 默认值：keepalive_requests 100 使用字段：http, server, location 服务器保持长连接的请求数。 123456789large_client_header_buffers语法：large_client_header_buffers number size 默认值：large_client_header_buffers 4 4k/8k 使用字段：http, server 指定客户端一些比较大的请求头使用的缓冲区数量和大小。请求字段不能大于一个缓冲区大小，如果客户端发送一个比较大的头，nginx将返回"Request URI too large" (414)同样，请求的头部最长字段不能大于一个缓冲区，否则服务器将返回"Bad request" (400)。缓冲区只在需求时分开。默认一个缓冲区大小为操作系统中分页文件大小，通常是4k或8k，如果一个连接请求最终将状态转换为keep-alive，它所占用的缓冲区将被释放。 12345678910limit_except语法：limit_except methods &#123;...&#125; 默认值：no 使用字段：location 指令可以在location字段中做一些http动作的限制。ngx_http_access_module和ngx_http_auth_basic_module模块有很强的访问控制功能。limit_except GET &#123; allow 192.168.1.0/32; deny all;&#125; 123456789101112limit_rate语法：limit_rate speed 默认值：no 使用字段：http, server, location, location中的if字段 限制将应答传送到客户端的速度，单位为字节/秒，限制仅对一个连接有效，即如果一个客户端打开2个连接，则它的速度是这个值乘以二。由于一些不同的状况，可能要在server字段来限制部分连接的速度，那么这个参数并不适用，不过你可以选择设置$limit_rate变量的值来达到目的：server &#123; if ($slow) &#123; set $limit_rate 4k; &#125;&#125;同样可以通过设置X-Accel-Limit-Rate头（NginxXSendfile）来控制proxy_pass返回的应答。并且不借助X-Accel-Redirect头来完成。 123456789101112limit_rate_after语法：limit_rate_after time 默认值：limit_rate_after 1m 使用字段：http, server, location, location中的if字段 在应答一部分被传递后限制速度：limit_rate_after 1m;limit_rate 100k;listen默认值：listen 80 使用字段：server listen指令指定了server&#123;...&#125;字段中可以被访问到的ip地址及端口号，可以只指定一个ip，一个端口，或者一个可解析的服务器名。 1234location语法：location [=|~|~*|^~|@] /uri/ &#123; ... &#125; 默认值：no 使用字段：server 这个参数根据URI的不同需求来进行配置，可以使用字符串与正则表达式匹配，如果要使用正则表达式，你必须指定下列前缀： 1、~* 不区分大小写。 2、~ 区分大小写。 要确定该指令匹配特定的查询，程序将首先对字符串进行匹配，字符串匹配将作为查询的开始，最确切的匹配将被使用。然后，正则表达式的匹配查询开始，匹配查询的第一个正则表达式找到后会停止搜索，如果没有找到正则表达式，将使用字符串的搜索结果。在一些操作系统，如Mac OS X和Cygwin，字符串将通过不区分大小写的方式完成匹配（0.7.7），但是，比较仅限于单字节的语言环境。正则表达式可以包含捕获（0.7.40），并用于其它指令中。可以使用“^~”标记禁止在字符串匹配后检查正则表达式，如果最确切的匹配location有这个标记，那么正则表达式不会被检查。使用“=”标记可以在URI和location之间定义精确的匹配，在精确匹配完成后并不进行额外的搜索，例如有请求“/”发生，则可以使用“location = /”来加速这个处理。即使没有“=”和“^~”标记，精确的匹配location在找到后同样会停止查询。下面是各种查询方式的总结： 1、前缀“=”表示精确匹配查询，如果找到，立即停止查询。 2、指令仍然使用标准字符串，如果匹配使用“^~”前缀，停止查询。 3、正则表达式按照他们在配置文件中定义的顺序。 4、如果第三条产生一个匹配，这个匹配将被使用，否则将使用第二条的匹配。 1234log_not_found语法：log_not_found [on|off] 默认值：log_not_found on 使用字段：http, server, location 指令指定是否将一些文件没有找到的错误信息写入error_log指定的文件中。1234log_subrequest语法：log_subrequest [on|off]默认值：log_subrequest off 使用字段：http, server, location 指令指定是否将一些经过rewrite rules和/或SSI requests的子请求日志写入access_log指定的文件中。1234msie_padding语法：msie_padding [on|off] 默认值：msie_padding on 使用字段：http, server, location 指令指定开启或关闭MSIE浏览器和chrome浏览器（0.8.25+）的msie_padding特征，当这个功能开启，nginx将为响应实体分配最小512字节，以便响应大于或等于400的状态代码。指令预防在MSIE和chrome浏览器中激活“友好的”HTTP错误页面，以便不在服务器端隐藏更多的错误信息。1234msie_refresh语法： msie_refresh [on|off] 默认值：msie_refresh off 使用字段：http, server, location 指令允许或拒绝为MSIE发布一个refresh而不是做一次redirect1234open_file_cache语法：open_file_cache max = N [inactive = time] | off 默认值：open_file_cache off 使用字段：http, server, location 这个指令指定缓存是否启用，如果启用，将记录文件以下信息： ·打开的文件描述符，大小信息和修改时间。 ·存在的目录信息。 ·在搜索文件过程中的错误信息 -- 没有这个文件、无法正确读取，参考open_file_cache_errors 指令选项： ·max - 指定缓存的最大数目，如果缓存溢出，最长使用过的文件（LRU）将被移除。 ·inactive - 指定缓存文件被移除的时间，如果在这段时间内文件没被下载，默认为60秒。 ·off - 禁止缓存。 例:1234open_file_cache max=1000 inactive=20s;open_file_cache_valid 30s;open_file_cache_min_uses 2;open_file_cache_errors on; 1234open_file_cache_errors语法：open_file_cache_errors on | off 默认值：open_file_cache_errors off 使用字段：http, server, location 这个指令指定是否在搜索一个文件是记录cache错误。1234open_file_cache_min_uses语法：open_file_cache_min_uses number 默认值：open_file_cache_min_uses 1 使用字段：http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数，如果使用更大的值，文件描述符在cache中总是打开状态。1234open_file_cache_valid语法：open_file_cache_valid time 默认值：open_file_cache_valid 60 使用字段：http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息。1234optimize_server_names语法：optimize_server_names [ on|off ] 默认值：optimize_server_names on 使用字段：http, server 这个指令指定是否在基于域名的虚拟主机中开启最优化的主机名检查。尤其是检查影响到使用主机名的重定向，如果开启最优化，那么所有基于域名的虚拟主机监听的一个“地址：端口对”具有相同的配置，这样在请求执行的时候并不进行再次检查，重定向会使用第一个server name。如果重定向必须使用主机名并且在客户端检查通过，那么这个参数必须设置为off。注意：这个参数不建议在nginx 0.7.x版本中使用，请使用server_name_in_redirect。1234port_in_redirect语法：port_in_redirect [ on|off ] 默认值：port_in_redirect on 使用字段：http, server, location 这个指令指定是否在让nginx在重定向操作中对端口进行操作。如果这个指令设置为off，在重定向的请求中nginx不会在url中添加端口。1234recursive_error_pages语法：recursive_error_pages [on|off] 默认值：recursive_error_pages off 使用字段：http, server, location recursive_error_pages指定启用除第一条error_page指令以外其他的error_page。1234resolver语法：resolver address 默认值：no 使用字段：http, server, location 指定DNS服务器地址，如：resolver 127.0.0.1;1234resolver_timeout语法：resolver_timeout time 默认值：30s 使用字段：http, server, location 解析超时时间。如：resolver_timeout 5s;1234root语法：root path 默认值：root html 使用字段：http, server, location ,location中的if字段 请求到达后的文件根目录。下例中：123location /i/ &#123; root /spool/w3;&#125; 如果请求”/i/top.gif”文件，nginx将转到”/spool/w3/i/top.gif”文件。你可以在参数中使用变量。注意：在请求中root会添加这个location到它的值后面，即”/i/top.gif”并不会请求”/spool/w3/top.gif”文件，如果要实现上述类似于apache alias的功能，可以使用alias指令。1234satisfy_any语法：satisfy_any [ on|off ] 默认值：satisfy_any off 使用字段：location 指令可以检查至少一个成功的密码效验，它在NginxHttpAccessModule或NginxHttpAuthBasicModule这两个模块中执行。1234567location / &#123; satisfy_any on; allow 192.168.1.0/32; deny all; auth_basic "closed site"; auth_basic_user_file conf/htpasswd;&#125; 1234send_timeout语法：send_timeout the time 默认值：send_timeout 60 使用字段：http, server, location 指令指定了发送给客户端应答后的超时时间，Timeout是指没有进入完整established状态，只完成了两次握手，如果超过这个时间客户端没有任何响应，nginx将关闭连接。123sendfile语法：sendfile [ on|off ] 默认值：sendfile off 使用字段：http, server, location是否启用sendfile()函数。1234server语法：server &#123;...&#125; 默认值：no 使用字段：http server字段包含虚拟主机的配置。没有明确的机制来分开基于域名（请求中的主机头）和基于IP的虚拟主机。可以通过listen指令来指定必须连接到这个server块的所有地址和端口，并且在server_name指令中可以指定所有的域名。1234server_name语法：server_name name [... ] 默认值：server_name hostname 使用字段：server 这个指令作用：将HTTP请求的主机头与在nginx配置文件中的server{…}字段中指定的参数进行匹配，并且找出第一个匹配结果。这就是如何定义虚拟主机的方法，域名遵循下述优先级规则： 1、完整匹配的名称。 2、名称开始于一个文件通配符：*.example.com。 3、名称结束于一个文件通配符：www.example.*。 4、使用正则表达式的名称。 如果没有匹配的结果，nginx配置文件将安装以下优先级使用[#server server { … }]字段： 1、listen指令被标记为default的server字段。 2、第一个出现listen（或者默认的listen 80）的server字段。 如果server_name_in_redirect被设置，这个指令将用于设置HTTP重定向的服务器名。1234server_name_in_redirect语法：server_name_in_redirect on|off 默认值：server_name_in_redirect on 使用字段：http, server, location 如果这个指令打开，nginx将使用server_name指定的基本服务器名作为重定向地址，如果关闭，nginx将使用请求中的主机头。1234server_names_hash_max_size语法：server_names_hash_max_size number 默认值：server_names_hash_max_size 512 使用字段：http 服务器名称哈希表的最大值，更多信息请参考nginx Optimizations。1234server_names_hash_bucket_size语法：server_names_hash_bucket_size number 默认值：server_names_hash_bucket_size 32/64/128 使用字段：http 服务器名称哈希表每个页框的大小，这个指令的默认值依赖于cpu缓存。更多信息请参考nginx Optimizations。1234server_tokens语法：server_tokens on|off 默认值：server_tokens on 使用字段：http, server, location 是否在错误页面和服务器头中输出nginx版本信息。1234tcp_nodelay语法：tcp_nodelay [on|off] 默认值：tcp_nodelay on 使用字段：http, server, location 这个指令指定是否使用socket的TCP_NODELAY选项，这个选项只对keep-alive连接有效。点击这里了解更多关于TCP_NODELAY选项的信息。1234tcp_nopush语法：tcp_nopush [on|off] 默认值：tcp_nopush off 使用字段：http, server, location 这个指令指定是否使用socket的TCP_NOPUSH（FreeBSD）或TCP_CORK（linux）选项，这个选项只在使用sendfile时有效。设置这个选项的将导致nginx试图将它的HTTP应答头封装到一个包中。点击这里查看关于TCP_NOPUSH和TCP_CORK选项的更多信息。1234try_files语法：try_files file1 [file2 ... filen] fallback 默认值：none 使用字段：location 这个指令告诉nginx将测试参数中每个文件的存在，并且URI将使用第一个找到的文件，如果没有找到文件，将请求名为fallback（可以使任何名称）的location字段，fallback是一个必须的参数，它可以是一个命名的location或者可靠的URI。123types语法：types &#123;...&#125; 使用字段：http, server, location 这个字段指定一些扩展的文件对应方式与应答的MIME类型，一个MIME类型可以有一些与其类似的扩展。默认使用以下文件对应方式：12345types &#123; text/html html; image/gif gif; image/jpeg jpg;&#125; 完整的对应视图文件为conf/mime.types，并且将被包含。如果你想让某些特定的location的处理方式使用MIME类型：application/octet-stream，可以使用以下配置：1234location /download/ &#123; types &#123; &#125; default_type application/octet-stream;&#125; 变量core module 支持一些内置的变量，与apache使用的变量相一致。首先，一些变量代表了客户端请求头部的一些字段，如：$http_user_agent, $http_cookie等等。注意，由于这些变量会在请求中定义，所以可能无法保证他们是存在的或者说可以定义到一些别的地方（例如遵循一定的规范）。一些其他变量：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455$arg_PARAMETER这个变量包含在查询字符串时GET请求PARAMETER的值。$args这个变量等于请求行中的参数。$binary_remote_addr二进制码形式的客户端地址。$content_length请求头中的Content-length字段。$content_type请求头中的Content-Type字段。$cookie_COOKIEcookie COOKIE的值。$document_root当前请求在root指令中指定的值。$document_uri与$uri相同。$host请求中的主机头字段，如果请求中的主机头不可用，则为服务器处理请求的服务器名称。$is_args如果$args设置，值为"?"，否则为""。$limit_rate这个变量可以限制连接速率。$nginx_version当前运行的nginx版本号。$query_string与$args相同。$remote_addr客户端的IP地址。$remote_port客户端的端口。$remote_user已经经过Auth Basic Module验证的用户名。$request_filename当前连接请求的文件路径，由root或alias指令与URI请求生成。$request_body这个变量包含请求的主要信息。在使用proxy_pass或fastcgi_pass指令的location中比较有意义。$request_body_file客户端请求主体信息的临时文件名。$request_method这个变量是客户端请求的动作，通常为GET或POST。包括0.8.20及之前的版本中，这个变量总为main request中的动作，如果当前请求是一个子请求，并不使用这个当前请求的动作。$request_uri这个变量等于包含一些客户端请求参数的原始URI，它无法修改，请查看$uri更改或重写URI。$schemeHTTP方法（如http，https）$server_addr服务器地址，在完成一次系统调用后可以确定这个值，如果要绕开系统调用，则必须在listen中指定地址并且使用bind参数。$server_name服务器名称$server_port请求到达服务器的端口号。$server_protocol请求使用的协议，通常是HTTP/1.0或HTTP/1.1。$uri请求中的当前URI(不带请求参数，参数位于$args)，可以不同于浏览器传递的$request_uri的值，它可以通过内部重定向，或者使用index指令进行修改。 HTTP负载均衡模块这个模块为后端的服务器提供简单的负载均衡（轮询（round-robin）和连接IP（client IP））如下例：1234567891011upstream backend &#123; server backend1.example.com weight=5; server backend2.example.com:8080; server unix:/tmp/backend3;&#125; server &#123; location / &#123; proxy_pass http://backend; &#125;&#125; 指令1234ip_hash语法：ip_hash 默认值：none 使用字段：upstream 这个指令将基于客户端连接的IP地址来分发请求。哈希的关键字是客户端的C类网络地址，这个功能将保证这个客户端请求总是被转发到一台服务器上，但是如果这台服务器不可用，那么请求将转发到另外的服务器上，这将保证某个客户端有很大概率总是连接到一台服务器。无法将权重（weight）与ip_hash联合使用来分发连接。如果有某台服务器不可用，你必须标记其为“down”，如下例:1234567upstream backend &#123; ip_hash; server backend1.example.com; server backend2.example.com; server backend3.example.com down; server backend4.example.com;&#125; 1234server语法：server name [parameters] 默认值：none 使用字段：upstream 指定后端服务器的名称和一些参数，可以使用域名，IP，端口，或者unix socket。如果指定为域名，则首先将其解析为IP。 weight = NUMBER - 设置服务器权重，默认为1。 max_fails = NUMBER - 在一定时间内（这个时间在fail_timeout参数中设置）检查这个服务器是否可用时产生的最多失败请求数，默认为1，将其设置为0可以关闭检查，这些错误在proxy_next_upstream或fastcgi_next_upstream（404错误不会使max_fails增加）中定义。 fail_timeout = TIME - 在这个时间内产生了max_fails所设置大小的失败尝试连接请求后这个服务器可能不可用，同样它指定了服务器不可用的时间（在下一次尝试连接请求发起之前），默认为10秒，fail_timeout与前端响应时间没有直接关系，不过可以使用proxy_connect_timeout和proxy_read_timeout来控制。 down - 标记服务器处于离线状态，通常和ip_hash一起使用。 backup - (0.6.7或更高)如果所有的非备份服务器都宕机或繁忙，则使用本服务器（无法和ip_hash指令搭配使用）。 示例配置12345upstream backend &#123; server backend1.example.com weight=5; server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3;&#125; 注意：如果你只使用一台上游服务器，nginx将设置一个内置变量为1，即max_fails和fail_timeout参数不会被处理。结果：如果nginx不能连接到上游，请求将丢失。解决：使用多台上游服务器。1234upstream语法：upstream name &#123; ... &#125; 默认值：none 使用字段：http 这个字段设置一群服务器，可以将这个字段放在proxy_pass和fastcgi_pass指令中作为一个单独的实体，它们可以可以是监听不同端口的服务器，并且也可以是同时监听TCP和Unix socket的服务器。服务器可以指定不同的权重，默认为1。示例配置12345upstream backend &#123; server backend1.example.com weight=5; server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3;&#125; 请求将按照轮询的方式分发到后端服务器，但同时也会考虑权重。在上面的例子中如果每次发生7个请求，5个请求将被发送到backend1.example.com，其他两台将分别得到一个请求，如果有一台服务器不可用，那么请求将被转发到下一台服务器，直到所有的服务器检查都通过。如果所有的服务器都无法通过检查，那么将返回给客户端最后一台工作的服务器产生的结果。变量12345678$upstream_addr前端服务器处理请求的服务器地址$upstream_status前端服务器的响应状态。$upstream_response_time前端服务器的应答时间，精确到毫秒，不同的应答以逗号和冒号分开。$upstream_http_$HEADER随意的HTTP协议头 HTTP访问控制模块这个模块提供简单的基于主机的访问控制。ngx_http_access_module这个模块可以详细的检查客户端IP，并且按顺序执行第一条匹配的规则。如下例：123456location / &#123; deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; deny all;&#125; 上面的例子中仅允许192.168.1.0/24和10.1.1.0/16网络段访问，但192.168.1.1是个例外。如果要实施很多复杂的规则，那么最好使用GeoIP module模块。指令1234Allow语法：allow [ address | CIDR | all ] 默认值：no 使用字段：http, server, location, limit_except 指令指定了允许访问的IP或网络段。1234deny语法：deny [ address | CIDR | all ] 默认值：no 使用字段：http, server, location, limit_except 指令指定了拒绝访问的IP或网络段。提示和技巧：HttpAccess模块可以和error_page指令搭配使用来重定向一个未经验证的访问请求。1234567error_page 403 http://example.com/forbidden.html;location / &#123; deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; deny all;&#125; HTTP基本认证模块这个模块提供基于用户名与密码的验证来保护你的站点或站点的一部分。如下例：1234location / &#123; auth_basic "Restricted"; auth_basic_user_file conf/htpasswd;&#125; 指令1234auth_basic语法：auth_basic [ text|off ] 默认值：auth_basic off 使用字段：http, server, location, limit_except 指令包含一个具有测试用户名和密码的HTTP基本认证，指定的参数将用于认证域。如果将值设置为“off”则忽略下级指令继承的动作。1234auth_basic_user_file语法：auth_basic_user_file the_file 默认值：no 使用字段：http, server, location, limit_except HTTP目录清单生成模块这个模块提供自动目录列表。连接请求仅在ngx_http_index_module中没有找到主页文件时才会请求这个模块。如下例：123location / &#123; autoindex on;&#125; 指令1234autoindex语法：autoindex [ on|off ] 默认值：autoindex off 使用字段：http, server, location 是否使用自动目录列表。1234autoindex_exact_size语法：autoindex_exact_size [ on|off ] 默认值：autoindex_exact_size on 使用字段：http, server, location 指定生成的自动目录文件大小，可以是精确到bytes或者使用KB, MB或GB。1234autoindex_localtime语法：autoindex_localtime [ on|off ] 默认值：autoindex_localtime off 使用字段：http, server, location 是否在目录列表文件中显示本地时间（GMT时间），默认为关。 浏览器相关模块这个模块按照请求头中的“User-agent”来创建一些变量： $modern_browser - 如果浏览器被识别为一个当前流行的浏览器，这个值等于指令modern_browser_value指定的值。 $ancient_browser - 如果浏览器被识别为一个比较旧的浏览器，这个值等于指令ancient_browser_value指定的值。 $msie - 如果浏览器被识别为MSIE，这个值为1。 如果不需要这个模块，可以在编译nginx时增加–without-http_browser_module参数。指令1234ancient_browser语法：ancient_browser line [ line... ] 默认值：no 使用字段：http, server, location 在”User-agent”字段中的浏览器被识别为旧浏览器时，这个指令指定一些子链。一个比较特殊的字段是”netscape4”，它对应正则表达式”^Mozilla/[1-4] “。12345ancient_browser_value语法：ancient_browser_value line 默认值：ancient_browser_value 1 使用字段：http, server, location 指定变量$ancient_browser的值。 1234modern_browser语法：modern_browser browser version|unlisted 默认值：no 使用字段：http, server, location 指令将指定哪个版本的浏览器将被认为是目前流行的。可以指定的浏览器为：msie, gecko (基于Mozilla的浏览器) opera, safari, konqueror。可以使用的版本格式为X, X.X, X.X.X, 或X.X.X.X，每个的最大值为4000, 4000.99, 4000.99.99,和4000.99.99.99。一个特殊的值”unlisted”在被认为是流行的浏览器中指定，而不是通过modern_browser或ancient_browser指令。如果请求头中没有”User-agent”字段，那么这个浏览器被认为是古老的（除非指定“modern_browser unlisted”）。1234modern_browser_value语法：modern_browser_value line 默认值：modern_browser_value 1 使用字段：http, server, location 指定$modern_browser变量的值。 字符集设置模块这个模块将在应答头中为”Content-Type”字段添加字符编码。此外，这个模块可以将数据重新编码，只能在单向对其进行重新编码，即来自服务器到达客户端。指令1234charset语法：charset encoding|off 默认值：charset off 使用字段：http, server, location, location中的if字段 这个指令使应答头中的”Content-Type”字段使用指定的编码集，如果这个字符集与source_charset指令设置的字符集不相同，将重新编码字符集，参数off表明不在应答头中添加”Content-Type”信息。1234charset_map语法：charset_map encoding1 encoding2 &#123;...&#125; 默认值：no 使用字段：http, server, location charset_map指定了一个编码转换表，同时会创建一个反向转换表，代码均使用十六进制，如果在80-FF范围内没有被记录的代码，它们将被标记为”？”。1234override_charset语法：override_charset on|off 默认值：override_charset off 使用字段：http, server, location, if中的location字段 参数指定在代理服务器或者FastCGI服务器上取得的应答头中存在”Content-Type”字段，将为应答启用编码转换，如果允许编码转换，将使用应答头中指定的编码对其初始化。注意如果是在一个子查询中取得的应答，会始终将应答中的编码转换为基础编码，并不依赖于override_charset指令。1234source_charset语法：source_charset encoding 默认值：no 使用字段：http, server, location, if中的location字段 参数指定了应答中的初始代码，如果这个参数与charset指令中的不同，将启用编码转换 Empty GIF模块这个模块在内存中保存一个能够很快传递的1×1透明GIF。简单用法：123location = /_.gif &#123; empty_gif;&#125; 指令1234empty_gif语法：empty_gif 默认值：n/a 使用字段：location FastCGI模块这个模块允许nginx同FastCGI协同工作，并且控制哪些参数将被安全传递。指令1234fastcgi_buffer_size语法：fastcgi_buffer_size the_size ;默认值：fastcgi_buffer_size 4k/8k ;使用字段：http, server, location 这个参数指定将用多大的缓冲区来读取从FastCGI服务器到来应答的第一部分。通常来说在这个部分中包含一个小的应答头。默认的缓冲区大小为fastcgi_buffers指令中的每块大小，可以将这个值设置更小。1234fastcgi_buffers语法：fastcgi_buffers the_number is_size; 默认值：fastcgi_buffers 8 4k/8k; 使用字段：http, server, location 这个参数指定了从FastCGI服务器到来的应答，本地将用多少和多大的缓冲区读取，默认这个参数等于分页大小，根据环境的不同可能是4K, 8K或16K。1234fastcgi_cache语法：fastcgi_cache zone|off; 默认值：off 使用字段：http, server, location 为缓存实际使用的共享内存指定一个区域，相同的区域可以用在不同的地方。1234fastcgi_cache_key语法：fastcgi_cache_key line默认值：none 使用字段：http, server, location 设置缓存的关键字，如：fastcgi_cache_key localhost:9000$request_uri;1234fastcgi_cache_path语法：fastcgi_cache_path path [levels=m:n] keys_zone=name:size [inactive=time] [max_size=size] 默认值：none 使用字段：http clean_time参数在0.7.45版本中已经移除。这个指令指定FastCGI缓存的路径以及其他的一些参数，所有的数据以文件的形式存储，缓存的关键字(key)和文件名为代理的url计算出的MD5值。Level参数设置缓存目录的目录分级以及子目录的数量，例如指令如果设置为：fastcgi_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m;那么数据文件将存储为：/data/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c缓存中的文件首先被写入一个临时文件并且随后被移动到缓存目录的最后位置，0.8.9版本之后可以将临时文件和缓存文件存储在不同的文件系统，但是需要明白这种移动并不是简单的原子重命名系统调用，而是整个文件的拷贝，所以最好在fastcgi_temp_path和fastcgi_cache_path的值中使用相同的文件系统。另外，所有活动的关键字及数据相关信息都存储于共享内存池，这个值的名称和大小通过key_zone参数指定，inactive参数指定了内存中的数据存储时间，默认为10分钟。max_size参数设置缓存的最大值，一个指定的cache manager进程将周期性的删除旧的缓存数据。1234fastcgi_cache_methods语法：fastcgi_cache_methods [GET HEAD POST]; 默认值：fastcgi_cache_methods GET HEAD; 使用字段：main,http,location 无法禁用GET/HEAD ，即使你只是这样设置：fastcgi_cache_methods POST;1234fastcgi_cache_min_uses语法：fastcgi_cache_min_uses n 默认值：fastcgi_cache_min_uses 1 使用字段：http, server, location 指令指定了经过多少次请求的相同URL将被缓存。1234fastcgi_cache_path语法：fastcgi_cache_path /path/to/cache [levels=m:n keys_zone=name:time inactive=time] 默认值：none 使用字段：http 1234fastcgi_cache_use_stale语法：fastcgi_cache_use_stale [updating|error|timeout|invalid_header|http_500] 默认值：fastcgi_cache_use_stale off; 使用字段：http, server, location 1234fastcgi_cache_valid语法：fastcgi_cache_valid [http_error_code|time] 默认值：none 使用字段：http, server, location 为指定的http返回代码指定缓存时间，例如：12fastcgi_cache_valid 200 302 10m;fastcgi_cache_valid 404 1m; 将响应状态码为200和302缓存10分钟，404缓存1分钟。默认情况下缓存只处理200，301，302的状态。同样也可以在指令中使用any表示任何一个。123fastcgi_cache_valid 200 302 10m;fastcgi_cache_valid 301 1h;fastcgi_cache_valid any 1m; 1234fastcgi_connect_timeout语法：fastcgi_connect_timeout time 默认值：fastcgi_connect_timeout 60 使用字段：http, server, location 指定同FastCGI服务器的连接超时时间，这个值不能超过75秒。1234fastcgi_index语法：fastcgi_index file 默认值：none 使用字段：http, server, location 如果URI以斜线结尾，文件名将追加到URI后面，这个值将存储在变量$fastcgi_script_name中。例如：12fastcgi_index index.php;fastcgi_param SCRIPT_FILENAME /home/www/scripts/php$fastcgi_script_name; 请求”/page.php”的参数SCRIPT_FILENAME将被设置为”/home/www/scripts/php/page.php”，但是”/“为”/home/www/scripts/php/index.php”。123fastcgi_hide_header语法：fastcgi_hide_header name 使用字段：http, server, location 默认情况下nginx不会将来自FastCGI服务器的”Status”和”X-Accel-…”头传送到客户端，这个参数也可以隐藏某些其它的头。如果必须传递”Status”和”X-Accel-…”头，则必须使用fastcgi_pass_header强制其传送到客户端。1234fastcgi_ignore_client_abort语法：fastcgi_ignore_client_abort on|off 默认值：fastcgi_ignore_client_abort off 使用字段：http, server, location 如果当前连接请求FastCGI服务器失败，为防止其与nginx服务器断开连接，可以用这个指令。123fastcgi_ignore_headers语法：fastcgi_ignore_headers name [name...] 使用字段：http, server, location 这个指令禁止处理一些FastCGI服务器应答的头部字段，比如可以指定像”X-Accel-Redirect”, “X-Accel-Expires”, “Expires”或”Cache-Control”等。1234fastcgi_intercept_errors语法：fastcgi_intercept_errors on|off 默认值：fastcgi_intercept_errors off 使用字段：http, server, location 这个指令指定是否传递4xx和5xx错误信息到客户端，或者允许nginx使用error_page处理错误信息。你必须明确的在error_page中指定处理方法使这个参数有效，正如Igor所说“如果没有适当的处理方法，nginx不会拦截一个错误，这个错误不会显示自己的默认页面，这里允许通过某些方法拦截错误。1234fastcgi_max_temp_file_size语法：fastcgi_max_temp_file_size 0 默认值：fastcgi_max_temp_file_size 0 使用字段：http, server, location 根据源代码关闭FastCGI缓冲。1234fastcgi_no_cache语法：fastcgi_no_cache variable [...]默认值：None 使用字段：http, server, location 确定在何种情况下缓存的应答将不会使用，示例：12fastcgi_no_cache $cookie_nocache $arg_nocache$arg_comment;fastcgi_no_cache $http_pragma $http_authorization; 如果为空字符串或者等于0，表达式的值等于false，例如，在上述例子中，如果在请求中设置了cookie “nocache”，缓存将被绕过。1234fastcgi_next_upstream语法：fastcgi_next_upstream error|timeout|invalid_header|http_500|http_503|http_404|off 默认值：fastcgi_next_upstream error timeout 使用字段：http, server, location 指令指定哪种情况请求将被转发到下一个FastCGI服务器： error — 传送中的请求或者正在读取应答头的请求在连接服务器的时候发生错误。 timeout — 传送中的请求或者正在读取应答头的请求在连接服务器的时候超时。 invalid_header — 服务器返回空的或者无效的应答。 http_500 — 服务器返回500应答代码。 http_503 — 服务器返回503应答代码。 http_404 — 服务器返回404应答代码。 off — 禁止请求传送到下一个FastCGI服务器。 注意传送请求在传送到下一个服务器之前可能已经将空的数据传送到了客户端，所以，如果在数据传送中有错误或者超时发生，这个指令可能无法修复一些传送错误。1234fastcgi_param语法：fastcgi_param parameter value 默认值：none 使用字段：http, server, location 指定一些传递到FastCGI服务器的参数。可以使用字符串，变量，或者其组合，这里的设置不会继承到其他的字段，设置在当前字段会清除掉任何之前的定义。下面是一个PHP需要使用的最少参数：12fastcgi_param SCRIPT_FILENAME /home/www/scripts/php$fastcgi_script_name;fastcgi_param QUERY_STRING $query_string; PHP使用SCRIPT_FILENAME参数决定需要执行哪个脚本，QUERY_STRING包含请求中的某些参数。如果要处理POST请求，则需要另外增加三个参数：123fastcgi_param REQUEST_METHOD $request_method;fastcgi_param CONTENT_TYPE $content_type;fastcgi_param CONTENT_LENGTH $content_length; 如果PHP在编译时带有–enable-force-cgi-redirect，则必须传递值为200的REDIRECT_STATUS参数：fastcgi_param REDIRECT_STATUS 200;1234fastcgi_pass语法：fastcgi_pass fastcgi-server 默认值：none 使用字段：http, server, location 1234fastcgi_pass_header语法：fastcgi_pass_header name 默认值：none 使用字段：http, server, location 1234fastcgi_read_timeout语法：fastcgi_read_timeout time 默认值：fastcgi_read_timeout 60 使用字段：http, server, location 前端FastCGI服务器的响应超时时间，如果有一些直到它们运行完才有输出的长时间运行的FastCGI进程，或者在错误日志中出现前端服务器响应超时错误，可能需要调整这个值。12fastcgi_redirect_errors语法：fastcgi_redirect_errors on|off 指令重命名为fastcgi_intercept_errors。1234fastcgi_send_timeout语法：fastcgi_send_timeout time 默认值：fastcgi_send_timeout 60 使用字段：http, server, location 指令为上游服务器设置等待一个FastCGI进程的传送数据时间，如果有一些直到它们运行完才有输出的长时间运行的FastCGI进程，那么可以修改这个值，如果你在上有服务器的error log里面发现一些超时错误，那么可以恰当的增加这个值。指令指定请求服务器的超时时间，指完成了2次握手的连接，而不是完整的连接，如果在这期间客户端没有进行数据传递，那么服务器将关闭这个连接。123fastcgi_split_path_info语法：fastcgi_split_path_info regex 使用字段：location 1234fastcgi_store语法：fastcgi_store [on | off | path] 默认值：fastcgi_store off 使用字段：http, server, location 制定了存储前端文件的路径，参数on指定了将使用root和alias指令相同的路径，off禁止存储，此外，参数中可以使用变量使路径名更明确：fastcgi_store /data/www$original_uri;应答中的”Last-Modified”头将设置文件的最后修改时间，为了使这些文件更加安全，可以将其在一个目录中存为临时文件，使用fastcgi_temp_path指令。这个指令可以用在为那些不是经常改变的后端动态输出创建本地拷贝的过程中。如：1234567891011121314location /images/ &#123; root /data/www; error_page 404 = /fetch$uri;&#125;location /fetch &#123; internal; fastcgi_pass fastcgi://backend; fastcgi_store on; fastcgi_store_access user:rw group:rw all:r; fastcgi_temp_path /data/temp; alias /data/www;&#125; fastcgi_store并不是缓存，某些需求下它更像是一个镜像。1234fastcgi_store_access语法：fastcgi_store_access users:permissions [users:permission ...] 默认值：fastcgi_store_access user:rw 使用字段：http, server, location 这个参数指定创建文件或目录的权限，例如：fastcgi_store_access user:rw group:rw all:r;如果要指定一个组的人的相关权限，可以不写用户，如：fastcgi_store_access group:rw all:r;1234fastcgi_temp_path语法：fastcgi_temp_path path [level1 [level2 [level3]]] 默认值：fastcgi_temp_path fastcgi_temp 使用字段：http, server, location 变量12$fastcgi_script_name这个变量等于一个以斜线结尾的请求URI加上fastcgi_index给定的参数。可以用这个变量代替SCRIPT_FILENAME 和PATH_TRANSLATED，以确定php脚本的名称。 Geo模块geo指令使用ngx_http_geo_module模块提供的。默认情况下，nginx有加载这个模块，除非人为的 –without-http_geo_module。ngx_http_geo_module模块可以用来创建变量，其值依赖于客户端IP地址。指令1234geo 语法: geo [$address] $variable &#123; ... &#125;默认值: —配置段: http 定义从指定的变量获取客户端的IP地址。默认情况下，nginx从$remote_addr变量取得客户端IP地址，但也可以从其他变量获得。如12345678geo $remote_addr $geo &#123; default 0; 127.0.0.1 1;&#125;geo $arg_ttlsa_com $geo &#123; default 0; 127.0.0.1 1;&#125; 如果该变量的值不能代表一个合法的IP地址，那么nginx将使用地址“255.255.255.255”。nginx通过CIDR或者地址段来描述地址，支持下面几个参数： delete：删除指定的网络 default：如果客户端地址不能匹配任意一个定义的地址，nginx将使用此值。 如果使用CIDR，可以用“0.0.0.0/0”代替default。 include： 包含一个定义地址和值的文件，可以包含多个。 proxy：定义可信地址。 如果请求来自可信地址，nginx将使用其“X-Forwarded-For”头来获得地址。 相对于普通地址，可信地址是顺序检测的。 proxy_recursive：开启递归查找地址。 如果关闭递归查找，在客户端地址与某个可信地址匹配时，nginx将使用“X-Forwarded-For”中的最后一个地址来代替原始客户端地址。如果开启递归查找，在客户端地址与某个可信地址匹配时，nginx将使用“X-Forwarded-For”中最后一个与所有可信地址都不匹配的地址来代替原始客户端地址。 ranges：使用以地址段的形式定义地址，这个参数必须放在首位。为了加速装载地址库，地址应按升序定义。 123456789101112geo $country &#123; default ZZ; include conf/geo.conf; delete 127.0.0.0/16; proxy 192.168.100.0/24; proxy 2001:0db8::/32; 127.0.0.0/24 US; 127.0.0.1/32 RU; 10.1.0.0/16 RU; 192.168.1.0/24 UK;&#125; 123vim conf/geo.conf10.2.0.0/16 RU;192.168.2.0/24 RU; 地址段例子：123456789geo $country &#123; ranges; default ZZ; 127.0.0.0-127.0.0.0 US; 127.0.0.1-127.0.0.1 RU; 127.0.0.1-127.0.0.255 US; 10.1.0.0-10.1.255.255 RU; 192.168.1.0-192.168.1.255 UK;&#125; 遵循最精确匹配原则，即nginx使用能最精确匹配客户端地址的值。 Gzip模块这个模块允许在文件传输过程中使用gzip压缩。指令1234gzip语法：gzip on|off 默认值：gzip off 使用字段：http, server, location, location中的if字段 指定是否启用gzip压缩。1234gzip_buffers语法：gzip_buffers number size 默认值：gzip_buffers 4 4k/8k 使用字段：http, server, location 指定缓存压缩应答的缓冲区数量和大小，如果不设置，一个缓存区的大小为分页大小，根据环境的不同可能是4k或8k。1234gzip_comp_level语法：gzip_comp_level 1..9 默认值：gzip_comp_level 1 使用字段：http, server, location 指定压缩等级，其值从1到9，1为最小化压缩（处理速度快），9为最大化压缩（处理速度慢）。123gzip_disable语法：gzip_disable regex 使用字段：http, server, location 使用正则表达式来指定某些不需要gzip压缩的浏览器（将和User-Agents进行匹配）。依赖于PCRE库。在0.6.23版本中首次使用。1234gzip_http_version语法：gzip_http_version 1.0|1.1 默认值：gzip_http_version 1.1 使用字段：http, server, location 是否根据HTTP请求版本来启用gzip压缩。当HTTP版本为1.0时，Vary: Accept-Encoding没有被设置，这将引起某些代理缓存失效，可以使用add_header，同样，在使用这个版本时Content-Length也没有设置，因此Keepalive不能在这个版本使用。1234gzip_min_length语法：gzip_min_length length 默认值：gzip_min_length 0 使用字段：http, server, location 设置被压缩的最小请求，单位为bytes。少于这个值大小的请求将不会被压缩，这个值由请求头中的Content-Length字段决定。1234gzip_proxied语法：gzip_proxied [off|expired|no-cache|no-store|private|no_last_modified|no_etag|auth|any] ... 默认值：gzip_proxied off 使用字段：http, server, location 根据某些请求和应答来决定是否在对代理请求的应答启用压缩，事实上，代理请求取决于请求头中的“Via”字段，指令中可以同时指定多个不同的参数： off - 为所有代理请求禁用压缩。 expired - 当“Expires”头禁用缓存时启用压缩。 no-cache - 当“Cache-Control”头设置为no-cache时启用压缩。 no-store - 当“Cache-Control”头设置为no-store时启用压缩。 private - 当“Cache-Control”头设置为private时启用压缩。 no_last_modified - 当“Last-Modified”没有定义时启用压缩。 no_etag - 没有“ETag”头时启用压缩。 auth - 当有一个“Authorization”头时启用压缩。 any - 为所有请求启用压缩。 1234gzip_typesgzip_types mime-type [mime-type ...] 默认值：gzip_types text/html 使用字段：http, server, location 为除“text/html”之外的MIME类型启用压缩，“text/html”总是会被压缩。1234gzip_varyggzip_vary on|off 默认值：gzip_vary off 使用字段：http, server, location 启用应答头“Vary: Accept-Encoding”，注意，由于一个bug将导致IE 4-6无法缓存内容。 HTTP头处理模块这个模块允许设置任意的HTTP头。指令1234add_header语法：add_header name value 默认值：none 使用字段：http, server, location 当服务器应答代码为200, 204, 301, 302或304时为HTTP应答添加头。这个值可以使用变量注意这个指令只会在输出的头部中增加某个新字段，而并不能对某些已经定义的头（如server）进行重写，如果要实现这个操作可以使用第三方模块headers_more。1234expires语法：expires [time|@time-of-day|epoch|max|off] 默认值：expires off 使用字段：http, server, location 这个指令控制是否在应答中标记一个过期时间，如果是，如何标记。 off 将禁止修改头部中的 Expires和Cache-Control字段。 epoch 将Expires头设置为1 January, 1970 00:00:01 GMT。 max 将Expires头设置为31 December 2037 23:59:59 GMT，将Cache-Control最大化到10 years。 如果将指令设置为一个不带@标记的值，那么过期时间将是应答时间的相对时间（如果这个时间在“modified”之前），或者是文件的修改时间（当&quot;modified&quot;存在，在版本0.7.0和0.6.32可用），并且可以指定一个负的时间，它将Cache-Control头设置为no-cache比较。 如果指令的值被设置为一个带@标记的值，那么将指定一个绝对的time-of-day过期时间，可以指定两种格式分别为Hh或Hh:Mm，其中H的大小范围为0到24，M的大小范围为0到59（在0.7.9和0.6.34可用）。 一个非负的时间值将Cache-Control头设置为 max-age = #，#将适当的换算为秒数。 注意：expires仅仅适用于200, 204, 301, 302,和304应答 默认主页设置模块如果URL中没有指定文件，则设置一个默认主页。如下例：1index index.html; 可以指定多个文件，如果第一个文件没有找到，将会查找后面指定的文件：1index index.html index.htm; 指令1234index语法：index file-path [file-path [ ... ] ]; 默认值：no 使用字段：server, location HTTP Referer模块当一个请求头的Referer字段中包含一些非正确的字段，这个模块可以禁止这个请求访问站点。这个头可以随意的伪造，因此，使用这个模块并不能100%的阻止这些请求，绝大多数拒绝的请求来自一些典型的浏览器，可以认为这些典型的浏览器并不能提供一个”Referer”头，甚至是那些正确的请求。如下例：1234567location /photos/ &#123; valid_referers none blocked www.mydomain.com mydomain.com; if ($invalid_referer) &#123; return 403; &#125;&#125; 指令1234valid_referers语法：valid_referers [none|blocked|server_names] ... 默认值：none 使用字段：server, location 这个指令在referer头的基础上为 $invalid_referer 变量赋值，其值为0或1。可以使用这个指令来实现防盗链功能，如果valid_referers列表中没有Referer头的值， $invalid_referer将被设置为1（参照前例）。 HTTP Limit Zone模块这个模块可以为一个地址指定的会话或者某些特殊情况限制同时连接数，如下例：123456789http &#123; limit_zone one $binary_remote_addr 10m; server &#123; location /download/ &#123; limit_conn one 1; &#125; &#125;&#125; 指令1234limit_zone语法：limit_zone zone_name $variable memory_max_size 默认值：no 使用字段：http 指令描述会话状态存储区域。会话的数目按照指定的变量来决定，它依赖于使用的变量大小和memory_max_size的值。1234limit_conn语法：limit_conn zone_name max_clients_per_ip 默认值：no 使用字段：http, server, location 指令指定一个会话的最大同时连接数，超过这个数字的请求将被返回”Service unavailable” (503)代码。 HTTP Limit Requests模块这个模块允许为一个指定的会话或者某个特殊情况限制请求数目。示例配置123456789101112http &#123; limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; ... server &#123; ... location /search/ &#123; limit_req zone=one burst=5; &#125; 指令123语法：limit_req_log_level info|notice|warn|error 默认值：warn 使用字段：http 指定记录日志的等级。123语法：limit_req_zone $session_variable zone=name_of_zone:size rate=rate 默认值：none 使用字段：http 指令描述会话状态存储区域。指令描述会话状态存储的某个区域，会话的值根据给定的变量，如下例：1limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; 在这种情况下，将为一个名为“one”的区域分配10MB，这个区域的平均查询速度为每秒最多1个请求。会话将追踪每个用户，但是注意它替换了变量$remote_addr，我们使用的是$binary_remote_addr，减少会话的大小为64字节，一个1MB的区域可以包含大约16000个会话状态。速度可以设置为每秒处理请求数和每分钟处理请求数，其值必须是整数，所以如果你需要指定每秒处理少于1个的请求，2秒处理一个请求，可以使用 “30r/m”。当会话状态储存区域为1M时理论上可以处理32000个会话，每个会话大小为32字节。123语法： limit_req zone=zone burst=burst [nodelay] 默认值：none 使用字段：http, server, location 这个指令指定区域（zone）可能的最大请求爆发值(burst),如果其值超过这个数，请求被延时，以便查询按照给定的速度处理。多余的请求将被延迟直到他们的数目小于burst值，在这种情况下，请求将得到”Service unavailable” (503)代码，默认burst的值为0。如下例：123456limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server &#123; location /search/ &#123; limit_req zone=one burst=5; &#125; 允许一个用户平均每秒处理不超过1个请求，这个区域最多同时处理不超过5个查询，如果在burst值之外的额外请求不可用，可以使用nodelay参数：limit_req zone=one burst=5 nodelay; 日志模块控制nginx如何记录请求日志。例如：12345log_format gzip '$remote_addr - $remote_user [$time_local] ' '"$request" $status $bytes_sent ' '"$http_referer" "$http_user_agent" "$gzip_ratio"'; access_log /spool/logs/nginx-access.log gzip buffer=32k; 关于记录nginx错误日志请参考HTTP核心模块。指令1234access_log语法：access_log path [format [buffer=size | off]] 默认值：access_log log/access.log combined 使用字段：http, server, location 参数为连接日志指定了路径，格式和缓冲区大小。使用“off”将在当前的字段中清除access_log的所有参数，如果没有指定日志格式，默认为“combined”。缓冲区大小不能超过写入磁盘文件的最小大小。日志文件路径可以包含变量（0.7.4以上版本），但是有一些限制： nginx指定的用户必须有创建日志文件的权限。 缓冲区不会工作 每个到来的连接，日志文件将被打开并且在记录日志后迅速关闭，然而，频繁使用的文件描述符将被保存到open_log_file_cache中，关于日志的轮询记录，必须记住随着时间的过去（使用open_log_file_cache的valid参数设置），日志仍然在旧的文件中记录。 nginx支持为每个location指定强大的日志记录，同样的连接可以在同一时间输出到不止一个的日志中。1234log_format语法：log_format name format [format ...] 默认值：log_format combined "..." 使用字段：http server 描述记录日志的格式，格式中可以使用大多数变量，也包括一些在写入日志文件过程中定义的变量： $body_bytes_sent，减去应答头后传送给客户端的字节数，这个变量兼容apache模块mod_log_config的%B参数（在0.3.10前这个变量为$apache_bytes_sent）。 $bytes_sent，传送给客户端的字节数。 $connection，连接数。 $msec，正在写入日志条目的当前时间（精确到百万分之一秒） $pipe，如果请求为管道的。 $request_length，请求主体的长度。 $request_time，从一个请求发出到而使nginx工作的时间，单位为毫秒（0.5.19版本后可以使用秒为单位）。 $status，应答的状态（代码）。 $time_local，写入普通日志格式的当地时间（服务器时间）。 传送到客户端的头中的变量以”sent_http_”标记开头，如：$sent_http_content_range。注意其他模块产生的变量同样可以写入日志，例如你可以记录前端负载均衡应答头使用“upstream_http_”开头的变量，具体请查看负载均衡模块。nginx有一个预定的日志格式称为combined：123log_format combined '$remote_addr - $remote_user [$time_local] ' '"$request" $status $body_bytes_sent ' '"$http_referer" "$http_user_agent"'; 1234open_log_file_cache语法：open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time] | off 默认值：open_log_file_cache off 使用字段：http server location 这个指令为频繁使用的日志文件描述符所在的路径变量设置缓存。指令选项： max - 缓存中存储的最大文件描述符数。 inactive - 设置缓存中在某个时间段内没有使用的文件描述符将被移除，默认为10秒。 min_uses - 在一定时间内（inactive指定），一个文件描述符最少使用多少次后被放入缓存，默认为1。 valid - 设置检查同名文件存在的时间，默认是60秒。 off - 关闭缓存。 Map模块这个模块允许你分类或者同时映射多个值到多个不同值并储存到一个变量中。如下例：1234567891011map $http_host $name &#123; hostnames; default 0; example.com 1; *.example.com 1; test.com 2; *.test.com 2; .site.com 3;&#125; 一个典型的使用映射的例子是代替一个含有很多服务器的/location或者重定向：123456789101112map $uri $new &#123; default http://www.domain.com/home/; /aa http://aa.domain.com/; /bb http://bb.domain.com/; /john http://my.domain.com/users/john/;&#125; server &#123; server_name www.domain.com; rewrite ^ $new redirect;&#125; 指令1234map语法：map $var1 $var2 &#123; ... &#125; 默认值：none 使用字段：http 1234map_hash_max_size语法：map_hash_max_size number 默认值：map_hash_max_size 2048 使用字段：http 这个指令设置映射表对应的哈希表的最大值。1234map_hash_bucket_size语法：map_hash_bucket_size n默认值：map_hash_bucket_size 32/64/128 使用字段：http 这个指令指定一个映射表中的变量在哈希表中的最大值，这个值取决于处理器的缓存。 Memcached模块使用这个模块简单的处理缓存，这个模块将不断的进行完善。示例配置：123456789101112server &#123; location / &#123; set $memcached_key $uri; memcached_pass name:11211; default_type text/html; error_page 404 = /fallback; &#125; location = /fallback &#123; proxy_pass backend; &#125;&#125; 指令1234memcached_pass语法：memcached_pass [ name:port ] 默认值：none 使用字段：http, server, location 后端需要在memcached中设置一些数据，memcached key为“”/uri?args”。1234memcached_connect_timeout语法：memcached_connect_timeout [ time ] 默认值：60000 使用字段：http, server, location 连接memcached的超时时间，单位为毫秒。1234memcached_read_timeout语法：memcached_read_timeout [ time ] 默认值：60000 使用字段：http, server, location 读取memcached数据的超时时间，单位为毫秒。1234memcached_send_timeout语法：memcached_send_timeout [ time ] 默认值：60000 使用字段：http, server, location 发送memcached数据的超时时间，单位为毫秒。1234memcached_buffer_size语法：memcached_buffer_size [ size ] 默认值：see getpagesize(2) 使用字段：http, server, location 发送/收到的缓冲区大小，单位是字节。1234memcached_next_upstream语法：memcached_next_upstream [ error | timeout | invalid_response | not_found | off ] 默认值：error timeout 使用字段：http, server, location 指定在哪种错误状态下请求将转发到另外的负载均衡服务器，仅当memcached_pass有两个或两个以上值的时候使用。变量12$memcached_keymemcached key的值 HTTP代理模块这个模块可以转发请求到其他的服务器。注意当使用http proxy模块（甚至FastCGI），所有的连接请求在发送到后端服务器之前nginx将缓存它们，因此，在测量从后端传送的数据时，它的进度显示可能不正确。指令1234proxy_buffer_size语法：proxy_buffer_size the_size 默认值：proxy_buffer_size 4k/8k 使用字段：http, server, location 设置从被代理服务器读取的第一部分应答的缓冲区大小。通常情况下这部分应答中包含一个小的应答头。默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小。1234proxy_buffering语法：proxy_buffering on|off 默认值：proxy_buffering on 使用字段：http, server, location 为后端的服务器启用应答缓冲。如果启用缓冲，nginx假设被代理服务器能够非常快的传递应答，并将其放入缓冲区，可以使用 proxy_buffer_size和proxy_buffers设置相关参数。如果响应无法全部放入内存，则将其写入硬盘。如果禁用缓冲，从后端传来的应答将立即被传送到客户端。nginx忽略被代理服务器的应答数目和所有应答的大小，接受proxy_buffer_size所指定的值。对于基于长轮询的Comet应用需要关闭这个指令，否则异步的应答将被缓冲并且Comet无法正常工作。1234proxy_buffers语法：proxy_buffers the_number is_size; 默认值：proxy_buffers 8 4k/8k; 使用字段：http, server, location 设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k。1234proxy_busy_buffers_size语法：proxy_busy_buffers_size size; 默认值：proxy_busy_buffers_size ["#proxy buffer size"] * 2; 使用字段：http, server, location, if 1234proxy_cache语法：proxy_cache zone_name; 默认值：None 使用字段：http, server, location 设置一个缓存区域的名称，一个相同的区域可以在不同的地方使用。1234proxy_cache_key语法：proxy_cache_key line; 默认值：$scheme$proxy_host$request_uri; 使用字段：http, server, location 指令指定了包含在缓存中的缓存关键字。proxy_cache_key “$host$request_uri$cookie_user”;注意默认情况下服务器的主机名并没有包含到缓存关键字中，如果你为你的站点在不同的location中使用二级域，你可能需要在缓存关键字中包换主机名：proxy_cache_key “$scheme$host$request_uri”;1234proxy_cache_path语法：proxy_cache_path path [levels=number] keys_zone=zone_name:zone_size [inactive=time] [max_size=size]; 默认值：None 使用字段：http 指令指定缓存的路径和一些其他参数，缓存的数据存储在文件中，并且使用代理url的哈希值作为关键字与文件名。1234proxy_cache_methods语法：proxy_cache_methods [GET HEAD POST]; 默认值：proxy_cache_methods GET HEAD; 使用字段：http, server, location GET/HEAD用来装饰语句，即你无法禁用GET/HEAD即使你只使用下列语句设置：proxy_cache_methods POST;1234proxy_cache_min_uses语法：proxy_cache_min_uses the_number; 默认值：proxy_cache_min_uses 1; 使用字段：http, server, location 多少次的查询后应答将被缓存，默认1。1234proxy_cache_valid语法：proxy_cache_valid reply_code [reply_code ...] time; 默认值：None 使用字段：http, server, location 为不同的应答设置不同的缓存时间，例如：12proxy_cache_valid 200 302 10m;proxy_cache_valid 404 1m; 为应答代码为200和302的设置缓存时间为10分钟，404代码缓存1分钟。如果只定义时间：proxy_cache_valid 5m;那么只对代码为200, 301和302的应答进行缓存。同样可以使用any参数任何应答。proxy_cache_valid 200 302 10m;proxy_cache_valid 301 1h;proxy_cache_valid any 1m;1234proxy_cache_use_stale语法：proxy_cache_use_stale [error|timeout|updating|invalid_header|http_500|http_502|http_503|http_504|http_404|off] [...]; 默认值：proxy_cache_use_stale off; 使用字段：http, server, location 这个指令告诉nginx何时从代理缓存中提供一个过期的响应，参数类似于proxy_next_upstream指令。为了防止缓存失效（在多个线程同时更新本地缓存时），你可以指定’updating’参数，它将保证只有一个线程去更新缓存，并且在这个线程更新缓存的过程中其他的线程只会响应当前缓存中的过期版本。1234proxy_connect_timeout语法：proxy_connect_timeout timeout_in_seconds 默认值：proxy_connect_timeout 60 使用字段：http, server, location 指定一个连接到代理服务器的超时时间，需要注意的是这个时间最好不要超过75秒。这个时间并不是指服务器传回页面的时间（这个时间由proxy_read_timeout声明）。如果你的前端代理服务器是正常运行的，但是遇到一些状况（例如没有足够的线程去处理请求，请求将被放在一个连接池中延迟处理），那么这个声明无助于服务器去建立连接。1234proxy_headers_hash_bucket_size语法：proxy_headers_hash_bucket_size size; 默认值：proxy_headers_hash_bucket_size 64; 使用字段：http, server, location, if 设置哈希表中存储的每个数据大小。1234proxy_headers_hash_max_size语法：proxy_headers_hash_max_size size; 默认值：proxy_headers_hash_max_size 512; 使用字段：http, server, location, if 设置哈希表的最大值。123proxy_hide_header语法：proxy_hide_header the_header 使用字段：http, server, location nginx不对从被代理服务器传来的”Date”, “Server”, “X-Pad”和”X-Accel-…”应答进行转发，这个参数允许隐藏一些其他的头部字段，但是如果上述提到的头部字段必须被转发，可以使用proxy_pass_header指令。1234proxy_ignore_client_abort语法：proxy_ignore_client_abort [ on|off ] 默认值：proxy_ignore_client_abort off 使用字段：http, server, location 防止在客户端自己终端请求的情况下中断代理请求。1234proxy_ignore_headers语法：proxy_ignore_headers name [name ...] 默认值：none 使用字段：http, server, location 这个指令(0.7.54+) 禁止处理来自代理服务器的应答。可以指定的字段为”X-Accel-Redirect”, “X-Accel-Expires”, “Expires”或”Cache-Control”。1234proxy_intercept_errors语法：proxy_intercept_errors [ on|off ] 默认值：proxy_intercept_errors off 使用字段：http, server, location 使nginx阻止HTTP应答代码为400或者更高的应答。默认情况下被代理服务器的所有应答都将被传递。如果将其设置为on则nginx会将阻止的这部分代码在一个error_page指令处理，如果在这个error_page中没有匹配的处理方法，则被代理服务器传递的错误应答会按原样传递。1234proxy_max_temp_file_size语法：proxy_max_temp_file_size size; 默认值：proxy_max_temp_file_size 1G; 使用字段：http, server, location, if 当代理缓冲区过大时使用一个临时文件的最大值，如果文件大于这个值，将同步传递请求而不写入磁盘进行缓存。如果这个值设置为零，则禁止使用临时文件。1234proxy_method语法：proxy_method [method] 默认值：None 使用字段：http, server, location 为后端服务器忽略HTTP请求处理方式，假如你将这个指令指定为POST，那么所有转发到后端的请求都将使用POST请求方式。1234proxy_next_upstream语法： proxy_next_upstream [error|timeout|invalid_header|http_500|http_502|http_503|http_504|http_404|off] 默认值：proxy_next_upstream error timeout 使用字段：http, server, location 确定在何种情况下请求将转发到下一个服务器： error - 在连接到一个服务器，发送一个请求，或者读取应答时发生错误。 timeout - 在连接到服务器，转发请求或者读取应答时发生超时。 invalid_header - 服务器返回空的或者错误的应答。 http_500 - 服务器返回500代码。 http_502 - 服务器返回502代码。 http_503 - 服务器返回503代码。 http_504 - 服务器返回504代码。 http_404 - 服务器返回404代码。 off - 禁止转发请求到下一台服务器。 转发请求只发生在没有数据传递到客户端的过程中。1234proxy_no_cache语法：proxy_no_cache variable1 variable2 ...; 默认值：None 使用字段：http, server, location 确定在何种情况下缓存的应答将不会使用，示例：12proxy_no_cache $cookie_nocache $arg_nocache$arg_comment;proxy_no_cache $http_pragma $http_authorization; 如果为空字符串或者等于0，表达式的值等于false。1234proxy_pass语法：proxy_pass URL 默认值：no 使用字段：location, location中的if字段 这个指令设置被代理服务器的地址和被映射的URI，地址可以使用主机名或IP加端口号的形式。123proxy_pass_header语法：proxy_pass_header the_name 使用字段：http, server, location 这个指令允许为应答转发一些隐藏的头部字段。1234proxy_pass_request_headers语法：proxy_pass_request_headers [ on | off ] ; 默认值：proxy_pass_request_headers on; 使用字段：http, server, location 1234proxy_redirect语法：proxy_redirect [ default|off|redirect replacement ] 默认值：proxy_redirect default 使用字段：http, server, location 如果需要修改从被代理服务器传来的应答头中的”Location”和”Refresh”字段，可以用这个指令设置。1234proxy_read_timeout语法：proxy_read_timeout time 默认值：proxy_read_timeout 60 使用字段：http, server, location 决定读取后端服务器应答的超时时间，它决定nginx将等待多久时间来取得一个请求的应答。超时时间是指完成了两次握手后并且状态为established的超时时间。相对于proxy_connect_timeout，这个时间可以扑捉到一台将你的连接放入连接池延迟处理并且没有数据传送的服务器，注意不要将此值设置太低，某些情况下代理服务器将花很长的时间来获得页面应答（例如如当接收一个需要很多计算的报表时），当然你可以在不同的location里面设置不同的值。12proxy_redirect_errors不推荐使用，请使用 proxy_intercept_errors 1234proxy_send_lowat语法：proxy_send_lowat [ on | off ] 默认值：proxy_send_lowat off; 使用字段：http, server, location, if 设置SO_SNDLOWAT，这个指令仅用于FreeBSD。1234proxy_send_timeout语法：proxy_send_timeout seconds 默认值：proxy_send_timeout 60 使用字段：http, server, location 设置代理服务器转发请求的超时时间，同样指完成两次握手后的时间，如果超过这个时间代理服务器没有数据转发到被代理服务器，nginx将关闭连接。1234proxy_set_body语法：proxy_set_body [ on | off ] 默认值：proxy_set_body off; 使用字段：http, server, location, if 1234proxy_set_header语法：proxy_set_header header value 默认值： Host and Connection使用字段：http, server, location 这个指令允许将发送到被代理服务器的请求头重新定义或者增加一些字段。这个值可以是一个文本，变量或者它们的组合。proxy_set_header在指定的字段中没有定义时会从它的上级字段继承。默认只有两个字段可以重新定义：proxy_set_header Host $proxy_host;proxy_set_header Connection Close;未修改的请求头“Host”可以用如下方式传送：proxy_set_header Host $http_host;但是如果这个字段在客户端的请求头中不存在，那么不发送数据到被代理服务器。这种情况下最好使用$Host变量，它的值等于请求头中的”Host”字段或服务器名：proxy_set_header Host $host;此外，可以将被代理的端口与服务器名称一起传递：proxy_set_header Host $host:$proxy_port;如果设置为空字符串，则不会传递头部到后端，例如下列设置将禁止后端使用gzip压缩：proxy_set_header Accept-Encoding “”;1234proxy_store语法：proxy_store [on | off | path] 默认值：proxy_store off 使用字段：http, server, location 这个指令设置哪些传来的文件将被存储，参数”on”保持文件与alias或root指令指定的目录一致，参数”off”将关闭存储，路径名中可以使用变量：proxy_store /data/www$original_uri;应答头中的”Last-Modified”字段设置了文件最后修改时间，为了文件的安全，可以使用proxy_temp_path指定一个临时文件目录。这个指令为那些不是经常使用的文件做一份本地拷贝。从而减少被代理服务器负载。12345678910111213location /images/ &#123; root /data/www; error_page 404 = /fetch$uri;&#125; location /fetch &#123; internal; proxy_pass http://backend; proxy_store on; proxy_store_access user:rw group:rw all:r; proxy_temp_path /data/temp; alias /data/www;&#125; 或者通过这种方式：123456789101112131415location /images/ &#123; root /data/www; error_page 404 = @fetch;&#125; location @fetch &#123; internal; proxy_pass http://backend; proxy_store on; proxy_store_access user:rw group:rw all:r; proxy_temp_path /data/temp; root /data/www;&#125; 注意proxy_store不是一个缓存，它更像是一个镜像。1234proxy_store_access语法：proxy_store_access users:permissions [users:permission ...] 默认值：proxy_store_access user:rw 使用字段：http, server, location 指定创建文件和目录的相关权限，如：proxy_store_access user:rw group:rw all:r;如果正确指定了组和所有的权限，则没有必要去指定用户的权限：proxy_store_access group:rw all:r;1234proxy_temp_file_write_size语法：proxy_temp_file_write_size size; 默认值：proxy_temp_file_write_size ["#proxy buffer size"] * 2; 使用字段：http, server, location, if 设置在写入proxy_temp_path时数据的大小，在预防一个工作进程在传递文件时阻塞太长。1234proxy_temp_path语法：proxy_temp_path dir-path [ level1 [ level2 [ level3 ] ; 默认值：在configure时由--http-proxy-temp-path指定 使用字段：http, server, location 类似于http核心模块中的client_body_temp_path指令，指定一个地址来缓冲比较大的被代理请求。12proxy_upstream_fail_timeout0.5.0版本后不推荐使用，请使用http负载均衡模块中server指令的fail_timeout参数。 12proxy_upstream_fail_timeout0.5.0版本后不推荐使用，请使用http负载均衡模块中server指令的max_fails参数。 变量该模块中包含一些内置变量，可以用于proxy_set_header指令中以创建头部。123456$proxy_host被代理服务器的主机名。$proxy_host被代理服务器的端口号。$proxy_add_x_forwarded_for包含客户端请求头中的"X-Forwarded-For"，与$remote_addr用逗号分开，如果没有"X-Forwarded-For"请求头，则$proxy_add_x_forwarded_for等于$remote_addr。 URL重写模块这个模块允许使用正则表达式重写URI（需PCRE库），并且可以根据相关变量重定向和选择不同的配置。如果这个指令在server字段中指定，那么将在被请求的location确定之前执行，如果在指令执行后所选择的location中有其他的重写规则，那么它们也被执行。如果在location中执行这个指令产生了新的URI，那么location又一次确定了新的URI。这样的循环可以最多执行10次，超过以后nginx将返回500错误。指令1234break语法：break默认值：none使用字段：server, location, if 完成当前设置的规则，停止执行其他的重写指令。示例：1234if ($slow) &#123; limit_rate 10k; break;&#125; 1234if语法：if (condition) &#123; ... &#125; 默认值：none使用字段：server, location 判断一个条件，如果条件成立，则后面的大括号内的语句将执行，相关配置从上级继承。可以在判断语句中指定下列值： 一个变量的名称；不成立的值为：空字符传&quot;&quot;或者一些用“0”开始的字符串。 一个使用=或者!=运算符的比较语句。 使用符号~*和~模式匹配的正则表达式： ~为区分大小写的匹配。 ~*不区分大小写的匹配（firefox匹配FireFox）。 !~和!~*意为“不匹配的”。 使用-f和!-f检查一个文件是否存在。 使用-d和!-d检查一个目录是否存在。 使用-e和!-e检查一个文件，目录或者软链接是否存在。 使用-x和!-x检查一个文件是否为可执行文件。 正则表达式的一部分可以用圆括号，方便之后按照顺序用$1-$9来引用。示例配置：12345678910111213141516171819202122232425262728if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125; if ($http_cookie ~* "id=([^;] +)(?:;|$)" ) &#123; set $id $1;&#125; if ($request_method = POST ) &#123; return 405;&#125; if (!-f $request_filename) &#123; break; proxy_pass http://127.0.0.1;&#125; if ($slow) &#123; limit_rate 10k;&#125; if ($invalid_referer) &#123; return 403;&#125; if ($args ~ post=140)&#123; rewrite ^ http://example.com/ permanent;&#125; 内置变量$invalid_referer用指令valid_referers指定。1234return语法：return code 默认值：none使用字段：server, location, if 这个指令结束执行配置语句并为客户端返回状态代码，可以使用下列的值：204，400，402-406，408，410, 411, 413, 416与500-504。此外，非标准代码444将关闭连接并且不发送任何的头部。1234rewrite语法：rewrite regex replacement flag 默认值：none使用字段：server, location, if 按照相关的正则表达式与字符串修改URI，指令按照在配置文件中出现的顺序执行。注意重写规则只匹配相对路径而不是绝对的URL，如果想匹配主机名，可以加一个if判断，如：1234if ($host ~* www\.(.*)) &#123; set $host_without_www $1; rewrite ^(.*)$ http://$host_without_www$1 permanent; # $1为'/foo'，而不是'www.mydomain.com/foo'&#125; 可以在重写指令后面添加标记。如果替换的字符串以http://开头，请求将被重定向，并且不再执行多余的rewrite指令。标记可以是以下的值： last - 完成重写指令，之后搜索相应的URI或location。 break - 完成重写指令。 redirect - 返回302临时重定向，如果替换字段用http://开头则被使用。 permanent - 返回301永久重定向。 注意如果一个重定向是相对的（没有主机名部分），nginx将在重定向的过程中使用匹配server_name指令的“Host”头或者server_name指令指定的第一个名称，如果头不匹配或不存在，如果没有设置server_name，将使用本地主机名，如果你总是想让nginx使用“Host”头，可以在server_name使用“*”通配符（查看http核心模块中的server_name）。例如：123rewrite ^(/download/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 last;rewrite ^(/download/.*)/audio/(.*)\..*$ $1/mp3/$2.ra last;return 403; 但是如果我们将其放入一个名为/download/的location中，则需要将last标记改为break，否则nginx将执行10次循环并返回500错误。12345location /download/ &#123; rewrite ^(/download/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 break; rewrite ^(/download/.*)/audio/(.*)\..*$ $1/mp3/$2.ra break; return 403;&#125; 如果替换字段中包含参数，那么其余的请求参数将附加到后面，为了防止附加，可以在最后一个字符后面跟一个问号：rewrite ^/users/(.*)$ /show?user=$1? last;注意：大括号（{和}），可以同时用在正则表达式和配置块中，为了防止冲突，正则表达式使用大括号需要用双引号（或者单引号）。例如要重写以下的URL：/photos/123456为:/path/to/photos/12/1234/123456.png则使用以下正则表达式（注意引号）：1rewrite "/photos/([0-9] &#123;2&#125;)([0-9] &#123;2&#125;)([0-9] &#123;2&#125;)" /path/to/photos/$1/$1$2/$1$2$3.png; 同样，重写只对路径进行操作，而不是参数，如果要重写一个带参数的URL，可以使用以下代替：123if ($args ^~ post=100)&#123; rewrite ^ http://example.com/new-address.html? permanent;&#125; 注意$args变量不会被编译，与location过程中的URI不同（参考http核心模块中的location）。1234set语法：set variable value 默认值：none使用字段：server, location, if 指令设置一个变量并为其赋值，其值可以是文本，变量和它们的组合。你可以使用set定义一个新的变量，但是不能使用set设置$http_xxx头部变量的值。具体可以查看这个例子1234uninitialized_variable_warn语法：uninitialized_variable_warn on|off 默认值：uninitialized_variable_warn on 使用字段：http, server, location, if 开启或关闭在未初始化变量中记录警告日志。事实上，rewrite指令在配置文件加载时已经编译到内部代码中，在解释器产生请求时使用。这个解释器是一个简单的堆栈虚拟机，如下列指令：12345678location /download/ &#123; if ($forbidden) &#123; return 403; &#125; if ($slow) &#123; limit_rate 10k; &#125; rewrite ^/(download/.*)/media/(.*)\..*$ /$1/mp3/$2.mp3 break; 将被编译成以下顺序：1234567891011121314variable $forbiddenchecking to zerorecovery 403completion of entire codevariable $slowchecking to zerocheckings of regular expressioncopying &quot;/&quot;copying $1copying &quot;/mp3/&quot;copying $2copying &quot;..mpe&quot;completion of regular expressioncompletion of entire sequence 注意并没有关于limit_rate的代码，因为它没有提及ngx_http_rewrite_module模块，“if”块可以类似”location”指令在配置文件的相同部分同时存在。如果$slow为真，对应的if块将生效，在这个配置中limit_rate的值为10k。指令：1rewrite ^/(download/.*)/media/(.*)\..*$ /$1/mp3/$2.mp3 break; 如果我们将第一个斜杠括入圆括号，则可以减少执行顺序：1rewrite ^(/download/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 break; 之后的顺序类似如下：1234567checking regular expressioncopying $1copying &quot;/mp3/&quot;copying $2copying &quot;..mpe&quot;completion of regular expressioncompletion of entire code SSI模块这个模块为处理服务器端包含（SSI）的输入提供一个过滤器，目前所支持的SSI命令并不完善。如下例：123location / &#123; ssi on;&#125; 指令1234ssi语法：ssi [ on | off ] 默认值：ssi off 使用字段：http, server, location, location中的if字段 启用SSI处理。注意如果启用SSI，那么Last-Modified头和Content-Length头不会传递。1234ssi_silent_errors语法：ssi_silent_errors [on|off] 默认值：ssi_silent_errors off 使用字段：http, server, location 如果在处理SSI的过程中出现“[an error occurred while processing the directive]”错误，禁止将其输出。1234ssi_types语法：ssi_types mime-type [mime-type ...] 默认值：ssi_types text/html 使用字段：http, server, location 默认只解析text/html类型，这个参数可以指定其他的MIME类型。1234ssi_value_length语法：ssi_value_length length 默认值：ssi_value_length 256 使用字段：http, server, location 定义允许SSI使用的参数值的长度。 SSI 命令命令格式如下：1&lt;!--# command parameter1=value parameter2=value... --&gt; 因为功能支持问题，暂不作详细的说明。 变量1234$date_local本地时区的当前时间，选项 "timefmt"可以指定格式。$date_gmt当前的格林尼治时间，选项 "timefmt"可以指定格式。 User ID模块模块ngx_http_userid_module为连接发布cookie，主要使用$uid_got和$uid_set变量，注意：$uid_got无法$uid_set在SSI中取得，因为SSI过滤模块工作在userid模块过滤之前。这个模块相当于Apache的mod_uid模块。示例配置：123456userid on;userid_name uid;userid_domain example.com;userid_path /;userid_expires 365d;userid_p3p 'policyref="/w3c/p3p.xml", CP="CUR ADM OUR NOR STA NID"'; 指令1234userid语法：userid [on|v1|log||off] 默认值：userid off 使用字段：http, server, location 是否启用发出cookie或者记录到被请求的cookie：1234on - 启用版本2的cookie并记录。v1 - 启用版本1的cookie并记录。log - 不传送cookie，但是写入日志。off - 禁用cookie。 1234userid_domain语法：userid_domain [ name | none ] 默认值：userid_domain none 使用字段：http, server, location 指定cookie的域名，参数“none”不对任何域名发出cookie。1234userid_expires语法：userid_expires [ time | max ] 默认值：none 使用字段：http, server, location 设置cookie的过期时间。参数设置并发出浏览器对于cookie的实效时间，值“max”指定过期时间为：2037年12月31日23:55:55 GMT，这是某些旧浏览器所能识别的最大时间。1234userid_name语法：userid_name name 默认值：userid_name uid 使用字段：http, server, location 设置cookie的名称。1234userid_p3p语法：userid_p3p line 默认值：none 使用字段：http, server, location 为和cookie一起传递的P3P头指定一个值。1234userid_path语法：userid_path path 默认值：userid_path / 使用字段：http, server, location 设置cookie路径。1234userid_service语法：userid_service number 默认值：userid_service address 使用字段：http, server, location 设置cookie发布的服务器地址，如果不设置，版本一的cookie将其设置为0，版本二将其设置为服务器IP。 uWSGI模块为uwsgi协议提供支持。示例配置：1234location / &#123; uwsgi_pass unix:///var/run/example.com.sock; include uwsgi_params; &#125; 注意不要把uwsgi协议和uWSGI服务器混淆。指令1234uwsgi_pass语法：uwsgi_pass uri默认值：none 使用字段：server, location 为一个uwsgi兼容服务器设置监听地址（tcp套接字，unix套接字或者流块）1234uwsgi_param语法：uwsgi_param key value默认值：none 使用字段：server, location 为一个uwsgi请求增加一对key/value值。示例：12345location / &#123; uwsgi_pass unix:///var/run/example.com.sock; include uwsgi_params; uwsgi_param NEW_VAR foo; &#125; 1234uwsgi_modifier1语法：uwsgi_modifier1 value 默认值：0 使用字段：server, location 为一个uwsgi请求设置第一个修饰语（默认为一个WSGI请求）。1234uwsgi_modifier2语法：uwsgi_modifier2 value 默认值：0 使用字段：server, location 为一个uwsgi请求设置第二个修饰语。1234uwsgi_string语法：uwsgi_string string 默认值： none 使用字段：server, location 为一个uwsgi请求增加一个字符串。示例（为一个支持eval修饰语的uwsgi兼容服务器）：1234567891011121314151617location / &#123; uwsgi_pass unix:///var/run/example.com.sock; uwsgi_pass_request_headers off; uwsgi_pass_request_body off; uwsgi_string " import uwsgi uwsgi.start_response('200 OK', [('Content-type','text/plain')])total = 30+22uwsgi.send("30 + 22 = %d" % total) "; uwsgi_modifier1 22; uwsgi_modifier2 0; &#125; 1234uwsgi_pass_request_headers语法：uwsgi_pass_request_headers on/off 默认值：on 使用字段：server, location 在uwsgi请求中传递HTTP请求头。1234uwsgi_pass_request_body语法：uwsgi_pass_request_body on/off 默认值：on 使用字段：server, location 在uwsgi请求中传递HTTP请求实体（如果其可用）。 SplitClients模块ngx-http-split-clients模块基于一些特定条件分开客户端连接，(例如ip地址,请求头,cookies等)示例配置：12345678910111213http &#123; split-clients "$&#123;remote-addr&#125;AAA" $variant &#123; 0.5% .one; 2.0% .two; - ""; &#125; server &#123; location / &#123; index index$&#123;variant&#125;.html; &#125; &#125;&#125; 可以使用$cookie-…作为来源来分离请求，来源字符串使用CRC32进行哈希计算并且哈希百分比将作为来源的值。指令1234split-clients语法：split-clients $variable &#123; ... &#125; 默认值：none使用字段：http 可选HTTP模块HTTP Addition模块这个模块可以在当前的location之前或者之后增加别的location。它作为一个输出过滤器执行，包含到其他location中的主请求和子请求不会被完全缓冲，并且仍然以流的形式传递到客户端，因为最终应答体的长度在传递HTTP头的时候是未知的，HTTP的chunked编码总是在这里使用。默认情况下这个模块是没有编译的，如果要使用则需要在编译时指定下列参数：./configure –with-http_addition_module示例配置：1234location / &#123; add_before_body /before_action; add_after_body /after_action;&#125; 指令1234add_before_body语法：add_before_body uri 默认值：no 使用字段：http, server, location 在应答体的前面增加URI，为一个处理结果发出子请求。1234add_after_body语法：add_after_body uri 默认值：no 使用字段：http, server, location 在应答体的后面增加URI，为一个处理结果发出子请求。1234addition_types语法：addition_types mime-type [mime-type ...] 默认值：text/html 使用字段：http, server, location 邮件模块邮件核心模块邮件代理配置nginx可以处理和代理以下的邮件协议： IMAP POP3 SMTP 认证nginx使用外部的HTTP类服务器来了解它将连接到哪个后端的IMAP/POP。nginx在HTTP头中通过认证信息：12345678GET /auth HTTP/1.0Host: auth.server.hostnameAuth-Method: plainAuth-User: userAuth-Pass: passwordAuth-Protocol: imapAuth-Login-Attempt: 1Client-IP: 192.168.1.1 合适的应答为：12345HTTP/1.0 200 OK # 这个字段实际上是被忽略或者可能不存在。Auth-Status: OKAuth-Server: 192.168.1.10Auth-Port: 110Auth-User: newname # 如果你连接到一个后端可以不理会这个用户名。 当为POP3认证使用APOP时，你必须返回Auth-Pass：123456HTTP/1.0 200 OK # 这个字段实际上是被忽略或者可能不存在。Auth-Status: OKAuth-Server: 192.168.1.10Auth-Port: 110Auth-User: newname # 如果你连接到一个后端可以不理会这个用户名。Auth-Pass: password # 这里必须为明文的用户名密码。 失败的应答为：123HTTP/1.0 200 OK # 这个字段实际上是被忽略或者可能不存在。Auth-Status: Invalid login or passwordAuth-Wait: 3 # nginx将在3秒后重新读取客户端的用户名与密码。 指令1234imap_capabilities语法：imap_capabilities "capability1" ["capability2" .. "capabilityN"] 默认值："IMAP4" "IMAP4rev1" "UIDPLUS" 使用字段：main, server 在客户端发布IMAP命令CAPABILITY时，设置IMAP协议扩展列表，STARTTLS在你使用starttls指令时会自动添加。1234imap_client_buffer语法：imap_client_buffer size 默认值：4K/8K使用字段：main, server 为IMAP命令设置读取缓冲区大小，默认值为分页大小（根据系统不同为4k或8k）。1234listen语法：listen address:port [ bind ] 默认值：no 使用字段：server 1234567891011listen指令指定了server&#123;...&#125;字段中可以被访问到的ip地址及端口号，可以只指定一个ip，一个端口，或者一个可解析的服务器名。listen 127.0.0.1:8000;listen 127.0.0.1;listen 8000;listen *:8000;listen localhost:8000;ipv6地址格式（0.7.58）在一个方括号中指定：listen [::]:8000;listen [fe80::1];指令中可以指出系统调用bind(2)。bind -- 指出必须为这个“地址：端口”对独立构建bind(2)，如果多个指令监听同一端口但是不同的地址和某个listen指令为这个端口（*:port）监听所有地址，那么nginx仅构建bind(2)到*:port，在这种情况下地址通过系统调用getsockname()取得。 1234pop3_auth语法：pop3_auth [plain] [apop] [cram-md5] 默认值：plain 使用字段：main, server 为POP3客户端设置允许的认证动作：·plain - USER/PASS,AUTH PLAIN,AUTH LOGIN·apop - APOP·cram-md5 - AUTH CRAM-MD51234pop3_capabilities语法：pop3_capabilities "capability1" ["capability2" .. "capabilityN"] 默认值："TOP" "USER" "UIDL" 使用字段：main, server 在客户端发布POP3命令CAPA时，设置POP3协议扩展列表，STLS在你使用starttls指令时会自动添加，SASL通过指令pop3_auth添加。1234protocol语法：protocol [ pop3 | imap | smtp ] ; 默认值：IMAP 使用字段：server 为这个server块设置邮件协议。1234server语法：server &#123;...&#125; 默认值：no 使用字段：mail 指定一个虚拟服务器配置。没有明确的机制来分开基于域名（请求中的主机头）和基于IP的虚拟主机。可以通过listen指令来指定必须连接到这个server块的所有地址和端口，并且在server_name指令中可以指定所有的域名。1234server_name语法：server_name name fqdn_server_host 默认值：主机名，通过调用gethostname()取得。 使用字段：mail, server 1234smtp_auth语法：smtp_auth [login] [plain] [cram-md5] ; 默认值：login plain 使用字段：main, server 为SMTP客户端设置允许的认证动作： login - AUTH LOGIN plain - AUTH PLAIN cram-md5 - AUTH CRAM-MD5 1234smtp_capabilities语法：smtp_capabilities “capability1” [“capability2” .. “capabilityN”] 默认值：no 使用字段：main, server 在客户端发布命令EHLO时，设置SMTP协议扩展列表，这个列表使用smtp_auth指令中启用的动作自动扩展。1234so_keepalive语法：so_keepalive on|off; 默认值：off 使用字段：main, server 为后端的IMAP/POP3设置socket SO_KEEPALIVE选项。FreeBSD中keepalive参数使用于所有的连接，并且可以通过内核参数（sysctl net.inet.tcp.always_keepalive）关闭。1234timeout语法：timeout milliseconds; 默认值：60000 使用字段：main, server 设置到后端代理连接的超时时间。 邮件认证模块示例配置：12auth_http localhost:9000/cgi-bin/nginxauth.cgi;auth_http_timeout 5; 指令1234auth_http语法：auth_http URL 默认值：no 使用字段：mail, server 为认证设置网址到扩展HTTP类服务器。到达的协议请查看邮件核心模块中的pop3_auth指令。1234auth_http_header语法：auth_http_header header value 默认值：no 使用字段：mail, server 在认证过程中增加一个HTTP头和它的值，可以使用一个共享的秘密短语确保请求总是通过nginx应答。如：auth_http_header X-NGX-Auth-Key “secret_string”;1234auth_http_timeout语法：auth_http_timeout milliseconds; 默认值：60000 使用字段：mail, server 为认证进程设置超时时间。 邮件代理模块nginx可以代理IMAP, POP3,和SMTP协议。指令1234proxy语法：proxy on | off 默认值：off 使用字段：mail, server 设置是否启用邮件代理。1234proxy_buffer语法：proxy_buffer size 默认值：4K/8K 使用字段：mail, server 为代理连接设置缓冲区大小，默认为分页大小，根据不同的操作系统可能是4k或8k。1234proxy_pass_error_message语法：proxy_pass_error_message on | off 默认值：off 使用字段：mail, server 可以把从后端获取的错误认证信息传递到客户端，通常如果通过了nginx的认证，那么后端的错误信息无法传递到客户端。但是一些正确密码应答中的POP3错误，如CommuniGatePro通知用户一个关于邮箱超出容量限制（或者其它事件）将在认证中周期性的发出错误，在这种情况下有必要打开proxy_error_message。1234proxy_timeout语法：proxy_timeout time 默认值：24h 使用字段：mail, server 为代理连接设置超时时间。1234xclient语法：xclient on | off 默认值：on 使用字段：mail, server 是否为SMTP后端连接启用XCLIENT命令，这将允许后端强制客户端连接建立在IP/HELO/LOGIN上。如果xclient启用，那么nginx首先转发到后端：EHLO server_name然后：XCLIENT PROTO=ESMTP HELO=client_helo ADDR=client_ip LOGIN=authentificated_user NAME=[UNAVAILABLE] 邮件SSL认证模块这个模块为POP3/IMAP/SMTP提供SSL/TLS支持。配置与HTTP SSL模块基本相同，但是不支持检察客户端证书。指令1234ssl语法：ssl on | off 默认值：ssl off 使用字段：mail, server 为这个虚拟主机启用SSL。1234ssl_certificate语法：ssl_certificate file 默认值：cert.pem 使用字段：mail, server 为这个虚拟主机指定PEM格式的证书文件，相同的文件可以包含其它的证书，同样密钥为PEM格式。1234ssl_certificate_key语法：ssl_certificate_key file 默认值：cert.pem 使用字段：mail, server 为这个虚拟主机指定PEM格式的密钥。1234ssl_ciphers语法：ssl_ciphers file ciphers 默认值：ALL:!ADH:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP 使用字段：mail, server 指出允许的密码，密码指定为OpenSSL支持的格式。1234ssl_prefer_server_ciphers语法：ssl_prefer_server_ciphers on | off 默认值：off 使用字段：mail, server 依赖SSLv3和TLSv1协议的服务器密码将优先于客户端密码。1234ssl_protocols语法：ssl_protocols [SSLv2] [SSLv3] [TLSv1] 默认值：SSLv2 SSLv3 TLSv1 使用字段：mail, server 指定要使用的SSL协议。1234ssl_session_cache语法：ssl_session_cache [builtin[:size [shared:name:size] 默认值：builtin:20480 使用字段：mail, server 设置储存SSL会话的缓存类型和大小。缓存类型为： builtin - 内建OpenSSL缓存，仅能用在一个工作进程中，缓存大小在会话总数中指定，注意：如果要使用这个类型可能会引起内存碎片问题，具体请查看下文中参考文档。 shared - 缓存在所有的工作进程中共享，缓存大小指定单位为字节，1MB缓存大概保存4000个会话，每个共享的缓存必须有自己的名称，相同名称的缓存可以使用在不同的虚拟主机中。 可以同时使用两个缓存类型，如：1ssl_session_cache builtin:1000 shared:SSL:10m; 然而仅当builtin没有影响共享缓存时会使用。1234ssl_session_timeout语法：ssl_session_timeout time 默认值：5m 使用字段：mail, server 设置客户端能够反复使用储存在缓存中的会话参数时间。1234starttls语法：starttls on | off | only 默认值：off 使用字段：mail, server 含义 on - 允许为IMAP/SMTP使用STARTTLS和为POP3使用STLS。 off - 禁止命令STLS和STARTTLS。 only - 在客户端使用TLS启用STLS和STARTTLS。 Nginx配置在更改配置文件之前首先备份配置文件nginx.conf1cp /data/nginx/conf/nginx.conf /data/backup/nginx.conf20180403.bak Nginx基本配置和参数说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156#运行用户user nobody;#启动进程,通常设置成和cpu的数量相等worker_processes 1; #全局错误日志及PID文件#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info; #pid logs/nginx.pid; #工作模式及连接数上限events &#123; #epoll是多路复用IO(I/O Multiplexing)中的一种方式, #仅用于linux2.6以上内核,可以大大提高nginx的性能 use epoll; #单个后台worker process进程的最大并发链接数 worker_connections 1024; # 并发总数是 worker_processes 和 worker_connections 的乘积 # 即 max_clients = worker_processes * worker_connections # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4 为什么 # 为什么上面反向代理要除以4，应该说是一个经验值 # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000 # worker_connections 值的设置跟物理内存大小有关 # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数 # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右 # 我们来看看360M内存的VPS可以打开的文件句柄数是多少： # $ cat /proc/sys/fs/file-max # 输出 34336 # 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内 # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置 # 使得并发总数小于操作系统可以打开的最大文件数目 # 其实质也就是根据主机的物理CPU和内存进行配置 # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。 # ulimit -SHn 65535 &#125; http &#123; #设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; #设定日志格式 log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log logs/access.log main; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件， #对于普通应用，必须设为 on, #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off， #以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; #开启gzip压缩 gzip on; gzip_disable "MSIE [1-6]."; #设定请求缓冲 client_header_buffer_size 128k; large_client_header_buffers 4 128k; #设定虚拟主机配置 server &#123; #侦听80端口 listen 80; #定义使用 www.nginx.cn访问 server_name www.nginx.cn; #定义服务器的默认网站根目录位置 root html; #设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; #默认请求 location / &#123; #定义首页索引文件的名称 index index.php index.html index.htm; &#125; # 定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; #过期30天，静态文件不怎么更新，过期可以设大一点， #如果频繁更新，则可以设置得小一点。 expires 30d; &#125; #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置. location ~ .php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; #禁止访问 .htxxx 文件 location ~ /.ht &#123; deny all; &#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; Nginx location匹配规则location匹配命令 ~ #波浪线表示执行一个正则匹配，区分大小写 ~* #表示执行一个正则匹配，不区分大小写 ^~ #^~表示普通字符匹配，如果该选项匹配，只匹配该选项，不匹配别的选项，一般用来匹配目录 = #进行普通字符精确匹配 @ #&quot;@&quot; 定义一个命名的 location，使用在内部定向时，例如 error_page, try_files location 匹配的优先级(与location在配置文件中的顺序无关) = 精确匹配会第一个被处理。如果发现精确匹配，nginx停止搜索其他匹配。 普通字符匹配，正则表达式规则和长的块规则将被优先和查询匹配，也就是说如果该项匹配还需去看有没有正则表达式匹配和更长的匹配。 ^~ 则只匹配该规则，nginx停止搜索其他匹配，否则nginx会继续处理其他location指令。 最后匹配理带有&quot;~&quot;和&quot;~*&quot;的指令，如果找到相应的匹配，则nginx停止搜索其他匹配；当没有正则表达式或者没有正则表达式被匹配的情况下，那么匹配程度最高的逐字匹配指令会被使用。 例如1234567891011121314151617location = / &#123; # 只匹配"/". [ configuration A ] &#125;location / &#123; # 匹配任何请求，因为所有请求都是以"/"开始 # 但是更长字符匹配或者正则表达式匹配会优先匹配 [ configuration B ] &#125;location ^~ /images/ &#123; # 匹配任何以 /images/ 开始的请求，并停止匹配 其它location [ configuration C ] &#125;location ~* .(gif|jpg|jpeg)$ &#123; # 匹配以 gif, jpg, or jpeg结尾的请求. # 但是所有 /images/ 目录的请求将由 [Configuration C]处理. [ configuration D ] Nginx开启php支持找到如下内容，删除注释字符,并将倒数第二行的 /scripts 替为 $document_root修改前1234567#location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; 修改后1234567location ~ \.php$ &#123; root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; 重启后生效。 Nginx配置反向代理nginx作为web服务器一个重要的功能就是反向代理。nginx反向代理的指令不需要新增额外的模块，默认自带proxy_pass指令，只需要修改配置文件就可以实现反向代理。配置前的准备工作，后端跑apache服务的ip和端口，也就是说可以通过http://ip:port能访问到你的网站。然后就可以新建一个vhost.conf,加入如下内容，记得修改ip和域名为你的ip和域名。修改nginx.conf，添加 include test.conf 到http{}段, reload nginx就可以了。test.conf文件如下：12345678910111213141516171819202122232425262728293031323334353637## Basic reverse proxy server #### Apache backend for www.test.com ##upstream apachephp &#123; server ip:8080; #Apache&#125; ## Start www.test.com ##server &#123; listen 80; server_name www.test.com; access_log logs/test.access.log main; error_log logs/test.error.log; root html; index index.html index.htm index.php; ## send request back to apache ## location / &#123; proxy_pass http://apachephp; #Proxy Settings proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; &#125;&#125;## End www.test.com ## Nginx配置负载均衡一个简单的负载均衡的示例，把www.test.com均衡到本机不同的端口，也可以改为均衡到不同的地址上。12345678910111213141516http &#123; upstream myproject &#123; server 127.0.0.1:8000 weight=3; server 127.0.0.1:8001; server 127.0.0.1:8002; server 127.0.0.1:8003; &#125; server &#123; listen 80; server_name www.test.com; location / &#123; proxy_pass http://myproject; &#125; &#125;&#125; Nginx配置图片服务器首先建立存放图片的目录文件夹，在/data/nginx/html目录下建立images文件夹(也可以是其他路径)Nginx默认使用端口是80，这里直接先把Nginx端口改为8088，在server字段中加入location字段123456789101112131415161718192021222324252627location ~ .*\.(gif|jpg|jpeg|png)$ &#123; #关于图片格式的设定，可以增加其他图片格式 expires 24h; root /data/nginx/html/images/;#指定图片存放路径 autoindex on;#打开预览功能 access_log /data/nginx/logs/images.log;#图片日志路径 #以下为关于代理访问的配置，也可以关闭 proxy_store on; proxy_store_access user:rw group:rw all:rw; proxy_temp_path /data/nginx/html/images/;#代理临时路径 proxy_redirect off; proxy_set_header Host 127.0.0.1; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; client_body_buffer_size 1280k; proxy_connect_timeout 900; proxy_send_timeout 900; proxy_read_timeout 900; proxy_buffer_size 40k; proxy_buffers 40 320k; proxy_busy_buffers_size 640k; proxy_temp_file_write_size 640k; if ( !-e $request_filename) &#123; proxy_pass http://127.0.0.1:8088;#代理访问地址，可以是其他地址 &#125; &#125; 这样一个简单的图片服务器就配置完成。 Nginx配置动静分离Nginx是一种轻量级，高性能，多进程的Web服务器，非常适合作为静态资源的服务器使用，而动态的访问操作可以使用稳定的Apache、Tomcat及IIS等来实现，这里就以Nginx作为代理服务器的同时，也使用其作为静态资源的服务器，而动态的访问服务器就以Apache和Tomcat为例说明。默认Nginx、Apache、Tomcat都安装在同台服务器，端口分别为80、88、8080。具体配置如下：123456789101112131415#默认静态资源location / &#123; root /datda/nginx/html; index index.html index.htm allow all; &#125;#动态资源加载location ~\.(php)?$ &#123; proxy_pass http://127.0.0.1:88; &#125; #动态资源加载location ~\.(do|jsp)?$ &#123; proxy_pass http://127.0.0.1:8080; &#125; 同时在Apache和Tomcat中关于动态资源目录的配置即可，可以是同目录，即/data/nginx/html。 Nginx配置下载服务器Nginx配置下载服务器即开启Nginx的索引功能，直接引导下载。可以直接对server字段进行配置，如下：12345678910111213server &#123; listen 81; #端口 server_name www.testa.com; #服务名 charset utf-8; #避免中文乱码 root /data/backup; #显示的根索引目录，注意这里要改成你自己的，目录要存在 location / &#123; autoindex on; #开启索引功能 autoindex_exact_size off; #关闭计算文件确切大小（单位bytes），只显示大概大小（单位kb、mb、gb） autoindex_localtime on; #显示本机时间而非 GMT 时间 &#125;&#125; Nginx上的所有服务名不能重复，端口不能重复，此次使用81端口进行访问。 Nginx配置邮件代理服务器一般情况下，客户端发起的邮件请求在经过Nginx这个邮件代理服务器后，从网络通信的角度来看，Nginx实现邮件代理功能时会把一个请求分为以下4个阶段：接收并解析客户端初始请求的阶段。向认证服务器验证请求合法性，并获取上游邮件服务器地址的阶段。Nginx根据用户信息多次与上游服务器交互验证合法性的阶段。Nginx在客户端与上游邮件服务器间纯粹透传TCP流的阶段。由此可以了解到，这些Nginx邮件模块的目的非常明确，就是使用事件框架在大量并发连接下高效地处理这4个阶段的请求。Nginx配置邮件代理服务器需要安装mail模块，安装参照Nginx升级操作。关于Nginx配置如下：1234567891011121314151617181920212223242526272829303132mail &#123; // 邮件认证服务器的访问URL auth_http IP:PORT/auth.php; // 当透传上，下游间的TCP流时，每个请求所使用的内存缓冲区大小 proxy_buffer 4k; server &#123; /*对于POP3协议，通常都是监听110端口。POP3协议接收初始客户端请求的缓冲区固定为128字节，配置文件中无法设置*/ listen 110; protocol pop3; proxy on; &#125; server &#123; // 对于IMAP，通常都是监听143端口 listen 143; protocol imap; // 设置接收初始客户端请求的缓冲区大小 imap_client_buffer 4k; proxy on; &#125; server &#123; // 对于SMTP，通常都是监听25端口 listen 25; protocol smtp; proxy on; // 设置接收初始客户端请求的缓冲区大小 smtp_client_buffer 4k; &#125; &#125; Nginx配置PC端和手机端分离一般情况下web网站的PC端页面和手机端页面是分开来开发的，那么就需要根据访问端的不同匹配到不同的页面，关于Nginx的配置示例如下：1234567891011121314151617181920212223242526272829303132server &#123; listen 80; #server_name www.testa.com; client_max_body_size 100M; client_body_buffer_size 100M; access_log logs/access_80.log main; error_log logs/error_80.log error; location / &#123; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow_Credentials' 'true'; add_header 'Access-Control-Allow-Headers' 'Authorization,Accept,Origin,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range'; add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS,PUT,DELETE,PATCH'; root /data/work/front/FrontEndPage; index index.html index.htm mobile.html; if ($http_user_agent ~* "(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino") &#123; root /data/work/front/FrontEndPage/mobile; &#125; if ($http_user_agent ~* "^(1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-)") &#123; root /data/work/front/FrontEndPage/mobile; &#125; try_files $uri $uri/ /index.html; error_page 404 /404.html; error_page 405 =200 $uri; &#125;&#125; 手机端页面的首页为mobile.html，所以在自定义首页中加入mobile.html。手机端页面目录mobile放在根目录下，实际生产中根据实际情况配置。 Nginx优化Nginx运行工作进程个数一般设置为CPU的核心数或者核心数的2倍查看系统核心数，使用top命令后按112345678top - 04:04:59 up 5 days, 22:57, 3 users, load average: 0.00, 0.01, 0.05Tasks: 149 total, 1 running, 148 sleeping, 0 stopped, 0 zombie%Cpu0 : 0.3 us, 0.3 sy, 0.0 ni, 98.7 id, 0.0 wa, 0.0 hi, 0.3 si, 0.3 st%Cpu1 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 7747784 total, 6489052 free, 138776 used, 1119956 buff/cacheKiB Swap: 3145724 total, 3145724 free, 0 used. 7332688 avail Mem 也可以通过命令1cat /proc/cpuinfo |grep processor |wc -l 查看核心数，查看到CPU核心数为4，修改Nginx配置文件/data/nginx/conf/nginx.conf，修改后为：1worker_processes 4; 重启nginx，查看nginx进程为：123456root 24041 1 0 Apr03 ? 00:00:00 nginx: master process nginxnobody 31044 24041 0 03:55 ? 00:00:00 nginx: worker processnobody 31045 24041 0 03:55 ? 00:00:00 nginx: worker processnobody 31046 24041 0 03:55 ? 00:00:00 nginx: worker processnobody 31047 24041 0 03:55 ? 00:00:00 nginx: worker processroot 31695 14682 0 04:11 pts/0 00:00:00 grep --color=auto nginx 可以看到Nginx的work process个数已经变为4个。 Nginx运行CPU亲和力比如4核配置12worker_processes 4;worker_cpu_affinity 0001 0010 0100 1000; 比如8核配置12worker_processes 8;worker_cpu_affinity 00000001 00000010 00000100 0000100000010000 00100000 01000000 10000000; worker_processes最多开启8个，8个以上性能提升不会再提升了，而且稳定性变得更低，所以8个进程够用了。 Nginx最多可以打开文件数1worker_rlimit_nofile 65535; 这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n的值保持一致。注： 文件资源限制的配置可以在/etc/security/limits.conf设置，针对root/user等各个用户或者*代表所有用户来设置。 12* soft nofile 65535* hard nofile 65535 用户重新登录生效（ulimit -n） Nginx事件处理模型12345events &#123;use epoll;worker_connections 65535;multi_accept on;&#125; nginx采用epoll事件模型，处理效率高work_connections是单个worker进程允许客户端最大连接数，这个数值一般根据服务器性能和内存来制定，实际最大值就是worker进程数乘以work_connections实际我们填入一个65535，足够了，这些都算并发值，一个网站的并发达到这么大的数量，也算一个大站了！multi_accept 告诉nginx收到一个新连接通知后接受尽可能多的连接，默认是on，设置为on后，多个worker按串行方式来处理连接，也就是一个连接只有一个worker被唤醒，其他的处于休眠状态，设置为off后，多个worker按并行方式来处理连接，也就是一个连接会唤醒所有的worker，直到连接分配完毕，没有取得连接的继续休眠。当你的服务器连接数不多时，开启这个参数会让负载有一定的降低，但是当服务器的吞吐量很大时，为了效率，可以关闭这个参数。 连接超时时间主要目的是保护服务器资源，CPU，内存，控制连接数，因为建立连接也是需要消耗资源的123456789101112keepalive_timeout 60;tcp_nodelay on;client_header_buffer_size 4k;open_file_cache max=102400 inactive=20s;open_file_cache_valid 30s;open_file_cache_min_uses 1;client_header_timeout 15;client_body_timeout 15;reset_timedout_connection on;send_timeout 15;server_tokens off;client_max_body_size 10m; 参数解释：123456789101112131415161718keepalived_timeout客户端连接保持会话超时时间，超过这个时间，服务器断开这个链接tcp_nodelay；也是防止网络阻塞，不过要包涵在keepalived参数才有效client_header_buffer_size 4k;客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过 1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。open_file_cache max=102400 inactive=20s;这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive 是指经过多长时间文件没被请求后删除缓存。open_file_cache_valid 30s;这个是指多长时间检查一次缓存的有效信息。open_file_cache_min_uses 1;open_file_cache指令中的inactive 参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive 时间内一次没被使用，它将被移除。client_header_timeout设置请求头的超时时间。我们也可以把这个设置低些，如果超过这个时间没有发送任何数据，nginx将返回request time out的错误client_body_timeout设置请求体的超时时间。我们也可以把这个设置低些，超过这个时间没有发送任何数据，和上面一样的错误提示reset_timeout_connection 告诉nginx关闭不响应的客户端连接。这将会释放那个客户端所占有的内存空间。send_timeout响应客户端超时时间，这个超时时间仅限于两个活动之间的时间，如果超过这个时间，客户端没有任何活动，nginx关闭连接server_tokens 并不会让nginx执行的速度更快，但它可以关闭在错误页面中的nginx版本数字，这样对于安全性是有好处的。client_max_body_size上传文件大小限制 fastcgi调优12345678910fastcgi_connect_timeout 600;fastcgi_send_timeout 600;fastcgi_read_timeout 600;fastcgi_buffer_size 64k;fastcgi_buffers 4 64k;fastcgi_busy_buffers_size 128k;fastcgi_temp_file_write_size 128k;fastcgi_temp_path/usr/local/nginx1.10/nginx_tmp;fastcgi_intercept_errors on;fastcgi_cache_path/usr/local/nginx1.10/fastcgi_cache levels=1:2 keys_zone=cache_fastcgi:128minactive=1d max_size=10g; 参数解释：12345678910111213141516171819202122232425fastcgi_connect_timeout 600; #指定连接到后端FastCGI的超时时间。fastcgi_send_timeout 600; #向FastCGI传送请求的超时时间。fastcgi_read_timeout 600; #指定接收FastCGI应答的超时时间。fastcgi_buffer_size 64k; #指定读取FastCGI应答第一部分需要用多大的缓冲区，默认的缓冲区大小为fastcgi_buffers指令中的每块大小，可以将这个值设置更小。fastcgi_buffers 4 64k; #指定本地需要用多少和多大的缓冲区来缓冲FastCGI的应答请求，如果一个php脚本所产生的页面大小为256KB，那么会分配4个64KB的缓冲区来缓存，如果页面大小大于256KB，那么大于256KB的部分会缓存到fastcgi_temp_path指定的路径中，但是这并不是好方法，因为内存中的数据处理速度要快于磁盘。一般这个值应该为站点中php脚本所产生的页面大小的中间值，如果站点大部分脚本所产生的页面大小为256KB，那么可以把这个值设置为“8 32K”、“4 64k”等。fastcgi_busy_buffers_size 128k; #建议设置为fastcgi_buffers的两倍，繁忙时候的bufferfastcgi_temp_file_write_size 128k; #在写入fastcgi_temp_path时将用多大的数据块，默认值是fastcgi_buffers的两倍，该数值设置小时若负载上来时可能报502BadGatewayfastcgi_temp_path #缓存临时目录fastcgi_intercept_errors on;#这个指令指定是否传递4xx和5xx错误信息到客户端，或者允许nginx使用error_page处理错误信息。注：静态文件不存在会返回404页面，但是php页面则返回空白页！！fastcgi_cache_path /usr/local/nginx1.10/fastcgi_cachelevels=1:2 keys_zone=cache_fastcgi:128minactive=1d max_size=10g;# fastcgi_cache缓存目录，可以设置目录层级，比如1:2会生成16*256个子目录，cache_fastcgi是这个缓存空间的名字，cache是用多少内存（这样热门的内容nginx直接放内存，提高访问速度），inactive表示默认失效时间，如果缓存数据在失效时间内没有被访问,将被删除，max_size表示最多用多少硬盘空间。fastcgi_cache cache_fastcgi; #表示开启FastCGI缓存并为其指定一个名称。开启缓存非常有用，可以有效降低CPU的负载，并且防止502的错误放生。cache_fastcgi为proxy_cache_path指令创建的缓存区名称fastcgi_cache_valid 200 302 1h; #用来指定应答代码的缓存时间，实例中的值表示将200和302应答缓存一小时，要和fastcgi_cache配合使用fastcgi_cache_valid 301 1d; #将301应答缓存一天fastcgi_cache_valid any 1m; #将其他应答缓存为1分钟fastcgi_cache_min_uses 1; #该指令用于设置经过多少次请求的相同URL将被缓存。fastcgi_cache_key http://$host$request_uri; #该指令用来设置web缓存的Key值,nginx根据Key值md5哈希存储.一般根据$host(域名)、$request_uri(请求的路径)等变量组合成proxy_cache_key 。fastcgi_pass #指定FastCGI服务器监听端口与地址，可以是本机或者其它总结：nginx的缓存功能有：proxy_cache / fastcgi_cacheproxy_cache的作用是缓存后端服务器的内容，可能是任何内容，包括静态的和动态。fastcgi_cache的作用是缓存fastcgi生成的内容，很多情况是php生成的动态的内容。proxy_cache缓存减少了nginx与后端通信的次数，节省了传输时间和后端宽带。fastcgi_cache缓存减少了nginx与php的通信的次数，更减轻了php和数据库(mysql)的压力。CGI是为了保证web server传递过来的数据是标准格式的，方便CGI程序的编写者。Fastcgi是用来提高CGI程序性能的。php-fpm是fastcgi进程的管理器，用来管理fastcgi进程的 gzip调优使用gzip压缩功能，可能为我们节约带宽，加快传输速度，有更好的体验，也为我们节约成本，所以说这是一个重点。Nginx启用压缩功能需要你来ngx_http_gzip_module模块（apache使用的是mod_deflate）。一般我们需要压缩的内容有：文本，js，html，css，对于图片，视频，flash什么的不压缩，同时也要注意，我们使用gzip的功能是需要消耗CPU的！12345678gzip on;gzip_min_length 2k;gzip_buffers 4 32k;gzip_http_version 1.1;gzip_comp_level 6;gzip_types text/plain text/css text/javascriptapplication/json application/javascript application/x-javascriptapplication/xml;gzip_vary on;gzip_proxied any; 参数解释：123456789101112gzip on; #开启压缩功能gzip_min_length 1k; #设置允许压缩的页面最小字节数，页面字节数从header头的Content-Length中获取，默认值是0，不管页面多大都进行压缩，建议设置成大于1K，如果小与1K可能会越压越大。gzip_buffers 4 32k; #压缩缓冲区大小，表示申请4个单位为32K的内存作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果。gzip_http_version 1.1; #压缩版本，用于设置识别HTTP协议版本，默认是1.1，目前大部分浏览器已经支持GZIP解压，使用默认即可gzip_comp_level 6; #压缩比例，用来指定GZIP压缩比，1压缩比最小，处理速度最快，9压缩比最大，传输速度快，但是处理慢，也比较消耗CPU资源。gzip_types text/css text/xml application/javascript; #用来指定压缩的类型，‘text/html’类型总是会被压缩。默认值: gzip_types text/html (默认不对js/css文件进行压缩)# 压缩类型，匹配MIME��型进行压缩# 不能用通配符 text/*# (无论是否指定)text/html默认已经压缩 # 设置哪压缩种文本文件可参考 conf/mime.typesgzip_vary on; #varyheader支持，改选项可以让前端的缓存服务器缓存经过GZIP压缩的页面，例如用Squid缓存经过nginx压缩的数据 expires缓存优化缓存，主要针对于图片，css，js等元素更改机会比较少的情况下使用，特别是图片，占用带宽大，我们完全可以设置图片在浏览器本地缓存365d，css，js，html可以缓存个10来天，这样用户第一次打开加载慢一点，第二次，就非常快了！缓存的时候，我们需要将需要缓存的拓展名列出来， Expires缓存配置在server字段里面12345678910location ~* \.(ico|jpe?g|gif|png|bmp|swf|flv)$ &#123; expires 30d; #log_not_found off; access_log off;&#125;location ~* \.(js|css)$ &#123; expires 7d; log_not_found off; access_log off;&#125; 注：log_not_found off;是否在error_log中记录不存在的错误。默认是。总结：expire功能优点 expires可以降低网站购买的带宽，节约成本 同时提升用户访问体验 减轻服务的压力，节约服务器成本，是web服务非常重要的功能。 expire功能缺点 被缓存的页面或数据更新了，用户看到的可能还是旧的内容，反而影响用户体验。解决办法：第一个缩短缓存时间，例如：1天，但不彻底，除非更新频率大于1天；第二个对缓存的对象改名。 网站不希望被缓存的内容 1）网站流量统计工具2）更新频繁的文件 防盗链防止别人直接从你网站引用图片等链接，消耗了你的资源和网络流量，那么我们的解决办法由几种： 1：水印，品牌宣传，你的带宽，服务器足够2：防火墙，直接控制，前提是你知道IP来源3：防盗链策略下面的方法是直接给予404的错误提示123456789location ~*^.+\.(jpg|gif|png|swf|flv|wma|wmv|asf|mp3|mmf|zip|rar)$ &#123; valid_referers noneblocked www.benet.com benet.com; if($invalid_referer) &#123; #return 302 http://127.0.0.1/img/nolink.jpg; return 404; break; &#125; access_log off; &#125; 参数可以使如下形式：none 意思是不存在的Referer头(表示空的，也就是直接访问，比如直接在浏览器打开一个图片)blocked 意为根据防火墙伪装Referer头，如：“Referer:XXXXXXX”。server_names 为一个或多个服务器的列表。 系统内核参数优化fs.file-max = 999999：这个参数表示进程（比如一个worker进程）可以同时打开的最大句柄数，这个参数直线限制最大并发连接数，需根据实际情况配置。net.ipv4.tcp_max_tw_buckets = 6000 #这个参数表示操作系统允许TIME_WAIT套接字数量的最大值，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。该参数默认为180000，过多的TIME_WAIT套接字会使Web服务器变慢。注：主动关闭连接的服务端会产生TIME_WAIT状态的连接net.ipv4.ip_local_port_range = 1024 65000 #允许系统打开的端口范围。net.ipv4.tcp_tw_recycle = 1#启用timewait快速回收。net.ipv4.tcp_tw_reuse = 1#开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接。这对于服务器来说很有意义，因为服务器上总会有大量TIME-WAIT状态的连接。net.ipv4.tcp_keepalive_time = 30：这个参数表示当keepalive启用时，TCP发送keepalive消息的频度。默认是2小时，若将其设置的小一些，可以更快地清理无效的连接。net.ipv4.tcp_syncookies = 1#开启SYN Cookies，当出现SYN等待队列溢出时，启用cookies来处理。net.core.somaxconn = 40960 #web 应用中 listen 函数的 backlog 默认会给我们内核参数的 net.core.somaxconn 限制到128，而nginx定义的NGX_LISTEN_BACKLOG 默认为511，所以有必要调整这个值。注：对于一个TCP连接，Server与Client需要通过三次握手来建立网络连接.当三次握手成功后,我们可以看到端口的状态由LISTEN转变为ESTABLISHED,接着这条链路上就可以开始传送数据了.每一个处于监听(Listen)状态的端口,都有自己的监听队列.监听队列的长度与如somaxconn参数和使用该端口的程序中listen()函数有关somaxconn参数:定义了系统中每一个端口最大的监听队列的长度,这是个全局的参数,默认值为128，对于一个经常处理新连接的高负载 web服务环境来说，默认的 128 太小了。大多数环境这个值建议增加到 1024 或者更多。大的侦听队列对防止拒绝服务 DoS 攻击也会有所帮助。net.core.netdev_max_backlog = 262144 #每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。net.ipv4.tcp_max_syn_backlog = 262144 #这个参数标示TCP三次握手建立阶段接受SYN请求队列的最大长度，默认为1024，将其设置得大一些可以使出现Nginx繁忙来不及accept新连接的情况时，Linux不至于丢失客户端发起的连接请求。net.ipv4.tcp_rmem = 10240 87380 12582912#这个参数定义了TCP接受缓存（用于TCP接受滑动窗口）的最小值、默认值、最大值。net.ipv4.tcp_wmem = 10240 87380 12582912：这个参数定义了TCP发送缓存（用于TCP发送滑动窗口）的最小值、默认值、最大值。net.core.rmem_default = 6291456：这个参数表示内核套接字接受缓存区默认的大小。net.core.wmem_default = 6291456：这个参数表示内核套接字发送缓存区默认的大小。net.core.rmem_max = 12582912：这个参数表示内核套接字接受缓存区的最大大小。net.core.wmem_max = 12582912：这个参数表示内核套接字发送缓存区的最大大小。net.ipv4.tcp_syncookies = 1：该参数与性能无关，用于解决TCP的SYN攻击。 完整的内核优化设置：123456789101112131415161718192021222324252627282930313233fs.file-max = 999999net.ipv4.ip_forward = 0net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1net.ipv4.tcp_syncookies = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296net.ipv4.tcp_max_tw_buckets = 6000net.ipv4.tcp_sack = 1net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_rmem = 10240 87380 12582912net.ipv4.tcp_wmem = 10240 87380 12582912net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.core.netdev_max_backlog = 262144net.core.somaxconn = 40960net.ipv4.tcp_max_orphans = 3276800net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_timestamps = 0net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_mem = 94500000 915000000 927000000net.ipv4.tcp_fin_timeout = 1net.ipv4.tcp_keepalive_time = 30net.ipv4.ip_local_port_range = 1024 65000 执行sysctl -p使内核修改生效。 系统连接数的优化linux 默认值 open files为1024 #ulimit -n1024说明server只允许同时打开1024个文件使用ulimit -a 可以查看当前系统的所有限制值12345678910111213141516core file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 31175max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 31175virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 使用ulimit -n 可以查看当前的最大打开文件数。新装的linux 默认只有1024 ，当作负载较大的服务器时，很容易遇到error: too many open files。因此，需要将其改大在/etc/security/limits.conf最后增加：1234* soft nofile 65535* hard nofile 65535* soft noproc 65535* hard noproc 65535]]></content>
      <categories>
        <category>Service</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xargs用法]]></title>
    <url>%2Fposts%2F8d4248f1.html</url>
    <content type="text"><![CDATA[xargs命令是给其他命令传递参数的一个过滤器，也是组合多个命令的一个工具。它擅长将标准输入数据转换成命令行参数，xargs能够处理管道或者stdin并将其转换成特定命令的命令参数。xargs也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。xargs的默认命令是echo，空格是默认定界符。这意味着通过管道传递给xargs的输入将会包含换行和空白，不过通过xargs的处理，换行和空白将被空格取代。xargs是构建单行命令的重要组件之一。 xargs用法xargs用作替换工具，读取输入数据重新格式化后输出。定义一个测试文件，内有多行文本数据：123456# cat test.txt a b c d e fh i j k l m no p q fr s t ju v w x y z 多行输入单行输出：12# cat test.txt | xargsa b c d e f h i j k l m n o p q f r s t j u v w x y z -n选项多行输出：123456789101112131415161718# cat test.txt | xargs -n3a b cd e fh i jk l mn o pq f rs t ju v wx y z# cat test.txt | xargs -n4a b c de f h ij k l mn o p qf r s tj u v wx y z 可见-n后的数字可以控制每行列数-d选项可以自定义一个定界符：12# echo "nameXnameXnameXname" | xargs -dXname name name name 结合-n选项使用：123# echo "nameXnameXnameXname" | xargs -dX -n2name namename name 读取stdin，将格式化后的参数传递给命令假设一个命令为 sk.sh 和一个保存参数的文件arg.txt：sk.sh内容：12345# cat sk.sh #!/bin/bash#sk.sh命令内容，打印出所有参数。 echo $* arg.txt文件内容：1234# cat arg.txt aaabbbccc xargs的一个选项-I，使用-I指定一个替换字符串{}，这个字符串在xargs扩展时会被替换掉，当-I与xargs结合使用，每一个参数命令都会被执行一次：1234# cat arg.txt | xargs -I &#123;&#125; ./sk.sh -p &#123;&#125; -l-p aaa -l-p bbb -l-p ccc -l 复制所有图片文件到 /data/backup/images 目录下：1ls *.jpg | xargs -n1 -I cp &#123;&#125; /data/backup/images xargs结合find使用用rm 删除太多的文件时候，可能得到一个错误信息：/bin/rm Argument list too long. 用xargs去避免这个问题：1find . -type f -name "*.log" -print0 | xargs -0 rm -f xargs -0将\0作为定界符。统计一个源代码目录中所有php文件的行数：1find . -type f -name "*.php" -print0 | xargs -0 wc -l 查找所有的jpg 文件，并且压缩它们：1find . -type f -name "*.jpg" -print | xargs tar -czvf images.tar.gz xargs其他应用假如你有一个文件包含了很多你希望下载的URL，你能够使用xargs下载所有链接：1cat url-list.txt | xargs wget -c]]></content>
      <categories>
        <category>OS</category>
        <category>Command&amp;Tool</category>
      </categories>
      <tags>
        <tag>xargs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible入门教程]]></title>
    <url>%2Fposts%2Fc593850f.html</url>
    <content type="text"><![CDATA[一、基本部署安装Ansible1234567891011yum -y install epel-releaseyum list all *ansible*yum info ansibleyum -y install ansible``` ### Ansible配置文件```bash/etc/ansible/ansible.cfg 主配置文件/etc/ansible/hosts Inventory/usr/bin/ansible-doc 帮助文件/usr/bin/ansible-playbook 指定运行任务文件 定义Inventory1234567891011# cd /etc/ansible/# cp hosts&#123;,.bak&#125;# &gt; hosts # cat hosts[webserver]127.0.0.110.186.60.60[dbserver]10.186.65.43 使用秘钥方式连接1234ssh-keygen -t rsa ssh-copy-id -i /root/.ssh/id_rsa.pub root@127.0.0.1ssh-copy-id -i /root/.ssh/id_rsa.pub root@10.186.60.60ssh-copy-id -i /root/.ssh/id_rsa.pub root@10.186.65.43 使用帮助12ansible-doc -l 列出ansible所有的模块ansible-doc -s MODULE_NAME 查看指定模块具体适用 Ansible命令应用基础12345678910111213语法：ansible &lt;host-pattern&gt; [-f forks] [-m module_name] [-a args]&lt;host-pattern&gt; 这次命令对哪些主机生效的 inventory group name ip all-f forks 一次处理多少个主机-m module_name 要使用的模块-a args 模块特有的参数# ansible 10.186.65.43 -m command -a 'date'# ansible webserver -m command -a 'date'# ansible all -m command -a 'date' 二、常见模块12command 命令模块(默认模块)用于在远程主机执行命令；不能使用变量，管道等 # ansible all -a 'date' 12345678910111213cron 计划任务 month 指定月份 minute 指定分钟 job 指定任务 day 表示那一天 hour 指定小时 weekday 表示周几 state 表示是添加还是删除 present：安装 absent：移除 # ansible webserver -m cron -a 'minute="*/10" job="/bin/echo hello" name="test cron job"' #不写默认都是*，每个任务都必须有一个名字 # ansible webserver -a 'crontab -l' # ansible webserver -m cron -a 'minute="*/10" job="/bin/echo hello" name="test cron job" state=absent' #移除任务 12345678910111213user 用户账号管理 name 用户名 uid uid state 状态 group 属于哪个组 groups 附加组 home 家目录 createhome 是否创建家目录 comment 注释信息 system 是否是系统用户 # ansible all -m user -a 'name="user1"' # ansible all -m user -a 'name="user1" state=absent' 1234567group 组管理 gid gid name 组名 state 状态 system 是否是系统组 # ansible webserver -m group -a 'name=mysql gid=306 system=yes' # ansible webserver -m user -a 'name=mysql uid=306 system=yes group=mysql' 12345678910copy 复制文件(复制本地文件到远程主机的指定位置) src 定义本地源文件路径 dest 定义远程目录文件路径(绝对路径) owner 属主 group 属组 mode 权限 content 取代src=,表示直接用此处的信息生成为文件内容 # yum -y install libselinux-python # ansible all -m copy -a 'src=/etc/fstab dest=/tmp/fstab.ansible owner=root mode=640' # ansible all -m copy -a 'content="hello ansible\nHi ansible" dest=/tmp/test.ansible' 12345678file 设置文件的属性 path|dest|name 对那个文件做设定 创建文件的符号链接： src： 指定源文件 path： 指明符号链接文件路径 # ansible all -m file -a 'owner=mysql group=mysql mode=644 path=/tmp/fstab.ansible' # ansible all -m file -a 'path=/tmp/fstab.link src=/tmp/fstab.ansible state=link' 12ping 测试指定主机是否能连接 # ansible all -m ping 123456789service 管理服务运行状态 enabled 是否开机自动启动 name 指定服务名 state 指定服务状态 started 启动服务 stoped 停止服务 restarted 重启服务 arguments 服务的参数 # ansible webserver -m service -a 'enabled=true name=httpd state=started' 123shell 在远程主机上运行命令 尤其是用到管道变量等功能的复杂命令 # ansible all -m shell -a 'echo magedu | passwd --stdin user1' 12script 将本地脚本复制到远程主机并运行之 # ansible all -m script -a '/tmp/test.sh' 123456yum 安装程序包 name 程序包名称(不指定版本就安装最新的版本latest) state present,latest表示安装，absent表示卸载 # ansible webserver -m yum -a 'name=httpd' # ansible all -m yum -a 'name=ntpdate' #默认就是安装 # ansible all -m yum -a 'name=ntpdate state=absent' 123setup 收集远程主机的facts 每个被管理节点在接受并运行管理命令之前，会将自己主机相关信息，如操作系统版本，IP地址等报告给远程的ansible主机 # ansible all -m setup 三、Ansible playbook组成结构：123456789inventory #以下操作应用的主机modules #调用哪些模块做什么样的操作ad hoc commands #在这些主机上运行哪些命令playbooks tasks #任务,即调用模块完成的某操作 variable #变量 templates #模板 handlers #处理器，由某事件触发执行的操作 roles #角色 四、YAML1、YAML介绍YAML是一个可读性高的用来表达资料序列的格式。YAML参考了其它多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822等。ClarkEvans在2001年首次发表了这种语言，另外Ingy dot Net与Oren Ben-Kiki也是这语言的共同设计者。YAML Ain’t Markup Language,即YAML不是XML，不过，在开发这种语言时，YAML的意思其实是：”Yet Another Markup Language”(仍是一种标记语言)，其特性： YAML的可读性好 YAML和脚本语言的交互性好 YAML使用实现语言的数据类型 YAML有一个一致的信息模型 YAML易于实现 YAML可以基于流来处理 YAML表达能力强，扩展性好 参考 更多的内容及规范参见http://www.yaml.org 2、YAML语法YAML的语法和其他高阶语言类似，并且可以简单表达清单、散列表、标量等数据结构，其结构(structure)通过空格来展示，序列(sequence)里的项用”-“来表示，Map里面的键值对用”:”分割，下面是一个示例。1234567891011121314name: john smithage: 41gender: malespouse: name:jane smith age:37 gender: femalechildren: - name:jimmy smith age:17 gender: male - name:jenny smith age: 13 gender: female YAML文件扩展名通常为.yaml，如example.yaml 1、list列表的所有元素均使用”-“打头，例如：12345# A list of testy fruits- Apple- Orange- Strawberry- Mango 2、dictionary字典通过key与value进行标识，例如：12345---# An employee recordname: Example Developerjob: Developerskill: Elite 也可以将key:value放置于{}中进行表示，例如：123---#An exmloyee record&#123;name: Example Developer, job: Developer, skill: Elite&#125; 五、Ansible基础元素1、变量1、变量命名变量名仅能由字母、数字和下划线组成，且只能以字母开头。 2、factsfacts是由正在通信的远程目标主机发回的信息，这些信息被保存在ansible变量中。要获取指定的远程主机所支持的所有facts，可使用如下命令进行：1#ansible hostname -m setup 3、register把任务的输出定义为变量，然后用于其他任务，实例如下：1234tasks: - shell: /usr/bin/foo register: foo_result ignore_errors: True 4、通过命令行传递变量在运行playbook的时候也可以传递一些变量供playbook使用，示例如下：1#ansible-playbook test.yml --extra-vars "hosts=www user=mageedu" 5、通过roles传递变量当给一个主机应用角色的时候可以传递变量，然后在角色内使用这些变量，示例如下：1234- hosts: webserver roles: - common - &#123;role: foo_app_instance, dir: '/web/htdocs/a.com', port: 8080&#125; 2、Inventoryansible的主要功用在于批量主机操作，为了便捷的使用其中的部分主机，可以在inventory file中将其分组命名，默认的inventory file为/etc/ansible/hostsinventory file可以有多个，且也可以通过Dynamic Inventory来动态生成。 1、inventory文件格式inventory文件遵循INI文件风格，中括号中的字符为组名。可以将同一个主机同时归并到多个不同的组中；此外，当如若目标主机使用非默认的SSH端口，还可以在主机名称之后使用冒号加端口号来表明。12345678910ntp.magedu.com[webserver]www1.magedu.com:2222www2.magedu.com[dbserver]db1.magedu.comdb2.magedu.comdb3.magedu.com 如果主机名遵循相似的命名模式，还可使用列表的方式表示多个主机，例如：12345[webserver]www[01:50].example.com[databases]db-[a:f].example.com 2、主机变量可以在inventory中定义主机时为其添加主机变量以便于在playbook中使用，例如：123[webserver]www1.magedu.com http_port=80 maxRequestsPerChild=808www2.magedu.com http_port=8080 maxRequestsPerChild=909 3、组变量组变量是指赋予给指定组内所有主机上的在playbook中可用的变量。例如：1234567[webserver]www1.magedu.comwww2.magedu.com[webserver:vars]ntp_server=ntp.magedu.comnfs_server=nfs.magedu.com 4、组嵌套inventory中，组还可以包含其它的组，并且也可以向组中的主机指定变量。不过，这些变量只能在ansible-playbook中使用，而ansible不支持。例如：1234567891011121314[apache]httpd1.magedu.comhttpd2.magedu.com[nginx]ngx1.magedu.comngx2.magedu.com[webserver:children] #固定格式apachenginx[webserver:vars]ntp_server=ntp.magedu.com 5、inventory参数ansible基于ssh连接inventory中指定的远程主机时，还可以通过参数指定其交互方式，这些参数如下所示：123456789ansible_ssh_hostansible_ssh_portansible_ssh_useransible_ssh_passansible_sudo_passansible_connectionansible_ssh_private_key_fileansible_shell_typeansible_python_interpreter 3、条件测试如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试。 1、when语句在task后添加when字句即可使用条件测试；when语句支持jinja2表达式语句，例如：1234tasks: - name: 'shutdown debian flavored system" command: /sbin/shutdown -h now when: ansible_os_family == "Debian" when语句中还可以使用jinja2的大多”filter”,例如果忽略此前某语句的错误并基于其结果(failed或success)运行后面指定的语句，可使用类似如下形式； 12345678910tasks: - command:/bin/false register: result ignore_errors: True - command: /bin/something when: result|failed - command: /bin/something_else when: result|success - command: /bin/still/something_else when: result|skipped 此外，when语句中还可以使用facts或playbook中定义的变量123456789# cat cond.yml - hosts: all remote_user: root vars: - username: user10 tasks: - name: create &#123;&#123; username &#125;&#125; user user: name=&#123;&#123; username &#125;&#125; when: ansible_fqdn == "node1.exercise.com" 4、迭代当有需要重复性执行的任务时，可以使用迭代机制。其使用格式为将需要迭代的内容定义为item变量引用，并通过with_items语句来指明迭代的元素列表即可。例如：12345- name: add server user user: name=&#123;&#123; item &#125;&#125; state=persent groups=wheel with_items: - testuser1 - testuser2 上面语句的功能等同于下面的语句：1234- name: add user testuser1 user: name=testuser1 state=present group=wheel- name: add user testuser2 user: name=testuser2 state=present group=wheel 事实上，with_items中可以使用元素还可为hashes，例如：12345- name: add several users user: name=&#123;&#123; item.name&#125;&#125; state=present groups=&#123;&#123; item.groups &#125;&#125; with_items: - &#123; name: 'testuser1', groups: 'wheel'&#125; - &#123; name: 'testuser2', groups: 'root'&#125; 参考 Ansible的循环机制还有更多的高级功能，具体请参考官方文档http://docs.ansible.com/playbooks_loops.html 六、模板示例12345678910111213141516171819202122232425262728# grep '&#123;&#123;' conf/httpd.conf MaxClients &#123;&#123; maxClients &#125;&#125;Listen &#123;&#123; httpd_port &#125;&#125;# cat /etc/ansible/hosts[webserver]127.0.0.1 httpd_port=80 maxClients=100192.168.10.149 httpd_port=8080 maxClients=200# cat apache.yml - hosts: webserver remote_user: root vars: - package: httpd - service: httpd tasks: - name: install httpd package yum: name=&#123;&#123; package &#125;&#125; state=latest - name: install configuration file for httpd template: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf notify: - restart httpd - name: start httpd service service: enabled=true name=&#123;&#123; service &#125;&#125; state=started handlers: - name: restart httpd service: name=httpd state=restarted 七、Ansible playbooksplaybook是由一个或多个”play”组成的列表。play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色。从根本上来讲，所有task无非是调用ansible的一个module。将多个play组织在一个playbook中，即可以让他们连同起来按事先编排的机制同唱一台大戏。下面是一个简单示例。12345678910111213- hosts: webserver vars: http_port: 80 max_clients: 256 remote_user: root tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted 1、playbook基础组件1、Hosts和Usersplaybook中的每一个play的目的都是为了让某个或某些主机以某个指定的用户身份执行任务。hosts用于指定要执行指定任务的主机，其可以使一个或多个由冒号分隔主机组；remote_user则用于指定远程主机的执行任务的用户，如上面的实例中的12- hosts: webserver remote_user: root 不过，remote_user也可用于各task中，也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或其任务；此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户。1234567- hosts: webserver remote_user: magedu tasks: - name: test connection ping: remote_user: magedu sudo: yes 2、任务列表和actionplay的主题部分是task list。task list中的各任务按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个任务后再开始第二个。在运行自上而下某playbook时，如果中途发生错误，所有已执行任务都可能回滚，在更正playbook后重新执行一次即可。taks的目的是使用指定的参数执行模块，而在模块参数中可以使用变量。模块执行是幂等的。这意味着多次执行是安全的，因为其结果均一致。每个task都应该有其name，用于playbook的执行结果输出，建议其内容尽可能清晰地描述任务执行步骤，如果为提供name，则action的结果将用于输出。定义task可以使用”action: module options”或”module：options“的格式推荐使用后者以实现向后兼容。如果action一行的内容过多，也中使用在行首使用几个空白字符进行换行。123tasks: - name:make sure apache is running service: name=httpd state=started 在众多的模块中，只有command和shell模块仅需要给定一个列表而无需使用”key=value”格式，例如：123tasks: - name: disable selinux command: /sbin/setenforce 0 如果命令或脚本的退出码不为零，可以使用如下方式替代：123tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true 或者使用ignore_errors来忽略错误信息：1234tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand ignore_errors: True 3、handlers用于当关注的资源发生变化时采取一定的操作。“notify”这个action可用于在每个play的最后被触发，这样可以避免多次有改变发生时每次都执行执行的操作，取而代之，仅在所有的变化发生完成后一次性地执行指定操作，在notify中列出的操作称为handlers，也即notify中调用handlers中定义的操作。12345- name: template configuration file template: src=template.j2 dest=/etc/foo.conf notify: - restart memcached - restart apache handlers是task列表，这些task与前述的task并没有本质上的不同。12345handlers： - name: restart memcached service: name=memcached state=restarted - name: restart apache service: name=apache state=restarted 简单示例1：12345678910111213141516# cat nginx.yml - hosts: webserver remote_user: root tasks: - name: create nginxn group group: name=nginx system=yes gid=208 - name: create nginx user user: name=nginx uid=208 group=nginx system=yes- hosts: dbserver remote_user: root tasks: - name: copy file to dbserver copy: src=/etc/inittab dest=/tmp/inittab.ans # ansible-playbook nginx.yml 简单示例2：123456789101112# cat apache.yml - hosts: webserver remote_user: root tasks: - name: install httpd package yum: name=httpd state=latest - name: install configuration file for httpd copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf - name: start httpd service service: enabled=true name=httpd state=started# ansible-playbook apache.yml handlers 示例：123456789101112131415161718# cat apache.yml - hosts: webserver remote_user: root tasks: - name: install httpd package yum: name=httpd state=latest - name: install configuration file for httpd copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf notify: - restart httpd - name: start httpd service service: enabled=true name=httpd state=started handlers: - name: restart httpd service: name=httpd state=restarted# ansible-playbook apache.yml variable 示例1：12345678910111213141516171819# cat apache.yml - hosts: webserver remote_user: root vars: - package: httpd - service: httpd tasks: - name: install httpd package yum: name=&#123;&#123; package &#125;&#125; state=latest - name: install configuration file for httpd copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf notify: - restart httpd - name: start httpd service service: enabled=true name=&#123;&#123; service &#125;&#125; state=started handlers: - name: restart httpd service: name=httpd state=restarted variable 示例2：(在playbook中可以使用所有的变量)123456# cat facts.yml - hosts: webserver remote_user: root tasks: - name: copy file copy: content="&#123;&#123; ansible_all_ipv4_addresses &#125;&#125; " dest=/tmp/vars.ans 八、rolesansible自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles能够根据层次型结构自动转载变量文件、tasks以及handlers等。要使用roles只需要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、文件、任务、模板以及处理器放置于单独的目录中，并可以便捷地include他们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以使用于构建守护进程的场景中一个roles的案例如下所示：123456789101112131415161718site.ymlwebserver.ymlfooserver.ymlroles/ common/ files/ templates/ tasks/ handlers/ vars/ meta/ webserver/ files/ templates/ tasks/ handlers/ vars/ meta/ 而在playbook中，可以这样使用roles1234- hosts: webserver roles: - common - webserver 也可以向roles传递参数，例如：12345- hosts: webserver roles: - common - &#123; role: foo_app_instance, dir:'/opt/a',port:5000&#125; - &#123; role: foo_app_instance, dir:'/opt/b',port:5001&#125; 甚至也可以条件式地使用roles，例如：123- hosts：webserver roles: - &#123; role: some_role, when: "ansible_so_family == 'RedHat" &#125; 1、创建role的步骤1、创建以roles命名的目录 2、在roles目录中分别创建以各角色命名的目录，如webserver等 3、在每个角色命名的目录中分别创建files、handlers、meta、tasks、templates和vars目录；用不到的目录可以创建为空目录，也可以不创建 4、在playbook文件中，调用各角色 2、role内各目录中可应用的文件 task目录：至少应该包含一个为main.yml的文件，其定义了此角色的任务列表；此文件可以使用include包含其它的位于此目录中的task文件； file目录：存放由copy或script等模板块调用的文件； template目录：template模块会自动在此目录中寻找jinja2模板文件； handlers目录：此目录中应当包含一个main.yml文件，用于定义此角色用到的各handlers，在handler中使用inclnude包含的其它的handlers文件也应该位于此目录中； vars目录：应当包含一个main.yml文件，用于定义此角色用到的变量 meta目录：应当包含一个main.yml文件，用于定义此角色的特殊设定及其依赖关系；ansible1.3及其以后的版本才支持； default目录：应当包含一个main.yml文件,用于为当前角色设定默认变量时使用此目录； 1234567891011121314151617181920212223242526272829303132# mkdir -pv ansible_playbooks/roles/&#123;webserver,dbserver&#125;/&#123;tasks,files,templates,meta,handlers,vars&#125; # cp /etc/httpd/conf/httpd.conf files/ # pwd/root/ansible_playbooks/roles/webserver # cat tasks/main.yml - name: install httpd package yum: name=httpd state=present- name: install configuretion file copy: src=httpd.conf dest=/etc/httpd/conf/httpd.conf tags: - conf notify: - restart httpd- name: start httpd service: name=httpd state=started# cat handlers/main.yml - name: restart httpd service: name=httpd state=restarted # pwd;ls/root/ansible_playbooksroles site.yml # cat site.yml - hosts: webserver remote_user: root roles: - webserver# ansible-playbook site.yml 九、Tagstags用于让用户选择运行或跳过playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常的长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片段。tags：在playbook可以为某个或某些任务定义一个”标签”，在执行此playbook时，通过为ansible-playbook命令使用–tags选项能耐实现仅运行指定的tasks而非所有的；1234567891011121314151617181920212223# cat apache.yml - hosts: webserver remote_user: root vars: - package: httpd - service: httpd tasks: - name: install httpd package yum: name=&#123;&#123; package &#125;&#125; state=latest - name: install configuration file for httpd template: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf tags: - conf notify: - restart httpd - name: start httpd service service: enabled=true name=&#123;&#123; service &#125;&#125; state=started handlers: - name: restart httpd service: name=httpd state=restarted# ansible-playbook apache.yml --tags='conf' 特殊tags：always #无论如何都会运行]]></content>
      <categories>
        <category>Automation</category>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
        <tag>playbook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在CentOS7中配置使用阿里云的yum源]]></title>
    <url>%2Fposts%2F5bd5694.html</url>
    <content type="text"><![CDATA[当前系统版本为centos7 1、备份原来的yum源1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 2、下载阿里云的CentOS-Base.repo 到/etc/yum.repos.d/1wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 或者1curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 3、添加阿里云公共DNS为了防止不能寻找yun源地址，生成cache，先添加阿里云的DNS1vim /etc/resolv.conf 添加12nameserver 223.5.5.5nameserver 223.6.6.6 4、清理缓存1yum clean all 5、生成新的缓存1yum makecache]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>yum源</tag>
        <tag>阿里云</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用python功能实现]]></title>
    <url>%2Fposts%2F5385b95c.html</url>
    <content type="text"><![CDATA[1、冒泡排序1234567891011nums = [56,12,45,67,23,5,78,64,345,123,-58,2,1231,-234]print(nums)def bubbleSort(nums): for i in range(len(nums)-1): # 这个循环负责设置冒泡排序进行的次数 for j in range(len(nums)-i-1): # ｊ为列表下标 if nums[j] &gt; nums[j+1]: nums[j], nums[j+1] = nums[j+1], nums[j] return numsprint (bubbleSort(nums)) 2、计算x的n次方1234567def power(x,n): s = 1 while n &gt; 0: n = n - 1 s = s * x return sprint(power(2,4)) 3、计算 aa + bb + ······1234567def calc(*numbers): sum = 0 for n in numbers: sum = sum + n*n return sumprint(calc(1,2,5,6,6,8,9)) 4、计算阶乘n!123456def factorial(n): if n == 0 or n == 1: return 1 else: return (n*factorial(n-1))print(factorial(5)) 5、列出当前目录下的所有文件和目录名12345678import osdef file_name(file_dir): for root, dirs, files in os.walk(file_dir): print('root_dir:', root) # 当前目录路径 print('sub_dirs:', dirs) # 当前路径下所有子目录 print('files:', files) # 当前路径下所有非目录子文件print (file_name('C:\Windows\AppPatch')) 6、把一个list中所有的字符串变成小写12L = ['Hello','World','IBM','Apple','Python','Which','GOOGLE']print([s.lower() for s in L]) 7、把原字典的键值对颠倒并产生新的字典123dict1 = &#123;"A":"a","B":"b","C":"c","D":"d","E":"e"&#125;dict2 = &#123;y:x for x,y in dict1.items()&#125;print(dict2) 8、打印九九乘法表1234for i in range(1,10): for j in range(1,i+1): print("%d*%d=%2d" % (i,j,i*j),end=" ") print() 9、列表合并去重123456list1 = [2,5,7,89,3,6,7,90]list2 = [5,7,78,32,45,6,90]list3 = list1 + list2print(list3)print(set(list3))print(list(set(list3)))]]></content>
      <categories>
        <category>Scripts</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系统巡检脚本]]></title>
    <url>%2Fposts%2Fd00f65b4.html</url>
    <content type="text"><![CDATA[需求领导要求春节期间对某台业务服务器进行重点巡检，但是回老家很不方便，所以制定一个脚本。脚本思路大概如下： 1、获取服务器的性能信息，业务信息，数据库备份信息等 2、制定word模板 3、将服务器信息插入到word模板中生成新的word文档 4、将word文档通过邮件方式发送给领导 具体实现word模板主要信息定制如下 脚本内容如下使用脚本之前需要解决缺少openssl-devel支持的问题，命令如下：1yum install gcc libffi-devel python-devel openssl-devel -y 在脚本内需要使用psutil包和docxtpl包，使用pip安装：12pip install psutilpip install docxtpl 脚本内容：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263#!/usr/bin/python# coding:utf-8#Author:Francisimport osimport subprocessimport psutilimport timeimport commandsimport datetimeimport smtplibfrom email.header import Headerfrom email.mime.text import MIMETextfrom email.mime.multipart import MIMEMultipartfrom email.mime.application import MIMEApplicationfrom psutil import *from docxtpl import DocxTemplatedef date_1(): return time.strftime('%Y/%m/%d',time.localtime(time.time())) def date_2(): return time.strftime('%Y%m%d',time.localtime(time.time()))def hostname(): print socket.gethostname()def cpu_usage_rate(): #cmd = """ top -bn1 | grep '%Cpu(s)'|awk '&#123;for(i=1;i&lt;9;i=i+1)&#123;printf $i" "&#125;;printf "\n"&#125;' """ cmd = """ top -bn1 | grep '%Cpu(s)'|awk '&#123;for(i=1;i&lt;9;i=i+1)&#123;printf $i" "&#125;&#125;' """ cpu_usage = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT) #print (cpu_usage.stdout.read()) #print ('获取内存占用率： '+(str)(psutil.virtual_memory().percent)+'%') #print ('打印本机cpu占用率： '+(str)(psutil.cpu_percent(0))+'%') return cpu_usage.stdout.read()def os_load_average(): cmd = """ uptime | sed 's/,//g' | awk '&#123;print $8,$9,$10&#125;' """ load_average = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT) #rint (load_average.stdout.read()) return load_average.stdout.read()def memory_usage_rate(): vime = virtual_memory() #print 'Memory: %5s%% %6s/%s' % ( #vime.percent, str(int(vime.used / 1024 / 1024)) + 'M', str(int(vime.total / 1024 / 1024)) + 'M') return 'Memory: %5s%% %6s/%s' % ( vime.percent, str(int(vime.used / 1024 / 1024)) + 'M', str(int(vime.total / 1024 / 1024)) + 'M')def disk_info(): cmd = """ df -h|grep '/dev/vd' """ disk_info = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT) #print (disk_info.stdout.read()) return disk_info.stdout.read()def process_info(): cmd = """ ps -ef|grep java|grep -Ev 'grep' """ process_info = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT) #print (process_info.stdout.read()) return process_info.stdout.read()def is_error(SubStrList,Str):#判断字符串Str是否包含序列SubStrList中的每一个子字符串 flag=[] for substr in SubStrList: for i in Str: if substr in i: flag.append(i) return flagdef new_error_file(): #要求文件名称中包含这些字符 keyword=['error'] file_dir = "/data/work/log/" listtmp=os.listdir(file_dir) #rint listtmp #rint '—'*100 list=is_error(keyword,listtmp) #rint list list.sort(key=lambda fn: os.path.getmtime(file_dir+fn) if not os.path.isdir(file_dir+fn) else 0) file=os.path.join(file_dir,list[-1]) d=datetime.datetime.fromtimestamp(os.path.getmtime(file_dir+list[-1])) #rint '—'*100 #rint('最后改动的文件是'+list[-1]+"，时间："+d.strftime("%Y-%m-%d %H-%M-%S")) #rint file return filedef mysql_status(): cmd = """ ps -ef|grep mysql|grep -Ev 'grep' """ mysql_status = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT) #print (mysql_status.stdout.read()) return mysql_status.stdout.read()def mysql_backup_file(): testdir = "/data/mysql/backup/" #列出目录下所有的文件 list = os.listdir(testdir) #对文件修改时间进行升序排列 list.sort(key=lambda fn: os.path.getmtime(testdir+fn) if not os.path.isdir(testdir+fn) else 0) #获取最新修改时间的文件 filetime = datetime.datetime.fromtimestamp(os.path.getmtime(testdir+list[-1])) #获取文件所在目录 filepath = os.path.join(testdir,list[-1]) #rint("最新修改的文件(夹)："+list[-1]) #rint("时间："+filetime.strftime('%Y-%m-%d %H-%M-%S')) #print filepath return filepath def mysql_backup(): testdir = "/data/mysql/backup/" #列出目录下所有的文件 list = os.listdir(testdir) #对文件修改时间进行升序排列 list.sort(key=lambda fn:os.path.getmtime(testdir + fn)) #获取最新修改时间的文件 filetime = datetime.datetime.fromtimestamp(os.path.getmtime(testdir+list[-1])) #获取文件所在目录 filepath = os.path.join(testdir,list[-1]) #rint("最新修改的文件(夹)："+list[-1]) #rint("时间："+filetime.strftime('%Y-%m-%d %H-%M-%S')) #print filepath return filepathdef get_disk_info(): print '磁盘信息：' for i in disk_io_counters(perdisk=True).items(): print i def get_net_info(): print '网络情况：' for i in net_io_counters(pernic=True).items(): print idef create_email(email_from, email_to, email_Subject, email_text, annex_path, annex_name): # 输入发件人昵称、收件人昵称、主题，正文，附件地址,附件名称生成一封邮件 #生成一个空的带附件的邮件实例 message = MIMEMultipart() #将正文以text的形式插入邮件中 message.attach(MIMEText(email_text, 'plain', 'utf-8')) #生成发件人名称（这个跟发送的邮件没有关系） message['From'] = Header(email_from, 'utf-8') #生成收件人名称（这个跟接收的邮件也没有关系） message['To'] = Header(email_to, 'utf-8') #生成邮件主题 message['Subject'] = Header(email_Subject, 'utf-8') #读取附件的内容 att1 = MIMEText(open(annex_path, 'rb').read(), 'base64', 'utf-8') att1["Content-Type"] = 'application/octet-stream' #生成附件的名称 att1.add_header('Content-Disposition', u'attachment', filename = ("utf-8", "",annex_name)) #att1["Content-Disposition"] = add_header('attachment; filename=' + annex_name) #att1["Content-Disposition"] = 'attachment; filename=' + annex_name #将附件内容插入邮件中 message.attach(att1) #返回邮件 return messagedef send_email(sender, password, receiver, msg): # 一个输入邮箱、密码、收件人、邮件内容发送邮件的函数 try: #找到你的发送邮箱的服务器地址，已加密的形式发送 server = smtplib.SMTP_SSL("smtp.exmail.qq.com", 465) # 发件人邮箱中的SMTP服务器 server.ehlo() #登录你的账号 server.login(sender, password) # 括号中对应的是发件人邮箱账号、邮箱密码 #发送邮件 server.sendmail(sender, receiver, msg.as_string()) # 括号中对应的是发件人邮箱账号、收件人邮箱账号（是一个列表）、邮件内容 print("邮件发送成功") server.quit() # 关闭连接 except Exception: print(traceback.print_exc()) print("邮件发送失败")session000 = date_2()session001 = cpu_usage_rate()session002 = os_load_average()session003 = memory_usage_rate()session004 = disk_info()session005 = process_info()session006 = new_error_file()session007 = mysql_status()session008 = mysql_backup_file()session009 = date_1()def main(): docx_into = "/data/scripts/gbj_ls_checkos_template.docx" docx_out = open("gbj_ls_checkos_" + session000 + ".docx",'w') tpl=DocxTemplate(docx_into) sd = tpl.new_subdoc() context = &#123; 'output001' : "%s" % session001, 'output002' : "%s" % session002, 'output003' : "%s" % session003, 'output004' : "%s" % session004, 'output005' : "%s" % session005, 'output006' : "%s" % session006, 'output007' : "%s" % session007, 'output008' : "%s" % session008, 'output009' : "%s" % session009, &#125; tpl.render(context) tpl.save(docx_out) my_email_from = '我发' my_email_to = '你收' # 邮件标题 my_email_Subject = '巡检报告' # 邮件正文 my_email_text = "Dear all,\n\t附件为你猜猜是什么，请查收！\n\n我发的" #附件地址 my_annex_path = "gbj_ls_checkos_" + session000 + ".docx" #附件名称 my_annex_name = "gbj_ls_checkos__" + session000 + ".docx" # 生成邮件 my_msg = create_email(my_email_from, my_email_to, my_email_Subject, my_email_text, my_annex_path, my_annex_name) my_sender = 'yunwei@actionsky.com' my_password = 'Action!23' #接收人邮箱列表 my_receiver = ['fujinpeng@actionsky.com','dutingting@actionsky.com','meilei@actionsky.com'] #发送邮件 send_email(my_sender, my_password, my_receiver, my_msg) print(datetime.datetime.now()) ''' print '—'*100 hostname() print '\n' cpu_usage_rate() print '\n' os_load_average() print '\n' memory_usage_rate() print '\n' disk_info() print '\n' process_info() print '\n' new_error_file() print '\n' mysql_status() print '\n' mysql_backup_file() print '\n' mysql_backup() print '\n' get_net_info() print '\n' get_disk_info() print '\n' print date_1() print '\n' print date_2()'''if __name__ == '__main__': main()]]></content>
      <categories>
        <category>Scripts</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Word</tag>
        <tag>邮件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB定时备份]]></title>
    <url>%2Fposts%2Ff146e600.html</url>
    <content type="text"><![CDATA[MongoDB数据备份在MongoDB中我们使用mongodump命令来备份MongoDB数据语法： mongodump -h dbhost --port dbport -u user -p password -d dbname --authenticationDatabase admin -o dbdirectory -h MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017，-h 127.0.0.1:27017等同于-h 127.0.0.1 –port 27017-d 需要备份的数据库实例，例如：test，没有指定即使备份全部数据库-o 备份的数据存放位置，例如：c:datadump，当然该目录需要提前建立，在备份完成后，系统自动在dump目录下建立一个test目录，这个目录里面存放该数据库实例的备份数据。-u -p 如果有设置用户和密码，需要设置对应的用户名和密码，否则没有权限–authenticationDatabase admin 验证权限 MongoDB数据恢复mongodb 使用 mongorestore 命令来恢复备份的数据 mongorestore -h &lt;hostname&gt;&lt;:port&gt; -d dbname &lt;path&gt; –host &lt;:port&gt;, -h &lt;:port&gt;：MongoDB所在服务器地址，默认为： localhost:27017–db , -d ：需要恢复的数据库实例，例如：test，当然这个名称也可以和备份时候的不一样，比如test2–drop：恢复的时候，先删除当前数据，然后恢复备份的数据。就是说，恢复后，备份后添加修改的数据都会被删除，慎用哦！ ：最后的一个参数，设置备份数据所在位置，例如：c:datadumptest。你不能同时指定 和 –dir 选项，–dir也可以设置备份目录。–dir：指定备份的目录不能同时指定 和 –dir 选项。 MongoDB定时备份Shell脚本编写脚步mongodb_bak.sh，脚本内容为12345678910111213141516171819202122232425262728293031323334#!/bin/shDUMP=/data/mongodb/bin/mongodump #mongodump备份文件执行路径OUT_DIR=/data/backup/mongodb_bak/baknow#临时备份目录TAR_DIR=/data/backup/mongodb_bak/baklist#备份存放路径DATE=`date +%Y%m%d` #获取当前系统时间DB_HOST=127.0.0.1#数据库地址DB_PORT=27017#数据库端口DB_USER=***#数据库账号DB_PASS=******#数据库密码DAYS=30#DAYS=30代表删除7天前的备份，即只保留最近7天的备份TAR_BAK="mongodb_bak_$DATE.tar.gz" #最终保存的数据库备份文件名cd $OUT_DIRrm -rf $OUT_DIR/*mkdir -p $OUT_DIR/$DATE$DUMP -h $DB_HOST --port $DB_PORT -u $DB_USER -p $DB_PASS --authenticationDatabase admin -o $OUT_DIR/$DATE#备份全部数据库tar -zcvP -f $TAR_DIR/$TAR_BAK $OUT_DIR/$DATE/*#压缩为.tar.gz格式find $TAR_DIR/ -mtime +$DAYS -delete #删除30天前的备份文件 脚本中的目录、host、port、user、password等需要根据实际情况自行修改，脚本放在/data/scripts目录下 创建对应的备份目录12mkdir -p /data/backup/mongodb_bak/baknowmkdir -p /data/backup/mongodb_bak/baklist 修改文件属性，使其可执行1chmod +x /data/scripts/mongodb_bak.sh 添加计划任务执行crontab -e添加130 1 * * * root /data/scripts/mongodb_bak.sh 其中计划任务是每天1点半执行备份任务crontab命令1234/sbin/service crond start /sbin/service crond stop /sbin/service crond restart /sbin/service crond reload 以上分别为重启服务、停止服务、启动服务、重新加载配置的命令修改过计划任务，需要执行restart或者reload]]></content>
      <categories>
        <category>DB</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>Shell</tag>
        <tag>定时任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix自动监控Windows端口]]></title>
    <url>%2Fposts%2Fa0ec7c04.html</url>
    <content type="text"><![CDATA[Windows服务端有需要监控的端口，主要监控处于LISTEN状态、协议为TCP的端口。 脚本首先编写脚本，脚本名为discovertcpport.bat，脚本内容如下1234567@echo offecho &#123;echo "data":[for /F "tokens=2 delims= " %%i IN ('netstat -anp tcp^|find /i "LISTENING"') DO for /F "tokens=2 delims=:" %%j IN ("%%i") DO echo &#123;"&#123;#LISTEN_PORT&#125;":"%%j"&#125;,echo &#123;"&#123;#LISTEN_PORT&#125;":"10050"&#125;echo ]echo &#125; 脚本说明：命令netstat -anp tcp ^|find /i &quot;LISTENING&quot;用来查看监听状态的TCP端口；for /F “tokens=2 delims= “表示循环输出的截取值，即每行以空格（delims=）分隔的第2段（token=2）值，以变量%%i输出；之后以同样的循环截取出端口号并格式化输出结果；这里的输出格式必须按JSON对象格式输出，否则报错“Value should be a JSON object”；特别要注意最后一行没有逗号，因此单独添加一行1echo &#123;"&#123;#LISTEN_PORT&#125;":"10050"&#125; 来结束，以满足JSON对象格式。 配置文件客户端的zabbix_agentd.conf中添加以下内容：12UnsafeUserParameters=1UserParameter=tcpportlisten,C:\zabbix_agents_3.0.10.win\discovertcpport.bat 说明：一条表示允许使用用户自定义参数，第二条设置用户参数，名称tcpportlisten是自定义的KEY名，后接KEY要执行的命令或脚本文件。 重新启动zabbix agentd服务12C:\zabbix_agents_3.0.10.win\bin\win64\zabbix_agentd.exe -c C:\zabbix_agents_3.0.10.win\conf\zabbix_agentd.win.conf -xC:\zabbix_agents_3.0.10.win\bin\win64\zabbix_agentd.exe -c C:\zabbix_agents_3.0.10.win\conf\zabbix_agentd.win.conf -s server端从server端尝试获取数据12345678910111213141516171819202122232425# /data/zabbix/bin/zabbix_get -s 172.16.92.251 -k Port_Low_Discovery&#123; "data":[ &#123;"&#123;#LISTEN_PORT&#125;":"22"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"80"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"135"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"443"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"445"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"593"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"3388"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"3389"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"5504"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"8122"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"10050"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"28000"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"28001"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"47001"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"49152"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"49153"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"49154"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"49155"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"139"&#125;, &#123;"&#123;#LISTEN_PORT&#125;":"10050"&#125; ]&#125; 可以看到获取了很多端口，这些端口有些是我们要监控的服务的端口，有些是系统主服务的端口，所以我们要过滤我们需要监控的端口。在zabbixserver的web界面去配置正则表达式。正则表达式如下图所示可以换个理解方式，只有在正则表达式中填写的端口号，zabbix才能去discovery。接下来配置模板和自发现准则，如下图所示下图为配置使用正则表达式来过滤获取到的端口Item prototypes配置如下Trigger prototypes配置如下 {Template OS Windows Port:net.tcp.listen[{#LISTEN_PORT}].count(#3,0,&quot;eq&quot;)}=3 表示三次获取信息为0即触发报警，Item prototypes配置时间为30秒，即90秒没有回应触发报警。这样配置是为了防止zabbixserver端和agent端通讯质量不好。]]></content>
      <categories>
        <category>Monitor</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Windows</tag>
        <tag>Zabbix</tag>
        <tag>Port</tag>
        <tag>Discovery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop2.9.2源码编译]]></title>
    <url>%2Fposts%2Fae01ba23.html</url>
    <content type="text"><![CDATA[官方对每个版本的hadoop提供了源码版本和二进制版本，但是官方提供的二进制版本是32位的，所以在安装hadoop时，为了更好的兼容系统位数和系统版本，或者添加Hadoop一些额外功能时，需要对Hadoop源码进行编译，本文以Hadoop2.9.2为例进行源码编译。 编译准备查看系统信息1234# cat /etc/redhat-release CentOS Linux release 7.6.1810 (Core) # uname -aLinux node-01 3.10.0-862.14.4.el7.x86_64 #1 SMP Wed Sep 26 15:12:11 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux 可以看到当前系统版本为centos7.6，64位，内核版本为3.10。 Hadoop下载下载地址：Hadoop2.9.2下载123tar -zxvf hadoop-2.9.2-src.tar.gzcd hadoop-2.9.2-srcless BUILDING.txt 可以看到所需编译环境 Requirements: * Unix System * JDK 1.7 or 1.8 * Maven 3.0 or later * Findbugs 1.3.9 (if running findbugs) * ProtocolBuffer 2.5.0 * CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac * Zlib devel (if compiling native code) * openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance) * Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs) * Internet connection for first build (to fetch all Maven and Hadoop dependencies) * python (for releasedocs) * Node.js / bower / Ember-cli (for YARN UI v2 building) 这是编译所需要的软件，包括： JDK1.7 or 1.8 maven 3.0 or later findbugs 1.3.9 protocolBuffer 2.5.0 cmake 2.6 zlib-devel openssl-devel 解决编译依赖需安装autoconf automake gcc等。 软件安装安装库文件yum -y install patch svn ncurses-devel gcc* yum -y install lzo-devel zlib-devel autoconf automake libtool cmake openssl-devel 安装JDK参考：CentOS上安装Java环境 安装Maven参考：CentOS上安装Maven 安装protocolBuffer概述：Google Protocol Buffer( 简称 Protobuf) 是 Google 公司内部的混合语言数据标准,Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 RPC 数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。目前提供了 C++、Java、Python 三种语言的 API。下载地址：protocol-buffers-2.5.0.tar.gz解压并编译安装1234567cd /data/backupwget https://github.com/protocolbuffers/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gztar -zxvf protobuf-2.5.0.tar.gzcd protobuf-2.5.0/./configuremakemake install 验证：输入protoc –version,有下面输出结果则安装并配置正确。12# protoc --versionlibprotoc 2.5.0 安装findbugs概述：FindBugs 是由马里兰大学提供的一款开源 Java静态代码分析工具。FindBugs通过检查类文件或 JAR文件，将字节码与一组缺陷模式进行对比从而发现代码缺陷，完成静态代码分析。下载地址：findbugs-1.3.9 下载解压123cd /data/backupwget https://jaist.dl.sourceforge.net/project/findbugs/findbugs/1.3.9/findbugs-1.3.9.tar.gztar -zxvf findbugs-1.3.9.tar.gz -C /data/findbugs1.3.9 配置环境变量1vim /etc/profile 末尾添加以下内容123#set findbugs environmentexport FINDBUGS_HOME=/data/findbugs1.3.9export PATH=$PATH:$FINDBUGS_HOME/bin 使环境变量生效1source /etc/profile (立即生效) 验证12# findbugs -version1.3.9 编译首先保证主机能上网，在编译过程中网络保持畅通；为了保证maven编译更顺畅，也可以更本地maven仓库地址更改为国内地址。进入到hadoop2.9.1源码的解压目录下，输入下面命令： # mvn package -Pdist,native -DskipTests -Dtar 或者 # mvn package -Pdist,native,docs,src -DskipTests -Dtar 前面只编译本地代码，后者编译本地代码和文档，因此前者速度较快。接下来开始等待出现如下界面表示编译成功编译好的文件在../hadoop-dist/target/hadoop-2.7.1.tar.gz下。 编译中的问题错误11Connection to http://repo.maven.apache.org refused 表示连接maven远程仓库拒绝，此时再运行一下编译命令，就会接着下载jar包。错误212[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hadoop-nfs: Compilation failure: Compilation failure:[ERROR] /data/backup/hadoop-2.9.2-src/hadoop-common-project/hadoop-nfs/src/main/java/org/apache/hadoop/oncrpc/XDR.java:[23,30] package org.jboss.netty.buffer does not exist 这个错误估计很少遇到，这是因为更换的仓库地址不能用，恢复成默认的仓库地址就好，虽然有点慢。错误312[ERROR] around Ant part ...&lt;exec dir="/data/backup/hadoop-2.9.2-src/hadoop-hdfs-project/hadoop-hdfs-httpfs/target" executable="sh" failonerror="true"&gt;... @ 10:123 in /data/backup/hadoop-2.9.2-src/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/antrun/build-main.xml[ERROR] -&gt; [Help 1] 这是由于tomcat的apache-tomcat-6.0.41.tar.gz包太大，没有下载完整，可以到…/hadoop-2.9.2-src/hadoop-hdfs-project/hadoop-hdfs-httpfs/downloads/apache-tomcat-6.0.41.tar.gz这个目录下，删除重新下载。提醒： 有时候编译过程中会出现下载某个包的时间太久，这是由于连接网站的过程中会出现假死，此时按ctrl+c，重新运行编译命令。 如果出现缺少了某个文件的情况，则要先清理maven(使用命令 mvn clean) 再重新编译。]]></content>
      <categories>
        <category>BigData</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Maven</tag>
        <tag>Hadoop</tag>
        <tag>编译</tag>
        <tag>Protobuf</tag>
        <tag>FindBugs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据离线-Hadoop入门]]></title>
    <url>%2Fposts%2F497086ea.html</url>
    <content type="text"><![CDATA[Hadoop介绍一般我们讲的Hadoop分为狭义和广义两部分 狭义上讲Hadoop 指 Apache 这款开源框架Hadoop 是 Apache 旗下的一个用 java 语言实现开源软件框架， 是一个开发和运行处理大规模数据的软件平台。 允许使用简单的编程模型在大量计算机集群上对大型数据集进行分布式处理。它的核心组件有： HDFS（分布式文件系统）：解决海量数据存储 YARN（作业调度和集群资源管理的框架）：解决资源任务调度 MAPREDUCE（分布式运算编程框架）： 解决海量数据计算 广义上讲Hadoop 通常是指一个更广泛的概念——Hadoop 生态圈。当下的 Hadoop 已经成长为一个庞大的体系，随着生态系统的成长，新出现的项目越来越多，其中不乏一些非 Apache 主管的项目，这些项目对 HADOOP 是很好的补充或者更高层的抽象。 比如： HDFS：分布式文件系统 MAPREDUCE：分布式运算程序开发框架 HIVE：基于 HADOOP 的分布式数据仓库，提供基于 SQL 的查询数据操作 HBASE：基于 HADOOP 的分布式海量数据库 ZOOKEEPER：分布式协调服务基础组件 Mahout：基于 mapreduce/spark/flink 等分布式运算框架的机器学习算法库 Oozie：工作流调度框架 Sqoop：数据导入导出工具（比如用于 mysql 和 HDFS 之间） Flume：日志数据采集框架 Impala： 基于 Hadoop 的实时分析 Hadoop发展历史 Hadoop 是 Apache Lucene 创始人 Doug Cutting 创建的。最早起源于 Nutch，它是 Lucene 的子项目。 Nutch 的设计目标是构建一个大型的全网搜索引擎，包括网页抓取、索引、查询等功能，但随着抓取网页数量的增加，遇到了严重的可扩展性问题： 如何解决数十亿网页的存储和索引问题。 2003 年 Google 发表了一篇论文为该问题提供了可行的解决方案。 论文中描述的是谷歌的产品架构，该架构称为： 谷歌分布式文件系统（GFS） ,可以解决他们在网页爬取和索引过程中产生的超大文件的存储需求。 2004 年 Google 发表论文向全世界介绍了谷歌版的 MapReduce 系统。同时期， Nutch 的开发人员完成了相应的开源实现 HDFS 和 MAPREDUCE，并从Nutch 中剥离成为独立项目 HADOOP，到 2008 年 1 月， HADOOP 成为 Apache 顶级项目，迎来了它的快速发展期。 2006 年 Google 发表了论文是关于 BigTable 的，这促使了后来的 Hbase 的发展。 因此， Hadoop 及其生态圈的发展离不开 Google 的贡献。 Hadoop的特点1、扩容能力Hadoop 是在可用的计算机集群间分配数据并完成计算任务的，这些集群可用方便的扩展到数以千计的节点中。2、成本低Hadoop 通过普通廉价的机器组成服务器集群来分发以及处理数据，以至于成本很低。3、高效率通过并发数据， Hadoop 可以在节点之间动态并行的移动数据，使得速度非常快。4、可靠性能自动维护数据的多份复制，并且在任务失败后能自动地重新部署（redeploy）计算任务。所以 Hadoop 的按位存储和处理数据的能力值得人们信赖。 Hadoop 国内外应用不管是国内还是国外， Hadoop 最受青睐的行业是互联网领域， 可以说互联网公司是 hadoop 的主要使用力量。国外应用 Yahoo 的 Hadoop 应用在支持广告系统、 用户行为分析、 支持 Web 搜索等。 Facebook 主要使用 Hadoop 存储内部日志与多维数据，并以此作为报告、分析和机器学习的数据源。 国内应用国内来说，BAT领头的互联网公司是当仁不让的 Hadoop 使用者、维护者。比如 Ali 云梯（14 年国内最大 Hadoop 集群）、百度的日志分析平台、推荐引擎系统等。国内其他非互联网领域也有不少 hadoop 的应用，比如： 金融行业： 个人征信分析 证券行业： 投资模型分析 交通行业： 车辆、路况监控分析 电信行业： 用户上网行为分析 总之： hadoop 并不会跟某种具体的行业或者某个具体的业务挂钩，它只是一种用来做海量数据分析处理的工具。 Hadoop集群搭建发行版本Hadoop 发行版本分为开源社区版和商业版。 社区版是指由 Apache 软件基金会维护的版本，是官方维护的版本体系。 商业版 Hadoop 是指由第三方商业公司在社区版 Hadoop 基础上进行了一些修改、整合以及各个服务组件兼容性测试而发行的版本， 比较著名的有 cloudera 的 CDH、 mapR 等。 我们介绍的是社区版： Apache Hadoop。 后续如未说明都是指 Apache 版。Hadoop 的版本很特殊，是由多条分支并行的发展着。 大的来看分为 3 个大的系列版本： 1.x、 2.x、 3.x。 Hadoop1.0 由一个分布式文件系统 HDFS 和一个离线计算框架 MapReduce 组成。 Hadoop 2.0 则包含一个支持 NameNode 横向扩展的 HDFS，一个资源管理系统YARN 和一个运行在 YARN 上的离线计算框架 MapReduce。相比于 Hadoop1.0，Hadoop 2.0 功能更加强大，且具有更好的扩展性、性能，并支持多种计算框架。 Hadoop 3.0 相比之前的 Hadoop 2.0 有一系列的功能增强。但目前还是个alpha 版本，有很多 bug，且不能保证 API 的稳定和质量。 当前 2 系列最稳定版本： Apache Hadoop 2.9.2。 集群介绍HADOOP 集群具体来说包含两个集群：HDFS集群和YARN集群，两者逻辑上分 离，但物理上常在一起。 HDFS 集群负责海量数据的存储，集群中的角色主要有：NameNode、 DataNode、 SecondaryNameNode YARN 集群负责海量数据运算时的资源调度，集群中的角色主要有：ResourceManager、 NodeManager mapreduce 是一个分布式运算编程框架，是应用程序开发包，由用户按照编程规范进行程序开发，后打包运行在 HDFS 集群上，并且受到 YARN 集群的资源调度管理。 Hadoop 部署方式分三种: 独立模式又称为单机模式， 仅 1 个机器运行 1 个 java 进程，主要用于调试。(单机) 伪分布模式也是在 1 个机器上运行 HDFS 的 NameNode 和 DataNode、 YARN 的ResourceManger 和 NodeManager， 但分别启动单独的 java 进程，主要用于调试。（单机） 集群模式主要用于生产环境部署。 会使用 N 台主机组成一个 Hadoop 集群。这种部署模式下， 主节点和从节点会分开部署在不同的机器上。 我们以 3 节点为例进行搭建，角色分配如下：角色分配如下： node-01 NameNode DataNode ResourceManager node-02 DataNode NodeManager SecondaryNameNode node-03 DataNode NodeManager 集群安装服务器准备node-01 10.186.60.12 node-02 10.186.60.60 node-03 10.186.65.43 服务器系统设置同步时间 #手动同步集群各机器时间 12date -s "2017-03-03 03:03:03"yum install ntpdate #网络同步时间 1ntpdate ntp6.aliyun.com 设置主机名 Linux主机名设置1vim /etc/hosts 输入内容 10.186.60.12 node-01 10.186.60.60 node-02 10.186.65.43 node-03 window主机名映射地址：C:\Windows\System32\drivers\etc修改hosts文件，添加内容 192.168.33.101 node-01 192.168.33.102 node-02 192.168.33.103 node-03 配置 ssh 免密登陆生成 ssh 免登陆密钥1ssh-keygen -t rsa （四个回车） 执行完这个命令后，会生成 id_rsa（私钥）、 id_rsa.pub（公钥）将公钥拷贝到要免密登陆的目标机器上12ssh-copy-id node-02ssh-copy-id node-03 配置防火墙查看防火墙状态 service iptables status关闭防火墙 service iptables stop查看防火墙开机启动状态 chkconfig iptables –list关闭防火墙开机启动 chkconfig iptables off JDK环境安装 上传 jdk 安装包 jdk-8u161-linux-x64.tar.gz 解压安装包 tar -zxvf jdk-8u161-linux-x64.tar.gz -C /data/jdk1.8 配置环境变量 vim /etc/profile 插入下面的内容 123export JAVA_HOME=/data/jdk1.8export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 刷新配置:source /etc/profile Hadoop 安装首先我们要有一版是适合我们系统版本的hadoop，所以我们需要编译。为什么要编译以及如何编译参考：Hadoop2.9.2源码编译 上传hadoop,解压hadoop-2.9.2-with-centos7.6.tar.gzhadoop的目录结构1234567891011121314# pwd/data/hadoop/hadoop-2.9.2[root@node-01 hadoop-2.9.2]# lltotal 128drwxr-xr-x 2 root root 194 Dec 27 03:45 bindrwxr-xr-x 3 root root 20 Dec 27 03:45 etcdrwxr-xr-x 2 root root 106 Dec 27 03:45 includedrwxr-xr-x 3 root root 20 Dec 27 03:45 libdrwxr-xr-x 2 root root 239 Dec 27 03:45 libexec-rw-r--r-- 1 root root 106210 Dec 27 03:45 LICENSE.txt-rw-r--r-- 1 root root 15917 Dec 27 03:45 NOTICE.txt-rw-r--r-- 1 root root 1366 Dec 27 03:45 README.txtdrwxr-xr-x 3 root root 4096 Dec 27 03:45 sbindrwxr-xr-x 4 root root 31 Dec 27 03:45 share bin： Hadoop 最基本的管理脚本和使用脚本的目录，这些脚本是 sbin 目录下管理脚本的基础实现，用户可以直接使用这些脚本管理和使用 Hadoop。 etc： Hadoop 配置文件所在的目录，包括 core-site,xml、 hdfs-site.xml、mapred-site.xml 等从 Hadoop1.0 继承而来的配置文件和 yarn-site.xml Hadoop2.0 新增的配置文件。 include：对外提供的编程库头文件（具体动态库和静态库在 lib 目录中），这些头文件均是用 C++定义的，通常用于 C++程序访问 HDFS 或者编写 MapReduce程序。 lib：该目录包含了 Hadoop 对外提供的编程动态库和静态库，与 include 目录中的头文件结合使用。 libexec：各个服务对用的 shell 配置文件所在的目录，可用于配置日志输出、启动参数（比如 JVM 参数）等基本信息。 sbin： Hadoop 管理脚本所在的目录，主要包含 HDFS 和 YARN 中各类服务的启动/关闭脚本。 share： Hadoop 各个模块编译后的 jar 包所在的目录。 Hadoop配置文件修改Hadoop 安装主要就是配置文件的修改， 一般在主节点进行修改，完毕后 scp下发给其他各个从节点机器。下面的文件都在 hadoop的etc/hadoop目录下： 修改hadoop-env.sh文件，更改 1export JAVA_HOME=$&#123;JAVA_HOME&#125; 为1export JAVA_HOME=/data/jdk1.8 此处JAVA_HOME为JDK的位置。 修改core-site.xml文件，在configuration中增加代码 1234567891011121314&lt;configuration&gt;&lt;!-- 用于设置 Hadoop 的文件系统，由 URI 指定 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://node-1:9000&lt;/value&gt; &lt;/property&gt;&lt;!-- 配置 Hadoop 的临时目录,默认/tmp/hadoop-$&#123;user.name&#125; --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/export/data/hadoopData&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改hdfs-site.xml，在configuration中增加代码 123456789101112&lt;configuration&gt;&lt;!-- 指定 HDFS 副本的数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt;&lt;!-- secondary namenode 所在主机的 ip 和端口-&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;node-02:50090&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改mapred-site.xml的，configuration中增加代码 1234567&lt;configuration&gt;&lt;!-- 指定 mr 运行时框架，这里指定在 yarn 上，默认是 local --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改yarn-site.xml的，configuration中增加代码 123456789101112&lt;configuration&gt;&lt;!-- 指定 YARN 的老大（ ResourceManager）的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;node-1&lt;/value&gt; &lt;/property&gt;&lt;!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序默认值： "" --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 创建slaves文件，如果存在进行编辑，删除locahost，增加文件 123node-1node-2node-3 将hadoop添加到环境变量 ，命令vim /etc/proflie 12export HADOOP_HOME=/data/hadoop/hadoop-2.9.2export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 保存配置文件，刷新配置文件：source /etc/profile 集群启动 启动方式 要启动 Hadoop 集群，需要启动 HDFS 和 YARN 两个集群。注意： 首次启动 HDFS 时，必须对其进行格式化操作。 本质上是一些清理和准备工作，因为此时的 HDFS 在物理上还是不存在的。hdfs namenode –format或者hadoop namenode –format 单节点逐个启动 1、在主节点上使用以下命令启动 HDFS NameNode：hadoop-daemon.sh start namenode2、在每个从节点上使用以下命令启动 HDFS DataNode：hadoop-daemon.sh start datanode3、在主节点上使用以下命令启动 YARN ResourceManager：yarn-daemon.sh start resourcemanager4、在每个从节点上使用以下命令启动 YARN nodemanager：yarn-daemon.sh start nodemanager以上脚本位于$HADOOP_PREFIX/sbin/目录下。 如果想要停止某个节点上某个角色，只需要把命令中的 start 改为 stop 即可。 脚本一键启动 如果配置了 etc/hadoop/slaves 和 ssh 免密登录，则可以使用程序脚本启动所有 Hadoop 两个集群的相关进程，在主节点所设定的机器上执行。hdfs： /sbin/start-dfs.shyarn: /sbin/start-yarn.sh停止集群： stop-dfs.sh、 stop-yarn.sh集群 web-ui一旦 Hadoop 集群启动并运行， 可以通过 web-ui 进行集群查看，如下所述：node-1:50070 HDFS的NameNode节点node-1:8088 YARN的主页 Hadoop初体验上传文件 从 Linux 本地上传一个文本文件到 hdfs 的/test/input 目录下 hadoop fs -mkdir -p /wordcount/input 创建文件夹 hadoop fs -put /root/somewords.txt /wordcount/input Linux上传到hadoop 运行程序 运行 mapreduce 程序 在 Hadoop 安装包的 hadoop-2.7.4/share/hadoop/mapreduce 下有官方自带的 mapreduce 程序。 我们可以使用如下的命令进行运行测试。示例程序 jar: hadoop-mapreduce-examples-2.7.4.jar 计算圆周率 计算圆周率: hadoop jar hadoop-mapreduce-examples-2.7.4.jar pi 20 50 这里使用的是Monte Carlo 方法来计算 Pi 值 使用Monte Carlo 计算圆周率]]></content>
      <categories>
        <category>BigData</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker容器进入的4种方式]]></title>
    <url>%2Fposts%2Fada60523.html</url>
    <content type="text"><![CDATA[进入Docker容器比较常见的几种做法如下： 使用docker attach 使用SSH 使用nsenter 使用exec 一、使用docker attach进入Docker容器Docker提供了attach命令来进入Docker容器。创建一个守护态的Docker容器，然后使用docker attach命令进入该容器。过程如下：1234567891011# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest 568c4670fa80 4 weeks ago 109MBghost latest dffc1260f5f5 4 weeks ago 814MB# docker run -itd nginx /bin/bash 85c99fad833008a67114dab7f774e091e7286a58d13278dc984544e18eb5bf91# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES85c99fad8330 nginx "/bin/bash" 5 seconds ago Up 4 seconds 80/tcp cranky_hamilton# docker attach 85c99fad8330root@85c99fad8330:/# 可以看到我们已经进入到该容器中了。但在，使用该命令有一个问题。当多个窗口同时使用该命令进入该容器时，所有的窗口都会同步显示。如果有一个窗口阻塞了，那么其他窗口也无法再进行操作。因为这个原因，所以docker attach命令不太适合于生产环境，平时自己开发应用时可以使用该命令。 二、使用SSH进入Docker容器在生产环境中排除了使用docker attach命令进入容器之后，相信大家第一个想到的就是ssh。在镜像（或容器）中安装SSH Server，这样就能保证多人进入容器且相互之间不受干扰了，相信大家在当前的生产环境中（没有使用Docker的情况）也是这样做的。但是使用了Docker容器之后不建议使用ssh进入到Docker容器内。请参考文章：为什么不需要在 Docker 容器中运行 sshd 三、使用nsenter进入Docker容器在上面两种方式都不适合的情况下，还有一种比较方便的方法，即使用nsenter进入Docker容器。关于什么是nsenter请参考如下文章：https://github.com/jpetazzo/nsenter在了解了什么是nsenter之后，系统默认将我们需要的nsenter安装到主机中如果没有安装的话，按下面步骤安装即可（注意是主机而非容器或镜像）下载地址：https://mirrors.edge.kernel.org/pub/linux/utils/util-linux/选择最新版本，具体的安装命令如下： 123456wget https://mirrors.edge.kernel.org/pub/linux/utils/util-linux/v2.33/util-linux-2.33.tar.gztar -zxvf util-linux-2.33.tar.gz cd util-linux-2.33./configure --without-ncursesmake nsentercp nsenter /usr/local/bin 安装好nsenter之后可以查看一下该命令的使用。12345678910111213141516171819202122232425262728# nsenter --helpUsage: nsenter [options] [&lt;program&gt; [&lt;argument&gt;...]]Run a program with namespaces of other processes.Options: -a, --all enter all namespaces -t, --target &lt;pid&gt; target process to get namespaces from -m, --mount[=&lt;file&gt;] enter mount namespace -u, --uts[=&lt;file&gt;] enter UTS namespace (hostname etc) -i, --ipc[=&lt;file&gt;] enter System V IPC namespace -n, --net[=&lt;file&gt;] enter network namespace -p, --pid[=&lt;file&gt;] enter pid namespace -C, --cgroup[=&lt;file&gt;] enter cgroup namespace -U, --user[=&lt;file&gt;] enter user namespace -S, --setuid &lt;uid&gt; set uid in entered namespace -G, --setgid &lt;gid&gt; set gid in entered namespace --preserve-credentials do not touch uids or gids -r, --root[=&lt;dir&gt;] set the root directory -w, --wd[=&lt;dir&gt;] set the working directory -F, --no-fork do not fork before exec'ing &lt;program&gt; -h, --help display this help -V, --version display versionFor more details see nsenter(1). 连接容器的格式 nsenter --target $PID --mount --uts --ipc --net --pid 容器的PID如何获取 PID=$(docker inspect --format &quot;{{ .State.Pid}}&quot; &lt;container id&gt;) 示例12345678# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa409b84edf94 nginx "nginx -g 'daemon of…" 50 seconds ago Up 49 seconds 80/tcp nginx02# docker inspect --format "&#123;&#123; .State.Pid&#125;&#125;" a409b84edf948335# nsenter --target 8335 --mount --uts --ipc --net --pidroot@a409b84edf94:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 如果觉得查找PID过程麻烦可以使用shell脚本docker-enter，内容如下：1234567891011121314151617181920212223242526272829303132#!/bin/shif [ -e $(dirname "$0")/nsenter ]; then # with boot2docker, nsenter is not in the PATH but it is in the same folder NSENTER=$(dirname "$0")/nsenterelse NSENTER=nsenterfiif [ -z "$1" ]; then echo "Usage: `basename "$0"` CONTAINER [COMMAND [ARG]...]" echo "" echo "Enters the Docker CONTAINER and executes the specified COMMAND." echo "If COMMAND is not specified, runs an interactive shell in CONTAINER."else PID=$(docker inspect --format "&#123;&#123;.State.Pid&#125;&#125;" "$1") if [ -z "$PID" ]; then exit 1 fi shift OPTS="--target $PID --mount --uts --ipc --net --pid --" if [ -z "$1" ]; then # No command given. # Use su to clear all host environment variables except for TERM, # initialize the environment variables HOME, SHELL, USER, LOGNAME, PATH, # and start a login shell. "$NSENTER" $OPTS su - root else # Use env to clear all host environment variables. "$NSENTER" $OPTS env --ignore-environment -- "$@" fifi 增加执行权限chmod +x docker-enter，运行docker-enter &lt;container id&gt;，这样就进入到指定的容器中。 四、使用docker exec进入Docker容器除了上面几种做法之外，docker在1.3.X版本之后还提供了一个新的命令exec用于进入容器，这种方式相对更简单一些，下面我们来看一下该命令的使用：123456789101112131415# docker exec --helpUsage: docker exec [OPTIONS] CONTAINER COMMAND [ARG...]Run a command in a running containerOptions: -d, --detach Detached mode: run command in the background --detach-keys string Override the key sequence for detaching a container -e, --env list Set environment variables -i, --interactive Keep STDIN open even if not attached --privileged Give extended privileges to the command -t, --tty Allocate a pseudo-TTY -u, --user string Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;]) -w, --workdir string Working directory inside the container 示例1234567# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa409b84edf94 nginx "nginx -g 'daemon of…" 24 minutes ago Up 24 minutes 80/tcp nginx02# docker exec -it a409b84edf94 /bin/bashroot@a409b84edf94:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr varroot@a409b84edf94:/#]]></content>
      <categories>
        <category>VT</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile命令详解]]></title>
    <url>%2Fposts%2F8df055d9.html</url>
    <content type="text"><![CDATA[Dockerfile 指令详解1 FROM 指定基础镜像FROM 指令用于指定其后构建新镜像所使用的基础镜像。FROM 指令必是 Dockerfile 文件中的首条命令，启动构建流程后，Docker 将会基于该镜像构建新镜像，FROM 后的命令也会基于这个基础镜像。 FROM语法格式为： FROM &lt;image&gt; 或 FROM &lt;image&gt;:&lt;tag&gt; 或 FROM &lt;image&gt;:&lt;digest&gt; 通过 FROM 指定的镜像，可以是任何有效的基础镜像。FROM 有以下限制： FROM 必须 是 Dockerfile 中第一条非注释命令 在一个 Dockerfile 文件中创建多个镜像时，FROM 可以多次出现。只需在每个新命令 FROM 之前，记录提交上次的镜像 ID。 tag 或 digest 是可选的，如果不使用这两个值时，会使用 latest 版本的基础镜像 2 RUN 执行命令在镜像的构建过程中执行特定的命令，并生成一个中间镜像。格式: #shell格式 RUN &lt;command&gt; #exec格式 RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] RUN 命令将在当前 image 中执行任意合法命令并提交执行结果。命令执行提交后，就会自动执行 Dockerfile 中的下一个指令。 层级 RUN 指令和生成提交是符合 Docker 核心理念的做法。它允许像版本控制那样，在任意一个点，对 image 镜像进行定制化构建。 RUN 指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定 –no-cache 参数，如：docker build –no-cache。 3 COPY 复制文件格式： COPY &lt;源路径&gt;... &lt;目标路径&gt; COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 和 RUN 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。COPY 指令将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置。比如： COPY package.json /usr/src/app/ &lt;源路径&gt;可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则，如： COPY hom* /mydir/ COPY hom?.txt /mydir/ &lt;目标路径&gt;可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。 此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。 4 ADD 更高级的复制文件ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。比如&lt;源路径&gt;可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到&lt;目标路径&gt;去。 在构建镜像时，复制上下文中的文件到镜像内，格式： ADD &lt;源路径&gt;... &lt;目标路径&gt; ADD [&quot;&lt;源路径&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 注意如果 docker 发现文件内容被改变，则接下来的指令都不会再使用缓存。关于复制文件时需要处理的/，基本跟正常的 copy 一致 5 ENV 设置环境变量格式有两种： ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 ENV VERSION=1.0 DEBUG=on \ NAME=&quot;Happy Feet&quot; 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。 6 EXPOSE为构建的镜像设置监听端口，使容器在运行时监听。格式： EXPOSE &lt;port&gt; [&lt;port&gt;...] EXPOSE 指令并不会让容器监听 host 的端口，如果需要，需要在 docker run 时使用 -p、-P 参数来发布容器端口到 host 的某个端口上。 7 VOLUME 定义匿名卷VOLUME用于创建挂载点，即向基于所构建镜像创始的容器添加卷： VOLUME [&quot;/data&quot;] 一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能： 卷可以容器间共享和重用 容器并不一定要和其它容器共享卷 修改卷后会立即生效 对卷的修改不会对镜像产生影响 卷会一直存在，直到没有任何容器在使用它 VOLUME 让我们可以将源代码、数据或其它内容添加到镜像中，而又不并提交到镜像中，并使我们可以多个容器间共享这些内容。 8 WORKDIR 指定工作目录WORKDIR用于在容器内设置一个工作目录： WORKDIR /path/to/workdir 通过WORKDIR设置工作目录后，Dockerfile 中其后的命令 RUN、CMD、ENTRYPOINT、ADD、COPY 等命令都会在该目录下执行。 如，使用WORKDIR设置工作目录： WORKDIR /a WORKDIR b WORKDIR c RUN pwd 在以上示例中，pwd 最终将会在 /a/b/c 目录中执行。在使用 docker run 运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。 9 USER 指定当前用户USER 用于指定运行镜像所使用的用户： USER daemon 使用USER指定用户时，可以使用用户名、UID 或 GID，或是两者的组合。以下都是合法的指定试： USER user USER user:group USER uid USER uid:gid USER user:gid USER uid:group 使用USER指定用户后，Dockerfile 中其后的命令 RUN、CMD、ENTRYPOINT 都将使用该用户。镜像构建完成后，通过 docker run 运行容器时，可以通过 -u 参数来覆盖所指定的用户。 10 CMDCMD用于指定在容器启动时所要执行的命令。CMD 有以下三种格式： CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] CMD [&quot;param1&quot;,&quot;param2&quot;] CMD command param1 param2 省略可执行文件的 exec 格式，这种写法使 CMD 中的参数当做 ENTRYPOINT 的默认参数，此时 ENTRYPOINT 也应该是 exec 格式，具体与 ENTRYPOINT 的组合使用，参考 ENTRYPOINT。注意与 RUN 指令的区别：RUN 在构建的时候执行，并生成一个新的镜像，CMD 在容器运行的时候执行，在构建时不进行任何操作。 11 ENTRYPOINTENTRYPOINT 用于给容器配置一个可执行程序。也就是说，每次使用镜像创建容器时，通过 ENTRYPOINT 指定的程序都会被设置为默认程序。ENTRYPOINT 有以下两种形式： ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] ENTRYPOINT command param1 param2 ENTRYPOINT 与 CMD 非常类似，不同的是通过docker run执行的命令不会覆盖 ENTRYPOINT，而docker run命令中指定的任何参数，都会被当做参数再次传递给 ENTRYPOINT。Dockerfile 中只允许有一个 ENTRYPOINT 命令，多指定时会覆盖前面的设置，而只执行最后的 ENTRYPOINT 指令。 docker run运行容器时指定的参数都会被传递给 ENTRYPOINT ，且会覆盖 CMD 命令指定的参数。如，执行docker run &lt;image&gt; -d时，-d 参数将被传递给入口点。 也可以通过docker run –entrypoint重写 ENTRYPOINT 入口点。如：可以像下面这样指定一个容器执行程序： ENTRYPOINT [&quot;/usr/bin/nginx&quot;] 完整构建代码： # Version: 0.0.3 FROM ubuntu:16.04 MAINTAINER 何民三 &quot;cn.liuht@gmail.com&quot; RUN apt-get update RUN apt-get install -y nginx RUN echo &apos;Hello World, 我是个容器&apos; \ &gt; /var/www/html/index.html ENTRYPOINT [&quot;/usr/sbin/nginx&quot;] EXPOSE 80 使用docker build构建镜像，并将镜像指定为 itbilu/test： docker build -t=&quot;itbilu/test&quot; . 构建完成后，使用itbilu/test启动一个容器： docker run -i -t itbilu/test -g &quot;daemon off;&quot; 在运行容器时，我们使用了 -g “daemon off;”，这个参数将会被传递给 ENTRYPOINT，最终在容器中执行的命令为 /usr/sbin/nginx -g “daemon off;”。 12 LABELLABEL用于为镜像添加元数据，元数以键值对的形式指定： LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ... 使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。 如，通过LABEL指定一些元数据： LABEL version=&quot;1.0&quot; description=&quot;这是一个Web服务器&quot; by=&quot;IT笔录&quot; 指定后可以通过docker inspect查看： docker inspect itbilu/test &quot;Labels&quot;: { &quot;version&quot;: &quot;1.0&quot;, &quot;description&quot;: &quot;这是一个Web服务器&quot;, &quot;by&quot;: &quot;IT笔录&quot; }, 13 ARGARG用于指定传递给构建运行时的变量： ARG &lt;name&gt;[=&lt;default value&gt;] 如，通过ARG指定两个变量： ARG site ARG build_user=IT笔录 以上我们指定了 site 和 build_user 两个变量，其中 build_user 指定了默认值。在使用 docker build 构建镜像时，可以通过 –build-arg = 参数来指定或重设置这些变量的值。 docker build --build-arg site=itiblu.com -t itbilu/test . 这样我们构建了 itbilu/test 镜像，其中site会被设置为 itbilu.com，由于没有指定 build_user，其值将是默认值 IT 笔录。 14 ONBUILDONBUILD用于设置镜像触发器： ONBUILD [INSTRUCTION] 当所构建的镜像被用做其它镜像的基础镜像，该镜像中的触发器将会被钥触发。 如，当镜像被使用时，可能需要做一些处理： [...] ONBUILD ADD . /app/src ONBUILD RUN /usr/local/bin/python-build --dir /app/src [...] 15 STOPSIGNALSTOPSIGNAL用于设置停止容器所要发送的系统调用信号： STOPSIGNAL signal 所使用的信号必须是内核系统调用表中的合法的值，如：SIGKILL。 16 SHELLSHELL用于设置执行命令（shell式）所使用的的默认 shell 类型： SHELL [&quot;executable&quot;, &quot;parameters&quot;] SHELL在Windows环境下比较有用，Windows 下通常会有 cmd 和 powershell 两种 shell，可能还会有 sh。这时就可以通过 SHELL 来指定所使用的 shell 类型： FROM microsoft/windowsservercore # Executed as cmd /S /C echo default RUN echo default # Executed as cmd /S /C powershell -command Write-Host default RUN powershell -command Write-Host default # Executed as powershell -command Write-Host hello SHELL [&quot;powershell&quot;, &quot;-command&quot;] RUN Write-Host hello # Executed as cmd /S /C echo hello SHELL [&quot;cmd&quot;, &quot;/S&quot;&quot;, &quot;/C&quot;] RUN echo hello Dockerfile 使用经验Dockerfile 示例构建Nginx运行环境Dockerfile文件 # 指定基础镜像 FROM sameersbn/ubuntu:14.04.20161014 # 维护者信息 MAINTAINER sameer@damagehead.com # 设置环境 ENV RTMP_VERSION=1.1.10 \ NPS_VERSION=1.11.33.4 \ LIBAV_VERSION=11.8 \ NGINX_VERSION=1.10.1 \ NGINX_USER=www-data \ NGINX_SITECONF_DIR=/etc/nginx/sites-enabled \ NGINX_LOG_DIR=/var/log/nginx \ NGINX_TEMP_DIR=/var/lib/nginx \ NGINX_SETUP_DIR=/var/cache/nginx # 设置构建时变量，镜像建立完成后就失效 ARG BUILD_LIBAV=false ARG WITH_DEBUG=false ARG WITH_PAGESPEED=true ARG WITH_RTMP=true # 复制本地文件到容器目录中 COPY setup/ ${NGINX_SETUP_DIR}/ RUN bash ${NGINX_SETUP_DIR}/install.sh # 复制本地配置文件到容器目录中 COPY nginx.conf /etc/nginx/nginx.conf COPY entrypoint.sh /sbin/entrypoint.sh # 运行指令 RUN chmod 755 /sbin/entrypoint.sh # 允许指定的端口 EXPOSE 80/tcp 443/tcp 1935/tcp # 指定网站目录挂载点 VOLUME [&quot;${NGINX_SITECONF_DIR}&quot;] ENTRYPOINT [&quot;/sbin/entrypoint.sh&quot;] CMD [&quot;/usr/sbin/nginx&quot;] 构建Tomcat环境Dockerfile文件 # 指定基于的基础镜像 FROM ubuntu:13.10 # 维护者信息 MAINTAINER zhangjiayang &quot;zhangjiayang@sczq.com.cn&quot; # 镜像的指令操作 # 获取APT更新的资源列表 RUN echo &quot;deb http://archive.ubuntu.com/ubuntu precise main universe&quot;&gt; /etc/apt/sources.list # 更新软件 RUN apt-get update # Install curl RUN apt-get -y install curl # Install JDK 7 RUN cd /tmp &amp;&amp; curl -L &apos;http://download.oracle.com/otn-pub/java/jdk/7u65-b17/jdk-7u65-linux-x64.tar.gz&apos; -H &apos;Cookie: oraclelicense=accept-securebackup-cookie; gpw_e24=Dockerfile&apos; | tar -xz RUN mkdir -p /usr/lib/jvm RUN mv /tmp/jdk1.7.0_65/ /usr/lib/jvm/java-7-oracle/ # Set Oracle JDK 7 as default Java RUN update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-7-oracle/bin/java 300 RUN update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java-7-oracle/bin/javac 300 # 设置系统环境 ENV JAVA_HOME /usr/lib/jvm/java-7-oracle/ # Install tomcat7 RUN cd /tmp &amp;&amp; curl -L &apos;http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.8/bin/apache-tomcat-7.0.8.tar.gz&apos; | tar -xz RUN mv /tmp/apache-tomcat-7.0.8/ /opt/tomcat7/ ENV CATALINA_HOME /opt/tomcat7 ENV PATH $PATH:$CATALINA_HOME/bin # 复件tomcat7.sh到容器中的目录 ADD tomcat7.sh /etc/init.d/tomcat7 RUN chmod 755 /etc/init.d/tomcat7 # Expose ports. 指定暴露的端口 EXPOSE 8080 # Define default command. ENTRYPOINT service tomcat7 start &amp;&amp; tail -f /opt/tomcat7/logs/catalina.out tomcat7.sh命令文件 export JAVA_HOME=/usr/lib/jvm/java-7-oracle/ export TOMCAT_HOME=/opt/tomcat7 case $1 in start) sh $TOMCAT_HOME/bin/startup.sh ;; stop) sh $TOMCAT_HOME/bin/shutdown.sh ;; restart) sh $TOMCAT_HOME/bin/shutdown.sh sh $TOMCAT_HOME/bin/startup.sh ;; esac exit 0 原则与建议 容器轻量化。从镜像中产生的容器应该尽量轻量化，能在足够短的时间内停止、销毁、重新生成并替换原来的容器。 使用 .gitignore。在大部分情况下，Dockerfile 会和构建所需的文件放在同一个目录中，为了提高构建的性能，应该使用 .gitignore 来过滤掉不需要的文件和目录。 为了减少镜像的大小，减少依赖，仅安装需要的软件包。 一个容器只做一件事。解耦复杂的应用，分成多个容器，而不是所有东西都放在一个容器内运行。如一个 Python Web 应用，可能需要 Server、DB、Cache、MQ、Log 等几个容器。一个更加极端的说法：One process per container。 减少镜像的图层。不要多个 Label、ENV 等标签。 对续行的参数按照字母表排序，特别是使用apt-get install -y安装包的时候。 使用构建缓存。如果不想使用缓存，可以在构建的时候使用参数–no-cache=true来强制重新生成中间镜像。]]></content>
      <categories>
        <category>VT</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Dockerfile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门教程]]></title>
    <url>%2Fposts%2Fca03914f.html</url>
    <content type="text"><![CDATA[如今Docker的使用已经非常普遍，特别在一线互联网公司。使用Docker技术可以帮助企业快速水平扩展服务，从而到达弹性部署业务的能力。在云服务概念兴起之后，Docker的使用场景和范围进一步发展，如今在微服务架构越来越流行的情况下，微服务+Docker的完美组合，更加方便微服务架构运维部署落地。 Docker简介Docker 是世界领先的软件容器平台。开发人员利用 Docker 可以消除协作编码时“在我的机器上可正常工作”的问题。运维人员利用 Docker 可以在隔离容器中并行运行和管理应用，获得更好的计算密度。企业利用 Docker 可以构建敏捷的软件交付管道，以更快的速度、更高的安全性和可靠的信誉为 Linux 和 Windows Server 应用发布新功能。 Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。 Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目已经超过 4 万 6 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 为什么要使用Docker容器除了运行其中应用外，基本不消耗额外的系统资源，使得应用的性能很高，同时系统的开销尽量小。传统虚拟机方式运行 10 个不同的应用就要起 10 个虚拟机，而Docker 只需要启动 10 个隔离的应用即可。 具体说来，Docker 在如下几个方面具有较大的优势。 1、更快速的交付和部署对开发和运维（devop）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。 开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码。 Docker 可以快速创建容器，快速迭代应用程序，并让整个过程全程可见，使团队中的其他成员更容易理解应用程序是如何创建和工作的。 Docker 容器很轻很快！容器的启动时间是秒级的，大量地节约开发、测试、部署的时间。 2、更高效的虚拟化Docker 容器的运行不需要额外的 hypervisor 支持，它是内核级的虚拟化，因此可以实现更高的性能和效率。 3、更轻松的迁移和扩展Docker 容器几乎可以在任意的平台上运行，包括物理机、虚拟机、公有云、私有云、个人电脑、服务器等。 这种兼容性可以让用户把一个应用程序从一个平台直接迁移到另外一个。 4、更简单的管理使用 Docker，只需要小小的修改，就可以替代以往大量的更新工作。所有的修改都以增量的方式被分发和更新，从而实现自动化并且高效的管理。 Docker vs VM从下图可以看出，VM是一个运行在宿主机之上的完整的操作系统，VM运行自身操作系统会占用较多的CPU、内存、硬盘资源。Docker不同于VM，只包含应用程序以及依赖库，基于libcontainer运行在宿主机上，并处于一个隔离的环境中，这使得Docker更加轻量高效，启动容器只需几秒钟之内完成。由于Docker轻量、资源占用少，使得Docker可以轻易的应用到构建标准化的应用中。但Docker目前还不够完善，比如隔离效果不如VM，共享宿主机操作系统的一些基础库等；网络配置功能相对简单，主要以桥接方式为主；查看日志也不够方便灵活。Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。 作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多；Docker 对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器。 相关概念Docker是CS架构，主要有两个概念： Docker daemon: 运行在宿主机上，Docker守护进程，用户通过Docker client(Docker命令)与Docker daemon交互 Docker client: Docker 命令行工具，是用户使用Docker的主要方式，Docker client与Docker daemon通信并将结果返回给用户，Docker client也可以通过socket或者RESTful api访问远程的Docker daemon 了解了Docker的组成，再来了解一下Docker的三个主要概念： Docker image：镜像是只读的，镜像中包含有需要运行的文件。镜像用来创建container，一个镜像可以运行多个container；镜像可以通过Dockerfile创建，也可以从Docker hub/registry上下载。 Docker container：容器是Docker的运行组件，启动一个镜像就是一个容器，容器是一个隔离环境，多个容器之间不会相互影响，保证容器中的程序运行在一个相对安全的环境中。 Docker hub/registry: 共享和管理Docker镜像，用户可以上传或者下载上面的镜像，官方地址为https://registry.hub.docker.com/，也可以搭建自己私有的Docker registry。 镜像就相当于打包好的版本，镜像启动之后运行在容器中，仓库就是装存储镜像的地方。 Docker安装建议在linux环境下安装Docker，window环境搭建比较复杂且容易出错，使用Centos7+yum来安装Docker环境很方便。 Docker 软件包已经包括在默认的 CentOS-Extras 软件源里。因此想要安装 docker，只需要运行下面的 yum 命令： yum install docker 安装完成后，使用下面的命令来启动 docker 服务，并将其设置为开机启动： service docker start chkconfig docker on LCTT 译注：此处采用了旧式的 sysv 语法，如采用CentOS 7中支持的新式 systemd 语法，如下： systemctl start docker.service systemctl enable docker.service 测试 docker version 输入上述命令，返回docker的版本相关信息，证明docker安装成功。 Hello World下面，我们通过最简单的 image 文件”hello world”，感受一下 Docker。 因为国内连接 Docker 的官方仓库很慢，因此我们在日常使用中会使用Docker 中国加速器。通过 Docker 官方镜像加速，中国区用户能够快速访问最流行的 Docker 镜像。该镜像托管于中国大陆，本地用户现在将会享受到更快的下载速度和更强的稳定性，从而能够更敏捷地开发和交付 Docker 化应用。 Docker 中国官方镜像加速可通过registry.docker-cn.com访问。该镜像库只包含流行的公有镜像，私有镜像仍需要从美国镜像库中拉取。 修改系统中docker对应的配置文件即可，如下： vi /etc/docker/daemon.json #添加后 { &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;], &quot;live-restore&quot;: true } 运行下面的命令，将 image 文件从仓库抓取到本地。 docker pull library/hello-world 上面代码中，docker image pull是抓取 image 文件的命令。library/hello-world是 image 文件在仓库里面的位置，其中library是 image 文件所在的组，hello-world是 image 文件的名字。 抓取成功以后，就可以在本机看到这个 image 文件了。 docker images #显示结果 REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/hello-world latest f2a91732366c 3 months ago 1.848 kB 现在，运行这个 image 文件。 docker run hello-world #显示结果 Hello from Docker! This message shows that your installation appears to be working correctly. ... 输出这段提示以后，hello world就会停止运行，容器自动终止。有些容器不会自动终止，因为提供的是服务，比如Mysql镜像等。 常用命令除过以上我们使用的Docker命令外，Docker还有一些其它常用的命令 拉取docker镜像 docker pull image_name 查看宿主机上的镜像，Docker镜像保存在/var/lib/docker目录下: docker images 删除镜像 docker rmi docker.io/tomcat:7.0.77-jre7 或者 docker rmi b39c68b7af30 查看当前有哪些容器正在运行 docker ps 查看所有容器 docker ps -a 启动、停止、重启容器命令： docker start container_name/container_id docker stop container_name/container_id docker restart container_name/container_id 后台启动一个容器后，如果想进入到这个容器，可以使用attach命令： docker attach container_name/container_id 删除容器的命令： docker rm container_name/container_id 删除所有停止的容器： docker rm $(docker ps -a -q) 查看当前系统Docker信息 docker info 从Docker hub上下载某个镜像: docker pull centos:latest 查找Docker Hub上的nginx镜像 docker search nginx 执行docker pull centos会将Centos这个仓库下面的所有镜像下载到本地repository。]]></content>
      <categories>
        <category>VT</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下解决docker端口映射到宿主机后外网无法访问的问题]]></title>
    <url>%2Fposts%2F897dc603.html</url>
    <content type="text"><![CDATA[解决办法：1# vim /etc/sysctl.conf 或者1# vim /usr/lib/sysctl.d/00-system.conf 添加如下代码：1net.ipv4.ip_forward=1 重启network服务1# systemctl restart network 查看是否修改成功1# sysctl net.ipv4.ip_forward 如果返回为“net.ipv4.ip_forward = 1”则表示成功了最后重启docker服务1# systemvtl restart docker.service]]></content>
      <categories>
        <category>VT</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell脚本常见面试题]]></title>
    <url>%2Fposts%2F40e68004.html</url>
    <content type="text"><![CDATA[注意事项1）开头加解释器：#!/bin/bash 2）语法缩进，使用四个空格；多加注释说明。 3）命名建议规则：变量名大写、局部变量小写，函数名小写，名字体现出实际作用。 4）默认变量是全局的，在函数中变量local指定为局部变量，避免污染其他作用域。 5）有两个命令能帮助我调试脚本：set -e 遇到执行非0时退出脚本，set-x 打印执行过程。 6）写脚本一定先测试再到生产上。 脚本目录1、获取随机字符串或数字获取随机8位字符串：123456789方法1：# echo $RANDOM |md5sum |cut -c 1-8471b94f2方法2：# openssl rand -base64 4vg3BEg==方法3：# cat /proc/sys/kernel/random/uuid |cut -c 1-8ed9e032c 获取随机8位数字：123456789方法1：# echo $RANDOM |cksum |cut -c 1-823648321方法2：# openssl rand -base64 4 |cksum |cut -c 1-838571131方法3：# date +%N |cut -c 1-869024815 cksum：打印CRC效验和统计字节 2、定义一个颜色输出字符串函数123456789101112131415161718192021方法1：function echo_color() &#123; if [ $1 == "green" ]; then echo -e "\033[32;40m$2\033[0m" elif [ $1 == "red" ]; then echo -e "\033[31;40m$2\033[0m" fi&#125;方法2：function echo_color() &#123; case $1 in green) echo -e "\033[32;40m$2\033[0m" ;; red) echo -e "\033[31;40m$2\033[0m" ;; *) echo "Example: echo_color red string" esac&#125; 使用方法：echo_color green “test”function关键字定义一个函数，可加或不加。 3、批量创建用户12345678910111213141516171819202122232425262728#!/bin/bashDATE=$(date +%F_%T)USER_FILE=user.txtecho_color()&#123; if [ $1 == "green" ]; then echo -e "\033[32;40m$2\033[0m" elif [ $1 == "red" ]; then echo -e "\033[31;40m$2\033[0m" fi&#125;# 如果用户文件存在并且大小大于0就备份if [ -s $USER_FILE ]; then mv $USER_FILE $&#123;USER_FILE&#125;-$&#123;DATE&#125;.bak echo_color green "$USER_FILE exist, rename $&#123;USER_FILE&#125;-$&#123;DATE&#125;.bak"fiecho -e "User\tPassword" &gt;&gt; $USER_FILEecho "----------------" &gt;&gt; $USER_FILEfor USER in user&#123;1..10&#125;; do if ! id $USER &amp;&gt;/dev/null; then PASS=$(echo $RANDOM |md5sum |cut -c 1-8) useradd $USER echo $PASS |passwd --stdin $USER &amp;&gt;/dev/null echo -e "$USER\t$PASS" &gt;&gt; $USER_FILE echo "$USER User create successful." else echo_color red "$USER User already exists!" fidone 4、检查软件包是否安装123456#!/bin/bashif rpm -q sysstat &amp;&gt;/dev/null; then echo "sysstat is already installed."else echo "sysstat is not installed!"fi 5、检查服务状态123456#!/bin/bashPORT_C=$(ss -anu |grep -c 123)PS_C=$(ps -ef |grep ntpd |grep -vc grep)if [ $PORT_C -eq 0 -o $PS_C -eq 0 ]; then echo "内容" | mail -s "主题" dst@example.comfi 6、检查主机存活状态方法1：将错误IP放到数组里面判断是否ping失败三次12345678910111213141516171819#!/bin/bash IP_LIST="192.168.18.1 192.168.1.1 192.168.18.2"for IP in $IP_LIST; do NUM=1 while [ $NUM -le 3 ]; do if ping -c 1 $IP &gt; /dev/null; then echo "$IP Ping is successful." break else # echo "$IP Ping is failure $NUM" FAIL_COUNT[$NUM]=$IP let NUM++ fi done if [ $&#123;#FAIL_COUNT[*]&#125; -eq 3 ];then echo "$&#123;FAIL_COUNT[1]&#125; Ping is failure!" unset FAIL_COUNT[*] fidone 方法2：将错误次数放到FAIL_COUNT变量里面判断是否ping失败三次1234567891011121314151617#!/bin/bash IP_LIST="192.168.18.1 192.168.1.1 192.168.18.2"for IP in $IP_LIST; do FAIL_COUNT=0 for ((i=1;i&lt;=3;i++)); do if ping -c 1 $IP &gt;/dev/null; then echo "$IP Ping is successful." break else # echo "$IP Ping is failure $i" let FAIL_COUNT++ fi done if [ $FAIL_COUNT -eq 3 ]; then echo "$IP Ping is failure!" fidone 方法3：利用for循环将ping通就跳出循环继续，如果不跳出就会走到打印ping失败1234567891011121314#!/bin/bashping_success_status() &#123; if ping -c 1 $IP &gt;/dev/null; then echo "$IP Ping is successful." continue fi&#125;IP_LIST="192.168.18.1 192.168.1.1 192.168.18.2"for IP in $IP_LIST; do ping_success_status ping_success_status ping_success_status echo "$IP Ping is failure!"done 7、监控CPU、内存和硬盘利用率1）CPU借助vmstat工具来分析CPU统计信息。1234567891011121314151617181920#!/bin/bashDATE=$(date +%F" "%H:%M)IP=$(ifconfig eth0 |awk -F '[ :]+' '/inet addr/&#123;print $4&#125;') # 只支持CentOS6MAIL="example@mail.com"if ! which vmstat &amp;&gt;/dev/null; then echo "vmstat command no found, Please install procps package." exit 1fiUS=$(vmstat |awk 'NR==3&#123;print $13&#125;')SY=$(vmstat |awk 'NR==3&#123;print $14&#125;')IDLE=$(vmstat |awk 'NR==3&#123;print $15&#125;')WAIT=$(vmstat |awk 'NR==3&#123;print $16&#125;')USE=$(($US+$SY))if [ $USE -ge 50 ]; then echo " Date: $DATE Host: $IP Problem: CPU utilization $USE " | mail -s "CPU Monitor" $MAILfi 2）内存123456789101112131415#!/bin/bashDATE=$(date +%F" "%H:%M)IP=$(ifconfig eth0 |awk -F '[ :]+' '/inet addr/&#123;print $4&#125;') MAIL="example@mail.com"TOTAL=$(free -m |awk '/Mem/&#123;print $2&#125;')USE=$(free -m |awk '/Mem/&#123;print $3-$6-$7&#125;')FREE=$(($TOTAL-$USE))# 内存小于1G发送报警邮件if [ $FREE -lt 1024 ]; then echo " Date: $DATE Host: $IP Problem: Total=$TOTAL,Use=$USE,Free=$FREE " | mail -s "Memory Monitor" $MAILfi 3）硬盘12345678910111213141516171819#!/bin/bashDATE=$(date +%F" "%H:%M)IP=$(ifconfig eth0 |awk -F '[ :]+' '/inet addr/&#123;print $4&#125;') MAIL="example@mail.com"TOTAL=$(fdisk -l |awk -F'[: ]+' 'BEGIN&#123;OFS="="&#125;/^Disk \/dev/&#123;printf "%s=%sG,",$2,$3&#125;')PART_USE=$(df -h |awk 'BEGIN&#123;OFS="="&#125;/^\/dev/&#123;print $1,int($5),$6&#125;')for i in $PART_USE; do PART=$(echo $i |cut -d"=" -f1) USE=$(echo $i |cut -d"=" -f2) MOUNT=$(echo $i |cut -d"=" -f3) if [ $USE -gt 80 ]; then echo " Date: $DATE Host: $IP Total: $TOTAL Problem: $PART=$USE($MOUNT) " | mail -s "Disk Monitor" $MAIL fidone 8、批量主机磁盘利用率监控前提监控端和被监控端SSH免交互登录或者密钥登录。写一个配置文件保存被监控主机SSH连接信息，文件内容格式：IP User Port12345678910111213141516#!/bin/bashHOST_INFO=host.infofor IP in $(awk '/^[^#]/&#123;print $1&#125;' $HOST_INFO); do USER=$(awk -v ip=$IP 'ip==$1&#123;print $2&#125;' $HOST_INFO) PORT=$(awk -v ip=$IP 'ip==$1&#123;print $3&#125;' $HOST_INFO) TMP_FILE=/tmp/disk.tmp ssh -p $PORT $USER@$IP 'df -h' &gt; $TMP_FILE USE_RATE_LIST=$(awk 'BEGIN&#123;OFS="="&#125;/^\/dev/&#123;print $1,int($5)&#125;' $TMP_FILE) for USE_RATE in $USE_RATE_LIST; do PART_NAME=$&#123;USE_RATE%=*&#125; USE_RATE=$&#123;USE_RATE#*=&#125; if [ $USE_RATE -ge 80 ]; then echo "Warning: $PART_NAME Partition usage $USE_RATE%!" fi donedone 9、检查网站可用性1）检查URL可用性方法1：123456check_url() &#123; HTTP_CODE=$(curl -o /dev/null --connect-timeout 3 -s -w "%&#123;http_code&#125;" $1) if [ $HTTP_CODE -ne 200 ]; then echo "Warning: $1 Access failure!" fi&#125; 方法2：123456check_url() &#123;if ! wget -T 10 --tries=1 --spider $1 &gt;/dev/null 2&gt;&amp;1; then #-T超时时间，--tries尝试1次，--spider爬虫模式 echo "Warning: $1 Access failure!" fi&#125; 使用方法：check_url www.baidu.com 2）判断三次URL可用性思路与上面检查主机存活状态一样。方法1：利用循环技巧，如果成功就跳出当前循环，否则执行到最后一行1234567891011121314#!/bin/bash check_url() &#123; HTTP_CODE=$(curl -o /dev/null --connect-timeout 3 -s -w "%&#123;http_code&#125;" $1) if [ $HTTP_CODE -eq 200 ]; then continue fi&#125;URL_LIST="www.baidu.com www.agasgf.com"for URL in $URL_LIST; do check_url $URL check_url $URL check_url $URL echo "Warning: $URL Access failure!"done 方法2：错误次数保存到变量12345678910111213141516#!/bin/bash URL_LIST="www.baidu.com www.agasgf.com"for URL in $URL_LIST; do FAIL_COUNT=0 for ((i=1;i&lt;=3;i++)); do HTTP_CODE=$(curl -o /dev/null --connect-timeout 3 -s -w "%&#123;http_code&#125;" $URL) if [ $HTTP_CODE -ne 200 ]; then let FAIL_COUNT++ else break fi done if [ $FAIL_COUNT -eq 3 ]; then echo "Warning: $URL Access failure!" fidone 方法3：错误次数保存到数组123456789101112131415161718#!/bin/bash URL_LIST="www.baidu.com www.agasgf.com"for URL in $URL_LIST; do NUM=1 while [ $NUM -le 3 ]; do HTTP_CODE=$(curl -o /dev/null --connect-timeout 3 -s -w "%&#123;http_code&#125;" $URL) if [ $HTTP_CODE -ne 200 ]; then FAIL_COUNT[$NUM]=$IP #创建数组，以$NUM下标，$IP元素 let NUM++ else break fi done if [ $&#123;#FAIL_COUNT[*]&#125; -eq 3 ]; then echo "Warning: $URL Access failure!" unset FAIL_COUNT[*] #清空数组 fidone 10、检查MySQL主从同步状态1234567891011#!/bin/bash USER=bakPASSWD=123456IO_SQL_STATUS=$(mysql -u$USER -p$PASSWD -e 'show slave status\G' |awk -F: '/Slave_.*_Running/&#123;gsub(": ",":");print $0&#125;') #gsub去除冒号后面的空格for i in $IO_SQL_STATUS; do THREAD_STATUS_NAME=$&#123;i%:*&#125; THREAD_STATUS=$&#123;i#*:&#125; if [ "$THREAD_STATUS" != "Yes" ]; then echo "Error: MySQL Master-Slave $THREAD_STATUS_NAME status is $THREAD_STATUS!" fidone]]></content>
      <categories>
        <category>Scripts</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM调优命令]]></title>
    <url>%2Fposts%2F445d9c99.html</url>
    <content type="text"><![CDATA[运用jvm自带的命令可以方便的在生产监控和打印堆栈的日志信息帮忙我们来定位问题！虽然jvm调优成熟的工具已经有很多：jconsole、大名鼎鼎的VisualVM，IBM的Memory Analyzer等等，但是在生产环境出现问题的时候，一方面工具的使用会有所限制，另一方面喜欢装X的我们，总喜欢在出现问题的时候在终端输入一些命令来解决。所有的工具几乎都是依赖于jdk的接口和底层的这些命令，研究这些命令的使用也让我们更能了解jvm构成和特性。 Sun JDK监控和故障处理命令有jps jstat jmap jhat jstack jinfo下面做一一介绍 jpsJVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。 命令格式1jps [options] [hostid] option参数-l : 输出主类全名或jar路径 -q : 只输出LVMID -m : 输出JVM启动时传递给main()的参数 -v : 输出JVM启动时显示指定的JVM参数 其中[option]、[hostid]参数也可以不写。 示例1234$ jps -l -m 28920 org.apache.catalina.startup.Bootstrap start 11589 org.apache.catalina.startup.Bootstrap start 25816 sun.tools.jps.Jps -l -m jstatjstat(JVM statistics Monitoring)是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。 命令格式1jstat [option] LVMID [interval] [count] 参数[option] : 操作参数 LVMID : 本地虚拟机进程ID [interval] : 连续输出的时间间隔 [count] : 连续输出的次数 option 参数总览 Option Displays… class class loader的行为统计。Statistics on the behavior of the class loader. compiler HotSpt JIT编译器行为统计。Statistics of the behavior of the HotSpot Just-in-Time compiler. gc 垃圾回收堆的行为统计。Statistics of the behavior of the garbage collected heap. gccapacity 各个垃圾回收代容量(young,old,perm)和他们相应的空间统计。Statistics of the capacities of the generations and their corresponding spaces. gcutil 垃圾回收统计概述。Summary of garbage collection statistics. gccause 垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因。Summary of garbage collection statistics (same as -gcutil), with the cause of the last and gcnew 新生代行为统计。Statistics of the behavior of the new generation. gcnewcapacity 新生代与其相应的内存空间的统计。Statistics of the sizes of the new generations and its corresponding spaces. gcold 年老代和永生代行为统计。Statistics of the behavior of the old and permanent generations. gcoldcapacity 年老代行为统计。Statistics of the sizes of the old generation. gcpermcapacity 永生代行为统计。Statistics of the sizes of the permanent generation. printcompilation HotSpot编译方法统计。HotSpot compilation method statistics. option 参数详解-class监视类装载、卸载数量、总空间以及耗费的时间 123$ jstat -class 11589 Loaded Bytes Unloaded Bytes Time 7035 14506.3 0 0.0 3.67 Loaded : 加载class的数量 Bytes : class字节大小 Unloaded : 未加载class的数量 Bytes : 未加载class的字节大小 Time : 加载时间 -compiler输出JIT编译过的方法数量耗时等123$ jstat -compiler 1262Compiled Failed Invalid Time FailedType FailedMethod 2573 1 0 47.60 1 org/apache/catalina/loader/WebappClassLoader findResourceInternal Compiled : 编译数量 Failed : 编译失败数量 Invalid : 无效数量 Time : 编译耗时 FailedType : 失败类型 FailedMethod : 失败方法的全限定名 -gc垃圾回收堆的行为统计，常用命令123# jstat -gc 19601 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 4608.0 4608.0 2050.8 0.0 809984.0 661873.2 204800.0 85366.7 80384.0 75427.8 9984.0 9171.5 98 1.814 3 0.799 2.613 C即Capacity 总容量，U即Used 已使用的容量 S0C : survivor0区的总容量 S1C : survivor1区的总容量 S0U : survivor0区已使用的容量 S1U : survivor1区已使用的容量 EC : Eden区的总容量 EU : Eden区已使用的容量 OC : Old区的总容量 OU : Old区已使用的容量 PC 当前perm的容量 (KB) PU perm的使用 (KB) YGC : 新生代垃圾回收次数 YGCT : 新生代垃圾回收时间 FGC : 老年代垃圾回收次数 FGCT : 老年代垃圾回收时间 GCT : 垃圾回收总消耗时间 1$ jstat -gc 1262 2000 20 这个命令意思就是每隔2000ms输出1262的gc情况，一共输出20次-gccapacity同-gc，不过还会输出Java堆各区域使用到的最大、最小空间123$ jstat -gccapacity 19601 NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC 819200.0 819200.0 819200.0 7168.0 6656.0 805376.0 204800.0 204800.0 204800.0 204800.0 0.0 1120256.0 79872.0 0.0 1048576.0 9984.0 88 3 NGCMN：新生代最小容量 NGCMX：新生代最大容量 NGC：当前新生代容量 S0C：第一个幸存区大小 S1C：第二个幸存区的大小 EC：伊甸园区的大小 OGCMN：老年代最小容量 OGCMX：老年代最大容量 OGC：当前老年代大小 OC:当前老年代大小 MCMN:最小元数据容量 MCMX：最大元数据容量 MC：当前元数据空间大小 CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：当前压缩类空间大小 YGC：年轻代gc次数 FGC：老年代GC次数 -gcutil同-gc，不过输出的是已使用空间占总空间的百分比123$ jstat -gcutil 28920 S0 S1 E O P YGC YGCT FGC FGCT GCT 12.45 0.00 33.85 0.00 4.44 4 0.242 0 0.000 0.242 S0C：第一个幸存区的大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 OC：老年代大小 OU：老年代使用大小 MC：方法区大小 MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 -gccause垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因123$ jstat -gccause 28920 S0 S1 E O P YGC YGCT FGC FGCT GCT LGCC GCC 12.45 0.00 33.85 0.00 4.44 4 0.242 0 0.000 0.242 Allocation Failure No GC LGCC：最近垃圾回收的原因 GCC：当前垃圾回收的原因 -gcnew统计新生代的行为123$ jstat -gcnew 28920 S0C S1C S0U S1U TT MTT DSS EC EU YGC YGCT 419392.0 419392.0 52231.8 0.0 6 6 209696.0 3355520.0 1172246.0 4 0.242 S0C：第一个幸存区大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 TT:对象在新生代存活的次数 MTT:对象在新生代存活的最大次数 DSS:期望的幸存区大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 -gcnewcapacity新生代与其相应的内存空间的统计123$ jstat -gcnewcapacity 28920 NGCMN NGCMX NGC S0CMX S0C S1CMX S1C ECMX EC YGC FGC 4194304.0 4194304.0 4194304.0 419392.0 419392.0 419392.0 419392.0 3355520.0 3355520.0 4 0 NGCMN：新生代最小容量 NGCMX：新生代最大容量 NGC：当前新生代容量(KB) S0CMX：最大幸存1区大小(KB) S0C：当前幸存1区大小(KB) S1CMX：最大幸存2区大小 S1C：当前幸存2区大小 ECMX：最大伊甸园区大小(KB) EC：当前伊甸园区大小(KB) YGC：年轻代垃圾回收次数 FGC：老年代回收次数 -gcold统计旧生代的行为123$ jstat -gcold 28920 PC PU OC OU YGC FGC FGCT GCT 1048576.0 46561.7 6291456.0 0.0 4 0 0.000 0.242 -gcoldcapacity统计旧生代的大小和空间123$ jstat -gcoldcapacity 28920 OGCMN OGCMX OGC OC YGC FGC FGCT GCT 6291456.0 6291456.0 6291456.0 6291456.0 4 0 0.000 0.242 -gcpermcapacity永生代行为统计123$ jstat -gcpermcapacity 28920 PGCMN PGCMX PGC PC YGC FGC FGCT GCT 1048576.0 2097152.0 1048576.0 1048576.0 4 0 0.000 0.242 -printcompilationhotspot编译方法统计123$ jstat -printcompilation 28920 Compiled Size Type Method 1291 78 1 java/util/ArrayList indexOf Compiled：被执行的编译任务的数量 Size：方法字节码的字节数 Type：编译类型 Method：编译方法的类名和方法名。类名使用”/” 代替 “.” 作为空间分隔符. 方法名是给出类的方法名. 格式是一致于HotSpot - XX:+PrintComplation 选项 jmapjmap(JVM Memory Map)命令用于生成heap dump文件，如果不使用这个命令，还阔以使用-XX:+HeapDumpOnOutOfMemoryError参数来让虚拟机出现OOM的时候·自动生成dump文件。 jmap不仅能生成dump文件，还阔以查询finalize执行队列、Java堆和永久代的详细信息，如当前使用率、当前使用的是哪种收集器等。 命令格式1jmap [option] LVMID option参数 dump : 生成堆转储快照 finalizerinfo : 显示在F-Queue队列等待Finalizer线程执行finalizer方法的对象 heap : 显示Java堆详细信息 histo : 显示堆中对象的统计信息 permstat : to print permanent generation statistics F : 当-dump没有响应时，强制生成dump快照 示例-dump常用格式1234567-dump::live,format=b,file=&lt;filename&gt; pid``` dump堆到文件,format指定输出格式，live指明是活着的对象,file指定文件名```bash$ jmap -dump:live,format=b,file=dump.hprof 28920 Dumping heap to /home/xxx/dump.hprof ... Heap dump file created dump.hprof这个后缀是为了后续可以直接用MAT(Memory Anlysis Tool)打开。 -finalizerinfo打印等待回收对象的信息123456$ jmap -finalizerinfo 28920 Attaching to process ID 28920, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.71-b01 Number of objects pending for finalization: 0 可以看到当前F-QUEUE队列中并没有等待Finalizer线程执行finalizer方法的对象。-heap打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况,可以用此来判断内存目前的使用情况以及垃圾回收情况123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051$ jmap -heap 28920 Attaching to process ID 28920, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.71-b01 using thread-local object allocation. Parallel GC with 4 thread(s)//GC 方式 Heap Configuration: //堆内存初始化配置 MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40) MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70) MaxHeapSize = 2082471936 (1986.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 1310720 (1.25MB)//对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小 MaxNewSize = 17592186044415 MB//对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小 OldSize = 5439488 (5.1875MB)//对应jvm启动参数-XX:OldSize=&lt;value&gt;:设置JVM堆的‘老生代’的大小 NewRatio = 2 //对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率 SurvivorRatio = 8 //对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 PermSize = 21757952 (20.75MB) //对应jvm启动参数-XX:PermSize=&lt;value&gt;:设置JVM堆的‘永生代’的初始大小 MaxPermSize = 85983232 (82.0MB)//对应jvm启动参数-XX:MaxPermSize=&lt;value&gt;:设置JVM堆的‘永生代’的最大大小 G1HeapRegionSize = 0 (0.0MB) Heap Usage://堆内存使用情况 PS Young Generation Eden Space://Eden区内存分布 capacity = 33030144 (31.5MB)//Eden区总容量 used = 1524040 (1.4534378051757812MB) //Eden区已使用 free = 31506104 (30.04656219482422MB) //Eden区剩余容量 4.614088270399305% used //Eden区使用比率 From Space: //其中一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% used To Space: //另一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% used PS Old Generation //当前的Old区内存分布 capacity = 86507520 (82.5MB) used = 0 (0.0MB) free = 86507520 (82.5MB) 0.0% used PS Perm Generation//当前的 “永生代” 内存分布 capacity = 22020096 (21.0MB) used = 2496528 (2.3808746337890625MB) free = 19523568 (18.619125366210938MB) 11.337498256138392% used 670 interned Strings occupying 43720 bytes. 可以很清楚的看到Java堆中各个区域目前的情况。-histo打印堆的对象统计，包括对象数、内存大小等等 （因为在dump:live前会进行full gc，如果带上live则只统计活对象，因此不加live的堆大小要大于加live堆的大小 ）1234567891011121314$ jmap -histo:live 28920 | more num #instances #bytes class name---------------------------------------------- 1: 83613 12012248 &lt;constMethodKlass&gt; 2: 23868 11450280 [B 3: 83613 10716064 &lt;methodKlass&gt; 4: 76287 10412128 [C 5: 8227 9021176 &lt;constantPoolKlass&gt; 6: 8227 5830256 &lt;instanceKlassKlass&gt; 7: 7031 5156480 &lt;constantPoolCacheKlass&gt; 8: 73627 1767048 java.lang.String 9: 2260 1348848 &lt;methodDataKlass&gt; 10: 8856 849296 java.lang.Class .... 仅仅打印了前10行xml class name是对象类型，说明如下： B byte C char D double F float I int J long Z boolean [ 数组，如[I表示int[] [L+类名 其他对象 -permstat打印Java堆内存的永久保存区域的类加载器的智能统计信息。对于每个类加载器而言，它的名称、活跃度、地址、父类加载器、它所加载的类的数量和大小都会被打印。此外，包含的字符串数量和大小也会被打印。123456789101112131415$ jmap -permstat 28920 Attaching to process ID 28920, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.71-b01 finding class loader instances ..done. computing per loader stat ..done. please wait.. computing liveness.liveness analysis may be inaccurate ... class_loader classes bytes parent_loader alive? type &lt;bootstrap&gt; 3111 18154296 null live &lt;internal&gt; 0x0000000600905cf8 1 1888 0x0000000600087f08 dead sun/reflect/DelegatingClassLoader@0x00000007800500a0 0x00000006008fcb48 1 1888 0x0000000600087f08 dead sun/reflect/DelegatingClassLoader@0x00000007800500a0 0x00000006016db798 0 0 0x00000006008d3fc0 dead java/util/ResourceBundle$RBClassLoader@0x0000000780626ec0 0x00000006008d6810 1 3056 null dead sun/reflect/DelegatingClassLoader@0x00000007800500a0 -F强制模式。如果指定的pid没有响应，请使用jmap -dump或jmap -histo选项。此模式下，不支持live子选项。 jhatjhat(JVM Heap Analysis Tool)命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP/HTML服务器，生成dump的分析结果后，可以在浏览器中查看。在此要注意，一般不会直接在服务器上进行分析，因为jhat是一个耗时并且耗费硬件资源的过程，一般把服务器生成的dump文件复制到本地或其他机器上进行分析。 命令格式1jhat [dumpfile] 参数 -stack false|true 关闭对象分配调用栈跟踪(tracking object allocation call stack)。 如果分配位置信息在堆转储中不可用. 则必须将此标志设置为 false. 默认值为 true.&gt; -refs false|true 关闭对象引用跟踪(tracking of references to objects)。 默认值为 true. 默认情况下, 返回的指针是指向其他特定对象的对象,如反向链接或输入引用(referrers or incoming references), 会统计/计算堆中的所有对象。&gt; -port port-number 设置 jhat HTTP server 的端口号. 默认值 7000.&gt; -exclude exclude-file 指定对象查询时需要排除的数据成员列表文件(a file that lists data members that should be excluded from the reachable objects query)。 例如, 如果文件列列出了 java.lang.String.value , 那么当从某个特定对象 Object o 计算可达的对象列表时, 引用路径涉及 java.lang.String.value 的都会被排除。&gt; -baseline exclude-file 指定一个基准堆转储(baseline heap dump)。 在两个 heap dumps 中有相同 object ID 的对象会被标记为不是新的(marked as not being new). 其他对象被标记为新的(new). 在比较两个不同的堆转储时很有用.&gt; -debug int 设置 debug 级别. 0 表示不输出调试信息。 值越大则表示输出更详细的 debug 信息.&gt; -version 启动后只显示版本信息就退出&gt; -J&lt; flag &gt; 因为 jhat 命令实际上会启动一个JVM来执行, 通过 -J 可以在启动JVM时传入一些启动参数. 例如, -J-Xmx512m 则指定运行 jhat 的Java虚拟机使用的最大堆内存为 512 MB. 如果需要使用多个JVM启动参数,则传入多个 -Jxxxxxx. 示例12345678910$ jhat -J-Xmx512m dump.hprof eading from dump.hprof... Dump file created Fri Mar 11 17:13:42 CST 2016 Snapshot read, resolving... Resolving 271678 objects... Chasing references, expect 54 dots...................................................... Eliminating duplicate references...................................................... Snapshot resolved. Started HTTP server on port 7000 Server is ready. 中间的-J-Xmx512m是在dump快照很大的情况下分配512M内存去启动HTTP服务器，运行完之后就可在浏览器打开Http://localhost:7000进行快照分析 堆快照分析主要在最后面的Heap Histogram里，里面根据class列出了dump的时候所有存活对象。分析同样一个dump快照，MAT需要的额外内存比jhat要小的多的多，所以建议使用MAT来进行分析，当然也看个人偏好。分析打开浏览器Http://localhost:7000，该页面提供了几个查询功能可供使用：1234567All classes including platformShow all members of the rootsetShow instance counts for all classes (including platform)Show instance counts for all classes (excluding platform)Show heap histogramShow finalizer summaryExecute Object Query Language (OQL) query 一般查看堆异常情况主要看这个两个部分： Show instance counts for all classes (excluding platform)，平台外的所有对象信息。如下图：Show heap histogram 以树状图形式展示堆情况。如下图：具体排查时需要结合代码，观察是否大量应该被回收的对象在一直被引用或者是否有占用内存特别大的对象无法被回收。一般情况，会down到客户端用工具来分析 jstackjstack用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。 命令格式1jstack [option] LVMID option参数 -F : 当正常输出请求不被响应时，强制输出线程堆栈 -l : 除堆栈外，显示关于锁的附加信息 -m : 如果调用到本地方法的话，可以显示C/C++的堆栈 示例12345678910111213141516171819202122232425262728$ jstack -l 11494|more2016-07-28 13:40:04Full thread dump Java HotSpot(TM) 64-Bit Server VM (24.71-b01 mixed mode):"Attach Listener" daemon prio=10 tid=0x00007febb0002000 nid=0x6b6f waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE Locked ownable synchronizers: - None"http-bio-8005-exec-2" daemon prio=10 tid=0x00007feb94028000 nid=0x7b8c waiting on condition [0x00007fea8f56e000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000cae09b80&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:104) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:32) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - None ..... 分析这里有一篇文章解释的很好 分析打印出的文件内容 jinfojinfo(JVM Configuration info)这个命令作用是实时查看和调整虚拟机运行参数。 之前的jps -v口令只能查看到显示指定的参数，如果想要查看未被显示指定的参数的值就要使用jinfo口令 命令格式1jinfo [option] [args] LVMID option参数 -flag : 输出指定args参数的值 -flags : 不需要args参数，输出所有JVM参数的值 -sysprops : 输出系统属性，等同于System.getProperties() 示例12$ jinfo -flag 11494-XX:CMSInitiatingOccupancyFraction=80]]></content>
      <categories>
        <category>OS</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>jps</tag>
        <tag>jstat</tag>
        <tag>jmap</tag>
        <tag>jhat</tag>
        <tag>jstack</tag>
        <tag>jinfo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC算法和垃圾回收器]]></title>
    <url>%2Fposts%2Fd67ec155.html</url>
    <content type="text"><![CDATA[概述垃圾收集 Garbage Collection 通常被称为“GC”，它诞生于1960年 MIT 的 Lisp 语言，经过半个多世纪，目前已经十分成熟了。 jvm 中，程序计数器、虚拟机栈、本地方法栈都是随线程而生随线程而灭，栈帧随着方法的进入和退出做入栈和出栈操作，实现了自动的内存清理，因此，我们的内存垃圾回收主要集中于 java 堆和方法区中，在程序运行期间，这部分内存的分配和使用都是动态的. 对象存活判断判断对象是否存活一般有两种方式：引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。不可达对象。在Java语言中，GC Roots包括： 虚拟机栈中引用的对象。 方法区中类静态属性实体引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI引用的对象。 垃圾收集算法标记 -清除算法“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。 它的主要缺点有两个：一个是效率问题，标记和清除过程的效率都不高；另外一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 这样使得每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为原来的一半，持续复制长生存期的对象则导致效率降低。 标记-压缩算法复制收集算法在对象存活率较高时就要执行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。 根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法GC分代的基本假设：绝大部分对象的生命周期都非常短暂，存活时间短。 “分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。 垃圾收集器1如果说收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现 Serial收集器串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。新生代、老年代使用串行回收；新生代复制算法、老年代标记-压缩；垃圾收集的过程中会Stop The World（服务暂停） 参数控制：-XX:+UseSerialGC 串行收集器 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本。新生代并行，老年代串行；新生代复制算法、老年代标记-压缩 参数控制：-XX:+UseParNewGC ParNew收集器-XX:ParallelGCThreads 限制线程数量 Parallel收集器Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。可以通过参数来打开自适应调节策略，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量；也可以通过参数控制GC的时间不大于多少毫秒或者比例；新生代复制算法、老年代标记-压缩 参数控制：-XX:+UseParallelGC使用Parallel收集器+ 老年代串行 Parallel Old 收集器Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。这个收集器是在JDK 1.6中才开始提供 参数控制：-XX:+UseParallelOldGC使用Parallel收集器+ 老年代并行 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。 从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤，包括： 初始标记（CMS initial mark） 并发标记（CMS concurrent mark） 重新标记（CMS remark） 并发清除（CMS concurrent sweep） 其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行。老年代收集器（新生代使用ParNew） 优点: 并发收集、低停顿缺点: 产生大量空间碎片、并发阶段会降低吞吐量 参数控制：-XX:+UseConcMarkSweepGC 使用CMS收集器-XX:+ UseCMSCompactAtFullCollection Full GC后，进行一次碎片整理；整理过程是独占的，会引起停顿时间变长-XX:+CMSFullGCsBeforeCompaction 设置进行几次Full GC后，进行一次碎片整理-XX:ParallelCMSThreads 设定CMS的线程数量（一般情况约等于可用CPU数量） G1收集器G1是目前技术发展的最前沿成果之一，HotSpot开发团队赋予它的使命是未来可以替换掉JDK1.5中发布的CMS收集器。与CMS收集器相比G1收集器有以下特点： 1、空间整合，G1收集器采用标记整理算法，不会产生内存空间碎片。分配大对象时不会因为无法找到连续空间而提前触发下一次GC。 2、可预测停顿，这是G1的另一大优势，降低停顿时间是G1和CMS的共同关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为N毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。 上面提到的垃圾收集器，收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔阂了，它们都是一部分（可以不连续）Region的集合。G1的新生代收集跟ParNew类似，当新生代占用达到一定比例的时候，开始出发收集。和CMS类似，G1收集器收集老年代对象会有短暂停顿。收集步骤： 1、标记阶段，首先初始标记(Initial-Mark),这个阶段是停顿的(Stop the World Event)，并且会触发一次普通Mintor GC。对应GC log:GC pause (young) (inital-mark) 2、Root Region Scanning，程序运行过程中会回收survivor区(存活到老年代)，这一过程必须在young GC之前完成。 3、Concurrent Marking，在整个堆中进行并发标记(和应用程序并发执行)，此过程可能被young GC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，会计算每个区域的对象活性(区域中存活对象的比例)。 4、Remark, 再标记，会有短暂停顿(STW)。再标记阶段是用来收集 并发标记阶段 产生新的垃圾(并发阶段和应用程序一同运行)；G1中采用了比CMS更快的初始快照算法:snapshot-at-the-beginning (SATB)。 5、Copy/Clean up，多线程清除失活对象，会有STW。G1将回收区域的存活对象拷贝到新区域，清除Remember Sets，并发清空回收区域并把它返回到空闲区域链表中。 6、复制/清除过程后。回收区域的活性对象已经被集中回收到深蓝色和深绿色区域。 常用的收集器组合 /* 第一列表格宽度 */ table th:nth-of-type(1){ width: 11%; } /* 第二列表格宽度 */ table th:nth-of-type(2){ width: 15%; } /* 第三列表格宽度 */ table th:nth-of-type(3){ width: 17%; } /* 第四列表格宽度 */ table th:nth-of-type(4){ width: 57%; } /* ... ... */ 服务器 新生代GC策略 老年老代GC策略 说明 组合1 Serial Serial Old Serial和Serial Old都是单线程进行GC，特点就是GC时暂停所有应用线程。 组合2 Serial CMS+Serial Old CMS（Concurrent Mark Sweep）是并发GC，实现GC线程和应用线程并发工作，不需要暂停所有应用线程。另外，当CMS进行GC失败时，会自动使用Serial Old策略进行GC。 组合3 ParNew CMS 使用-XX:+UseParNewGC选项来开启。ParNew是Serial的并行版本，可以指定GC线程数，默认GC线程数为CPU的数量。可以使用-XX:ParallelGCThreads选项指定GC的线程数。如果指定了选项-XX:+UseConcMarkSweepGC选项，则新生代默认使用ParNew GC策略。 组合4 ParNew Serial Old 使用-XX:+UseParNewGC选项来开启。新生代使用ParNew GC策略，年老代默认使用Serial Old GC策略。 组合5 Parallel Scavenge Serial Old Parallel Scavenge策略主要是关注一个可控的吞吐量：应用程序运行时间 / (应用程序运行时间 + GC时间)，可见这会使得CPU的利用率尽可能的高，适用于后台持久运行的应用程序，而不适用于交互较多的应用程序。 组合6 Parallel Scavenge Parallel Old Parallel Old是Serial Old的并行版本 组合7 G1GC G1GC -XX:+UnlockExperimentalVMOptions -XX:+UseG1GC #开启；-XX:MaxGCPauseMillis =50 #暂停时间目标；-XX:GCPauseIntervalMillis =200 #暂停间隔目标；-XX:+G1YoungGenSize=512m #年轻代大小；-XX:SurvivorRatio=6 #幸存区比例]]></content>
      <categories>
        <category>OS</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>GC</tag>
        <tag>垃圾回收器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存结构]]></title>
    <url>%2Fposts%2Fe614237b.html</url>
    <content type="text"><![CDATA[所有的Java开发人员和运维人员可能会遇到这样的困惑？我该为堆内存设置多大空间呢？OutOfMemoryError的异常到底涉及到运行时数据的哪块区域？该怎么解决呢？其实如果你经常解决服务器性能问题，那么这些问题就会变的非常常见，了解JVM内存也是为了服务器出现性能问题的时候可以快速的了解那块的内存区域出现问题，以便于快速的解决生产故障。 先看一张图，这张图能很清晰的说明JVM内存结构布局。JVM内存结构主要有三大块：堆内存、方法区和栈。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配； 方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)；栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。 在通过一张图来了解如何通过参数来控制各区域的内存大小控制参数 -Xms设置堆的最小空间大小。 -Xmx设置堆的最大空间大小。 -XX:NewSize设置新生代最小空间大小。 -XX:MaxNewSize设置新生代最大空间大小。 -XX:PermSize设置永久代最小空间大小。 -XX:MaxPermSize设置永久代最大空间大小。 -Xss设置每个线程的堆栈大小。 没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制。 老年代空间大小=堆空间大小-年轻代大空间大小 从更高的一个维度再次来看JVM和系统调用之间的关系方法区和对是所有线程共享的内存区域；而java栈、本地方法栈和程序员计数器是运行是线程私有的内存区域。 下面我们详细介绍每个区域的作用 Java堆（Heap）对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。 根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 方法区（Method Area）方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。 对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。 Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。 根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 方法区有时被称为持久代（PermGen）。所有的对象在实例化后的整个运行周期内，都被存放在堆内存中。堆内存又被划分成不同的部分：伊甸区(Eden)，幸存者区域(Survivor Sapce)，老年代（Old Generation Space）。 方法的执行都是伴随着线程的。原始类型的本地变量以及引用都存放在线程栈中。而引用关联的对象比如String，都存在在堆中。为了更好的理解上面这段话，我们可以看一个例子：123456789101112import java.text.SimpleDateFormat;import java.util.Date;import org.apache.log4j.Logger; public class HelloWorld &#123; private static Logger LOGGER = Logger.getLogger(HelloWorld.class.getName()); public void sayHello(String message) &#123; SimpleDateFormat formatter = new SimpleDateFormat(&quot;dd.MM.YYYY&quot;); String today = formatter.format(new Date()); LOGGER.info(today + &quot;: &quot; + message); &#125;&#125; 这段程序的数据在内存中的存放如下：通过JConsole工具可以查看运行中的Java程序（比如Eclipse）的一些信息：堆内存的分配，线程的数量以及加载的类的个数； 程序计数器（Program Counter Register）程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 JVM栈（JVM Stacks）与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。 其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈（Native Method Stacks）本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 哪儿的OutOfMemoryError对内存结构清晰的认识同样可以帮助理解不同OutOfMemoryErrors： 1Exception in thread “main”: java.lang.OutOfMemoryError: Java heap space 原因：对象不能被分配到堆内存中 1Exception in thread “main”: java.lang.OutOfMemoryError: PermGen space 原因：类或者方法不能被加载到持久代。它可能出现在一个程序加载很多类的时候，比如引用了很多第三方的库； 1Exception in thread “main”: java.lang.OutOfMemoryError: Requested array size exceeds VM limit 原因：创建的数组大于堆内存的空间 1Exception in thread “main”: java.lang.OutOfMemoryError: request &lt;size&gt; bytes for &lt;reason&gt;. Out of swap space? 原因：分配本地分配失败。JNI、本地库或者Java虚拟机都会从本地堆中分配内存空间。 1Exception in thread “main”: java.lang.OutOfMemoryError: &lt;reason&gt; &lt;stack trace&gt;（Native method） 原因：同样是本地方法内存分配失败，只不过是JNI或者本地方法或者Java虚拟机发现]]></content>
      <categories>
        <category>OS</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins发布SpringCloud微服务到WindowsServer]]></title>
    <url>%2Fposts%2F712db630.html</url>
    <content type="text"><![CDATA[SpringCloud微服务可以在Jenkins上配置Maven项目打包发布到Linux系统，打包后发布到远程系统上文件为jar包。需要Jenkins系统环境支持为：Git：用以从Gitlab&amp;Github拉取代码。Maven：用以对代码进行打包，打包成jar格式的服务包。Jdk：用以运行Jar包所需的Java环境。SpringCloud架构中的微服务本质为可以独立运行的jar包。Jenkins发布服务到WindosServer则需要以下步骤。 一、配置WindowsServer支持SSH1、配置SSH环境当前系统为WindowsServer2012R2，实现SSH连接windows服务器，需要使用PowerShell Server。从官网下载后安装，具体配置如下建议勾选Run as a Windows Service，然后启动12345[2018/12/19 14:46:02] [2808] [1] Starting (user initiated).[2018/12/19 14:46:02] [2808] [1] Starting PowerShell Server Win32 Service...[2018/12/19 14:46:03] [33576] [4] PowerShell Server Started. Version: 16.0.6801.[2018/12/19 14:46:03] [33576] [4] Max Connections: 5[2018/12/19 14:46:04] [2808] [8] PowerShell Server Win32 Service started. 出现以上信息表示启动成功关系客户端连接的日志信息、报错信息等都会出现在这个界面内，出现问题时候可以注意检查。PowerShell Server支持如下客户端： Putty on Windows Connect-PowerShellServer, Invoke-PowerShellServer, and Disconnect-PowerShellServer Cmdlets included in NetCmdlets. PSClient in IP*Works! SSH Any SSH client on a mobile device. OpenSSH with XTerm, gnome-terminal, Konsole. 具体链接过程不再演示系统用户名为administrator 远程端口为22 IP不变 密码不变 2、配置Java环境Java环境配置直接官网下载，默认安装即可，不再详细描述。只是要注意JAVA_HOME的路径即好。 二、Jenkins相关配置首先将WindowsServer的的远程密码配置进Jenkisn的全局凭据中。在配置中的SSH sites中和SSH Servers中添加WindowsServer，如下图所示：test显示成功则可以继续进行Jenkins Job的配置，Jenkins Job的配置和LinuxServer区别不大，不再详细描述。 三、WindowsServer相关脚本配置首先Jenkins发布的jar包会上传到上图二中所示，目录C:\work\service_jar下。 1、启动脚本关于启动脚本使用bat脚本jar包启动需要特殊权限，所以需要先获取管理员权限。脚本执行完成以后需要返回给Jenkins状态码0，不然Jenkins会提示报错，提示发布不稳定。完整脚本如下：12345678910111213141516171819202122232425@echo offecho Get Administrator privilegescacls.exe "%SystemDrive%\System Volume Information" &gt;nul 2&gt;nulif %errorlevel%==0 goto Adminif exist "%temp%\getadmin.vbs" del /f /q "%temp%\getadmin.vbs"echo Set RequestUAC = CreateObject^("Shell.Application"^)&gt;"%temp%\getadmin.vbs"echo RequestUAC.ShellExecute "%~s0","","","runas",1 &gt;&gt;"%temp%\getadmin.vbs"echo WScript.Quit &gt;&gt;"%temp%\getadmin.vbs""%temp%\getadmin.vbs" /fif exist "%temp%\getadmin.vbs" del /f /q "%temp%\getadmin.vbs"exit:Adminecho Get Administrator privileges Successfullyset YYYYmmdd=%date:~0,4%%date:~5,2%%date:~8,2%set t=%time:~,8%set t=%t::=%set t=%t: =0%SET JAVA_HOME="C:\jdk1.8"copy "%JAVA_HOME%\bin\java.exe" "%JAVA_HOME%\bin\riskArchiveService.exe""%JAVA_HOME%\bin\riskArchiveService.exe" -Xms1024M -Xmx1024M -Xmn385M -XX:+PrintGCDetails -jar C:\work\service_jar\riskArchiveService.jar --server.port=28000 --management.port=28001 --config.profile=pro --config.ip=http://172.16.109.142:17001/ &gt; C:\work\logs\riskArchiveService_%YYYYmmdd%_%t%.log 2&gt;&amp;1exit 0 脚本中讲java.execopy为servicename.exe，以此种方式启动后，则服务名为独立的，可以启动多个jar服务。如果进行此操作也可以启动，但是服务名为java.exe，则整个系统只能启动一个服务，不利于系统资源利用。可以从任务管理器和系统信息中查看启动的服务。 2、停止脚本WindowsServer上停止服务比较简单，依旧使用bat脚本，如下：12tasklist|find /i "riskArchiveService.exe"||exit 0taskkill -f -t -im riskArchiveService.exe 首先查找具体服务，如果服务不存在，则返回码为0。如果服务存在则taskkill。]]></content>
      <categories>
        <category>Automation</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>Windows</tag>
        <tag>PowerShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置http跳转到https]]></title>
    <url>%2Fposts%2F54491443.html</url>
    <content type="text"><![CDATA[现有域名test.com www.test.com配置https需要将http跳转到https，将test.com跳转到www.test.comNginx配置示例如下1234567891011121314151617181920212223242526272829303132333435363738server &#123; listen 80; server_name www.test.com test.com; rewrite ^(.*)$ https://$&#123;server_name&#125;$1 permanent; &#125;server &#123; listen 443; server_name www.test.com test.com; if ( $host != 'www.test.com' ) &#123; rewrite ^/(.*)$ https://www.test.com/$1 permanent; &#125; ssl on; ssl_certificate /data/nginx/cert/cert_www.test.com.crt; ssl_certificate_key /data/nginx/cert/cert_www.test.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; access_log logs/access_test.log main; error_log logs/error_test.log error; location / &#123; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow_Credentials' 'true'; add_header 'Access-Control-Allow-Headers' 'Authorization,Accept,Origin,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range'; add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS,PUT,DELETE,PATCH'; root /data/work/test; index login.html login.htm; error_page 405 =200 $uri; &#125;&#125; 以上配置访问http://www.test.com https://test.com https://test.com最终都会跳转到https://www.test.com也可以将配置一个server实例如下：12345678910111213141516171819202122232425262728293031323334server &#123; listen 80; listen 443 sssl; server_name www.test.com test.com; if ( $host != 'www.test.com' ) &#123; rewrite ^/(.*)$ https://www.test.com/$1 permanent; &#125; #ssl on; ssl_certificate /data/nginx/cert/cert_www.test.com.crt; ssl_certificate_key /data/nginx/cert/cert_www.test.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; access_log logs/access_test.log main; error_log logs/error_test.log error; location / &#123; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow_Credentials' 'true'; add_header 'Access-Control-Allow-Headers' 'Authorization,Accept,Origin,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range'; add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS,PUT,DELETE,PATCH'; root /data/work/test; index login.html login.htm; error_page 405 =200 $uri; &#125;&#125; 其中需要将ssl on;注释，将443修改为443 ssl。]]></content>
      <categories>
        <category>Service</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>http</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka基础文档]]></title>
    <url>%2Fposts%2Fce9c4656.html</url>
    <content type="text"><![CDATA[一、Kafka简介1、简介Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。Apache的Kafka™是一个分布式流平台(a distributed streaming platform)。这到底意味着什么？我们认为，一个流处理平台应该具有三个关键能力：（1）它可以让你发布和订阅记录流。在这方面，它类似于一个消息队列或企业消息系统。（2）它可以让你持久化收到的记录流，从而具有容错能力。（3）它可以让你处理收到的记录流。Kafka擅长哪些方面？它被用于两大类应用：（1）建立实时流数据管道从而能够可靠地在系统或应用程序之间的共享数据（2）构建实时流应用程序，能够变换或者对数据（3）进行相应的处理。想要了解Kafka如何具有这些能力，让我们从下往上深入探索Kafka的能力。首先，明确几个概念：（1）Kafka是运行在一个或多个服务器的集群(Cluster)上的。（2）Kafka集群分类存储的记录流被称为主题(Topics)。（3）每个消息记录包含一个键，一个值和时间戳。Kafka有四个核心API：（1）生产者 API 允许应用程序发布记录流至一个或多个Kafka的话题(Topics)。（2）消费者API允许应用程序订阅一个或多个主题，并处理这些主题接收到的记录流。（3）Streams API允许应用程序充当流处理器（stream processor），从一个或多个主题获取输入流，并生产一个输出流至一个或多个的主题，能够有效地变换输入流为输出流。（4）Connector API允许构建和运行可重用的生产者或消费者，能够把 Kafka主题连接到现有的应用程序或数据系统。例如，一个连接到关系数据库的连接器(connector)可能会获取每个表的变化。 2、应用场景主要应用场景是：（1）构建实时的流数据管道，可靠地获取系统和应用程序之间的数据。（2）构建实时流的应用程序，对数据流进行转换或反应。Kafka主要设计目标如下：（1）以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。（2）高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。（3）支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。（4）同时支持离线数据处理和实时数据处理。 3、Kafka的设计原理分析一个典型的kafka集群中包含若干producer，若干broker，若干consumer，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。producer使用push模式将消息发布到broker，consumer使用pull模式从broker订阅并消费消息。Kafka专用术语：Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。消费者可以订阅一个或多个主题(topic),并从Broker拉数据，从而消费这些已发布的消息。每个消息（也叫作record记录,也被称为消息）是由一个key，一个value和时间戳构成。Topic：一类消息，Kafka集群能够同时负责多个topic的分发。Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。Segment：partition物理上由多个segment组成。offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset，用于partition唯一标识一条消息。Producer：负责发布消息到Kafka broker，可以理解为生产者。Consumer：消息消费者，向Kafka broker读取消息的客户端，可以理解为生产者。Consumer Group：每个Consumer属于一个特定的Consumer Group。topic: 消息以topic为类别记录,Kafka将消息种子(Feed)分门别类,每一类的消息称之为一个主题(Topic)。 4、主题（Topic）和日志（Logs）作为Kafka对数据提供的核心抽象，主题是发布的数据流的类别或名称。主题在Kafka中，总是支持多订阅者的; 也就是说，主题可以有零个，一个或多个消费者订阅写到相应主题的数据. 对应每一个主题，Kafka集群会维护像一个如下这样的分区的日志：每个分区都是是一个有序的，不可变的，并且不断被附加的记录序列，—也就是一个结构化提交日志（commit log）。为了保证唯一标性识分区中的每个数据记录，分区中的记录每个都会被分配一个一个叫做偏移（offset）顺序的ID号。通过一个可配置的保留期，Kafka集群会保留所有被发布的数据，不管它们是不是已经被消费者处理。例如，如果保留期设置为两天，则在发布记录后的两天内，数据都可以被消费，之后它将被丢弃以释放空间。 卡夫卡的性能是不为因为数据量大小而受影响的，因此长时间存储数据并不成问题。事实上，在每个消费者上保留的唯一元数据是消费者在日志中的偏移位置。这个偏移由消费者控制：通常消费者会在读取记录时线性地提高其偏移值（offset++），但实际上，由于偏移位置由消费者控制，它可以以任何顺序来处理数据记录。事实上，在每个消费者上保留的唯一元数据是消费者在日志中的偏移位置。这个偏移由消费者控制：通常消费者会在读取记录时线性地提高其偏移值（offset++），但实际上，由于偏移位置由消费者控制，它可以以任何顺序来处理数据记录。 5、数据的分配（Distribution）在Kafka集群中，不同分区日志的分布在相应的不同的服务器节点上，每个服务器节点处理自己分区对应的数据和请求。每个分区都会被复制备份到几个（可配置）服务器节点，以实现容错容灾。 分布在不同节点的同一个分区都会有一个服务器节点作为领导者（”leader”）和0个或者多个跟随者（”followers”），分区的领导者会处理所有的读和写请求，而跟随者只会被动的复制领导者。如果leader挂了, 一个follower会自动变成leader。每个服务器都会作为其一些分区的领导者，但同时也可能作为其他分分区的跟随者，Kafka以此来实现在集群内的负载平衡。 6、生产者生产者将数据发布到他们选择的主题。 生产者负责选择要吧数据分配给主题中哪个分区。这可以通过循环方式（round-robin）简单地平衡负载，或者可以根据某些语义分区（例如基于数据中的某些关键字）来完成。 7、消费者消费者们使用消费群组名称来标注自己，几个消费者共享一个组群名，每一个发布到主题的数据会被传递到每个消费者群组中的一个消费者实例。 消费者实例可以在不同的进程中或不同的机器上。 如果所有的消费者实例具有相同的消费者组，则记录将在所有的消费者实例上有效地负载平衡,每个数据只发到了一个消费者 如果所有的消费者实例都有不同的消费者群体，那么每个记录将被广播给所有的消费者进程，每个数据都发到了所有的消费者。 8、Kafka作为消息系统消息系统传统上有两种模式: 队列和发布-订阅. 在队列中，消费者池可以从服务器读取，每条记录都转到其中一个; 在发布订阅中，记录将广播给所有消费者。 这两个模型中的每一个都有优点和缺点。 排队的优点是它允许您在多个消费者实例上分配数据处理，从而可以扩展您的处理。 不幸的是，队列支持多用户，一旦一个进程读取数据就没有了。 发布订阅允许您将数据广播到多个进程，但无法缩放和扩容，因为每个消息都发送给每个订阅用户。 卡夫卡消费群体概念概括了这两个概念。 与队列一样，消费者组允许您通过一系列进程（消费者组的成员）来划分处理。 与发布订阅一样，Kafka允许您将消息广播到多个消费者组。 Kafka模型的优点是，每个主题都具有这两个属性，它可以进行缩放处理，也是多用户的，没有必要选择一个而放弃另一个。 卡夫卡也比传统的消息系统有更强大的消息次序保证。 传统队列在服务器上保存顺序的记录，如果多个消费者从队列中消费，则服务器按照存储顺序输出记录。 然而，虽然服务器按顺序输出记录，但是记录被异步传递给消费者，所以它们可能会在不同的消费者处按不确定的顺序到达。 这意味着在并行消耗的情况下，记录的排序丢失。 消息传递系统通常通过使“唯一消费者”的概念只能让一个进程从队列中消费，但这当然意味着处理中没有并行性。 卡夫卡做得更好。通过分区，在一个主题之内的并行处理，Kafka能够在消费者流程池中，即提供排序保证，也负载平衡。这是通过将主题中的分区分配给消费者组中的消费者来实现的，以便每一个分区由组中的一个消费者使用。 通过这样做，我们确保消费者是该分区的唯一读者，并按顺序消耗数据。 由于有许多分区，这仍然平衡了许多消费者实例的负载。 但是请注意，消费者组中的消费者实例个数不能超过分区的个数。 9、Kafka作为存储系统任何允许发布消息，解耦使用消息的消息队列，都在本质上充当传输中途消息的存储系统。 卡夫卡的不同之处在于它是一个很好的存储系统。 写入Kafka的数据写入磁盘并进行复制以进行容错。 Kafka允许生产者等待写入完成的确认，这样在数据完全复制之前，写入是未完成的，并且即使写入服务器失败，也保证持久写入。 Kafka的磁盘结构使用可以很好的扩容，无论您在服务器上是否有50KB或50TB的持久数据，Kafka都能保持稳定的性能。 由于对存储花费了很多精力，并允许客户端控制其读取位置，您可以将Kafka视为，专用于高性能，低延迟的日志存储复制和传播的专用分布式文件系统。任何允许发布消息，解耦使用消息的消息队列，都在本质上充当传输中途消息的存储系统。 卡夫卡的不同之处在于它是一个很好的存储系统。 写入Kafka的数据写入磁盘并进行复制以进行容错。 Kafka允许生产者等待写入完成的确认，这样在数据完全复制之前，写入是未完成的，并且即使写入服务器失败，也保证持久写入。 Kafka的磁盘结构使用可以很好的扩容，无论您在服务器上是否有50KB或50TB的持久数据，Kafka都能保持稳定的性能。 由于对存储花费了很多精力，并允许客户端控制其读取位置，您可以将Kafka视为，专用于高性能，低延迟的日志存储复制和传播的专用分布式文件系统。 10、Kafka用于流数据处理仅读取，写入和存储数据流是不够的，Kafka的目的是实现流的实时处理。 在Kafka中，流处理器的定义是：任何从输入主题接收数据流，对此输入执行一些处理，并生成持续的数据流道输出主题的组件。 例如，零售应用程序可能会收到销售和出货的输入流，并输出根据该数据计算的重新排序和价格调整的输出流。 当然我们也可以直接用producer and consumer APIs在做简单的出列. 然而对于更复杂的转换，Kafka提供了一个完全集成的Streams API。这允许我们构建应用程序进行更复杂的运算，或者聚合，或将流连接在一起。 该设施有助于解决这种类型的应用程序面临的困难问题：处理无序数据，重新处理输入作为代码更改，执行有状态计算等。 Stream API基于Kafka提供的核心原语构建：它使用生产者和消费者API进行输入，使用Kafka进行有状态存储，并在流处理器实例之间使用相同的组机制来实现容错。仅读取，写入和存储数据流是不够的，Kafka的目的是实现流的实时处理。 在Kafka中，流处理器的定义是：任何从输入主题接收数据流，对此输入执行一些处理，并生成持续的数据流道输出主题的组件。 例如，零售应用程序可能会收到销售和出货的输入流，并输出根据该数据计算的重新排序和价格调整的输出流。 当然我们也可以直接用producer and consumer APIs在做简单的出列. 然而对于更复杂的转换，Kafka提供了一个完全集成的Streams API。这允许我们构建应用程序进行更复杂的运算，或者聚合，或将流连接在一起。 该设施有助于解决这种类型的应用程序面临的困难问题：处理无序数据，重新处理输入作为代码更改，执行有状态计算等。 Stream API基于Kafka提供的核心原语构建：它使用生产者和消费者API进行输入，使用Kafka进行有状态存储，并在流处理器实例之间使用相同的组机制来实现容错。综上所述：消息系统，数据存储和流处理的这种组合似乎是不寻常的，但是这些特性对于Kafka作为流媒体平台的角色至关重要。 像HDFS这样的分布式文件系统允许存储用于批处理的静态文件。 本质上，这样的系统允许存储和处理来自过去的历史数据。 传统的企业邮消息系统允许处理将在您订阅之后到达的未来消息。 以这种方式构建的应用程序在未来数据到达时即使处理。 Kafka结合了这两种功能，这种组合对于Kafka作为流应用程序和流数据管道平台来说至关重要。 通过组合存储和低延迟订阅，流式应用程序可以以相同的方式处理过去和未来的数据。 这是一个单一的应用程序可以处理历史记录数据，而不是在到达最后一个记录时结束，它可以随着将来的数据到达而继续处理。 这是一个广泛的流处理概念，其中包含批处理以及消息驱动应用程序。 同样，对于流数据流水线，订阅到实时事件的组合使得可以使用Kafka进行非常低延迟的管道传输; 可靠地存储数据的能力使得可以将其用于必须保证数据传送的关键数据，或者与仅负载数据的离线系统集成，或者可能会长时间停机以进行维护。流处理功能在数据到达时进行数据转换处理。 二、Kafka安装Kafka需要Zookeeper的监控，所以先要安装Zookeeper。新版本Kafka拥有自带的zookeeper，也可以不用安装zookeeper，根据选择的kafka版本确定。Zookeeper需要java环境支持，所以先要安装jdk。 1、JDK安装检查系统是否已经安装jdk1java -version 如果没有显示java版本信息，则表示没有安装java12345678910#安装javatar -zxvf jdk-8u161-linux-x64.tar.gzmv jdk1.8.0_161 /data/jdk1.8#修改系统变量vi /etc/profile#在文本末尾添加以下内容：PATH=/data/jdk1.8/bin:$PATHexport PATH#使添加内容生效 source /etc/profile 再查看java版本 出现如下信息表示安装成功1234# java -versionjava version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 2、Zookeeper安装官网下载地址：http://apache.fayea.com/zookeeper/stable/Zookeeper属于可选安装1234567891011#下载wget http://apache.fayea.com/zookeeper/stable/zookeeper-3.4.10.tar.gztar -zxvf zookeeper-3.4.10.tar.gz mv zookeeper-3.4.10 /data/zookeepercd /data/zookeeper/#创建数据目录mkdir /data/zookeeper/datacd conf/#创建配置文件cp zoo_sample.cfg zoo.cfg vim zoo.cfg zoo.cfg修改后为12345tickTime=2000initLimit=10syncLimit=5dataDir=/data/zookeeper/dataclientPort=2181 配置环境变量：vim /etc/profile，加入以下内容12export ZOOKEEPER_HOME=/data/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf source /etc/profile使新增加环境变量生效zookeeper相关命令123456#开启/data/zookeeper/bin/zkServer.sh start#停止/data/zookeeper/bin/zkServer.sh status#查看状态/data/zookeeper/bin/zkServer.sh status 3、Kafka安装官网下载地址：http://kafka.apache.org/downloads本次下载最新版本123wget http://mirror.bit.edu.cn/apache/kafka/1.1.0/kafka_2.12-1.1.0.tgztar -zxvf kafka_2.12-1.1.0.tgz mv kafka_2.12-1.1.0 /data/kafka 修改配置文件12cd /data/kafka/vim config/server.properties Server.properties修改后为12345678910111213141516171819broker.id=0port=9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/data/kafka/logs/kafka-logsnum.partitions=1num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=localhost:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0 修改关于zookeeper的配置文件zookeeper.properties1vim config/zookeeper.properties zookeeper.properties修改后为123dataDir=/data/kafka/zkdataclientPort=2181maxClientCnxns=0 在kafka目录启动zookeeper12cd /data/kafkabin/zookeeper-server-start.sh config/zookeeper.properties &amp; 启动kafka1bin/kafka-server-start.sh config/server.properties &amp; 以后台方式启动1234#zookeepernohup zookeeper-server-start.sh /data/kafka/config/zookeeper.properties 1&gt;/dev/null 2&gt;&amp;1 &amp;#kafkanohup kafka-server-start.sh /data/kafka/config/server.properties 1&gt;/dev/null 2&gt;&amp;1 &amp; kafka启动时候需要zookeeper，可以使用单独的zookeeper，也可以启动kafka中已集成的zookeeper。]]></content>
      <categories>
        <category>Service</category>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>Message</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大日志文件进行分割的N种方法]]></title>
    <url>%2Fposts%2Ff58e63b6.html</url>
    <content type="text"><![CDATA[当日志容量上G的时候，用vi查看具体内容效率就会变得特别低，这个时候就需要将大日志进行分割。为了比较各种分割方法的效果，我选取的测试日志基本信息如下：1234# ls -lrth test.log-rw-r--r-- 1 root root 645M 5月 30 20:42 test.log# wc -l test.log8856340 test.log 1、split方法分割split命令专门用来将一个大文件分割成很多个小文件，我把split命令的选项做一个简要说明 选项 含义 -b 分割后的文档大小，单位是byte -C 分割后的文档，单行最大byte数 -d 使用数字作为后缀，同时使用-a length指定后缀长度 -l 分割后文档的行数 为了尽量保证日志的可读性，我们按行分割大日志文件，并且指定分割后的文件的前缀和后缀 123456789101112131415#后缀是数字，占两位，前缀是test.logsplit -l 1000000 test.log -d -a 2 test.log#分割之后的结果ls -lrth总用量 1.3G-rw-r--r-- 1 root root 645M 5月 30 20:42 test.log-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log00-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log01-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log02-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log03-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log04-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log05-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log06-rw-r--r-- 1 root root 73M 5月 30 20:55 test.log07-rw-r--r-- 1 root root 64M 5月 30 20:55 test.log08 2、dd分割123dd bs=1M count=300 if=test.log of=newlog.1dd bs=1M count=300 if=test.log of=newlog.2 skip=300dd bs=1M count=300 if=test.log of=newlog.3 skip=600 分割后的效果123456ls -lrth总用量 1.3G-rw-r--r-- 1 root root 645M 5月 30 20:42 test.log-rw-r--r-- 1 root root 300M 5月 30 21:07 newlog.1-rw-r--r-- 1 root root 300M 5月 30 21:07 newlog.2-rw-r--r-- 1 root root 45M 5月 30 21:07 newlog.3 在上面使用的命令中，bs代表数据块的大小，count表示复制的块数，if表示输入文件，of表示输出文件。这个命令不能一下就把文件分割到我们想要的状态，而且很有可能一行日志被分到两个文件中。 3、head+tail分割用这两个命令获取文件部分内容，然后重定向就能实现文件分割，但是限制也挺多，只能把文件分成两部分，如果文件特别大，想要达到预期的效果，就要一直分割下去。head/tail -n $行数 test.log &gt; newlog因为这两个命令都比较熟悉，不再多讲。 4、sed实现分割实现原理就是用sed截取特定行之间的内容，然后进行重定向。12345sed -n '1,2000000p' test.log &gt; test.log.1sed -n '2000001,4000000p' test.log &gt; test.log.2sed -n '4000001,6000000p' test.log &gt; test.log.3sed -n '6000001,8000000p' test.log &gt; test.log.4sed -n '8000001,$p' test.log &gt; test.log.5 $表示最后一行，这个如果分割过多，也需要一个循环。 5、awk实现分割实现原理和sed差不多，因为使用awk不多，这里只举一个小例子：12awk ‘&#123;if (NR&lt;120000) print $0&#125;’ test.log &gt; a.txtawk ‘&#123;if (NR&gt;=120000) print $0&#125;’ test.log &gt; b.txt 还是split用得舒服。]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>日志</tag>
        <tag>分割</tag>
        <tag>split</tag>
        <tag>dd</tag>
        <tag>head</tag>
        <tag>tail</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装Nodejs]]></title>
    <url>%2Fposts%2F1e4469a2.html</url>
    <content type="text"><![CDATA[Node官方地址：https://nodejs.org/en/选择LTS最新版本 1、二进制包安装1234wget https://nodejs.org/dist/v10.14.2/node-v10.14.2-linux-x64.tar.xztar -d node-v10.14.2-linux-x64.tar.xztar -xvf node-v8.11.3-linux-x64.tarmv node-v8.11.3-linux-x64 /data/node 配置环境变量1vim /etc/profile 最后加入以下内容并保存12#set node environmentexport PATH=/data/node/bin:$PATH 执行以下命令，使环境变量生效1source /etc/profile 验证nodejs是否安装成功。12# node -vv8.11.3 出现以上信息即表示node安装成功。 2、源码包编译安装123456wget https://nodejs.org/dist/v10.14.2/node-v10.14.2.tar.gztar -zxvf node-v10.14.2.tar.gzcd node-v10.14.2./configure –prefix=/data/nodemakemake install 配置环境变量1vim /etc/profile 最后加入以下内容并保存12#set node environmentexport PATH=/data/node/bin:$PATH 执行以下命令，使环境变量生效1source /etc/profile 验证nodejs是否安装成功。12# node -vv8.11.3 出现以上信息即表示node安装成功。]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装Maven]]></title>
    <url>%2Fposts%2Ff5410423.html</url>
    <content type="text"><![CDATA[1、下载打开官方下载地址：http://maven.apache.org/download.cgi选择版本下载，选择最优版本Maven3.3.9下载链接为：http://mirror.bit.edu.cn/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz直接通过wget下载12cd /data/backupwget http://mirror.bit.edu.cn/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz 2、安装解压Maven并移动到/data目录下12tar -zxvf apache-maven-3.3.9-bin.tar.gzmv apache-maven-3.3.9 /data/maven3 配置环境变量1vim /etc/profile 最后加入以下内容并保存1234#set maven environmentMAVEN_HOME=/data/maven3export MAVEN_HOMEexport PATH=$&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;/bin 执行以下命令，使环境变量生效1source /etc/profile 验证maven是否安装成功。1234567# mvn -vApache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)Maven home: /data/maven3Java version: 1.8.0_161, vendor: Oracle CorporationJava home: /data/jdk1.8/jreDefault locale: en_US, platform encoding: UTF-8OS name: "linux", version: "3.10.0-693.2.2.el7.x86_64", arch: "amd64", family: "unix" 出现以上信息即表示maven安装成功。]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装Java环境]]></title>
    <url>%2Fposts%2Fa4e9a4f1.html</url>
    <content type="text"><![CDATA[检查系统是否已经安装jdk1java -version 如果没有显示java版本信息，则表示没有安装java下载地址：http://www.oracle.com/technetwork/cn/java/javase/downloads/jdk8-downloads-2133151-zhs.html如果有更新最新版本，可以获取最新版本下载，需要同意协议才可获取下载链接，在服务器上可以通过wget下载 #安装java12tar -zxvf jdk-8u161-linux-x64.tar.gzmv jdk1.8.0_161 /data/jdk1.8 #修改系统变量1vi /etc/profile 在文本末尾添加以下内容：123#set java environmentPATH=/data/jdk1.8/bin:$PATHexport PATH 使添加内容生效1source /etc/profile 再查看java版本1234# java -versionjava version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 出现如下信息表示安装成功]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB基础文档]]></title>
    <url>%2Fposts%2Fdc462543.html</url>
    <content type="text"><![CDATA[一、 MongoDB简介1、MongoDB历史MongoDB最初于2007年开发，当时公司正在建立一个类似于窗口天蓝(window azure)的服务平台。“Window azure是由Microsoft创建的云计算平台和基础设施，通过全球网络构建，部署和管理应用程序和服务。”MongoDB由位于纽约的一个名为10gen的组织开发，现在被称为MongoDB Inc.，它最初被开发为PAAS(平台即服务)。 2009年晚些时候，它被作为一个由MongoDB公司维护和支持的开源数据库服务器在市场上引入。MongoDB的第一个真正产品是从2010年3月发布的MongoDB 1.4版本开始的。2014年1月10日发布的最新版本：MongoDB2.4.9。首先应该知道什么是面向文档的数据库？面向文档的数据库示例MongoDB是面向文档的数据库。这是MongoDB的一个主要功能。它提供面向文档的存储。这很简单，可以很容易地编程。MongoDB将数据存储为文档，因此被称为面向文档的数据库。12345FirstName = "Max", Address = "Haikou City", Spouse = [&#123;Name: "Maxsu"&#125;]. FirstName ="Kobe", Address = "LAC" 有两个不同的文件(用“.”分隔开)。以这种方式存储数据称为面向文档的数据库。 Mongodb属于一类名为面向文档数据库(Document Oriented Databases)。它属于一个叫作“NoSQL数据库”的数据库类别称。 2、MongoDB特点MongoDB的一些重要功能特性： 支持特别查询在MongoDB中，可以通过字段，范围查询进行搜索，并且还支持正则表达式搜索。 索引可以索引文档中的任何字段。 复制MongoDB支持主从复制。主机可以执行读写操作，从机从主机复制数据，只能用于读取或备份(不写入) 复制数据MongoDB可以在多台服务器上运行。 复制数据以保持系统正常运行，并在硬件故障的情况下保持其运行状态。 负载均衡由于数据放在碎片中，因此具有自动负载平衡配置。 支持映射缩减和聚合工具 使用JavaScript而不是Procedure 它是一个用C++编写的无模式数据库 提供高性能 轻松存储任何大小的文件，而不会使您的堆栈复杂化 在故障的情况下易于管理 具有动态模式的JSON数据模型 自动分片用于水平可扩展性 内置复制高可用性现在，许多公司使用 MongoDB 来创建新类型的应用程序，以提高性能和可用性。 3、MongoDB数据库的优点到目前为止，MongoDB是一个新的和普遍使用的数据库。它是一个基于文档的非关系数据库提供程序。虽然它比传统的数据库快100倍，但早期说它将广泛地取代传统的RDBMS。但是，不可否认的是：在性能和可扩展性方面 MongoDB 有着明显的优势。关系数据库具有典型的架构设计，可以显示表的数量以及这些表之间的关系，而在MongoDB中则没有关系的概念。（1）MongoDB优点 * MongoDB 的架构较少。它是一个文档数据库，它的一个集合持有不同的文档。 * 从一个到另一个的文档的数量，内容和大小可能有差异。 * MongoDB 中单个对象的结构很清淅。 * MongoDB 中没有复杂的连接。 * MongoDB 提供深度查询的功能，因为它支持对文档的强大的动态查询。 * MongoDB 很容易扩展。 * 它使用内部存储器来存储工作集，这是其快速访问的原因。 （2）MongoDb的独特功能 * 使用方便 * 重量轻/轻量级 * 比RDBMS快得多 （3）MongoDB应用场景 * 大而复杂的数据 * 移动和社会基础设施数据 * 内容管理和交付 * 用户数据管理 * 数据中心 （4）MongoDB和RDBMS的性能分析 * 在关系数据库(RDBMS)中，表用作存储元素，而在 MongoDB 中使用的是集合。 * 在RDBMS中有多个模式，在每个模式中，可创建用于存储数据的表，而 MongoDB 是面向文档的数据库，数据是以类似JSON格式的BSON格式编写的存储的。 * MongoDB几乎比传统数据库系统快100倍。 4、MongoDB快速入门MongoDB是一个跨平台，面向文档的数据库，提供高性能，高可用性和易于扩展。MongoDB是工作在集合和文档上一种概念。数据库数据库是一个集合的物理容器。每个数据库获取其自己设定在文件系统上的文件。一个单一的MongoDB服务器通常有多个数据库。集合集合是一组MongoDB的文件。它与一个RDBMS表是等效的。一个集合存在于数据库中。集合不强制执行模式。集合中的文档可以有不同的字段。通常情况下，在一个集合中的所有文件都是类似或相关目的。文档文档是一组键值对。文档具有动态模式。动态模式是指，在同一个集合的文件不必具有相同一组集合的文档字段或结构，并且相同的字段可以保持不同类型的数据。 二、MongoDB安装1、下载MongoDb的linux版本下载地址为https://www.mongodb.org/dl/linux/选择合适的版本下载1234wget http://downloads.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.2.20.tgz?_ga=2.11328048.543796309.1528358506-412859566.1526522668mv mongodb-linux-x86_64-rhel70-3.2.20.tgz\?_ga\=2.11328048.543796309.1528358506-412859566.1526522668 mongodb-linux-x86_64-rhel70-3.2.20.tgztar -zxvf mongodb-linux-x86_64-rhel70-3.2.20.tgz mv mongodb-linux-x86_64-rhel70-3.2.20 /data/mongodb 2、安装将Mongod移动到/data目录下，然后加入系统环境变量12#set mongodb environmentexport PATH=/data/mongodb/bin:$PATH 执行以下命令使配置生效1source /etc/profile 新建log、data、conf目录，如下123456789101112# pwd/data/mongodb# lltotal 104drwxr-xr-x 2 root root 4096 Jun 7 04:16 bindrwxr-xr-x 2 root root 6 Jun 7 04:29 confdrwxr-xr-x 4 root root 4096 Jun 7 04:43 data-rw-r--r-- 1 root root 34520 May 8 18:08 GNU-AGPL-3.0drwxr-xr-x 2 root root 6 Jun 7 04:43 log-rw-r--r-- 1 root root 16726 May 8 18:08 MPL-2-rw-r--r-- 1 root root 2262 May 8 18:08 README-rw-r--r-- 1 root root 35910 May 8 18:08 THIRD-PARTY-NOTICES mongodb的bin下各工具的用途： * mongod：数据库服务端，类似mysqld，每个实例启动一个进程，可以fork为Daemon运行 * mongo：客户端命令行工具，类似sqlplus/mysql，其实也是一个js解释器，支持js语法 * mongodump/mongorestore：将数据导入为bson格式的文件/将bson文件恢复为数据库，类似xtracbackup * mongoexport/mongoimport：将collection导出为json/csv格式数据/将数据导入数据库，类似mysqldump/mysqlimport * bsondump：将bson格式的文件转储为json格式的数据 * mongos：分片路由，如果使用了sharding功能，则应用程序连接的是mongos而不是mongod * mongofiles：GridFS管理工具 * mongostat：实时监控工具启动mongodb 启动1mongod --dbpath /data/mongodb/data/ 出现以下信息表示启动成功 3、配置配置mongodb1234567891011# cat conf/mongodb.conf dbpath=/data/mongodb/datalogpath=/data/mongodb/log/mongodb.logpidfilepath=/data/mongodb/data/mongodb.pidlogappend=true#bind_ip=10.186.21.85bind_ip=0.0.0.0port=27017maxConns=20000fork=true#auth = true # 先关闭, 创建好用户在启动 mongod的主要参数有：dbpath: 数据文件存放路径，每个数据库会在其中创建一个子目录。logpath：错误日志文件logappend： 错误日志采用追加模式（默认是覆写模式）bind_ip： 对外服务的绑定ip，一般设置为空，及绑定在本机所有可用ip上，如有需要可以单独指定。只能绑定本机网卡上绑定的ip地址，如果指定ip没有绑定在本机网卡，则绑定0.0.0.0，此种情况适用于绑定云服务器的外网ip。port： 对外服务端口。Web管理端口在这个port的基础上+1000fork： 以后台Daemon形式运行服务journal：开启日志功能，通过保存操作日志来降低单机故障的恢复时间，在1.8版本后正式加入，取代在1.7.5版本中的dur参数。syncdelay： 执行sync的间隔，单位为秒。directoryperdb： 每个db存放在单独的目录中，建议设置该参数。maxConns： 最大连接数repairpath： 执行repair时的临时目录。在如果没有开启journal，异常宕机后重启，必须执行repair操作。此时可以指定配置文件启动mongodb1234# mongod -f /data/mongodb/conf/mongodb.conf about to fork child process, waiting until server is ready for connections.forked process: 20815child process started successfully, parent exiting 以上即表示启动成功 4、管理mongodb服务官网文档https://docs.mongodb.com/manual/tutorial/manage-mongodb-processes/#stop-mongod-processesStart mongod Processes（1）mongod（2）mongod –dbpath /srv/mongodb/（3）mongod –port 12345（4）mongod –fork –logpath /var/log/mongodb.log（5）mongod -f /data/mongodb/conf/mongodb.confStop mongod Processes（1）Use shutdownServer()12use admin db.shutdownServer() （2）Use –shutdown1mongod –shutdown （3）Use CTRL-C（4）Use kill12kill &lt;mongod process ID&gt;kill -2 &lt;mongod process ID&gt; 禁止使用-912WARNING:Never use kill -9 (i.e. SIGKILL) to terminate a mongod instance. 5、修复monogdb当出现服务器非正常关机的情况，重新启动的时候会出现以下类似报错12ERROR: child process failed, exited with error number 100ERROR: child process failed, exited with error number 48 解决方法为123mongod -f /data/mongodb/conf/mongodb.conf –repairmongod -f /data/mongodb/conf/mongodb.conf --authmongod -f /data/mongodb/conf/mongodb.conf 通过repair修复连接mongodb方法为1mongo --host 101.132.37.169:27017 其中ip地址为配置文件中bind_ip地址，如果是本地可以直接mongo连接6、打开网页在mongodb.conf配置文件中加入以下参数1rest=true 即可打开网页端口，默认为28017，如图所示 三、MongoDB操作1、用户操作创建用户12use admin db.createUser(&#123;user:"root",pwd:"root",roles:[&#123;role:"readWrite",db:"admin"&#125;]&#125;) 查看已存在的用户123&gt; db.system.users.find()&#123; "_id" : "admin.root", "user" : "root", "db" : "admin", "credentials" : &#123; "SCRAM-SHA-1" : &#123; "iterationCount" : 10000, "salt" : "1hkiX4Tscoj6bUpxF2x7+A==", "storedKey" : "ciyQR1bc5Bbm6Qxg4euAijnadCw=", "serverKey" : "F/Gg0NmM19ih62VjbccW/SYOAh4=" &#125; &#125;, "roles" : [ &#123; "role" : "root", "db" : "admin" &#125; ] &#125;&#123; "_id" : "testdb.testdb", "user" : "testdb", "db" : "testdb", "credentials" : &#123; "SCRAM-SHA-1" : &#123; "iterationCount" : 10000, "salt" : "VhSm/77+cGXEUwYAbdHvSw==", "storedKey" : "hDtO9gq4OVNdcChNSoRhYiXmSQQ=", "serverKey" : "L1bPBquYwey5O0BYsDl7zsiSojs=" &#125; &#125;, "roles" : [ &#123; "role" : "dbOwner", "db" : "testdb" &#125; ] &#125; 删除用户12&gt; db.system.users.remove(&#123;user:"testdb1u1"&#125;)WriteResult(&#123; "nRemoved" : 1 &#125;) 用户登录数据库测试1mongo -u testdb -p 123456 127.0.0.1:27017/testdb 2、数据库操作创建数据库12&gt; use newdbswitched to db newdb 检查当前选择的数据库12&gt; dbnewdb 检查数据库列表123&gt; show dbsadmin 0.000GBlocal 0.000GB 新创建的数据库(newdb)不在列表中。要显示数据库，需要至少插入一个文档，否则空的数据库是不显示出来的。123456&gt; db.items.insert(&#123;"name":"yiibai tutorials"&#125;)WriteResult(&#123; "nInserted" : 1 &#125;)&gt; show dbsadmin 0.000GBlocal 0.000GBnewdb 0.000GB 在 MongoDB 中默认数据库是：test。 如果您还没有创建过任何数据库，则集合/文档将存储在test数据库中。删除数据库MongoDB中的 db.dropDatabase()命令用于删除现有的数据库。123456789101112131415&gt; show dbsadmin 0.000GBlocal 0.000GBnewdb 0.000GB&gt; show dbsadmin 0.000GBlocal 0.000GBnewdb 0.000GB&gt; dbnewdb&gt; db.dropDatabase()&#123; "dropped" : "newdb", "ok" : 1 &#125;&gt; show dbsadmin 0.000GBlocal 0.000GB 以上过程已把数据库newdb删除 四、MongoDB集群1、MongoDB主从模式搭建（1）Master-Slave搭建两台服务器IP分别为：10.186.21.85（主）、10.186.21.84（从）关于mongodb的详细配置可以从配置文件看到主库配置文件1234567891011121314151617181920# cat /data/mongodb/conf/mongodb.conf dbpath=/data/mongodb/data #数据库路径logpath=/data/mongodb/log/mongodb.log #日志输出文件路径logappend=true #日志输出方式pidfilepath=/data/mongodb/data/mongodb.pid #pid文件路径#bind_ip=10.186.21.85bind_ip=0.0.0.0port=27017 #端口号rest=true #设置后打开28017网页端口httpinterface=truemaxConns=20000fork=true #设置后台运行shardsvr=true#directoryperdb=true#auth = true # 先关闭, 创建好用户在启动#nohttpinterface=falsejournal=truequiet=truemaster=true 从库配置文件123456789101112131415161718192021# cat /data/mongodb/conf/mongodb.conf dbpath=/data/mongodb/data #数据库路径logpath=/data/mongodb/log/mongodb.log #日志输出文件路径logappend=true #日志输出方式pidfilepath=/data/mongodb/data/mongodb.pid #pid文件路径#bind_ip=10.186.21.84bind_ip=0.0.0.0port=27017 #端口号rest=true #设置后打开28017网页端口httpinterface=truemaxConns=20000fork=true #设置后台运行shardsvr=true#directoryperdb=true#auth = true # 先关闭, 创建好用户在启动#nohttpinterface=falsejournal=truequiet=trueslave=truesource=10.186.21.85:27017 验证主库添加数据库12345678910111213&gt; show dbsadmin 0.000GBlocal 0.000GB&gt; use testdbswitched to db testdb&gt; db.items.insert(&#123;"name":"yiibai tutorials"&#125;)WriteResult(&#123; "nInserted" : 1 &#125;)&gt; use testdbswitched to db testdb&gt; show dbsadmin 0.000GBlocal 0.000GBtestdb 0.000GB 从库查看数据库验证12345&gt; rs.slaveOk()&gt; show dbsadmin 0.000GBlocal 0.000GBtestdb 0.000GB 登录从库后执行命令可能会报错1[thread1] Error: listDatabases failed:&#123; "ok" : 0, "errmsg" : "not master and slaveOk=false", "code" : 13435 &#125; : 解决方法为登录从库后执行rs.slaveOk()，如下123456789101112&gt; show dbs2018-06-08T05:25:43.065-0400 E QUERY [thread1] Error: listDatabases failed:&#123; "ok" : 0, "errmsg" : "not master and slaveOk=false", "code" : 13435 &#125; :_getErrorWithCode@src/mongo/shell/utils.js:25:13Mongo.prototype.getDBs@src/mongo/shell/mongo.js:62:1shellHelper.show@src/mongo/shell/utils.js:781:19shellHelper@src/mongo/shell/utils.js:671:15@(shellhelp2):1:1&gt; rs.slaveOk()&gt; show dbsadmin 0.000GBlocal 0.000GB （2）Master-Slave安全这个主从安全在 MongoDB官网说的很清楚。不能和普通的mongod权限验证那样。这里除了需要加入 —auth 还需要加入 —keyFile 的验证。首先，我们生成我们的keyFile，根据官网提供的说明，这个keyfile是可以任意内容的，只要保证所有集群中的机器都拥有同样的文件即可。在linux环境下，我们通过1openssl rand -base64 741 &gt; /data/mongodb/mongo-keyfile 这条命令来生成我们的keyFile。保证主从库上使用的配置文件相同，在配置文件中加入1keyFile=/data/mongodb/mongo-keyfile 重新启动monodb，报错1234# mongod -f /data/mongodb/conf/mongodb.confabout to fork child process, waiting until server is ready for connections.forked process: 16492ERROR: child process failed, exited with error number 1 查看日志12CONTROL [main] ***** SERVER RESTARTED *****ACCESS [main] permissions on /data/mongodb/mongo-keyfile are too open 可以看到是文件权限过大调整权限为400123456789101112# chmod 400 mongo-keyfile # lltotal 108drwxr-xr-x 2 root root 4096 Jun 7 04:16 bindrwxr-xr-x 2 root root 25 Jun 8 05:44 confdrwxr-xr-x 4 root root 4096 Jun 8 05:49 data-rw-r--r-- 1 root root 34520 May 8 18:08 GNU-AGPL-3.0drwxr-xr-x 2 root root 24 Jun 7 05:20 log-r-------- 1 root root 7 Jun 8 05:42 mongo-keyfile-rw-r--r-- 1 root root 16726 May 8 18:08 MPL-2-rw-r--r-- 1 root root 2262 May 8 18:08 README-rw-r--r-- 1 root root 35910 May 8 18:08 THIRD-PARTY-NOTICES 重新启动，即可启动成功]]></content>
      <categories>
        <category>DB</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>集群</tag>
        <tag>主从</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix安装]]></title>
    <url>%2Fposts%2F2da12ea3.html</url>
    <content type="text"><![CDATA[一、环境配置关闭selinux12vim /etc/sysconfig/selinuxSELINUX=disabled 二、Nginx安装Nginx在生产环境推荐使用编译方式安装 1、安装编译环境、gcc12yum -y install gcc gcc-c++ automake autoconf libtool makeyum install gcc gcc-c++ 一般我们都需要先装pcre, zlib，前者为了重写rewrite，后者为了gzip压缩。从ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/ 下载最新的 PCRE 源码包，使用下面命令下载编译和安装 PCRE 包： 2、安装pcre1234567cd /data/backupwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.42.tar.gztar -zxvf pcre-8.42.tar.gzcd pcre-8.42./configuremakemake install 3、安装zlib从http://zlib.net下载最新的 zlib 源码包，使用下面命令下载编译和安装 zlib包：1234567cd /data/backupwget http://zlib.net/zlib-1.2.11.tar.gz tar -zxvf zlib-1.2.11.tar.gzcd zlib-1.2.11./configuremakemake install 4、安装openssl123cd /data/backupwget https://www.openssl.org/source/openssl-1.1.0h.tar.gztar -zxvf openssl-1.1.0h.tar.gz 5、安装Nginx1234567cd /data/backupwget http://nginx.org/download/nginx-1.14.0.tar.gztar -zxvf nginx-1.14.0.tar.gz cd nginx-1.14.0./configure --prefix=/data/nginx/ --with-http_v2_module --with-http_ssl_module --with-http_flv_module --with-http_mp4_module --with-http_sub_module --with-http_stub_status_module --with-http_gzip_static_module --without-http-cache --with-http_realip_module --with-pcre=/data/backup/pcre-8.42 --with-zlib=/data/backup/zlib-1.2.11 --with-openssl=/data/backup/openssl-1.1.0hmakemake install 创建Nginx软连接到环境变量1ln -s /data/nginx/sbin/* /usr/local/sbin/ 三、php安装Zabbix界面需要支持的PHP组件可以从官网查看，如下图： 1、安装插件1yum install -y libxml2 libxml2-devel openssl openssl-devel bzip2 bzip2-devel libcurl libcurl-devel libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel gmp gmp-devel libmcrypt libmcrypt-devel readline readline-devel libxslt libxslt-devel libicu-devel 2、编译安装PHP123456wget http://cn2.php.net/distributions/php-7.2.8.tar.gztar -zxvf php-7.2.8.tar.gz cd php-7.2.8/./configure --prefix=/data/php --with-curl --with-freetype-dir --with-gd --with-gettext --with-iconv-dir --with-kerberos --with-libdir=lib64 --with-libxml-dir --with-mysqli --with-openssl --with-pcre-regex --with-pdo-mysql --with-pdo-sqlite --with-pear --with-png-dir --with-jpeg-dir --with-xmlrpc --with-xsl --with-zlib --with-bz2 --with-mhash --enable-fpm --enable-bcmath --enable-libxml --enable-inline-optimization --enable-mbregex --enable-mbstring --enable-opcache --enable-pcntl --enable-shmop --enable-soap --enable-sockets --enable-sysvsem --enable-sysvshm --enable-xml --enable-zipmakemake install 复制配置文件12cp php.ini-development /data/php/lib/php.inicp /data/php/etc/php-fpm.conf.default /data/php/etc/php-fpm.conf 启动1/data/php/sbin/php-fpm 三、Mysql安装1、yum安装123yum -y install libaiowget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpmyum localinstall mysql-community-release-el7-5.noarch.rpm 验证下是否添加成功1234yum repolist enabled | grep "mysql.*-community.*"yum install mysql-develyum install mysql-community-serversystemctl start mysqld 更改数据存放目录123mkdir /home/datamysqladmin -u root -p shutdownmv /var/lib/mysql /home/data 修改 /etc/my.cnf 文件12345[mysqld]datadir=/data/mysqldata/mysqlsocket=/data/mysqldata/mysql/mysql.sock[mysql]socket=/data/mysqldata/mysql/mysql.sock 授权1chown -R mysql:mysql /data/mysqldata/mysql 重启mysql服务配置开机自起123# systemctl is-enabled mysql.service;echo $?enabled0 如果是 enabled 则说明是开机自动，如果不是，执行1chkconfig --levels 235 mysqld on 修改 /etc/my.cnf 文件，添加字符集的设置1234[mysqld] character_set_server = utf8[mysql]default-character-set = utf8 创建数据库1create database zabbix default charset utf8; 2、源码包安装参考链接：mysql安装 四、Zabbix Server端安装创建用户12groupadd zabbixuseradd -g zabbix zabbix 安装zabbix server从官网查找最新稳定版本，当前为3.0.*，下载后解压123mkdir /data/zabbix./configure --prefix=/data/zabbix/ --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2 --enable-javamake install 启动server进程1/data/zabbix/sbin/zabbix_server -c /data/zabbix/etc/zabbix_server.conf 启动agent进程1/data/zabbix/sbin/zabbix_agentd -c /data/zabbix/etc/zabbix_agentd.conf 可能出现的报错：1234checking for mysql_config... noconfigure: error: MySQL library not found#解决方法yum -y install mysql-devel 123configure: error: Invalid Net-SNMP directory - unable to find net-snmp-config#解决方法yum -y install net-snmp net-snmp-devel 五、Zabbix Web安装12cd /data/backup/zabbix-3.0.8/frontends/phpcp -a . /data/watch01.sa.mtiancity.com/zabbix/ 配置nginx可以访问，略过修改php.ini12345post_max_size = 16Mmax_execution_time = 300date.timezone =Asia/Shanghaialways_populate_raw_post_data = -1max_input_time = 300 导入数据库1234cd /data/backup/zabbix-3.0.8/database/mysql/mysql -u root zabbix&lt;schema.sqlmysql -u root zabbix&lt;images.sqlmysql -u root zabbix&lt;data.sql 打开nginx配置的url访问，如下图：也可能出现报错此时按照提示，将配置文件放入相应目录即可初始化完成后，登陆zabbix web，默认用户名：Admin，密码：zabbix 六、Zabbix Agnet端安装安装方法二选一即可，推荐rpm安装 1、编译安装创建用户组和用户12groupadd zabbixuseradd -g zabbix zabbix yum安装组件1yum -y install mysql-devel libxml2-devel unixODBC-devel OpenIPMI-devel curl-devel net-snmp-devel 安装zabbix agent1234tar -zxvf zabbix-3.0.8.tar.gzcd zabbix-3.0.8/./configure --prefix=/data/zabbix/ --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2make &amp;&amp; make install 复制配置文件1cp /data/backup/zabbix_agentd.conf /data/zabbix/etc/ 启动agent1/data/zabbix/sbin/zabbix_agentd -c /data/zabbix/etc/zabbix_agentd.conf 2、rpm包安装12345yum -y install unixODBC#centos6rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/6/x86_64/zabbix-agent-3.0.1-1.el6.x86_64.rpm#centos7rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-agent-3.0.9-1.el7.x86_64.rpm 配置文件位置/etc/zabbix/zabbix_agentd.conf，可以根据实际场景修改启动客户端1zabbix_agentd]]></content>
      <categories>
        <category>Monitor</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS系统巡检]]></title>
    <url>%2Fposts%2F12a847f6.html</url>
    <content type="text"><![CDATA[1、巡检脚本首先编写单台系统巡检脚本，内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730# cat checkos.sh#!/bin/bash#################################################################### Functions: this script from polling system status# Info: be suitable for CentOS/RHEL 6/7 # Changelog:# 2016-09-15 shaon initial commit####################################################################set path env,if not set will some command not found in crontabexport PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binsource /etc/profilerm -f /data/scripts/*.csv# run this script use root[ $(id -u) -gt 0 ] &amp;&amp; echo "please use root run the script! " &amp;&amp; exit 1# check system versionOS_Version=$(awk '&#123;print $(NF-1)&#125;' /etc/redhat-release)# declare script version dateScript_Version="2018.10.30"# define polling log pathLOGPATH=/data/scripts[ -d $LOGPATH ] || mkdir -p $LOGPATHRESULTFILE="$LOGPATH/`hostname`-`date +%Y%m%d`.csv"# define globle variablereport_DateTime="" #日期 okreport_Hostname="" #主机名 okreport_OSRelease="" #发行版本 okreport_Kernel="" #内核 okreport_Language="" #语言/编码 okreport_LastReboot="" #最近启动时间 okreport_Uptime="" #运行时间（天） okreport_CPUs="" #CPU数量 okreport_CPUType="" #CPU类型 okreport_Arch="" #CPU架构 okreport_MemTotal="" #内存总容量(MB) okreport_MemFree="" #内存剩余(MB) okreport_MemUsedPercent="" #内存使用率% okreport_DiskTotal="" #硬盘总容量(GB) okreport_DiskFree="" #硬盘剩余(GB) okreport_DiskUsedPercent="" #硬盘使用率% okreport_InodeTotal="" #Inode总量 okreport_InodeFree="" #Inode剩余 okreport_InodeUsedPercent="" #Inode使用率 okreport_IP="" #IP地址 okreport_MAC="" #MAC地址 okreport_Gateway="" #默认网关 okreport_DNS="" #DNS okreport_Listen="" #监听 okreport_Selinux="" #Selinux okreport_Firewall="" #防火墙 okreport_USERs="" #用户 okreport_USEREmptyPassword="" #空密码用户 okreport_USERTheSameUID="" #相同ID的用户 ok report_PasswordExpiry="" #密码过期（天） okreport_RootUser="" #root用户 okreport_Sudoers="" #sudo授权 okreport_SSHAuthorized="" #SSH信任主机 okreport_SSHDProtocolVersion="" #SSH协议版本 okreport_SSHDPermitRootLogin="" #允许root远程登录 okreport_DefunctProsess="" #僵尸进程数量 okreport_SelfInitiatedService="" #自启动服务数量 okreport_SelfInitiatedProgram="" #自启动程序数量 okreport_RuningService="" #运行中服务数 okreport_Crontab="" #计划任务数 okreport_Syslog="" #日志服务 okreport_SNMP="" #SNMP OKreport_NTP="" #NTP okreport_JDK="" #JDK版本 okfunction version()&#123; echo "" echo "System Polling：Version $Script_Version " echo ""&#125;function getCpuStatus()&#123; echo "" echo "############################ Check CPU Status#############################" Physical_CPUs=$(grep "physical id" /proc/cpuinfo| sort | uniq | wc -l) Virt_CPUs=$(grep "processor" /proc/cpuinfo | wc -l) CPU_Kernels=$(grep "cores" /proc/cpuinfo|uniq| awk -F ': ' '&#123;print $2&#125;') CPU_Type=$(grep "model name" /proc/cpuinfo | awk -F ': ' '&#123;print $2&#125;' | sort | uniq) CPU_Arch=$(uname -m) echo "物理CPU个数:$Physical_CPUs" echo "逻辑CPU个数:$Virt_CPUs" echo "每CPU核心数:$CPU_Kernels" echo " CPU型号:$CPU_Type" echo " CPU架构:$CPU_Arch" # report information report_CPUs=$Virt_CPUs #CPU数量 report_CPUType=$CPU_Type #CPU类型 report_Arch=$CPU_Arch #CPU架构&#125;function getMemStatus()&#123; echo "" echo "############################ Check Memmory Usage ###########################" if [[ $OS_Version &lt; 7 ]];then free -mo else free -h fi # report information MemTotal=$(grep MemTotal /proc/meminfo| awk '&#123;print $2&#125;') #KB MemFree=$(grep MemFree /proc/meminfo| awk '&#123;print $2&#125;') #KB let MemUsed=MemTotal-MemFree MemPercent=$(awk "BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \"%.2f\",$MemUsed*100/$MemTotal&#125;&#125;") report_MemTotal="$((MemTotal/1024))""MB" #内存总容量(MB) report_MemFree="$((MemFree/1024))""MB" #内存剩余(MB) report_MemUsedPercent="$(awk "BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \"%.2f\",$MemUsed*100/$MemTotal&#125;&#125;")""%" #内存使用率%&#125;function getDiskStatus()&#123; echo "" echo "############################ Check Disk Status ############################" df -hiP | sed 's/Mounted on/Mounted/' &gt; /tmp/inode df -hTP | sed 's/Mounted on/Mounted/' &gt; /tmp/disk join /tmp/disk /tmp/inode | awk '&#123;print $1,$2,"|",$3,$4,$5,$6,"|",$8,$9,$10,$11,"|",$12&#125;'| column -t # report information diskdata=$(df -TP | sed '1d' | awk '$2!="tmpfs"&#123;print&#125;') #KB disktotal=$(echo "$diskdata" | awk '&#123;total+=$3&#125;END&#123;print total&#125;') #KB diskused=$(echo "$diskdata" | awk '&#123;total+=$4&#125;END&#123;print total&#125;') #KB diskfree=$((disktotal-diskused)) #KB diskusedpercent=$(echo $disktotal $diskused | awk '&#123;if($1==0)&#123;printf 100&#125;else&#123;printf "%.2f",$2*100/$1&#125;&#125;') inodedata=$(df -iTP | sed '1d' | awk '$2!="tmpfs"&#123;print&#125;') inodetotal=$(echo "$inodedata" | awk '&#123;total+=$3&#125;END&#123;print total&#125;') inodeused=$(echo "$inodedata" | awk '&#123;total+=$4&#125;END&#123;print total&#125;') inodefree=$((inodetotal-inodeused)) inodeusedpercent=$(echo $inodetotal $inodeused | awk '&#123;if($1==0)&#123;printf 100&#125;else&#123;printf "%.2f",$2*100/$1&#125;&#125;') report_DiskTotal=$((disktotal/1024/1024))"GB" #硬盘总容量(GB) report_DiskFree=$((diskfree/1024/1024))"GB" #硬盘剩余(GB) report_DiskUsedPercent="$diskusedpercent""%" #硬盘使用率% report_InodeTotal=$((inodetotal/1000))"K" #Inode总量 report_InodeFree=$((inodefree/1000))"K" #Inode剩余 report_InodeUsedPercent="$inodeusedpercent""%" #Inode使用率% echo ""&#125;function getSystemStatus()&#123; echo "" echo "############################ Check System Status ############################" if [ -e /etc/sysconfig/i18n ];then default_LANG="$(grep "LANG=" /etc/sysconfig/i18n | grep -v "^#" | awk -F '"' '&#123;print $2&#125;')" else default_LANG=$LANG fi export LANG="en_US.UTF-8" Release=$(cat /etc/redhat-release 2&gt;/dev/null) Kernel=$(uname -r) OS=$(uname -o) Hostname=$(uname -n) SELinux=$(/usr/sbin/sestatus | grep "SELinux status: " | awk '&#123;print $3&#125;') LastReboot=$(who -b | awk '&#123;print $3,$4&#125;') uptime=$(cat /proc/uptime| awk -F. '&#123;run_days=$1 / 86400;run_hour=($1 % 86400)/3600;run_minute=($1 % 3600)/60;run_second=$1 % 60;printf("%d天%d时%d分%d秒",run_days,run_hour,run_minute,run_second)&#125;') echo " 系统：$OS" echo " 发行版本：$Release" echo " 内核：$Kernel" echo " 主机名：$Hostname" echo " SELinux：$SELinux" echo "语言/编码：$default_LANG" echo " 当前时间：$(date +'%F %T')" echo " 最后启动：$LastReboot" echo " 运行时间：$uptime" # report information report_DateTime=$(date +"%F %T") #日期 report_Hostname="$Hostname" #主机名 report_OSRelease="$Release" #发行版本 report_Kernel="$Kernel" #内核 report_Language="$default_LANG" #语言/编码 report_LastReboot="$LastReboot" #最近启动时间 report_Uptime="$uptime" #运行时间（天） report_Selinux="$SELinux" export LANG="$default_LANG" echo ""&#125;function getServiceStatus()&#123; echo "" echo "############################ Check Service Status ############################" if [[ $OS_Version &gt; 7 ]];then conf=$(systemctl list-unit-files --type=service --state=enabled --no-pager | grep "enabled") process=$(systemctl list-units --type=service --state=running --no-pager | grep ".service") # report information report_SelfInitiatedService="$(echo "$conf" | wc -l)" #自启动服务数量 report_RuningService="$(echo "$process" | wc -l)" #运行中服务数量 else conf=$(/sbin/chkconfig | grep -E ":on|:启用") process=$(/sbin/service --status-all 2&gt;/dev/null | grep -E "is running|正在运行") # report information report_SelfInitiatedService="$(echo "$conf" | wc -l)" #自启动服务数量 report_RuningService="$(echo "$process" | wc -l)" #运行中服务数量 fi echo "Service Configure" echo "--------------------------------" echo "$conf" | column -t echo "" echo "The Running Services" echo "--------------------------------" echo "$process"&#125;function getAutoStartStatus()&#123; echo "" echo "############################ Check Self-starting Services ##########################" conf=$(grep -v "^#" /etc/rc.d/rc.local| sed '/^$/d') echo "$conf" # report information report_SelfInitiatedProgram="$(echo $conf | wc -l)" #自启动程序数量&#125;function getLoginStatus()&#123; echo "" echo "############################ Check Login In ############################" last | head&#125;function getNetworkStatus()&#123; echo "" echo "############################ Check Network ############################" if [[ $OS_Version &lt; 7 ]];then /sbin/ifconfig -a | grep -v packets | grep -v collisions | grep -v inet6 else #ip address for i in $(ip link | grep BROADCAST | awk -F: '&#123;print $2&#125;');do ip add show $i | grep -E "BROADCAST|global"| awk '&#123;print $2&#125;' | tr '\n' ' ' ;echo "" ;done fi GATEWAY=$(ip route | grep default | awk '&#123;print $3&#125;') DNS=$(grep nameserver /etc/resolv.conf| grep -v "#" | awk '&#123;print $2&#125;' | tr '\n' ',' | sed 's/,$//') echo "" echo "Gateway: $GATEWAY " echo " DNS: $DNS" # report information IP=$(ip -f inet addr | grep -v 127.0.0.1 | grep inet | awk '&#123;print $NF,$2&#125;' | tr '\n' ',' | sed 's/,$//') MAC=$(ip link | grep -v "LOOPBACK\|loopback" | awk '&#123;print $2&#125;' | sed 'N;s/\n//' | tr '\n' ',' | sed 's/,$//') report_IP="$IP" #IP地址 report_MAC=$MAC #MAC地址 report_Gateway="$GATEWAY" #默认网关 report_DNS="$DNS" #DNS&#125;function getListenStatus()&#123; echo "" echo "############################ Check Listen Status ############################"# TCPListen=$(ss -ntul | column -t) TCPListen=$(netstat -ntulp | column -t) AllConnect=$(ss -an | awk 'NR&gt;1 &#123;++s[$1]&#125; END &#123;for(k in s) print k,s[k]&#125;' | column -t) echo "$TCPListen" echo "$AllConnect" # report information report_Listen="$(echo "$TCPListen"| sed '1d' | awk '/tcp/ &#123;print $5&#125;' | awk -F: '&#123;print $NF&#125;' | sort | uniq | wc -l)"&#125;function getCronStatus()&#123; echo "" echo "############################ Check Crontab List ########################" Crontab=0 for shell in $(grep -v "/sbin/nologin" /etc/shells);do for user in $(grep "$shell" /etc/passwd | awk -F: '&#123;print $1&#125;');do crontab -l -u $user &gt;/dev/null 2&gt;&amp;1 status=$? if [ $status -eq 0 ];then echo "$user" echo "-------------" crontab -l -u $user let Crontab=Crontab+$(crontab -l -u $user | wc -l) echo "" fi done done # scheduled task find /etc/cron* -type f | xargs -i ls -l &#123;&#125; | column -t let Crontab=Crontab+$(find /etc/cron* -type f | wc -l) # report information report_Crontab="$Crontab" #计划任务数&#125;function getHowLongAgo()&#123; # 计算一个时间戳离现在有多久了 datetime="$*" [ -z "$datetime" ] &amp;&amp; echo "错误的参数：getHowLongAgo() $*" Timestamp=$(date +%s -d "$datetime") #转化为时间戳 Now_Timestamp=$(date +%s) Difference_Timestamp=$(($Now_Timestamp-$Timestamp)) days=0;hours=0;minutes=0; sec_in_day=$((60*60*24)); sec_in_hour=$((60*60)); sec_in_minute=60 while (( $(($Difference_Timestamp-$sec_in_day)) &gt; 1 )) do let Difference_Timestamp=Difference_Timestamp-sec_in_day let days++ done while (( $(($Difference_Timestamp-$sec_in_hour)) &gt; 1 )) do let Difference_Timestamp=Difference_Timestamp-sec_in_hour let hours++ done echo "$days 天 $hours 小时前"&#125;function getUserLastLogin()&#123; # 获取用户最近一次登录的时间，含年份 # 很遗憾last命令不支持显示年份，只有"last -t YYYYMMDDHHMMSS"表示某个时间之间的登录，我 # 们只能用最笨的方法了，对比今天之前和今年元旦之前（或者去年之前和前年之前……）某个用户 # 登录次数，如果登录统计次数有变化，则说明最近一次登录是今年。 username=$1 : $&#123;username:="`whoami`"&#125; thisYear=$(date +%Y) oldesYear=$(last | tail -n1 | awk '&#123;print $NF&#125;') while(( $thisYear &gt;= $oldesYear));do loginBeforeToday=$(last $username | grep $username | wc -l) loginBeforeNewYearsDayOfThisYear=$(last $username -t $thisYear"0101000000" | grep $username | wc -l) if [ $loginBeforeToday -eq 0 ];then echo "Never Login" break elif [ $loginBeforeToday -gt $loginBeforeNewYearsDayOfThisYear ];then lastDateTime=$(last -i $username | head -n1 | awk '&#123;for(i=4;i&lt;(NF-2);i++)printf"%s ",$i&#125;')" $thisYear" #格式如: Sat Nov 2 20:33 2015 lastDateTime=$(date "+%Y-%m-%d %H:%M:%S" -d "$lastDateTime") echo "$lastDateTime" break else thisYear=$((thisYear-1)) fi done&#125;function getUserStatus()&#123; echo "" echo "############################ Check User ############################" # /etc/passwd the last modification time pwdfile="$(cat /etc/passwd)" Modify=$(stat /etc/passwd | grep Modify | tr '.' ' ' | awk '&#123;print $2,$3&#125;') echo "/etc/passwd The last modification time：$Modify ($(getHowLongAgo $Modify))" echo "" echo "A privileged user" echo "-----------------" RootUser="" for user in $(echo "$pwdfile" | awk -F: '&#123;print $1&#125;');do if [ $(id -u $user) -eq 0 ];then echo "$user" RootUser="$RootUser,$user" fi done echo "" echo "User List" echo "--------" USERs=0 echo "$( echo "UserName UID GID HOME SHELL LasttimeLogin" for shell in $(grep -v "/sbin/nologin" /etc/shells);do for username in $(grep "$shell" /etc/passwd| awk -F: '&#123;print $1&#125;');do userLastLogin="$(getUserLastLogin $username)" echo "$pwdfile" | grep -w "$username" |grep -w "$shell"| awk -F: -v lastlogin="$(echo "$userLastLogin" | tr ' ' '_')" '&#123;print $1,$3,$4,$6,$7,lastlogin&#125;' done let USERs=USERs+$(echo "$pwdfile" | grep "$shell"| wc -l) done )" | column -t echo "" echo "Null Password User" echo "------------------" USEREmptyPassword="" for shell in $(grep -v "/sbin/nologin" /etc/shells);do for user in $(echo "$pwdfile" | grep "$shell" | cut -d: -f1);do r=$(awk -F: '$2=="!!"&#123;print $1&#125;' /etc/shadow | grep -w $user) if [ ! -z $r ];then echo $r USEREmptyPassword="$USEREmptyPassword,"$r fi done done echo "" echo "The Same UID User" echo "----------------" USERTheSameUID="" UIDs=$(cut -d: -f3 /etc/passwd | sort | uniq -c | awk '$1&gt;1&#123;print $2&#125;') for uid in $UIDs;do echo -n "$uid"; USERTheSameUID="$uid" r=$(awk -F: 'ORS="";$3=='"$uid"'&#123;print ":",$1&#125;' /etc/passwd) echo "$r" echo "" USERTheSameUID="$USERTheSameUID $r," done # report information report_USERs="$USERs" #用户 report_USEREmptyPassword=$(echo $USEREmptyPassword | sed 's/^,//') report_USERTheSameUID=$(echo $USERTheSameUID | sed 's/,$//') report_RootUser=$(echo $RootUser | sed 's/^,//') #特权用户&#125;function getPasswordStatus &#123; echo "" echo "############################ Check Password Status ############################" pwdfile="$(cat /etc/passwd)" echo "" echo "Password Expiration Check" echo "-------------------------" result="" for shell in $(grep -v "/sbin/nologin" /etc/shells);do for user in $(echo "$pwdfile" | grep "$shell" | cut -d: -f1);do get_expiry_date=$(/usr/bin/chage -l $user | grep 'Password expires' | cut -d: -f2) if [[ $get_expiry_date = ' never' || $get_expiry_date = 'never' ]];then printf "%-15s never expiration\n" $user result="$result,$user:never" else password_expiry_date=$(date -d "$get_expiry_date" "+%s") current_date=$(date "+%s") diff=$(($password_expiry_date-$current_date)) let DAYS=$(($diff/(60*60*24))) printf "%-15s %s expiration after days\n" $user $DAYS result="$result,$user:$DAYS days" fi done done report_PasswordExpiry=$(echo $result | sed 's/^,//') echo "" echo "Check The Password Policy" echo "------------" grep -v "#" /etc/login.defs | grep -E "PASS_MAX_DAYS|PASS_MIN_DAYS|PASS_MIN_LEN|PASS_WARN_AGE" echo ""&#125;function getSudoersStatus()&#123; echo "" echo "############################ Sudoers Check #########################" conf=$(grep -v "^#" /etc/sudoers| grep -v "^Defaults" | sed '/^$/d') echo "$conf" echo "" # report information report_Sudoers="$(echo $conf | wc -l)"&#125;function getInstalledStatus()&#123; echo "" echo "############################ Software Check ############################" rpm -qa --last | head | column -t &#125;function getProcessStatus()&#123; echo "" echo "############################ Process Check ############################" if [ $(ps -ef | grep defunct | grep -v grep | wc -l) -ge 1 ];then echo "" echo "zombie process"; echo "--------" ps -ef | head -n1 ps -ef | grep defunct | grep -v grep fi echo "" echo "Merory Usage TOP10" echo "-------------" echo -e "PID %MEM RSS COMMAND $(ps aux | awk '&#123;print $2, $4, $6, $11&#125;' | sort -k3rn | head -n 10 )"| column -t echo "" echo "CPU Usage TOP10" echo "------------" top b -n1 | head -17 | tail -11 # report information report_DefunctProsess="$(ps -ef | grep defunct | grep -v grep|wc -l)"&#125;function getJDKStatus()&#123; echo "" echo "############################ JDK Check #############################" java -version 2&gt;/dev/null if [ $? -eq 0 ];then java -version 2&gt;&amp;1 fi echo "JAVA_HOME=\"$JAVA_HOME\"" # report information report_JDK="$(java -version 2&gt;&amp;1 | grep version | awk '&#123;print $1,$3&#125;' | tr -d '"')"&#125;function getSyslogStatus()&#123; echo "" echo "############################ Syslog Check ##########################" echo "Service Status：$(getState rsyslog)" echo "" echo "/etc/rsyslog.conf" echo "-----------------" cat /etc/rsyslog.conf 2&gt;/dev/null | grep -v "^#" | grep -v "^\\$" | sed '/^$/d' | column -t #report information report_Syslog="$(getState rsyslog)"&#125;function getFirewallStatus()&#123; echo "" echo "############################ Firewall Check ##########################" # Firewall Status/Poilcy if [[ $OS_Version &lt; 7 ]];then /etc/init.d/iptables status &gt;/dev/null 2&gt;&amp;1 status=$? if [ $status -eq 0 ];then s="active" elif [ $status -eq 3 ];then s="inactive" elif [ $status -eq 4 ];then s="permission denied" else s="unknown" fi else s="$(getState iptables)" fi echo "iptables: $s" echo "" echo "/etc/sysconfig/iptables" echo "-----------------------" cat /etc/sysconfig/iptables 2&gt;/dev/null # report information report_Firewall="$s"&#125;function getSNMPStatus()&#123; #SNMP Service Status,Configure echo "" echo "############################ SNMP Check ############################" status="$(getState snmpd)" echo "Service Status：$status" echo "" if [ -e /etc/snmp/snmpd.conf ];then echo "/etc/snmp/snmpd.conf" echo "--------------------" cat /etc/snmp/snmpd.conf 2&gt;/dev/null | grep -v "^#" | sed '/^$/d' fi # report information report_SNMP="$(getState snmpd)"&#125;function getState()&#123; if [[ $OS_Version &lt; 7 ]];then if [ -e "/etc/init.d/$1" ];then if [ `/etc/init.d/$1 status 2&gt;/dev/null | grep -E "is running|正在运行" | wc -l` -ge 1 ];then r="active" else r="inactive" fi else r="unknown" fi else #CentOS 7+ r="$(systemctl is-active $1 2&gt;&amp;1)" fi echo "$r"&#125;function getSSHStatus()&#123; #SSHD Service Status,Configure echo "" echo "############################ SSH Check #############################" # Check the trusted host pwdfile="$(cat /etc/passwd)" echo "Service Status：$(getState sshd)" Protocol_Version=$(cat /etc/ssh/sshd_config | grep Protocol | awk '&#123;print $2&#125;') echo "SSH Protocol Version：$Protocol_Version" echo "" echo "Trusted Host" echo "------------" authorized=0 for user in $(echo "$pwdfile" | grep /bin/bash | awk -F: '&#123;print $1&#125;');do authorize_file=$(echo "$pwdfile" | grep -w $user | awk -F: '&#123;printf $6"/.ssh/authorized_keys"&#125;') authorized_host=$(cat $authorize_file 2&gt;/dev/null | awk '&#123;print $3&#125;' | tr '\n' ',' | sed 's/,$//') if [ ! -z $authorized_host ];then echo "$user authorization \"$authorized_host\" Password-less access" fi let authorized=authorized+$(cat $authorize_file 2&gt;/dev/null | awk '&#123;print $3&#125;'|wc -l) done echo "" echo "Whether to allow ROOT remote login" echo "----------------------------------" config=$(cat /etc/ssh/sshd_config | grep PermitRootLogin) firstChar=$&#123;config:0:1&#125; if [ $firstChar == "#" ];then PermitRootLogin="yes" #The default is to allow ROOT remote login else PermitRootLogin=$(echo $config | awk '&#123;print $2&#125;') fi echo "PermitRootLogin $PermitRootLogin" echo "" echo "/etc/ssh/sshd_config" echo "--------------------" cat /etc/ssh/sshd_config | grep -v "^#" | sed '/^$/d' # report information report_SSHAuthorized="$authorized" #SSH信任主机 report_SSHDProtocolVersion="$Protocol_Version" #SSH协议版本 report_SSHDPermitRootLogin="$PermitRootLogin" #允许root远程登录&#125;function getNTPStatus()&#123; # The NTP service status, the current time, configuration, etc echo "" echo "############################ NTP Check #############################" if [ -e /etc/ntp.conf ];then echo "Service Status：$(getState ntpd)" echo "" echo "/etc/ntp.conf" echo "-------------" cat /etc/ntp.conf 2&gt;/dev/null | grep -v "^#" | sed '/^$/d' fi # report information report_NTP="$(getState ntpd)"&#125;function getZabbixStatus()&#123; # Check Zabbix Serivce Status echo "" echo "######################### Zabbix Check ##############################" netstat -nltp | grep -v grep | grep zabbix &gt; /dev/null 2&gt;&amp;1 if [ $? -eq 0 ];then echo "Service Status": Zabbix is running! else echo "Service Status": Zabbix not running! fi # report information&#125;function uploadHostDailyCheckReport()&#123; json="&#123; \"DateTime\":\"$report_DateTime\", \"Hostname\":\"$report_Hostname\", \"OSRelease\":\"$report_OSRelease\", \"Kernel\":\"$report_Kernel\", \"Language\":\"$report_Language\", \"LastReboot\":\"$report_LastReboot\", \"Uptime\":\"$report_Uptime\", \"CPUs\":\"$report_CPUs\", \"CPUType\":\"$report_CPUType\", \"Arch\":\"$report_Arch\", \"MemTotal\":\"$report_MemTotal\", \"MemFree\":\"$report_MemFree\", \"MemUsedPercent\":\"$report_MemUsedPercent\", \"DiskTotal\":\"$report_DiskTotal\", \"DiskFree\":\"$report_DiskFree\", \"DiskUsedPercent\":\"$report_DiskUsedPercent\", \"InodeTotal\":\"$report_InodeTotal\", \"InodeFree\":\"$report_InodeFree\", \"InodeUsedPercent\":\"$report_InodeUsedPercent\", \"IP\":\"$report_IP\", \"MAC\":\"$report_MAC\", \"Gateway\":\"$report_Gateway\", \"DNS\":\"$report_DNS\", \"Listen\":\"$report_Listen\", \"Selinux\":\"$report_Selinux\", \"Firewall\":\"$report_Firewall\", \"USERs\":\"$report_USERs\", \"USEREmptyPassword\":\"$report_USEREmptyPassword\", \"USERTheSameUID\":\"$report_USERTheSameUID\", \"PasswordExpiry\":\"$report_PasswordExpiry\", \"RootUser\":\"$report_RootUser\", \"Sudoers\":\"$report_Sudoers\", \"SSHAuthorized\":\"$report_SSHAuthorized\", \"SSHDProtocolVersion\":\"$report_SSHDProtocolVersion\", \"SSHDPermitRootLogin\":\"$report_SSHDPermitRootLogin\", \"DefunctProsess\":\"$report_DefunctProsess\", \"SelfInitiatedService\":\"$report_SelfInitiatedService\", \"SelfInitiatedProgram\":\"$report_SelfInitiatedProgram\", \"RuningService\":\"$report_RuningService\", \"Crontab\":\"$report_Crontab\", \"Syslog\":\"$report_Syslog\", \"SNMP\":\"$report_SNMP\", \"NTP\":\"$report_NTP\", \"JDK\":\"$report_JDK\" &#125;" #echo "$json" curl -l -H "Content-type: application/json" -X POST -d "$json" "$uploadHostDailyCheckReportApi" 2&gt;/dev/null&#125;function check()&#123; version getSystemStatus getCpuStatus getMemStatus getDiskStatus getNetworkStatus getListenStatus getProcessStatus getServiceStatus getAutoStartStatus getLoginStatus getCronStatus getUserStatus getPasswordStatus getSudoersStatus getJDKStatus getFirewallStatus getSSHStatus getSyslogStatus getSNMPStatus getNTPStatus getZabbixStatus getInstalledStatus&#125;# Perform inspections and save the inspection results #执行检查并保存检查结果check &gt; $RESULTFILEecho "Check the result：$RESULTFILE"# Upload the result file #上传检查结果的文件#curl -F "filename=@$RESULTFILE" "$uploadHostDailyCheckApi" 2&gt;/dev/null#Upload inspection result report #上传检查结果的报表#uploadHostDailyCheckReport 1&gt;/dev/null 运行脚本后，会在脚本设定的目录：/data/scripts/checklog/下生成以csv为后缀的文件，文件格式也是在脚本中已经设定。 2、文件合并需要将多个csv文件合成为xlsx后缀的文件，将多台服务器的执行结果都保存在checklog目录下。脚本内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# cat toall_xlsx.py #!/usr/bin/python# coding=utf_8_sigimport osimport sysimport csvimport globimport timesys.path.append("/home/shdi/bin/pymodule")import xlsxwriterimport sysreload(sys)sys.setdefaultencoding('utf-8') def merge_csv2xlsx(csv_dir, xlsxfile): # Create a new workbook and add a worksheet workbook = xlsxwriter.Workbook(xlsxfile) fmt_plain = workbook.add_format(&#123; 'font_size': 12, 'font_name': "Arial Narrow", &#125;) for filename in glob.glob("%s/*.csv" % csv_dir): print " procsss %s" % filename (f_path, f_name) = os.path.split(filename) (f_short_name, f_extension) = os.path.splitext(f_name) sheet_name = f_short_name worksheet = workbook.add_worksheet(sheet_name) spamReader = csv.reader(open(filename, 'rb'), delimiter=',',quotechar='"') row_count = 0 for row in spamReader: for col in range(len(row)): #ws.write(row_count,col,row[col]) worksheet.write(row_count, col, row[col],fmt_plain) row_count +=1 workbook.close() print "xlsx file saved: %s" % xlsxfile returnif __name__ == "__main__": if len(sys.argv) != 2: print "Usage:" print "\t%s &lt;csvdir&gt;" % sys.argv[0] sys.exit(0) csvdir = sys.argv[1] savefile = time.strftime("/data/scripts/checklog/check_%Y%m%d.xlsx") merge_csv2xlsx(csvdir, savefile) print("\n\nCVS merged file saved to %s" % savefile) 此脚本放在checklog下，讲同目录下所有文件合并成xlsx文件。 3、定时任务添加多台服务器ip，并将脚本添加进定时任务脚本如下：123456789101112131415161718192021222324252627282930313233343536373839404142# pwd/data/scripts[root@gbw_manage scripts]# cat run_xunjian.sh #!/bin/bashHOSTLIST=("172.16.109.139 172.16.109.149172.16.109.145 172.16.109.146 172.16.109.150 172.16.109.140 172.16.109.151 172.16.109.147 172.16.109.141 172.16.109.137 172.16.109.138 172.16.109.144 172.16.109.148 172.16.109.143 172.16.109.142172.16.109.153")#echo "$HOSTLIST"COUNT=`echo "$HOSTLIST" |grep -v '^$'|wc -l`#echo $COUNTfor ip in $&#123;HOSTLIST[*]&#125;do /usr/bin/ssh root@$ip -C "/bin/bash" &lt; /data/scripts/checkos.sh echo $ipdonerm -f /data/scripts/checklog/*.csvfor ip in $&#123;HOSTLIST[*]&#125;do scp root@$ip:/data/scripts/*.csv /data/scripts/checklog/ echo $ipdone/usr/bin/python /data/scripts/checklog/toall_xlsx.py /data/scripts/checklog 最后的结果文档会保存在/data/scripts/checklog下，文件后缀为xlsx。将此脚本添加定时任务，每天1点执行一次，即可实现定时巡检系统。完善：可以在脚本内增加邮件发送功能，将最后的结果文件发送到对应的接收人员。]]></content>
      <categories>
        <category>Scripts</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Python</tag>
        <tag>巡检</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ应用文档]]></title>
    <url>%2Fposts%2F3c3a0b8d.html</url>
    <content type="text"><![CDATA[一、Rabbitmq简介1、Rabbitmq介绍RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。AMQP，即Advanced message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 2、Rabbitmq系统概念 RabbitMQ Server 也叫broker server，是一种传输服务，负责维护一条从Producer到consumer的路线，保证数据能够按照指定的方式进行传输。 Producer 数据的发送方。 Consumer 数据的接收方。 Exchanges 接收消息，转发消息到绑定的队列。主要使用3种类型：direct， topic， fanout。 Queue RabbitMQ内部存储消息的对象。相同属性的queue可以重复定义，但只有第一次定义的有效。 Bindings 绑定Exchanges和Queue之间的路由。 Connection 就是一个TCP的连接。Producer和consumer都是通过TCP连接到RabbitMQ Server的。 Channel 虚拟连接。它建立在上述的TCP连接中。数据流动都是在Channel中进行的。也就是说，一般情况是程序起始建立TCP连接，第二步就是建立这个Channel。 3、AMQP协议简介AMQP在一致性客户端和消息中间件(也称为”brokers”)之间创建了全功能的互操作．为了完全实现消息中间件的互操作性，需要充分定义网络协议和消息代理服务的功能语义。因此，AMQP通过如下来定义了网络协议(AMQP是协议！)和服务端服务：1、一套确定的消息交换功能，也就是“高级消息交换协议模型”。AMQP模型包括一套用于路由和存储消息的功能模块，以及一套在这些模块之间交换消息的规则。2、 一个网络线级协议（数据传输格式），AMQP促使客户端可使用AMQ模型来与服务器交互。可以只实现AMQP协议规范中的的部分语义，但是我们相信这些明确的语义有助于理解这个协议。我们需要明确定义服务器语义，因为所有服务器实现都应该与这些语义保持一致性，否则就无法进行互操作. 因此AMQ 模型定义了一系列模块化组件和标准规则来进行协作. 有三种类型的组件可以连接服务器处理链来创建预期的功能:1、”交换器(exchange)” ：接收来自发布者应用程序的消息，并基于任意条件(通常是消息属性和内容）将这些消息路由到消息队列(message queues).2、”消息队列(message queue)”：存储消息直到它们可以被消费客户端应用程序(或多线程应用程序)安全处理。3、”绑定(binding)”:定义了消息队列与交换器之间的关系，并提供了消息路由条件．使用这些模型我们可以很容易地模拟经典的存储转发队列和面向消息中间件的主题订阅概念. 我们还可以表示更为复杂的概念，例如：基于内容的路由，工作负载分配和按需消息队列。大致上讲， AMQP 服务器类似与邮件服务器, 每个交换器都扮演了消息传送代理,每个消息队列都作为邮箱，而绑定则定义了每个传送代理中的路由表.发布者发送消息给独立的传送代理,然后传送代理再路由消息到邮箱中.消费者从邮箱中收取消息. 相比较而言，在AMQP之前的许多中间件系统中，发布者直接发送消息到独立收件箱(在存储转发队列的情况下),或者发布到邮件列表中 (在主题订阅的情况下)。区别就在于用户可以控制消息队列和交换器之间的绑定规则，这可以做很多有趣的事情，比如定义一条规则：“将所有包含这样消息头的消息都复制一份再发送到消息队列中”。AMQ模型是基于下面的需求来驱动设计的：1、支持与主要消息产品相媲美的语义。.2、 提供与主要消息产品相媲美的性能水平.3、允许通过应用程序使用服务器特定语义来编程.4、灵活性，可扩展性，简单性 二、安装Rabbitmq1、安装好系统运行12yum update -yreboot #一般情况不用重启 2、安装依赖文件12yum -y install gcc glibc-devel make ncurses-devel openssl-devel xmlto perl wget#部分依赖可能在安装其他服务时已安装 3、安装erlang语言环境官网地址：http://www.erlang.org/downloads，由于环境支持问题，建议下载最新版本123456wget http://erlang.org/download/otp_src_20.3.tar.gztar -zxvf otp_src_20.3.tar.gz cd otp_src_20.3./configure --prefix=/data/erlangmakemake install 配置erlang环境变量12345678vi /etc/profile #在底部添加以下内容 #set erlang environmentERL_HOME=/data/erlangPATH=$ERL_HOME/bin:$PATHexport ERL_HOME PATHsource /etc/profile #生效 在控制台输入命令erl如果进入erlang的shell则证明安装成功，退出即可。 4、安装rabbitmq官网地址：http://www.rabbitmq.com/install-generic-unix.html，下载最新稳定版本1234wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.4/rabbitmq-server-generic-unix-3.7.4.tar.xzxz -d rabbitmq-server-generic-unix-3.7.4.tar.xz tar -xvf rabbitmq-server-generic-unix-3.7.4.tar mv rabbitmq_server-3.7.4 /data/rabbitmq 配置rabbitmq环境变量123456vi /etc/profile #在底部添加以下内容 #set rabbitmq environmentexport PATH=$PATH:/data/rabbitmq/sbinsource /etc/profile #生效 启动服务1rabbitmq-server -detached #启动rabbitmq，-detached代表后台守护进程方式启动 出现以下界面此时rabbit-servery已经启动官网解释：http://www.rabbitmq.com/rabbitmq-server.8.html但是由于没有写入PID file文件，可能导致服务停止查看状态1rabbitmqctl status 如果显示如下截图说明安装成功其他相关命令 启动服务：rabbitmq-server -detached 或者/data/rabbitmq/sbin/rabbitmq-server -detached 查看状态：rabbitmqctl status 或者/usr/local/rabbitmq/sbin/rabbitmqctl status 关闭服务：rabbitmqctl stop 或者/usr/local/rabbitmq/sbin/rabbitmqctl stop 列出角色：rabbitmqctl list_users 或者/usr/local/rabbitmq/sbin/rabbitmqctl list_users 5、配置网页插件首先创建目录，否则可能报错1mkdir /etc/rabbitmq 启用web管理插件1rabbitmq-plugins enable rabbitmq_management 6、配置防火墙配置linux端口15672网页管理5672AMQP端口123firewall-cmd --permanent --add-port=15672/tcpfirewall-cmd --permanent --add-port=5672/tcpsystemctl restart firewalld.service 在浏览器输入http://ip:15672，可以看到RabbitMQ的WEB管理页面，如下 7、配置访问账号密码和权限默认网页是不允许访问的，需要增加一个用户修改一下权限123rabbitmqctl add_user action action #添加用户，后面两个参数分别是用户名和密码rabbitmqctl set_permissions -p / action ".*" ".*" ".*" #添加权限rabbitmqctl set_user_tags action administrator #修改用户角色 查看角色并确认123# rabbitmqctl list_usersListing users ...action [administrator] 然后就可以远程访问了，然后可直接配置用户权限等信息。登录：http://ip:15672 登录之后在admin里面把guest删除。 8、Rabbitmq配置RabbitMQ 提供了三种方式来定制服务器: 环境变量：定义端口，文件位置和名称(接受shell输入,或者在环境配置文件（rabbitmq-env.conf）中设置) 配置文件：为服务器组件设置权限,限制和集群，也可以定义插件设置. 运行时参数和策略：可在运行时进行修改集群设置 1）配置文件rabbitmq.config 文件rabbitmq.config配置文件允许配置RabbitMQ 核心程序， Erlang 服务和RabbitMQ 插件. 它是标准的Erlang 配置文件, 文档位于Erlang Config Man Page.最小化的样例配置文件如下:1[ &#123;rabbit, [&#123;tcp_listeners, [5673]&#125;]&#125; ]. 这个例子中将会修改RabbitMQ监听AMQP 0-9-1 客户端连接端口，5672修改为5673.配置文件不同于环境配置文件rabbitmq-env.conf这些文件的位置分布特定的. 默认情况下，这些文件是没有创建的,但每个平台上期望的位置如下：12345Generic UNIX - $RABBITMQ_HOME/etc/rabbitmq/Debian - /etc/rabbitmq/RPM - /etc/rabbitmq/Mac OS X (Homebrew) - $&#123;install_prefix&#125;/etc/rabbitmq/, the Homebrew prefix is usually/usr/localWindows - %APPDATA%\RabbitMQ\ 如果rabbitmq-env.conf不存在, 可在默认位置中手动创建.。它不能用于Windows系统.如果rabbitmq.config不存在，可以手动创建它. 如果你修改了位置，可设置RABBITMQ_CONFIG_FILE 环境变量来指定. Erlang 运行时会自动在此变量值后添加.config扩展名，重启服务器后生效。Windows 服务用户在删除配置文件后，需要重新安装服务。 2）rabbitmq.config中的变量配置大部分的RabbitMQ用户都会不会修改这些值，有些是相当模糊的。为了完整性，他们都在这里列出。 Key Documentation tcp_listeners 用于监听 AMQP连接的端口列表(无SSL). 可以包含整数 (即”监听所有接口”)或者元组如 {“127.0.0.1”, 5672} 用于监听一个或多个接口. Default: [5672] num_tcp_acceptors 接受TCP侦听器连接的Erlang进程数。 Default: 10 handshake_timeout AMQP 0-8/0-9/0-9-1 handshake (在 socket 连接和SSL 握手之后）的最大时间, 毫秒为单位. Default: 10000 ssl_listeners 如上所述，用于SSL连接。 Default: [] num_ssl_acceptors 接受SSL侦听器连接的Erlang进程数。 Default: 1 ssl_options SSL配置.参考SSL documentation. Default: [] ssl_handshake_timeout SSL handshake超时时间,毫秒为单位. Default: 5000 vm_memory_high_watermark 流程控制触发的内存阀值．相看memory-based flow control 文档. Default: 0.4 vm_memory_high_watermark_paging_ratio 高水位限制的分数，当达到阀值时，队列中消息消息会转移到磁盘上以释放内存. 参考memory-based flow control 文档. Default: 0.5 disk_free_limit RabbitMQ存储数据分区的可用磁盘空间限制．当可用空间值低于阀值时，流程控制将被触发. 此值可根据RAM的总大小来相对设置 (如.{mem_relative, 1.0}). 此值也可以设为整数(单位为bytes)或者使用数字单位(如．”50MB”). 默认情况下，可用磁盘空间必须超过50MB. 参考 Disk Alarms 文档. Default: 50000000 log_levels 控制日志的粒度.其值是日志事件类别(category)和日志级别(level)成对的列表． level 可以是 ‘none’ (不记录日志事件), ‘error’ (只记录错误), ‘warning’ (只记录错误和警告), ‘info’ (记录错误，警告和信息), or ‘debug’ (记录错误，警告，信息以及调试信息). 目前定义了４种日志类别. 它们是： channel -针对所有与AMQP channels相关的事件 connection - 针对所有与网络连接相关的事件 federation - 针对所有与federation相关的事件 mirroring -针对所有与 mirrored queues相关的事件 Default: [{connection, info}] frame_max 与客户端协商的允许最大frame大小. 设置为０表示无限制，但在某些QPid客户端会引发bug. 设置较大的值可以提高吞吐量;设置一个较小的值可能会提高延迟. Default: 131072 channel_max 与客户端协商的允许最大chanel大小. 设置为０表示无限制．该数值越大，则broker使用的内存就越高． Default: 0 channel_operation_timeout Channel 操作超时时间(毫秒为单位） (内部使用，因为消息协议的区别和限制，不暴露给客户端). Default: 5000 heartbeat 表示心跳延迟(单位为秒) ，服务器将在connection.tune frame中发送.如果设置为 0, 心跳将被禁用. 客户端可以不用遵循服务器的建议, 查看 AMQP reference 来了解详情. 禁用心跳可以在有大量连接的场景中提高性能，但可能会造成关闭了非活动连接的网络设备上的连接落下． Default: 60 (3.5.5之前的版本是580) default_vhost 当RabbitMQ从头开始创建数据库时创建的虚拟主机. amq.rabbitmq.log交换器会存在于这个虚拟主机中. Default: &lt;&lt;”/“&gt;&gt; default_user RabbitMQ从头开始创建数据库时，创建的用户名. Default: &lt;&lt;”guest”&gt;&gt; default_pass 默认用户的密码. Default: &lt;&lt;”guest”&gt;&gt; default_user_tags 默认用户的Tags. Default: [administrator] default_permissions 创建用户时分配给它的默认Permissions . Default: [&lt;&lt;”.“&gt;&gt;, &lt;&lt;”.“&gt;&gt;, &lt;&lt;”.*”&gt;&gt;] loopback_users 只能通过环回接口(即localhost)连接broker的用户列表 如果你希望默认的guest用户能远程连接,你必须将其修改为[]. Default: [&lt;&lt;”guest”&gt;&gt;] cluster_nodes 当节点第一次启动的时候，设置此选项会导致集群动作自动发生. 元组的第一个元素是其它节点想与其建立集群的节点. 第二个元素是节点的类型，要么是disc,要么是ram Default: {[], disc} server_properties 连接时向客户端声明的键值对列表 Default: [] collect_statistics 统计收集模式。主要与管理插件相关。选项： none (不发出统计事件) coarse (发出每个队列 /每个通道 /每个连接的统计事件) fine (也发出每个消息统计事件) 你自已可不用修改此选项. Default: none collect_statistics_interval 统计收集时间间隔(毫秒为单位)． 主要针对于 management plugin. Default: 5000 auth_mechanisms 提供给客户端的SASL authentication mechanisms. Default: [‘PLAIN’, ‘AMQPLAIN’] auth_backends 用于 authentication / authorisation backends 的列表. 此列表可包含模块的名称(在模块相同的情况下，将同时用于认证来授权)或像{ModN, ModZ}这样的元组，在这里ModN将用于认证，ModZ将用于授权. 在２元组的情况中, ModZ可由列表代替,列表中的所有元素必须通过每个授权的确认，如{ModN, [ModZ1, ModZ2]}. 这就允许授权插件进行组合提供额外的安全约束. 除rabbit_auth_backend_internal外，其它数据库可以通常 plugins来使用. Default: [rabbit_auth_backend_internal] reverse_dns_lookups 设置为true,可让客户端在连接时让RabbitMQ 执行一个反向DNS查找, 然后通过 rabbitmqctl 和 管理插件来展现信息. Default: false delegate_count 内部集群通信中，委派进程的数目. 在一个有非常多核的机器(集群的一部分)上,你可以增加此值. Default: 16 trace_vhosts tracer内部使用. 你不应该修改. Default: [] tcp_listen_options 默认socket选项. 你可能不想修改这个选项. Default: [{backlog, 128}, {nodelay, true}, {exit_on_close, false}] hipe_compile 将此选项设置为true,将会使用HiPE预编译部分RabbitMQ,Erlang的即时编译器. 这可以增加服务器吞吐量，但会增加服务器的启动时间． 你可以看到花费几分钟延迟启动的成本，就可以带来20-50% 更好性能.这些数字与高度依赖于工作负载和硬件． HiPE 支持可能没有编译进你的Erlang安装中.如果没有的话，启用这个选项,并启动RabbitMQ时，会看到警告消息． 例如, Debian / Ubuntu 用户需要安装erlang-base-hipe 包. HiPE并非在所有平台上都可用, 尤其是Windows. 在 Erlang/OTP 1７.５版本之前，HiPE有明显的问题 . 对于HiPE,使用最新的OTP版本是高度推荐的． Default: false cluster_partition_handling 如何处理网络分区.可用模式有: ignore pause_minority {pause_if_all_down, [nodes], ignore autoheal}where [nodes] is a list of node names (ex: [‘rabbit@node1’, ‘rabbit@node2’]) autoheal 参考documentation on partitions 来了解更多信息 Default: ignore cluster_keepalive_interval 节点向其它节点发送存活消息和频率(毫秒). 注意，这与 net_ticktime是不同的; 丢失存活消息不会引起节点掉线 Default: 10000 queue_index_embed_msgs_below 消息大小在此之下的会直接内嵌在队列索引中. 在修改此值时，建议你先阅读 persister tuning 文档. Default: 4096 msg_store_index_module 队列索引的实现模块. 在修改此值时，建议你先阅读 persister tuning 文档. Default: rabbit_msg_store_ets_index backing_queue_module 队列内容的实现模块. 你可能不想修改此值． Default: rabbit_variable_queue msg_store_file_size_limit Tunable value for the persister. 你几乎肯定不应该改变此值。 Default: 16777216 mnesia_table_loading_timeout 在集群中等待使用Mnesia表可用的超时时间。 Default: 30000 queue_index_max_ journal_entries Tunable value for the persister. 你几乎肯定不应该改变此值。 Default: 65536 queue_master_locator Queue master 位置策略. 可用策略有: &lt;&lt;”min-masters”&gt;&gt; &lt;&lt;”client-local”&gt;&gt; &lt;&lt;”random”&gt;&gt; 查看documentation on queue master location 来了解更多信息． Default: &lt;&lt;”client-local”&gt;&gt; 此外，许多插件也可以在配置文件中配置, 其名称是rabbitmq_plugin的形式. 我们的维护的插件被记录在以下位置： 123456rabbitmq_managementrabbitmq_management_agentrabbitmq_mochiwebrabbitmq_stomprabbitmq_shovelrabbitmq_auth_backend_ldap 3）文件位置 名称 描述 RABBITMQ_BASE 此基础目录包含了RabbitMQ server的数据库，日志文件的子目录. 另外，也可以独立设置RABBITMQ_MNESIA_BASE 和 RABBITMQ_LOG_BASE 目录. RABBITMQ_CONFIG_FILE 用于配置文件的路径，无.config扩展名. 如果 configuration file 存在，服务器将使用它来配置RabbitMQ组件. 参考 Configuration guide 来了解更多信息. RABBITMQ_MNESIA_BASE 包含RabbitMQ 服务器Mnesia数据库文件子目录的基本目录,除非明确设置了RABBITMQ_MNESIA_DIR目录，否则每个节点都应该配置一个. (除了Mnesia文件，这个位置还包含消息存储和索引文件以及模式和集群的细节．） RABBITMQ_MNESIA_DIR RabbitMQ节点Mnesia数据库文件安放的目录. (除了Mnesia文件，这个位置还包含消息存储和索引文件以及模式和集群的细节.) RABBITMQ_LOG_BASE 用于包含RabbitMQ 服务器日志文件的基本目录, 除非明确设置了RABBITMQ_LOGS 或 RABBITMQ_SASL_LOGS. RABBITMQ_LOGS RabbitMQ 服务器的Erlang日志文件路径.在Window上不能覆盖此变量． RABBITMQ_SASL_LOGS RabbitMQ服务器的Erlang SASL (System Application Support Libraries)日志文件路径. 在Window上不能覆盖此变量． RABBITMQ_PLUGINS_DIR 用于查找插件的目录 . RABBITMQ_PLUGINS_EXPAND_DIR 用于在启动服务器时扩展启用插件的工作目录。 RABBITMQ_ENABLED_PLUGINS_FILE 此文件记录了显式启用的插件。 RABBITMQ_PID_FILE 此文件中包含了rabbitmqctl所等待进程ID的信息． Unix默认位置在下面的表格中，${install_prefix}表示某个路径. Homebrew 安装时使用installation-prefix (Homebrew Cellar) . 默认是/usr/local.Deb / RPM 包安装使用空${install_prefix}. Name Location RABBITMQ_BASE (Not used) RABBITMQ_CONFIG_FILE ${install_prefix}/etc/rabbitmq/rabbitmq RABBITMQ_MNESIA_BASE ${install_prefix}/var/lib/rabbitmq/mnesia RABBITMQ_MNESIA_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME RABBITMQ_LOG_BASE ${install_prefix}/var/log/rabbitmq RABBITMQ_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME.log RABBITMQ_SASL_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME-sasl.log RABBITMQ_PLUGINS_DIR $RABBITMQ_HOME/plugins RABBITMQ_PLUGINS_EXPAND_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME-plugins-expand RABBITMQ_ENABLED_PLUGINS_FILE ${install_prefix}/etc/rabbitmq/enabled_plugins RABBITMQ_PID_FILE $RABBITMQ_MNESIA_DIR.pid Windows默认位置 Name Location RABBITMQ_BASE %APPDATA%\RabbitMQ RABBITMQ_CONFIG_FILE %RABBITMQ_BASE%\rabbitmq RABBITMQ_MNESIA_BASE %RABBITMQ_BASE%\db RABBITMQ_MNESIA_DIR %RABBITMQ_MNESIA_BASE%\%RABBITMQ_NODENAME% RABBITMQ_LOG_BASE %RABBITMQ_BASE%\log RABBITMQ_LOGS %RABBITMQ_LOG_BASE%\%RABBITMQ_NODENAME%.log RABBITMQ_SASL_LOGS %RABBITMQ_LOG_BASE%\%RABBITMQ_NODENAME%-sasl.log RABBITMQ_PLUGINS_DIR Installation-directory/plugins RABBITMQ_PLUGINS_EXPAND_DIR %RABBITMQ_MNESIA_BASE%\%RABBITMQ_NODENAME%-plugins-expand RABBITMQ_ENABLED_PLUGINS_FILE %RABBITMQ_BASE%\enabled_plugins RABBITMQ_PID_FILE (Not currently supported) 通用Unix默认位置（即本次测试使用Rabbitmq版本）当解压Generic Unix tar文件并运行时，由于默认获得到位置，不需要进行. 在下面的表格中，$RABBITMQ_HOME指的是rabbitmq_server-3.7.4解压后的目录。 Name Location RABBITMQ_BASE (Not used) RABBITMQ_CONFIG_FILE $RABBITMQ_HOME/etc/rabbitmq/rabbitmq RABBITMQ_MNESIA_BASE $RABBITMQ_HOME/var/lib/rabbitmq/mnesia RABBITMQ_MNESIA_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME RABBITMQ_LOG_BASE $RABBITMQ_HOME/var/log/rabbitmq RABBITMQ_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME.log RABBITMQ_SASL_LOGS $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME-sasl.log RABBITMQ_PLUGINS_DIR $RABBITMQ_HOME/plugins RABBITMQ_PLUGINS_EXPAND_DIR $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME-plugins-expand RABBITMQ_ENABLED_PLUGINS_FILE $RABBITMQ_HOME/etc/rabbitmq/enabled_plugins RABBITMQ_PID_FILE $RABBITMQ_MNESIA_DIR.pid 4）持久化配置RabbitMQ持久层的目的是为了得到好的结果，在大多数情况下没有配置。然而，一些配置有时是有用的。首先，先讲一下背景: 持久化和短暂消息都可以写入磁盘。持久化消息一旦到达队列，就会写入磁盘,而短暂消息只在内存压力较大被赶出内存时才会写入磁盘。持久化消息在内存紧张释放内存时，依然也会存在内存中． 持久层指的是存储这两种类型消息到磁盘的机制。队列是指无镜像队列或master队列或slave队列。 队列镜像会发生以上的持久化。持久层有两个组件: 队列索引和消息存储.队列索引负责维护消息在队列的位置，以及是否被投递，是否应答的信息. 因此，每个队列都有一个队列索引。消息存储是消息的key-value存储, 由服务器中的所有队列共享.消息(消息体, 消息属性或消息头)可直接存储于队列索引，也可以写到消息存储中.在技术上有两个消息存储（一个暂时的和一个持久的消息），但他们通常一起被被认为是“消息存储”。内存成本在内存压力下，持久层试图尽可能多地写入磁盘，并尽可能的从内存中删除。然而有一些事情必须留在内存中：每个队列都会为每个未应答消息维护一些元数据．如果它的目的地是消息存储，则消息本身可以从内存中删除。消息存储需要索引. 默认消息存储索引对于存储中的每个消息会使用少量内存。队列索引中的消息将消息写入队列索引有优点也有缺点。优点:消息可在一个操作中(而不是两个）写入磁盘; 对于微小的消息，这可以是一个实质性的增益。写入队列索引的消息不需要消息存储索引中的条目，因此当页出(paged out)时，不需要花费内存成本。缺点:队列索引在内存中保有固定数量的记录块;如果写入队列索引中的消息不是小消息，那么内存占用也是巨大的。如果一个消息通过一个交换路由到多个队列，则消息将需要写入多个队列索引。如果这样的消息被写入消息存储区，则只有一个副本需要被写入。目的地是队列索引的未应答消息总会保存在内存中。将小消息存储在队列索引中目的是优化，所有其它消息将会写入消息存储.这可以配置项queue_index_embed_msgs_below来配置.默认情况下，序列后大小小于4096字节 (包括属性和头)会存储在队列索引中。当从磁盘中读取消息时，每个队列索引至少需要在内存中保留一个段文件(segment file). 段文件中包含了16,384个消息. 因此要谨慎如果增加queue_index_embed_msgs_below；小的增加会导致大量的内存使用。无意中有限的持久性能(Accidentally limited persister performance）持久化有可能表现不佳，因为持久化受限于文件句柄的数目或与它工作的异步线程.在这两种情况下，当您有大量需要同时访问磁盘的队列时，会发生这样的情况。.太少的文件句柄RabbitMQ 服务器通常受限于它能打开的文件句柄数量(在Unix上，无论如何). 每个运行的网络连接都需要一个文件句柄, 其余的可用于队列使用。如果磁盘访问队列比考虑到网络连接后文件句柄更多，那么磁盘访问队列将与文件句柄一起共享; 每个都会在它返回交给另一个队列之前，都会使用文件句柄一段时间。当有太多磁盘访问队列时，这可以防止服务器崩溃,但代价是昂贵的. 管理插件可以显示集群中每个节点的统计I/O统计信息，如读，写，查找的速率．同时它也会显示重新开始(reopens)的速率- 文件句柄通过这种方式来回收利用. 一个有太少文件句柄繁忙的服务器每秒可能会做几百次reopens - 在这种情况下，如果增加文件句柄，就有可能提高性能。太少的异步线程Erlang 虚拟机创建异步线程池来处理长时间运行的文件I/O操作. 这些线程池是所有队列所共享的.每个活跃的文件I/O操作都会使用一个异步线程. 太少的异步线程可以因此伤害性能。注意，异步线程的情况并不完全类似与文件句柄的情况. 如果一个队列按顺序来执行一定数量的I/O操作，假设它持有一个文件句柄来所理所有操作，其性能是最好的，否则，我们会占用ＣＰＵ来做更多的刷新，查找 操作. 然而,队列不能从持有一个异步线程执行一系列的操作中获益(事实上也做不到)。因此理论上应该要有足够的文件句柄来处理所有队列上的I/O流操作, 并且要有足够的线程来处理并发的 (simultaneous )的I/O操作。由异步线程缺乏造成的性能问题，不是太明显. (一般情况下都不太可能，可首先检查其它地方!) 。太少异步线程的典型症状是，当服务器忙于持久化时，在很短的时间内，每秒 I/O操作的数目将会下降到０(管理插件可报告) ,报告的每个 I/O操作的时间将会增加。Erlang虚拟主机的异步线程数目可通过+A 参数进行配置，这里有描述, 通常情况下，也可以通过环境变量RABBITMQ_SERVER_ERL_ARGS来配置. 默认值是 +A 30. 在修改之前，多进行几次尝试总是好主意。 三、Rabbitmq集群RabbitMQ是用erlang开发的，集群非常方便，因为erlang天生就是一门分布式语言,但其本身并不支持负载均衡。Rabbit模式大概分为以下三种：单一模式、普通模式、镜像模式单一模式：最简单的情况，非集群模式。普通模式：默认的集群模式。对于Queue来说，消息实体只存在于其中一个节点，A、B两个节点仅有相同的元数据，即队列结构。当消息进入A节点的Queue中后，consumer从B节点拉取时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连A或B，出口总在A，会产生瓶颈。该模式存在一个问题就是当A节点故障后，B节点无法取到A节点中还未消费的消息实体。如果做了消息持久化，那么得等A节点恢复，然后才可被消费；如果没有持久化的话，就会很容易发生故障。镜像模式：把需要的队列做成镜像队列，存在于多个节点，属于RabbitMQ的HA方案。该模式解决了上述问题，其实质和普通模式不同之处在于，消息实体会主动在镜像节点间同步，而不是在consumer取数据时临时拉取。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉，所以在对可靠性要求较高的场合中适用。 1、集群中的基本概念RabbitMQ的集群节点包括内存节点、磁盘节点。顾名思义内存节点就是将所有数据放在内存，磁盘节点将数据放在磁盘。不过，如前文所述，如果在投递消息时，打开了消息的持久化，那么即使是内存节点，数据还是安全的放在磁盘。一个rabbitmq集群中可以共享 user，vhost，queue，exchange等，所有的数据和状态都是必须在所有节点上复制的，一个例外是，那些当前只属于创建它的节点的消息队列，尽管它们可见且可被所有节点读取。rabbitmq节点可以动态的加入到集群中，一个节点它可以加入到集群中，也可以从集群环集群会进行一个基本的负载均衡。集群中有两种节点：1 内存节点：只保存状态到内存（一个例外的情况是：持久的queue的持久内容将被保存到disk）2 磁盘节点：保存状态到内存和磁盘。内存节点虽然不写入磁盘，但是它执行比磁盘节点要好。集群中，只需要一个磁盘节点来保存状态 就足够了如果集群中只有内存节点，那么不能停止它们，否则所有的状态，消息等都会丢失。 2、集群模式配置1）配置hosts在2台节点服务器中，分别修改/etc/hosts文件1210.186.21.84 10-186-21-8410.186.21.85 10-186-21-85 还有hostname文件也要正确，分别是10-186-21-84、10-186-21-85，如果修改hostname建议安装rabbitmq前修改。请注意RabbitMQ集群节点必须在同一个网段里，如果是跨广域网效果就差。 2）设置每个节点CookieRabbitmq的集群是依赖于erlang的集群来工作的，所以必须先构建起erlang的集群环境。Erlang的集群中各节点是通过一个magic cookie来实现的，这个cookie存放在 /var/lib/rabbitmq/.erlang.cookie 中，文件是400的权限。所以必须保证各节点cookie保持一致，否则节点之间就无法通信。将10-186-21-84中的cookie 复制到10-186-21-85中，先修改下10-186-21-84中的.erlang.cookie权限1chmod 777 /root/.erlang.cookie 将queue的/root/.erlang.cookie这个文件，拷贝到10-186-21-85的同一位置（反过来亦可），该文件是集群节点进行通信的验证密钥，所有节点必须一致。拷完后重启下RabbitMQ。复制好后别忘记还原.erlang.cookie的权限，否则可能会遇到错误chmod 400 /root/.erlang.cookie设置好cookie后先将三个节点的rabbitmq重启12rabbitmqctl stoprabbitmq-server start 3）重启所有节点停止所有节点RabbitMq服务，然后使用detached参数独立运行，尤其增加节点停止节点后再次启动遇到无法启动都可以参照这个顺序（此步骤很重要）12rabbitmqctl stoprabbitmq-server -detached 分别查看节点集群信息第一台1234567[root@10-186-21-84 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-30-84 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-30-84']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-30-84']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-30-84"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-30-84',[]&#125;]&#125;] 第二台1234567[root@10-186-21-85 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-21-85 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-21-85']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-21-85']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-21-85"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-21-85',[]&#125;]&#125;] 4）配置集群10-186-21-84作为内存节点，10-186-21-84作为磁盘节点创建集群。在10-186-21-84上操作加入集群rabbit@10-186-21-851234567[root@10-186-21-84 ~]# rabbitmqctl stop_appStopping rabbit application on node rabbit@10-186-30-84 ...[root@10-186-21-84 ~]# rabbitmqctl join_cluster --ram rabbit@10-186-21-85Clustering node rabbit@10-186-30-84 with rabbit@10-186-21-85[root@10-186-21-84 ~]# rabbitmqctl start_appStarting node rabbit@10-186-30-84 ... completed with 3 plugins. 此时重新查看节点上集群信息在10-186-21-84上查看1234567[root@10-186-21-84 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-21-84 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-21-85']&#125;,&#123;ram,['rabbit@10-186-21-84']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-21-85','rabbit@10-186-21-84']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-21-85"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-21-85',[]&#125;,&#123;'rabbit@10-186-21-84',[]&#125;]&#125;] 在10-186-21-85上查看1234567[root@10-186-21-85 ~]# rabbitmqctl cluster_statusCluster status of node rabbit@10-186-21-85 ...[&#123;nodes,[&#123;disc,['rabbit@10-186-21-85']&#125;,&#123;ram,['rabbit@10-186-21-84']&#125;]&#125;, &#123;running_nodes,['rabbit@10-186-21-84','rabbit@10-186-21-85']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@10-186-21-85"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@10-186-21-84',[]&#125;,&#123;'rabbit@10-186-21-85',[]&#125;]&#125;] disc代表磁盘模式ram代表内存模式cluster_name代表集群名称查看消息队列是否一致1rabbitmqctl list_queues -p hrsystem 5）节点相关操作change_cluster_node_type {disc | ram}修改集群节点的类型. 要成功执行此操作，必须首先停止节点，要将节点转换为RAM节点，则此节点不能是集群中的唯一disc节点。ram节点转换为disc节点亦然。例如:1rabbitmqctl change_cluster_node_type disc 此命令会将一个RAM节点转换为disc节点。 forget_cluster_node [–offline][–offline]允许节点从脱机节点中删除. 这只在所有节点都脱机且最后一个掉线节点不能再上线的情况下有用，从而防止整个集群从启动。它不能使用在其它情况下，因为这会导致不一致．远程删除一个集群节点.要删除的节点必须是脱机的, 而在删除节点期间节点必须是在线的，除非使用了–offline 标志.当使用–offline 标志时，rabbitmqctl不会尝试正常连接节点;相反，它会临时改变节点以作修改.如果节点不能正常启动的话，这是非常有用的.在这种情况下，节点将变成集群元数据的规范源（例如，队列的存在），即使它不是以前的。因此，如果有可能，你应该在最新的节点上使用这个命令来关闭。例如:1rabbitmqctl -n hare@mcnulty forget_cluster_node rabbit@stringer 此命令会从节点hare@mcnulty中删除rabbit@stringer节点.1rename_cluster_node &#123;oldnode1&#125; &#123;newnode1&#125; [oldnode2] [newnode2 ...] 支持在本地数据库中重命名集群节点.此子命令会促使rabbitmqctl临时改变节点以作出修改. 因此本地集群必须是停止的，其它节点可以是在线或离线的．这个子命令接偶数个参数，成对表示节点的旧名称和新名称.你必须指定节点的旧名称和新名称，因为其它停止的节点也可能在同一时间重命名.同时停止所有节点来重命名也是可以的(在这种情况下，每个节点都必须给出旧名称和新名称)或一次停止一个节点来重命名(在这种情况下，每个节点只需要被告知其名句是如何变化的).例如:1rabbitmqctl rename_cluster_node rabbit@misshelpful rabbit@cordelia 此命令来将节点名称rabbit@misshelpful 重命名为rabbit@cordelia.12update_cluster_nodes &#123;clusternode&#125;clusternode 用于咨询具有最新消息的节点.指示已集群的节点醒来时联系clusternode.这不同于join_cluster ，因为它不会加入任何集群 - 它会检查节点已经以clusternode的形式存在于集群中了．需要这个命令的动机是当节点离线时，集群可以变化.考虑这样的情况，节点Ａ和节点Ｂ都在集群里边，这里节点Ａ掉线了，Ｃ又和Ｂ集群了，然后Ｂ又离开了集群．当Ａ醒来的时候，它会尝试联系Ｂ，但这会失败，因为Ｂ已经不在集群中了.update_cluster_nodes -n A C 可解决这种场景．1force_boot 确保节点将在下一次启动，即使它不是最后一个关闭的。通常情况下，当你关闭整个RabbitMQ 集群时，你重启的第一个节点应该是最后一个下线的节点，因为它可以看到其它节点所看不到的事情. 但有时这是不可能的:例如，如果整个集群是失去了电力而所有节点都在想它不是最后一个关闭的．在这种节点掉线情况下，你可以调用rabbitmqctl force_boot ．这就告诉节点下一次无条件的启动节点.在此节点关闭后，集群的任何变化，它都会丢失．如果最后一个掉线的节点永久丢失了，那么你需要优先使用rabbitmqctl forget_cluster_node –offline, 因为它可以确保在丢失的节点上掌握的镜像队列得到提升。例如:1rabbitmqctl force_boot 这可以强制节点下次启动时不用等待其它节点．12sync_queue [-p vhost] &#123;queue&#125;queue 同步队列的名称指示未同步slaves上的镜像队列自行同步.同步发生时，队列会阻塞(所有出入队列的发布者和消费者都会阻塞).此命令成功执行后，队列必须是镜像的。注意，未同步队列中的消息被耗尽后，最终也会变成同步. 此命令主要用于未耗尽的队列。12cancel_sync_queue [-p vhost] &#123;queue&#125;queue 取消同步的队列名称.指示同步镜像队列停止同步.12purge_queue [-p vhost] &#123;queue&#125;queue 要清除队列的名称.清除队列(删除其中的所有消息).1set_cluster_name &#123;name&#125; 设置集群名称. 集群名称在client连接时，会通报给client,也可用于federation和shovel插件记录消息的来源地. 群集名称默认是来自在群集中的第一个节点的主机名，但可以改变。例如:1rabbitmqctl set_cluster_name london 设置集群名称为”london”. 3、镜像模式配置上面配置RabbitMQ默认集群模式，但并不保证队列的高可用性，尽管交换机、绑定这些可以复制到集群里的任何一个节点，但是队列内容不会复制，虽然该模式解决一部分节点压力，但队列节点宕机直接导致该队列无法使用，只能等待重启，所以要想在队列节点宕机或故障也能正常使用，就要复制队列内容到集群里的每个节点，需要创建镜像队列。下面配置镜像模式来解决复制的问题，从而提高可用性。 1）增加负载均衡器选择HAProxy作为RabbitMQ前端的LB安装haproxy1yum install haproxy 配置负载均衡，在/etc/haproxy/haproxy.cfg中加入以下内容12345listen rabbitmq_cluster 0.0.0.0:5672 mode tcp balance roundrobin server rqslave1 10.186.21.84:5672 check inter 2000 rise 2 fall 3# server rqslave2 10.186.21.85:5672 check inter 2000 rise 2 fall 3 负载均衡器会监听5672端口，轮询内存节点10.186.21.84的5672端口,由于资源问题，此处只配置一个内存节点，应该是配置多个才有意义。10.186.21.85为磁盘节点，只做备份不提供给生产者、消费者使用，当然如果我们服务器资源充足情况也可以配置多个磁盘节点，这样磁盘节点除了故障也不会影响，除非同时出故障。 2）配置策略使用Rabbit镜像功能，需要基于rabbitmq策略来实现，政策是用来控制和修改群集范围的某个vhost队列行为和Exchange行为。在cluster中任意节点启用策略，策略会自动同步到集群节点rabbitmqctl set_policy -p hrsystem ha-allqueue”^” ‘{“ha-mode”:”all”}’这行命令在vhost名称为hrsystem创建了一个策略，策略名称为ha-allqueue,策略模式为 all 即复制到所有节点，包含新增节点，策略正则表达式为 “^” 表示所有匹配所有队列名称。Set_policy语法参看官网：1set_policy [-p vhost] [--priority priority] [--apply-to apply-to] name pattern definition 用法12Usage:rabbitmqctl [-n &lt;node&gt;] [-t &lt;timeout&gt;] [-q] set_policy [-p &lt;vhost&gt;] [--priority &lt;priority&gt;] [--apply-to &lt;apply-to&gt;] &lt;name&gt; &lt;pattern&gt; &lt;definition&gt; 通过命令行添加，例如12[root@10-186-21-84 ~]# rabbitmqctl set_policy delete_ha "^delete" '&#123;"ha-mode":"all"&#125;'Setting policy "delete_ha" for pattern "^delete" to "&#123;"ha-mode":"all"&#125;" with priority "0" for vhost "/" .. 查看web界面从上图可以看到已添加成功。也可以通过rabbit控制台添加下图为以添加的两个policy下图可以看到在exchanges中已经可以看all_ha已经被应用 3）新加入队列创建队列时需要指定ha 参数，如果不指定x-ha-prolicy 的话将无法复制。 4、单机多节点集群配置在启动RabbitMQ节点之后，服务器默认的节点名称是Rabbit和监听端口5672，如果想在同一台机器上启动多个节点，那么其他的节点就会因为节点名称和端口与默认的冲突而导致启动失败，可以通过设置环境变量来实现，具体方法如下：配置三个rabbitmq节点，分别为rabbit1, rabbit2和rabbit3主要开启命令如下：123RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit1 rabbitmq-server -detachedRABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit2 rabbitmq-server -detachedRABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=rabbit3 rabbitmq-server -detached 结束命令如下：123rabbitmqctl -n rabbit1 stoprabbitmqctl -n rabbit2 stoprabbitmqctl -n rabbit3 stop rabbit1上配置集群1234rabbitmqctl -n rabbit1 stop_apprabbitmqctl -n rabbit1 resetrabbitmqctl -n rabbit1 cluster rabbitmqctl -n rabbit1 start_app rabbit2加入rabbit1集群1234rabbitmqctl -n rabbit2 stop_apprabbitmqctl -n rabbit2 resetrabbitmqctl -n rabbit2 cluster rabbit1@`hostname -s`rabbitmqctl -n rabbit2 start_app 查看集群状态1rabbitmqctl -n rabbit1 cluster_status 将rabbit3加入集群1234rabbitmqctl -n rabbit3 stop_apprabbitmqctl -n rabbit3 resetrabbitmqctl -n rabbit3 cluster rabbit1@`hostname -s`rabbitmqctl -n rabbit3 start_app 再查看集群状态1rabbitmqctl -n rabbit1 cluster_status 由于此种集群方案对于并无太大意思，所以只简单讲述方法。同理可以配置多机多节点集群。]]></content>
      <categories>
        <category>Service</category>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>集群</tag>
        <tag>erlang</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat基础文档]]></title>
    <url>%2Fposts%2F4dff34fc.html</url>
    <content type="text"><![CDATA[一、 前言1、Tomcat是什么Tomcat 是由 Apache 开发的一个 Servlet 容器，实现了对 Servlet 和 JSP 的支持，并提供了作为Web服务器的一些特有功能，如Tomcat管理和控制平台、安全域管理和Tomcat阀等。由于 Tomcat 本身也内含了一个 HTTP 服务器，它也可以被视作一个单独的 Web 服务器。但是，不能将 Tomcat 和 Apache HTTP 服务器混淆，Apache HTTP 服务器是一个用 C 语言实现的 HTTP Web 服务器；这两个 HTTP web server 不是捆绑在一起的。Tomcat 包含了一个配置管理工具，也可以通过编辑XML格式的配置文件来进行配置。 2、Tomcat重要目录1234* /bin - Tomcat 脚本存放目录（如启动、关闭脚本）。 *.sh 文件用于 Unix 系统； *.bat 文件用于 Windows 系统。* /conf - Tomcat 配置文件目录。* /logs - Tomcat 默认日志目录。* /webapps - webapp 运行的目录。 3、web工程发布目录一般web项目路径结构123456789101112|-- webapp # 站点根目录 |-- META-INF # META-INF 目录 | `-- MANIFEST.MF # 配置清单文件 |-- WEB-INF # WEB-INF 目录 | |-- classes # class文件目录 | | |-- *.class # 程序需要的 class 文件 | | `-- *.xml # 程序需要的 xml 文件 | |-- lib # 库文件夹 | | `-- *.jar # 程序需要的 jar 包 | `-- web.xml # Web应用程序的部署描述文件 |-- &lt;userdir&gt; # 自定义的目录 |-- &lt;userfiles&gt; # 自定义的资源文件 webapp：工程发布文件夹。其实每个 war 包都可以视为 webapp 的压缩包。 META-INF：META-INF 目录用于存放工程自身相关的一些信息，元文件信息，通常由开发工具，环境自动生成。 WEB-INF：Java web应用的安全目录。所谓安全就是客户端无法访问，只有服务端可以访问的目录。 /WEB-INF/classes：存放程序所需要的所有 Java class 文件。 /WEB-INF/lib：存放程序所需要的所有 jar 文件。 /WEB-INF/web.xml：web 应用的部署配置文件。它是工程中最重要的配置文件，它描述了servlet和组成应用的其它组件，以及应用初始化参数、安全管理约束等。 二、安装Tomcat需要java环境支持，无论windows server还是linux server都需要先安装JAVA环境，本次安装tomcat8.5.29版本需要最低JAVA SE 7或以上版本支持。具体的JAVA版本支持可以从tomcat官网tomcat.apache.org查看。 1、 windwos server安装Tomcat由于windows server环境安装过于简单，以及实际使用较少，在这里只简述过程。 1）安装JDK下载JDK版本为1.8.0_161，windows版本可以双击直接安装，或者添加系统环境变量JAVA_HOME，环境变量的值为JDK的路径。 2）安装Tomcat下载zip压缩版本，下载后解压，可以直接双击bin目录下的startup.bat启动，也可以注册服务，以服务方式启动。 2、linux server安装Tomcat1）安装JDK检查系统是否已经安装jdk1java -version 如果没有显示java版本信息，则表示没有安装java12345678910#安装javatar -zxvf jdk-8u161-linux-x64.tar.gzmv jdk1.8.0_161 /data/jdk1.8#修改系统变量vi /etc/profile#在文本末尾添加以下内容：PATH=/data/jdk1.8/bin:$PATHexport PATH#使添加内容生效 source /etc/profile 再查看java版本 出现如下信息表示安装成功1234# java -versionjava version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 2）安装Tomcat12345678910111213141516171819202122232425#解压tar zxvf apache-tomcat-8.5.29.tar.gz#修改目录名并移动位置mv apache-tomcat-8.5.29 /data/tomcat#修改默认启动脚本cd /usr/local/tomcat/binvim catalina.sh#首先找到CLASSPATH=，改为CLASSPATH=/data/jdk1.8/lib/tools.jar:/data/jdk1.8/lib/dt.jar#然后在文件的第二行空行插入以下内容（带#号注释的那行也要）：#chkconfig: 35 85 15CATALINA_HOME=/data/tomcatJAVA_HOME=/data/jdk1.8JRE_HOME=/data/jdk1.8#复制脚本到/etc/init.d/cp catalina.sh /etc/init.d/tomcat #给脚本加上可可执行权限chmod +x /etc/init.d/tomcat#启动tomcatservice tomcat start#查看进程# netstat -lntp|grep javatcp6 0 0 :::8009 :::* LISTEN 19310/java tcp6 0 0 :::8080 :::* LISTEN 19310/java tcp6 0 0 127.0.0.1:8005 :::* LISTEN 19310/java 访问ip:8080就能看到欢迎页 三、配置详解本节将列举一些重要、常见的配置项。 1、ServerServer 元素表示整个 Catalina servlet 容器。因此，它必须是 conf/server.xml 配置文件中的根元素。它的属性代表了整个 servlet 容器的特性。属性 描述 备注className 这个类必须实现org.apache.catalina.Server接口。 默认 org.apache.catalina.core.StandardServeraddress 服务器等待关机命令的TCP / IP地址。如果没有指定地址，则使用localhost。port 服务器等待关机命令的TCP / IP端口号。设置为-1以禁用关闭端口。shutdown 必须通过TCP / IP连接接收到指定端口号的命令字符串，以关闭Tomcat。 2、ServiceService元素表示一个或多个连接器组件的组合，这些组件共享一个用于处理传入请求的引擎组件。Server 中可以有多个 Service。属性 描述 备注className 这个类必须实现org.apache.catalina.Service接口。 默认 org.apache.catalina.core.StandardServicename 此服务的显示名称，如果您使用标准 Catalina 组件，将包含在日志消息中。与特定服务器关联的每个服务的名称必须是唯一的。conf/server.xml配置文件示例：123456&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8080" shutdown="SHUTDOWN"&gt; &lt;Service name="xxx"&gt; ... &lt;/Service&gt;&lt;/Server&gt; 3、ExecutorExecutor表示可以在Tomcat中的组件之间共享的线程池。属性 描述 备注className 这个类必须实现org.apache.catalina.Executor接口。 默认 org.apache.catalina.core.StandardThreadExecutorname 线程池名称。 要求唯一, 供Connector元素的executor属性使用namePrefix 线程名称前缀。maxThreads 最大活跃线程数。 默认200minSpareThreads 最小活跃线程数。 默认25maxIdleTime 当前活跃线程大于minSpareThreads时,空闲线程关闭的等待最大时间。 默认60000msmaxQueueSize 线程池满情况下的请求排队大小。 默认Integer.MAX_VALUE示例：123&lt;Service name="xxx"&gt; &lt;Executor name="tomcatThreadPool" namePrefix="catalina-exec-" maxThreads="300" minSpareThreads="25"/&gt;&lt;/Service&gt; 4、ConnectorConnector代表连接组件。Tomcat 支持三种协议：HTTP/1.1、HTTP/2.0、AJP。属性 说明 备注asyncTimeout Servlet3.0规范中的异步请求超时 默认30sport 请求连接的TCP Port 设置为0,则会随机选取一个未占用的端口号protocol 协议. 一般情况下设置为 HTTP/1.1,这种情况下连接模型会在NIO和APR/native中自动根据配置选择URIEncoding 对URI的编码方式. 如果设置系统变量org.apache.catalina.STRICT_SERVLET_COMPLIANCE为true,使用 ISO-8859-1编码;如果未设置此系统变量且未设置此属性, 使用UTF-8编码useBodyEncodingForURI 是否采用指定的contentType而不是URIEncoding来编码URI中的请求参数以下属性在标准的Connector(NIO, NIO2 和 APR/native)中有效:属性 说明 备注acceptCount 当最大请求连接maxConnections满时的最大排队大小 默认100,注意此属性和Executor中属性maxQueueSize的区别.这个指的是请求连接满时的堆栈大小,Executor的maxQueueSize指的是处理线程满时的堆栈大小connectionTimeout 请求连接超时 默认60000msexecutor 指定配置的线程池名称keepAliveTimeout keeAlive超时时间 默认值为connectionTimeout配置值.-1表示不超时maxConnections 最大连接数 连接满时后续连接放入最大为acceptCount的队列中. 对 NIO和NIO2连接,默认值为10000;对 APR/native,默认值为8192maxThreads 如果指定了Executor, 此属性忽略;否则为Connector创建的内部线程池最大值 默认200minSpareThreads 如果指定了Executor, 此属性忽略;否则为Connector创建线程池的最小活跃线程数 默认10processorCache 协议处理器缓存Processor对象的大小 -1表示不限制.当不使用servlet3.0的异步处理情况下: 如果配置Executor,配置为Executor的maxThreads;否则配置为Connnector的maxThreads. 如果使用Serlvet3.0异步处理, 取maxThreads和maxConnections的最大值 5、ContextContext元素表示一个Web应用程序，它在特定的虚拟主机中运行。每个Web应用程序都基于Web应用程序存档（WAR）文件，或者包含相应的解包内容的相应目录，如Servlet规范中所述。属性 说明 备注altDDName web.xml部署描述符路径 默认 /WEB-INF/web.xmldocBase Context的Root路径 和Host的appBase相结合, 可确定web应用的实际目录failCtxIfServletStartFails 同Host中的failCtxIfServletStartFails, 只对当前Context有效 默认为falselogEffectiveWebXml 是否日志打印web.xml内容(web.xml由默认的web.xml和应用中的web.xml组成) 默认为falsepath web应用的context path 如果为根路径,则配置为空字符串(“”), 不能不配置privileged 是否使用Tomcat提供的manager servletreloadable /WEB-INF/classes/ 和/WEB-INF/lib/ 目录中class文件发生变化是否自动重新加载 默认为falseswallowOutput true情况下, System.out和System.err输出将被定向到web应用日志中 默认为false 6、EngineEngine元素表示与特定的Catalina服务相关联的整个请求处理机器。它接收并处理来自一个或多个连接器的所有请求，并将完成的响应返回给连接器，以便最终传输回客户端。属性 描述 备注defaultHost 默认主机名，用于标识将处理指向此服务器上主机名称但未在此配置文件中配置的请求的主机。 这个名字必须匹配其中一个嵌套的主机元素的名字属性。name 此引擎的逻辑名称，用于日志和错误消息。 在同一服务器中使用多个服务元素时，每个引擎必须分配一个唯一的名称。 7、HostHost元素表示一个虚拟主机，它是一个服务器的网络名称（如“www.mycompany.com”）与运行Tomcat的特定服务器的关联。属性 说明 备注name 名称 用于日志输出appBase 虚拟主机对应的应用基础路径 可以是个绝对路径, 或${CATALINA_BASE}相对路径xmlBase 虚拟主机XML基础路径,里面应该有Context xml配置文件 可以是个绝对路径, 或${CATALINA_BASE}相对路径createDirs 当appBase和xmlBase不存在时,是否创建目录 默认为trueautoDeploy 是否周期性的检查appBase和xmlBase并deploy web应用和context描述符 默认为truedeployIgnore 忽略deploy的正则deployOnStartup Tomcat启动时是否自动deploy 默认为truefailCtxIfServletStartFails 配置为true情况下,任何load-on-startup &gt;=0的servlet启动失败,则其对应的Contxt也启动失败 默认为false 8、ClusterTomcat集群配置。集群的配置比较复杂，默认的集群配置可以满足一般的开发需求。一个Cluster配置案例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120&lt;!-- Cluster(集群,族) 节点,如果你要配置tomcat集群,则需要使用此节点. className 表示tomcat集群时,之间相互传递信息使用那个类来实现信息之间的传递. channelSendOptions可以设置为2、4、8、10，每个数字代表一种方式 2 = Channel.SEND_OPTIONS_USE_ACK(确认发送) 4 = Channel.SEND_OPTIONS_SYNCHRONIZED_ACK(同步发送) 8 = Channel.SEND_OPTIONS_ASYNCHRONOUS(异步发送) 在异步模式下，可以通过加上确认发送(Acknowledge)来提高可靠性，此时channelSendOptions设为10--&gt;&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;!-- Manager决定如何管理集群的Session信息。Tomcat提供了两种Manager：BackupManager和DeltaManager BackupManager－集群下的所有Session，将放到一个备份节点。集群下的所有节点都可以访问此备份节点 DeltaManager－集群下某一节点生成、改动的Session，将复制到其他节点。 DeltaManager是Tomcat默认的集群Manager，能满足一般的开发需求 使用DeltaManager，每个节点部署的应用要一样；使用BackupManager，每个节点部署的应用可以不一样. className－指定实现org.apache.catalina.ha.ClusterManager接口的类,信息之间的管理. expireSessionsOnShutdown－设置为true时，一个节点关闭，将导致集群下的所有Session失效 notifyListenersOnReplication－集群下节点间的Session复制、删除操作，是否通知session listeners maxInactiveInterval－集群下Session的有效时间(单位:s)。 maxInactiveInterval内未活动的Session，将被Tomcat回收。默认值为1800(30min) --&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;!-- Channel是Tomcat节点之间进行通讯的工具。 Channel包括5个组件：Membership、Receiver、Sender、Transport、Interceptor --&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;!-- Membership维护集群的可用节点列表。它可以检查到新增的节点，也可以检查到没有心跳的节点 className－指定Membership使用的类 address－组播地址 port－组播端口 frequency－发送心跳(向组播地址发送UDP数据包)的时间间隔(单位:ms)。默认值为500 dropTime－Membership在dropTime(单位:ms)内未收到某一节点的心跳，则将该节点从可用节点列表删除。默认值为3000 注: 组播（Multicast）：一个发送者和多个接收者之间实现一对多的网络连接。 一个发送者同时给多个接收者传输相同的数据，只需复制一份相同的数据包。 它提高了数据传送效率，减少了骨干网络出现拥塞的可能性 相同组播地址、端口的Tomcat节点，可以组成集群下的子集群 --&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;!-- Receiver : 接收器，负责接收消息 接收器分为两种：BioReceiver(阻塞式)、NioReceiver(非阻塞式) className－指定Receiver使用的类 address－接收消息的地址 port－接收消息的端口 autoBind－端口的变化区间 如果port为4000，autoBind为100，接收器将在4000-4099间取一个端口，进行监听 selectorTimeout－NioReceiver内轮询的超时时间 maxThreads－线程池的最大线程数 --&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;!-- Sender : 发送器，负责发送消息 Sender内嵌了Transport组件，Transport真正负责发送消息 --&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;!-- Transport分为两种：bio.PooledMultiSender(阻塞式)、nio.PooledParallelSender(非阻塞式) --&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;!-- Interceptor : Cluster的拦截器 TcpFailureDetector－网络、系统比较繁忙时，Membership可能无法及时更新可用节点列表， 此时TcpFailureDetector可以拦截到某个节点关闭的信息， 并尝试通过TCP连接到此节点，以确保此节点真正关闭，从而更新集群可以用节点列表 --&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;!-- MessageDispatch15Interceptor－查看Cluster组件发送消息的方式是否设置为 Channel.SEND_OPTIONS_ASYNCHRONOUS(Cluster标签下的channelSendOptions为8时)。 设置为Channel.SEND_OPTIONS_ASYNCHRONOUS时， MessageDispatch15Interceptor先将等待发送的消息进行排队，然后将排好队的消息转给Sender --&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;!-- Valve : 可以理解为Tomcat的拦截器 ReplicationValve－在处理请求前后打日志；过滤不涉及Session变化的请求 vmRouteBinderValve－Apache的mod_jk发生错误时，保证同一客户端的请求发送到集群的同一个节点 --&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;!-- Deployer : 同步集群下所有节点的一致性。 --&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;!-- ClusterListener : 监听器，监听Cluster组件接收的消息 使用DeltaManager时，Cluster接收的信息通过ClusterSessionListener传递给DeltaManager --&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt;&lt;/Cluster&gt; 四、配置实例1、Tomcat配置使用manager管理项目Tomcat在部署新项目时，可以通过/manager/html来上传war包，来完成部署。部署完成的访问路径为：ip:8080/warname。首先配置tomcat可以访问manager和host-manager在conf/tomcat-users.xml中标签中添加以下配置信息：123456789&lt;role rolename="admin"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="admin-script"/&gt;&lt;role rolename="manager"/&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;role rolename="manager-jmx"/&gt; &lt;role rolename="manager-status"/&gt; &lt;user username="tomcat" password="tomcat" roles="admin,admin-gui,admin-script,manager,manager-gui,manager-script,manager-jmx,manager-status"/&gt; 相关配置注释：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157manager-gui #允许访问html接口(即URL路径为/manager/html/*)manager-script #允许访问纯文本接口(即URL路径为/manager/text/*)manager-jmx #允许访问JMX代理接口(即URL路径为/manager/jmxproxy/*)manager-status #允许访问Tomcat只读状态页面(即URL路径为/manager/status/*)特别需要说明的是：manager-gui、manager-script、manager-jmx均具备manager-status的权限，也就是说，manager-gui、manager-script、manager-jmx三种角色权限无需再额外添加manager-status权限，即可直接访问路径”/manager/status/*”。Tomcat8中还需要增加一段配置才能满足要求，在conf/Catalina/localhost中新建文件名manager.xml，内容为：&lt;Context privileged="true" antiResourceLocking="false" docBase="$&#123;catalina.home&#125;/webapps/manager"&gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="^.*$" /&gt; &lt;/Context&gt;在conf/Catalina/localhost中新建文件名host-manager.xml，内容为：&lt;Context privileged="true" antiResourceLocking="false" docBase="$&#123;catalina.home&#125;/webapps/host-manager"&gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="^.*$" /&gt; &lt;/Context&gt;``` 配置完成后，重启tomcat，即可以访问manager。### 2、Nginx+Tomcat配置+多Tomcat负载均衡关于Nginx的配置请查看文档《Nginx应用文档》，Nginx的配置文件如下：```bashuser nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream lvs &#123; #配置两台tomcat负载均衡，ip：port地址为tomcat地址。weight为权重，权重越大，访问概率越大， server 127.0.0.1:8081 weight=10; server 127.0.0.1:8082 weight=10; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; # access_log logs/host.access.log main; location ~ .*\.(gif|jpg|jpeg|bmp|png|ico|txt|js|css)$ &#123; root /data/nainx/html/; #expires定义用户浏览器缓存的时间为7天，如果静态页面不常更新，可以设置更长，这样可以节省带宽和缓解服务器的压力 expires 7d; &#125; location ~ (\.jsp)|(\.do)$ &#123; #root html; #index index.jsp index.htm; #lvs是 upstream 后面的名字 lvs proxy_pass http://lvs; #localhost是nginx服务器的主机地址，如果不写此句，会导致静态文件访问路径为http://lvs，导致找不到地址 proxy_set_header Host localhost; #forwarded信息，用于告诉后端服务器终端用户的ip地址，否则后端服务器只能获取前端代理服务器的ip地址。 proxy_set_header Forwarded $remote_addr; &#125; # / 表示匹配所有地址，默认最大前缀匹配，如果其他没有匹配的才会匹配 location /&#123; root /data/lvs; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html #错误页面地址，500 502 503 504错误的地址 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 路径转发配置（可以不用配置）：1234567891011121314151617181920server &#123; listen 80; server_name *.*.*.*;#本服务器ip地址 #charset koi8-r; #access_log logs/host.access.log main; location /&#123; #root html; #index index.html index.htm; proxy_pass http://10.8.0.66:8090/; #当地址最后加上 /时，匹配路径的 yanshi 不会加到转发路径中 proxy_set_header X-Forwarded-For $remote_addr; #当下面这句话不加，Host $host; 会导致post请求参数丢失 proxy_set_header Host $host; proxy_set_header X-Real-Ip $remote_addr; &#125;&#125; 以下是关于tomcat的配置：同一服务器部署多个tomcat时，存在端口号冲突的问题，所以需要修改tomcat配置文件server.xml：首先了解下tomcat的几个主要端口：12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="60000" redirectPort="8443" disableUploadTimeout="false" executor="tomcatThreadPool" URIEncoding="UTF-8"/&gt;其中8080为HTTP端口，8443为HTTPS端口&lt;Server port="8005" shutdown="SHUTDOWN"&gt; 8005为远程停服务端口&lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt;``` 8009为AJP端口，APACHE能过AJP协议访问TOMCAT的8009端口。部署多个tomcat主要修改三个端口：第一个tomcat配置server.xml如下：```bash&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8006" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8081" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8010" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="/data/lvs " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8006、8081、8010第二个tomcat配置server.xml如下：123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8007" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8082" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8011" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="/data/lvs " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8007、8082、8011如果需要更多的tomcat做负载，端口号依次增加即可。nginx与tomcat的结合，主要用的是nginx中的upstream,后端可包括有多台tomcat来处ginx的upstream目前支持5种方式的分配 1）轮询（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 2）weight指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如：1234 upstream bakend &#123; server 192.168.0.14 weight=10; server 192.168.0.15 weight=10;&#125; 3）ip_hash每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session 的问题。例如：12345upstreambakend &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80; &#125; 4）fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。12345upstream backend &#123; server server1; server server2; fair;&#125; 5）url_hash（第三方）按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法123456upstream backend &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_methodcrc32;&#125; 示例：1234567upstream bakend&#123;#定义负载均衡设备的Ip及设备状态 ip_hash; server127.0.0.1:9090 down; server127.0.0.1:8080 weight=2; server127.0.0.1:6060; server127.0.0.1:7070 backup;&#125; 在需要使用负载均衡的server中增加1proxy_pass http://bakend/; 每个设备的状态设置为:1.down 表示单前的server暂时不参与负载2.weight 默认为1.weight越大，负载的权重就越大。3.max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误4.fail_timeout:max_fails次失败后，暂停的时间。5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 nginx支持同时设置多组的负载均衡，用来给不用的server来使用。client_body_in_file_only 设置为On 可以讲clientpost过来的数据记录到文件中用来做debugclient_body_temp_path 设置记录文件的目录 可以设置最多3层目录location 对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡 3、Apache+Tomcat集群配置1）集群简述集群是一组协同工作的服务实体，用以提供比单一服务实体更具扩展性与可用性的服务平台。在客户端看来，一个集群就象是一个服务实体，但 事实上集群由一组服务实体组成。与单一服务实体相比较，集群提供了以下两个关键特性：·可扩展性－－集群的性能不限于单一的服务实体，新的服 务实体可以动态地加入到集群，从而增强集群的性能。·高可用性－－集群通过服务实体冗余使客户端免于轻易遇到out of service的警告。在集群中，同样的服务可以由多个服务实体提供。如果一个服务实体失败了，另一个服务实体会接管失败的服务实体。集群提供的从一个出 错的服务实体恢复到另一个服务实体的功能增强了应用的可用性。为了具有可扩展性和高可用性特点，集群的必须具备以下两大能力： 负载均衡－－负载均衡能把任务比较均衡地分布到集群环境下的计算和网络资源。 错误恢复－－由于某种原因，执行某个任务的资源出现故障，另一服 务实体中执行同一任务的资源接着完成任务。这种由于一个实体中的资源不能工作，另一个实体中的资源透明的继续完成任务的过程叫错误恢复。负载均衡 和错误恢复都要求各服务实体中有执行同一任务的资源存在，而且对于同一任务的各个资源来说，执行任务所需的信息视图（信息上下文）必须是一样的。 集群主要分成三大类：高可用集群(High Availability Cluster/HA)， 负载均衡集群(Load Balance Cluster)，高性能计算集群(High Performance Computing Cluster/HPC) 高可用集群(High Availability Cluster/HA)：一般是指当集群中有某个节点失效的情况下，其上的任务会自动转移到其他正常的节点上。还指可以将集群中的某节点进行离线维护再上线，该过程并不影响整个集群的运行。常见的就是2个节点做 成的HA集群，有很多通俗的不科学的名称，比如”双机热备”, “双机互备”, “双机”，高可用集群解决的是保障用户的应用程序持续对外提供服 务的能力。 负载均衡集群(Load Balance Cluster)：负载均衡集群运行时一般通过一个或者多个前端负载均衡器将工作负载分发到后端的一组服务器上，从而达到将工作负载分发。这样的计算机集群有时也被称为服务器群（Server Farm）。一般web服务器集群、数据库集群 和应用服务器集群都属于这种类型。这种集群可以在接到请求时，检查接受请求较少，不繁忙的服务器，并把请求转到这些服务器 上。从检查其他服务器状态这一点上 看，负载均衡和容错集群很接近，不同之处是数量上更多。 高性能计算集群(High Performance Computing Cluster/HPC)：高性能计算集群采用将计算任务分配到集群的不同计算节点而提高计算能力，因而主要应用在科学计算领域。这类集群致力于提供单个计算机所不能提供的强大的计算能力 Tomcat集群配置的优缺点：通常配置tomcat集群有三种方式：使用DNS轮询，使用apache r-proxy代理方式，使用apache mod_jk方式。（1）DNS轮询的缺点：当集群中某台服务器停止之后，用户由于dns缓存的缘故，便无法访问服务，必 须等到dns解析更新，或者这台服务器重新启动。还有就是必须把集群中的所有服务端口暴露给外界，没有用apache做前置代理的方式安全，并 且占用大量公网IP地址，而且tomcat还要负责处理静态网页资源，影响效率。优点是集群配置最简单，dns设置也非常简单。（2）R- proxy的缺点：当其中一台tomcat停止运行的时候，apache仍然会转发请求过去，导致502网关错误。但是只要服务器再启动就不存 在这个问题。（3）mod_jk方式的优点是，Apache 会自动检测到停止掉的tomcat，然后不再发请求过去。缺点就是，当停 止掉的tomcat服务器再次启动的时候，Apache检测不到，仍然不会转发请求过去。R-proxy和mod_jk的共同优点是.可 以只将Apache置于公网，节省公网IP地址资源。可以通过设置来实现Apache专门负责处理静态网页，让Tomcat专门负责处理jsp和 servlet等动态请求。共同缺点是：如果前置Apache代理服务器停止运行，所有集群服务将无法对外提供。R-proxy和 mod_jk对静态页面请求的处理，都可以通设置来选取一个尽可能优化的效果。这三种方式对实现最佳负载均衡都有一定不足，mod_jk相对好些，可以通过设置lbfactor参数来分配请求任务。2）Apache安装12345678910111213141516171819202122232425#下载安装包wget http://mirrors.hust.edu.cn/apache//httpd/httpd-2.4.33.tar.gzwget http://archive.apache.org/dist/apr/apr-1.4.5.tar.gzwget http://archive.apache.org/dist/apr/apr-util-1.3.12.tar.gzwget http://jaist.dl.sourceforge.net/project/pcre/pcre/8.10/pcre-8.42.zip#apr安装tar -zxf apr-1.4.5.tar.gz cd apr-1.4.5 ./configure --prefix=/usr/local/apr make &amp;&amp; make install #apr-util安装tar -zxf apr-util-1.3.12.tar.gz cd apr-util-1.3.12 ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr/bin/apr-1-config make &amp;&amp; make install#pcre安装unzip -o pcre-8.42.zip cd pcre-8.42./configure --prefix=/usr/local/pcre make &amp;&amp; make install #apache安装tar -zxvf httpd-2.4.33.tar.gzcd httpd-2.4.33./configure --prefix=/data/apache --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util --with-pcre=/usr/local/pcremake &amp;&amp; make install 在apache安装过程中会有报错：差找不到文件apr_escape.h由于centos7默认是使用的是xfs的硬盘格式，在安装apr的时候由于automake编译根据硬盘格式会默认系统不需要这个文件，如果是其他硬盘格式，比如：ext3、ext4，则不会出现这个问题。解决方法：从apache官网上查找该文件源码，并放入apr的include/apr-1内，本次环境apr的目录为：/usr/local/apr/include/apr-1以下为apr_escape.h文件的源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374/* Licensed to the Apache Software Foundation (ASF) under one or more* contributor license agreements. See the NOTICE file distributed with* this work for additional information regarding copyright ownership.* The ASF licenses this file to You under the Apache License, Version 2.0* (the "License"); you may not use this file except in compliance with* the License. You may obtain a copy of the License at** http://www.apache.org/licenses/LICENSE-2.0** Unless required by applicable law or agreed to in writing, software* distributed under the License is distributed on an "AS IS" BASIS,* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.* See the License for the specific language governing permissions and* limitations under the License.*//*** @file apr_escape.h* @brief APR-UTIL Escaping*/#ifndef APR_ESCAPE_H#define APR_ESCAPE_H#include "apr.h"#include "apr_general.h"#ifdef __cplusplusextern "C" &#123;#endif/*** @defgroup APR_Util_Escaping Escape functions* @ingroup APR* @&#123;*//* Simple escape/unescape functions.**//*** When passing a string to one of the escape functions, this value can be* passed to indicate a string-valued key, and have the length computed* automatically.*/#define APR_ESCAPE_STRING (-1)/*** Perform shell escaping on the provided string.** Shell escaping causes characters to be prefixed with a '\' character.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_shell(char *escaped, const char *str,apr_ssize_t slen, apr_size_t *len);/*** Perform shell escaping on the provided string, returning the result* from the pool.** Shell escaping causes characters to be prefixed with a '\' character.** If no characters were escaped, the original string is returned.* @param p Pool to allocate from* @param str The original string* @return the encoded string, allocated from the pool, or the original* string if no escaping took place or the string was NULL.*/APR_DECLARE(const char *) apr_pescape_shell(apr_pool_t *p, const char *str)__attribute__((nonnull(1)));/*** Unescapes a URL, leaving reserved characters intact.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param url String to be unescaped* @param slen The length of the original url, or APR_ESCAPE_STRING* @param forbid Optional list of forbidden characters, in addition to* 0x00* @param reserved Optional list of reserved characters that will be* left unescaped* @param plus If non zero, '+' is converted to ' ' as per* application/x-www-form-urlencoded encoding* @param len If set, the length of the escaped string will be returned* @return APR_SUCCESS on success, APR_NOTFOUND if no characters are* decoded or the string is NULL, APR_EINVAL if a bad escape sequence is* found, APR_BADCH if a character on the forbid list is found.*/APR_DECLARE(apr_status_t) apr_unescape_url(char *escaped, const char *url,apr_ssize_t slen, const char *forbid, const char *reserved, int plus,apr_size_t *len);/*** Unescapes a URL, leaving reserved characters intact, returning the* result from a pool.* @param p Pool to allocate from* @param url String to be unescaped in place* @param forbid Optional list of forbidden characters, in addition to* 0x00* @param reserved Optional list of reserved characters that will be* left unescaped* @param plus If non zero, '+' is converted to ' ' as per* application/x-www-form-urlencoded encoding* @return A string allocated from the pool on success, the original string* if no characters are decoded, or NULL if a bad escape sequence is found* or if a character on the forbid list is found, or if the original string* was NULL.*/APR_DECLARE(const char *) apr_punescape_url(apr_pool_t *p, const char *url,const char *forbid, const char *reserved, int plus)__attribute__((nonnull(1)));/*** Escape a path segment, as defined in RFC1808.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_path_segment(char *escaped,const char *str, apr_ssize_t slen, apr_size_t *len);/*** Escape a path segment, as defined in RFC1808, returning the result from a* pool.* @param p Pool to allocate from* @param str String to be escaped* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_pescape_path_segment(apr_pool_t *p,const char *str) __attribute__((nonnull(1)));/*** Converts an OS path to a URL, in an OS dependent way, as defined in RFC1808.* In all cases if a ':' occurs before the first '/' in the URL, the URL should* be prefixed with "./" (or the ':' escaped). In the case of Unix, this means* leaving '/' alone, but otherwise doing what escape_path_segment() does. For* efficiency reasons, we don't use escape_path_segment(), which is provided for* reference. Again, RFC 1808 is where this stuff is defined.** If partial is set, os_escape_path() assumes that the path will be appended to* something with a '/' in it (and thus does not prefix "./").* @param escaped Optional buffer to write the encoded string, can be* NULL* @param path The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param partial If non zero, suppresses the prepending of "./"* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or if the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_path(char *escaped, const char *path,apr_ssize_t slen, int partial, apr_size_t *len);/*** Converts an OS path to a URL, in an OS dependent way, as defined in RFC1808,* returning the result from a pool.** In all cases if a ':' occurs before the first '/' in the URL, the URL should* be prefixed with "./" (or the ':' escaped). In the case of Unix, this means* leaving '/' alone, but otherwise doing what escape_path_segment() does. For* efficiency reasons, we don't use escape_path_segment(), which is provided for* reference. Again, RFC 1808 is where this stuff is defined.** If partial is set, os_escape_path() assumes that the path will be appended to* something with a '/' in it (and thus does not prefix "./").* @param p Pool to allocate from* @param str The original string* @param partial If non zero, suppresses the prepending of "./"* @return A string allocated from the pool on success, the original string* if no characters are encoded or if the string was NULL.*/APR_DECLARE(const char *) apr_pescape_path(apr_pool_t *p, const char *str,int partial) __attribute__((nonnull(1)));/*** Urlencode a string, as defined in* http://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.1.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or if the stirng was NULL*/APR_DECLARE(apr_status_t) apr_escape_urlencoded(char *escaped, const char *str,apr_ssize_t slen, apr_size_t *len);/*** Urlencode a string, as defined in* http://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.1, returning* the result from a pool.* @param p Pool to allocate from* @param str String to be escaped* @return A string allocated from the pool on success, the original string* if no characters are encoded or if the string was NULL.*/APR_DECLARE(const char *) apr_pescape_urlencoded(apr_pool_t *p,const char *str) __attribute__((nonnull(1)));/*** Apply entity encoding to a string. Characters are replaced as follows:* '&lt;' becomes '&amp;lt;', '&gt;' becomes '&amp;gt;', '&amp;' becomes '&amp;amp;', the* double quote becomes '&amp;quot;" and the single quote becomes '&amp;apos;'.** If toasc is not zero, any non ascii character will be encoded as* '%\#ddd;', where ddd is the decimal code of the character.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param toasc If non zero, encode non ascii characters* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_entity(char *escaped, const char *str,apr_ssize_t slen, int toasc, apr_size_t *len);/*** Apply entity encoding to a string, returning the result from a pool.* Characters are replaced as follows: '&lt;' becomes '&amp;lt;', '&gt;' becomes* '&amp;gt;', '&amp;' becomes '&amp;amp;', the double quote becomes '&amp;quot;" and the* single quote becomes '&amp;apos;'.* @param p Pool to allocate from* @param str The original string* @param toasc If non zero, encode non ascii characters* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_pescape_entity(apr_pool_t *p, const char *str,int toasc) __attribute__((nonnull(1)));/*** Decodes html entities or numeric character references in a string. If* the string to be unescaped is syntactically incorrect, then the* following fixups will be made:* unknown entities will be left undecoded;* references to unused numeric characters will be deleted.* In particular, &amp;#00; will not be decoded, but will be deleted.* @param unescaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_unescape_entity(char *unescaped, const char *str,apr_ssize_t slen, apr_size_t *len);/*** Decodes html entities or numeric character references in a string. If* the string to be unescaped is syntactically incorrect, then the* following fixups will be made:* unknown entities will be left undecoded;* references to unused numeric characters will be deleted.* In particular, &amp;#00; will not be decoded, but will be deleted.* @param p Pool to allocate from* @param str The original string* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_punescape_entity(apr_pool_t *p, const char *str)__attribute__((nonnull(1)));/*** Escape control characters in a string, as performed by the shell's* 'echo' command. Characters are replaced as follows:* \\a alert (bell), \\b backspace, \\f form feed, \\n new line, \\r carriage* return, \\t horizontal tab, \\v vertical tab, \\ backslash.** Any non ascii character will be encoded as '\\xHH', where HH is the hex* code of the character.** If quote is not zero, the double quote character will also be escaped.* @param escaped Optional buffer to write the encoded string, can be* NULL* @param str The original string* @param slen The length of the original string, or APR_ESCAPE_STRING* @param quote If non zero, encode double quotes* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if no changes to the string were* detected or the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_echo(char *escaped, const char *str,apr_ssize_t slen, int quote, apr_size_t *len);/*** Escape control characters in a string, as performed by the shell's* 'echo' command, and return the results from a pool. Characters are* replaced as follows: \\a alert (bell), \\b backspace, \\f form feed,* \\n new line, \\r carriage return, \\t horizontal tab, \\v vertical tab,* \\ backslash.** Any non ascii character will be encoded as '\\xHH', where HH is the hex* code of the character.** If quote is not zero, the double quote character will also be escaped.* @param p Pool to allocate from* @param str The original string* @param quote If non zero, encode double quotes* @return A string allocated from the pool on success, the original string* if no characters are encoded or the string is NULL.*/APR_DECLARE(const char *) apr_pescape_echo(apr_pool_t *p, const char *str,int quote);/*** Convert binary data to a hex encoding.* @param dest The destination buffer, can be NULL* @param src The original buffer* @param srclen The length of the original buffer* @param colon If not zero, insert colon characters between hex digits.* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if the string was NULL*/APR_DECLARE(apr_status_t) apr_escape_hex(char *dest, const void *src,apr_size_t srclen, int colon, apr_size_t *len);/*** Convert binary data to a hex encoding, and return the results from a* pool.* @param p Pool to allocate from* @param src The original buffer* @param slen The length of the original buffer* @param colon If not zero, insert colon characters between hex digits.* @return A zero padded buffer allocated from the pool on success, or* NULL if src was NULL.*/APR_DECLARE(const char *) apr_pescape_hex(apr_pool_t *p, const void *src,apr_size_t slen, int colon) __attribute__((nonnull(1)));/*** Convert hex encoded string to binary data.* @param dest The destination buffer, can be NULL* @param str The original buffer* @param slen The length of the original buffer* @param colon If not zero, ignore colon characters between hex digits.* @param len If present, returns the length of the string* @return APR_SUCCESS, or APR_NOTFOUND if the string was NULL, or APR_BADCH* if a non hex character is present.*/APR_DECLARE(apr_status_t) apr_unescape_hex(void *dest, const char *str,apr_ssize_t slen, int colon, apr_size_t *len);/*** Convert hex encoding to binary data, and return the results from a pool.* If the colon character appears between pairs of hex digits, it will be* ignored.* @param p Pool to allocate from* @param str The original string* @param colon If not zero, ignore colon characters between hex digits.* @param len If present, returns the length of the final buffer* @return A buffer allocated from the pool on success, or NULL if src was* NULL, or a bad character was present.*/APR_DECLARE(const void *) apr_punescape_hex(apr_pool_t *p, const char *str,int colon, apr_size_t *len);/** @&#125; */#ifdef __cplusplus&#125;#endif#endif /* !APR_ESCAPE_H */ 由于Apache和Nginx同台安装，所以修改Apache的端口为88，配置ServerName启动apache1./bin/apachectl start 访问apache服务器：http://ip:88响应结果：It works！ #apache服务器安装成功 3）Tomcat安装配置同一服务器部署多个tomcat时，存在端口号冲突的问题，所以需要修改tomcat配置文件server.xml：首先了解下tomcat的几个主要端口：123456&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="60000" redirectPort="8443" disableUploadTimeout="false" executor="tomcatThreadPool" URIEncoding="UTF-8"/&gt;#其中8080为HTTP端口，8443为HTTPS端口&lt;Server port="8005" shutdown="SHUTDOWN"&gt; #8005为远程停服务端口&lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; #8009为AJP端口，APACHE能过AJP协议访问TOMCAT的8009端口。 部署多个tomcat主要修改三个端口：第一个tomcat配置server.xml如下：123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8006" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8081" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8010" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat1"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8006、8081、8010第二个tomcat配置server.xml如下：123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8007" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8082" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8011" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat2"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps " unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 三个端口分别为：8007、8082、8011如果需要更多的tomcat做负载，端口号依次增加即可。tomcat1测试http://ip:8081tomcat2 测试http://ip:8082结果：显示tomcat首页 4）集群配置创建mod_jk.so文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142#下载wget http://archive.apache.org/dist/tomcat/tomcat-connectors/jk/tomcat-connectors-1.2.41-src.tar.gztar -zxvf tomcat-connectors-1.2.41-src.tar.gz cd tomcat-connectors-1.2.41-srccd native/#进行编译，生成文件，但是不需要make install./configure --with-apxs=/data/apache/bin/apxsmakecd apache-2.0/#拷贝到apache目录下cp mod_jk.so /data/apache/modules//data/apache/modules/在httpd.conf中加入配置Include conf/mod_jk.conf/data/apache/conf下创建mod_jk.conf文件，文件内容为#mod_jk 配置mod_jk包 LoadModule jk_module modules/mod_jk.so #workers 配置工作负责文件 JkWorkersFile conf/workers.properties #jk log 配置jk日志文件 JkLogFile logs/mod_jk.log #jk log leve 配置日志级别 JkLogLevel info #配置jk日志内存共享 JkShmFile logs/mod_jk.shm #balancer 配置负载均衡模式 JkMount /*.jsp balancer 在/data/apache/conf下创建workers.properties文件，文件内容为#tomcat1的配置 worker.tomcat1.port=8010worker.tomcat1.host=127.0.0.1worker.tomcat1.reference=worker.template worker.tomcat1.activation=A #worker.tomcat1.lbfactor=1 #tomcat2 的配置 worker.tomcat2.port=8011 worker.tomcat2.host=127.0.0.1worker.tomcat2.reference=worker.template worker.tomcat2.activation=A #worker.tomcat2.lbfactor=1 worker.list=balancer #balancer 负载配置 worker.balancer.type=lb worker.balancer.balance_workers=tomcat1,tomcat2 worker.balancer.sticky_session=1 #tempalte 负载模板配置 worker.template.type=ajp13``` 重启apache、tomcat1、tomcat2验证，可以访问apache地址http://ip:88/testjsp.jsp，可以看到不同的客户端或刷新后显示的可以是tomcat1，也可以是tomcat2，验证成功。#### 5）Session复制在Tomcat集群中实现session同步，可以通过session共享和复制来实现，下面以session复制来实现session同步。Session复制需要修改server.xml配置Tomcat1中在&lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat1"&gt;后面加上以下配置```bash&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" #默认为auto，改为自己的IP port="4001" #同一台服务器上的tomcat必须修改为不同的端口，tomcat1修改为4001，tomcat2修改为4002。 autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt;``` Tomcat2中在&lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tomcat1"&gt;后面加上以下配置```bash &lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" #默认为auto，改为自己的IP port="4002" #同一台服务器上的tomcat必须修改为不同的端口，tomcat1修改为4001，tomcat2修改为4002。 autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt; ``` 在集群中所有tomcat的应用项目中web.xml中的配置 ：在WEB-INF/web.xml中加入以下内容```bash&lt;!--此应用将与群集服务器复制Session--&gt; &lt;distributable/&gt;]]></content>
      <categories>
        <category>Service</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx+lua组建基础waf防火墙]]></title>
    <url>%2Fposts%2F49ebe7e1.html</url>
    <content type="text"><![CDATA[一、nginx+Lua环境部署1、系统基础信息123456# ifconfig eth0|grep 'inet addr'|awk -F ":" '&#123;print $2&#125;'|awk '&#123;print $1&#125;'192.168.83.129# cat /etc/redhat-releaseCentOS release 6.5 (Final)# uname -r2.6.32-431.el6.x86_64 2、安装基础库12yum -y install gcc gcc-c++yum -y install openssl openssl-devel 3、创建Nginx运行的普通用户1useradd -s /sbin/nologin -M www 4、下载需要的程序并安装123456789cd /usr/local/src/wget http://nginx.org/download/nginx-1.9.4.tar.gzwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.38.tar.gzwget -c http://luajit.org/download/LuaJIT-2.0.4.tar.gzwget https://github.com/simpl/ngx_devel_kit/archive/v0.2.19.tar.gzwget https://github.com/openresty/lua-nginx-module/archive/v0.9.16.tar.gztar zxvf ngx_devel_kit-0.2.19.tar.gztar zxvf lua-nginx-module-0.9.16.tar.gztar zxvf pcre-8.38.tar.gz 5、安装LuaJIT Luajit是Lua即时编译器123tar zxvf LuaJIT-2.0.4.tar.gzcd /usr/local/src/LuaJIT-2.0.4make &amp;&amp; make install 6、安装nginx并加载模块123456cd nginx-1.9.4/export LUAJIT_LIB=/usr/local/libexport LUAJIT_INC=/usr/local/include/luajit-2.0/./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-http_stub_status_module --with-file-aio --with-http_dav_module --add-module=../ngx_devel_kit-0.2.19/ --add-module=../lua-nginx-module-0.9.16/ --with-pcre=/usr/local/src/pcre-8.38/make -j2 &amp;&amp; make installln -s /usr/local/lib/libluajit-5.1.so.2 /lib64/libluajit-5.1.so.2 安装完毕后，下面可以测试安装了，修改nginx.conf 增加第一个配置123456789101112131415161718 server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location /hello &#123; default_type 'text/plain'; content_by_lua 'ngx.say("hello,lua")'; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 启动nginx1234/usr/local/nginx/sbin/nginx -t nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful/usr/local/nginx/sbin/nginx 7、测试看lua环境是否正常 二、openresty实现WAF功能1、系统基础信息123456# ifconfig eth0|grep 'inet addr'|awk -F ":" '&#123;print $2&#125;'|awk '&#123;print $1&#125;'192.168.83.129# cat /etc/redhat-releaseCentOS release 6.5 (Final)# uname -r2.6.32-431.el6.x86_64 2、安装基础依赖包1yum install -y readline-devel pcre-devel openssl-devel 3、下载并编译安装openresty1234567cd /usr/local/src/wget https://openresty.org/download/ngx_openresty-1.9.3.2.tar.gztar zxvf ngx_openresty-1.9.3.2.tar.gzcd ngx_openresty-1.9.3.2./configure --prefix=/usr/local/openresty-1.9.3.2 --with-luajit --with-http_stub_status_module --with-pcre --with-pcre-jitgmake &amp;&amp; gmake installln -s /usr/local/openresty-1.9.3.2/ /usr/local/openresty 4、测试openresty安装12345678910111213# vim /usr/local/openresty/nginx/conf/nginx.conf server &#123; location /hello &#123; default_type text/html; content_by_lua_block &#123; ngx.say("HelloWorld") &#125; &#125; &#125;# /usr/local/openresty/nginx/sbin/nginx -t nginx: the configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf test is successful# /usr/local/openresty/nginx/sbin/nginx 5、WAF部署：在github上克隆下代码123yum -y install gitcd /usr/local/openresty/nginx/conf/git clone https://github.com/unixhot/waf.git 6、修改Nginx的配置文件，加入（http字段）以下配置。注意路径，同时WAF日志默认存放在/tmp/日期_waf.log12345678910111213# vim /usr/local/openresty/nginx/conf/nginx.conf http &#123; include mime.types; default_type application/octet-stream; #WAF lua_shared_dict limit 50m; lua_package_path "/usr/local/openresty/nginx/conf/waf/?.lua"; init_by_lua_file "/usr/local/openresty/nginx/conf/waf/init.lua"; access_by_lua_file "/usr/local/openresty/nginx/conf/waf/access.lua";# /usr/local/openresty/nginx/sbin/nginx -t nginx: the configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf test is successful# /usr/local/openresty/nginx/sbin/nginx -s reload 7、根据日志记录位置，创建日志目录12# mkdir /tmp/waf_logs# chown www.www /tmp/waf_logs 8、配置信息与注释1234567891011121314151617181920212223242526272829303132333435363738394041424344# cat /usr/local/openresty/nginx/conf/waf/config.lua--WAF config file,enable = "on",disable = "off" --waf status config_waf_enable = "on" #是否开启配置 --log dir config_log_dir = "/tmp/waf_logs" #日志记录地址 --rule setting config_rule_dir = "/usr/local/nginx/conf/waf/rule-config" #匹配规则缩放地址 --enable/disable white url config_white_url_check = "on" #是否开启url检测 --enable/disable white ip config_white_ip_check = "on" #是否开启IP白名单检测 --enable/disable block ip config_black_ip_check = "on" #是否开启ip黑名单检测 --enable/disable url filtering config_url_check = "on" #是否开启url过滤 --enalbe/disable url args filtering config_url_args_check = "on" #是否开启参数检测 --enable/disable user agent filtering config_user_agent_check = "on" #是否开启ua检测 --enable/disable cookie deny filtering config_cookie_check = "on" #是否开启cookie检测 --enable/disable cc filtering config_cc_check = "on" #是否开启防cc攻击 --cc rate the xxx of xxx seconds config_cc_rate = "10/60" #允许一个ip60秒内只能访问10此 --enable/disable post filtering config_post_check = "on" #是否开启post检测 --config waf output redirect/html config_waf_output = "html" #action一个html页面，也可以选择跳转 --if config_waf_output ,setting url config_waf_redirect_url = "http://www.baidu.com" config_output_html=[[ #下面是html的内容 &lt;html&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt; &lt;meta http-equiv="Content-Language" content="zh-cn" /&gt; &lt;title&gt;网站防火墙&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1 align="center"&gt; # 您的行为已违反本网站相关规定，注意操作规范。 &lt;/body&gt; &lt;/html&gt; ]] 三、启用waf并做测试1、模拟sql注入即url攻击日志显示如下,记录了UA，匹配规则，URL，客户端类型，攻击的类型，请求的数据12# tail -f /tmp/2018-07-30_waf.log&#123;"user_agent":"Mozilla\/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/67.0.3396.99 Safari\/537.36","rule_tag":"\\.(bak|inc|old|mdb|sql|backup|java|class|tgz|gz|tar|zip)$","req_url":"\/eastmonet.sql","client_ip":"192.168.83.1","local_time":"2018-07-30 10:46:52","attack_method":"Deny_URL","req_data":"-","server_name":"localhost"&#125; 2、使用ab压力测试工具模拟防CC攻击12# ifconfig eth0|grep 'inet addr'|awk -F ":" '&#123;print $2&#125;'|awk '&#123;print $1&#125;'192.168.83.131 将对方IP放入黑名单12# echo 192.168.83.131 &gt;&gt; /usr/local/openresty/nginx/conf/waf/rule-config/blackip.rule# /usr/local/openresty/nginx/sbin/nginx -s reload 再拿192.168.83.131访问的时候就提示403了将对方IP放入白名单12[root@tiejiang-src1 ~]# echo 192.168.83.131 &gt;&gt; /usr/local/openresty/nginx/conf/waf/rule-config/whiteip.rule[root@tiejiang-src1 ~]# /usr/local/openresty/nginx/sbin/nginx -s reload 此时将不对此ip进行任何防护措施，所以sql注入时应该返回404目录： waf目录：/usr/local/openresty/nginx/conf/waf 配置文件：/usr/local/openresty/nginx/conf/waf/config.lua Waf的ip黑名单：/usr/local/openresty/nginx/conf/waf/rule-config/blackip.rule Waf的ip白名单：/usr/local/openresty/nginx/conf/waf/rule-config/whiteip.rule]]></content>
      <categories>
        <category>Service</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Nginx</tag>
        <tag>lua</tag>
        <tag>waf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7升级Python版本]]></title>
    <url>%2Fposts%2Fde9d62ba.html</url>
    <content type="text"><![CDATA[centos7.4中默认python默认安装版本为2.7.*。12345# pythonPython 2.7.5 (default, Oct 30 2018, 23:45:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux2Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; quit() 但是随着python3的成熟，生产需要需要使用python3版本进行支持，以下升级安装3.*版本python。 1、python3安装python官网地址：https://www.python.org/查看python的各个支持版本的最新版，本次开发需求为python3.6版本，官网最新3.6版本为3.6.6版本。首先安装编译模块支持yum -y install zlib*其他在安装过程中提示需要的模块请自行安装。下载、安装1234567wget https://www.python.org/ftp/python/3.6.6/Python-3.6.6.tgztar -zxvf Python-3.6.6.tgzmkdir /data/pythoncd Python-3.6.6./configure --prefix=/data/pythonmakemake install 安装检查1234567# /data/python/bin/python3Python 3.6.6 (default, Aug 10 2018, 16:26:38) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; quit()# /data/python/bin/pip3 -Vpip 10.0.1 from /data/python/lib/python3.6/site-packages/pip (python 3.6) 可以看到安装的python版本为3.6.6，pip版本为10.0.1。 2、环境配置为了符合代码习惯制作软连接12ln -s /data/python/bin/python3.6 /usr/bin/python3ln -s /data/python/bin/pip3 /usr/bin/pip3 再次验证1234567891011# python3Python 3.6.6 (default, Aug 10 2018, 16:26:38) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; print("hello world")hello world&gt;&gt;&gt; quit()# pip3 -Vpip 10.0.1 from /data/python/lib/python3.6/site-packages/pip (python 3.6)# whereis python3python3: /usr/bin/python3 查看/usr/bin/下python版本123456# ll /usr/bin/py*-rwxr-xr-x. 1 root root 78 Aug 4 2017 /usr/bin/pydoclrwxrwxrwx 1 root root 24 Aug 10 16:55 /usr/bin/python -&gt; /data/python/bin/python3lrwxrwxrwx. 1 root root 9 Oct 15 2017 /usr/bin/python2 -&gt; python2.7-rwxr-xr-x. 1 root root 7136 Aug 4 2017 /usr/bin/python2.7lrwxrwxrwx 1 root root 26 Aug 10 16:33 /usr/bin/python3 -&gt; /data/python/bin/python3.6 可以看到同时存在两个版本，python2.7和python3.6。不建议将python3直接软连接到/usr/bin/python，因为可能影响yum使用。可以在代码中头文件中说明调用/usr/bin/python3。 3、单版本配置同上述步骤，在配置软连接1ln -s /data/python/bin/python3.6 /usr/bin/python 查看/usr/bin/1234567ll /usr/bin/py*-rwxr-xr-x. 1 root root 78 Aug 4 2017 /usr/bin/pydoclrwxrwxrwx 1 root root 30 Aug 6 18:24 /usr/bin/python -&gt; /data/python/bin/python3lrwxrwxrwx. 1 root root 9 Oct 15 2017 /usr/bin/python2 -&gt; python2.7-rwxr-xr-x. 1 root root 7136 Aug 4 2017 /usr/bin/python2.7lrwxrwxrwx 1 root root 26 Aug 6 14:01 /usr/bin/python3 -&gt; /data/python/bin/python3.6lrwxrwxrwx. 1 root root 7 Oct 15 2017 /usr/bin/python.bak -&gt; python2 此时，系统默认python版本即为python3.6.6。需要注意的是，由于系统默认python版本更换，需要更改之前使用python2的应用配置，比如yum等。]]></content>
      <categories>
        <category>OS</category>
        <category>Env</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK6.3+head插件安装配置]]></title>
    <url>%2Fposts%2Fc633f90.html</url>
    <content type="text"><![CDATA[一、前言1、为什么用ELK一般我们需要进行日志分析场景：直接在日志文件中 grep、awk 就可以获得自己想要的信息。但在规模较大的场景中，此方法效率低下，面临问题包括日志量太大如何归档、文本搜索太慢怎么办、如何多维度查询。需要集中化的日志管理，所有服务器上的日志收集汇总。常见解决思路是建立集中式日志收集系统，将所有节点上的日志统一收集，管理，访问。一般大型系统是一个分布式部署的架构，不同的服务模块部署在不同的服务器上，问题出现时，大部分情况需要根据问题暴露的关键信息，定位到具体的服务器和服务模块，构建一套集中式日志系统，可以提高定位问题的效率。一个完整的集中式日志系统，需要包含以下几个主要特点： * 收集－能够采集多种来源的日志数据 * 传输－能够稳定的把日志数据传输到中央系统 * 存储－如何存储日志数据 * 分析－可以支持 UI 分析 * 警告－能够提供错误报告，监控机制 ELK提供了一整套解决方案，并且都是开源软件，之间互相配合使用，完美衔接，高效的满足了很多场合的应用。目前主流的一种日志系统。 2、ELK简介ELK是三个开源软件的缩写，分别表示：Elasticsearch , Logstash, Kibana , 它们都是开源软件。新增了一个FileBeat，它是一个轻量级的日志收集处理工具(Agent)，Filebeat占用资源少，适合于在各个服务器上搜集日志后传输给Logstash，官方也推荐此工具。Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。Logstash 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。Filebeat隶属于Beats。目前Beats包含四种工具：（1）Packetbeat（搜集网络流量数据）（2）Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）（3）Filebeat（搜集文件数据）（4）Winlogbeat（搜集 Windows 事件日志数据） 3、设计架构1）简单架构一般最简单的架构只用elasticsearch、logstash、kibana组成即可，如下图：logstash收集处理数据，并输出到elasticsearchelasticsearch存储日志数据kibana用于数据的检索、查询、web展示2）高可用架构随着业务、性能、稳定性等需求的增加，架构中引进filebeat和缓存机制，如下图filebeat：用于收集数据，替代logstash，在每台agent端需要部署，相比于logstash，filebeat占用更少的系统资源缓存集群：可以使用kafka或者redis，使日志的汇总处理更快速logstash集群：提高日志管道的传输速度和系统性能elasticsearch集群：存储日志数据kibana集群：提高web的访问负载能力，前端使用nginx代替这种架构中各节点使用集群替代，具有更大的负载能力和数据处理能力。 二、 安装1、环境准备修改/etc/sysctl.conf，并使之生效12345678910111213141516171819# cat /etc/sysctl.conf |grep vm.maxvm.max_map_count=262144[root@izuf63k1rfnrzs6zc1g95qz elasticsearch-head]# sysctl -p /etc/sysctl.conf net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1net.ipv6.conf.lo.disable_ipv6 = 1vm.swappiness = 0net.ipv4.neigh.default.gc_stale_time = 120net.ipv4.conf.all.rp_filter = 0net.ipv4.conf.default.rp_filter = 0net.ipv4.conf.default.arp_announce = 2net.ipv4.conf.lo.arp_announce = 2net.ipv4.conf.all.arp_announce = 2net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_syn_backlog = 1024net.ipv4.tcp_synack_retries = 2kernel.sysrq = 1vm.max_map_count = 262144 修改/etc/security/limits.conf，添加以下两行123# cat /etc/security/limits.conf |grep elasticsearchelasticsearch soft nofile 65536elasticsearch hard nofile 65536 关于网络设置和端口开放部分不再描述，使用端口可以根据自己需求修改。 2、elasticsearch安装ELK官网地址：https://www.elastic.co/Elasticsearch需要java环境支持，请自行安装。需要的安装文件自行下载，不再给予下载地址。12345678910111213141516171819# tar -zxvf elasticsearch-6.3.2.tar.gz# mv elasticsearch-6.3.2 /data/elasticsearch创建用户和用户组groupadd elasticsearch #新建elsearch组useradd elasticsearch -g elasticsearch -p elasticsearch #新建一个elsearch用户chown -R elasticsearch. elasticsearch /data/elasticsearch #对文件夹授权配置elasticsearch# cd /data/elasticsearch# cat config/elasticsearch.yml |grep -v '^#'|grep -v '^$'path.data: /data/elasticsearch/datapath.logs: /data/elasticsearch/logsbootstrap.memory_lock: falsenetwork.host: 0.0.0.0http.port: 9200http.cors.enabled: truehttp.cors.allow-origin: "*"切换用户，启动elasticsearch# su elasticsearch$ /data/elasticsearch/bin/elasticsearch -d -d是以后台进程方式启动浏览器访问，如下图表示安装成功，也可以使用curl方式访问。 3、logstash安装Logstash安装可以切换到root用户进行安装1234567891011121314151617181920212223242526# tar -zxvf logstash-6.3.2.tar.gz# mv logstash-6.3.2 /data/logstash配置logstash# cd /data/logstash/# mkdir conf.d# cat config/logstash.yml |grep -v '^$'|grep -v '^#'path.config: /data/logstash/conf.dpath.logs: /data/logstash/logs# cat conf.d/logstash_test.confinput&#123; file&#123; path =&gt;"/data/work/logs/MsgService.log" start_position=&gt;"beginning" &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "MsgService-%&#123;+YYYY.MM.dd&#125;" &#125; stdout&#123; codec=&gt;rubydebug &#125;&#125; 启动并验证1# /data/logstash/bin/logstash -f /data/logstash/conf.d/logstash_test.conf --path.data=/data/logstash/data/002 出现以下格式信息表示启动成功1234567&#123; "message" =&gt; "2018-07-19 10:18:23.431 INFO 21554 --- [tbeatExecutor-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_MSGSERVICE/172.19.254.54:23000/msgService - registration status: 204", "path" =&gt; "/data/work/logs/MsgService.log", "@timestamp" =&gt; 2018-07-26T08:43:43.081Z, "host" =&gt; "izuf63k1rfnrzs6zc1g95qz", "@version" =&gt; "1"&#125; logstash中input表示读取日志文件，filter表示过滤，output表示输出具体的语法，根据不同的日志文件配置。input、filter、output其实都是logstash的插件，根据需求我们可以安装检查和卸载插件。通过1# ./bin/logstash-plugin list 查看插件管理的命令帮助。常用的命令有1234bin/logstash-plugin list #查看已安装插件列表bin/logstash-plugin install plugin_name #安装插件bin/logstash-plugin update plugin_name #卸载插件bin/logstash-plugin uninstall plugin_name #卸载插件 通过list命令查看插件列表时候，无非下列四种类型的插件： * logstash-codec-* #编码解码插件 * logstash-filter-* #数据处理插件 * logstash-input-* #输入插件 * logstash-output-* #输出插件 此处需要完善一个概念：Logstash 不只是一个input | filter | output 的数据流，而是一个 input | decode | filter | encode | output 的数据流！上面插件中的codec 就是用来 decode、encode 事件的。启动语句中–path.data表示指定目录，为了实现多实例启动，在配置文件中可以不配置path.data参数，在启动时候加上。以后台方式启动1# nohup /data/logstash/bin/logstash -f /data/logstash/conf.d/logstash_test.conf --path.data=/data/logstash/data/002 &amp; 4、安装elasticsearch-headelasticsearch-head从5.x版本以后不再依附于elasticsearch安装，作为独立进程安装。elasticsearch-head项目地址：https://github.com/mobz/elasticsearch-head#connecting-to-elasticsearchelasticsearch-head需要node环境，首先安装node，这里不贴出详细步骤。验证node版本12# node -vv8.11.3 下载安装123456789101112131415161718192021# wget https://github.com/mobz/elasticsearch-head/archive/master.zip为了后续安装phantomjs，使用bzip2解压，需要安装bzip2# yum install bzip2 -y解压到/data目录# cd /data/elasticsearch-head# npm -v5.6.0# npm install --registry=https://registry.npm.taobao.org --unsafe-perm安装过程会有点慢--registry=https://registry.npm.taobao.org表示使用国内镜像资源--unsafe-perm表示取消秘钥验证验证安装# ll ./node_modules/grunttotal 32drwxr-xr-x 2 root root 4096 Jul 26 14:03 bin-rw-r--r-- 1 root root 7111 Apr 6 2016 CHANGELOGdrwxr-xr-x 4 root root 4096 Jul 26 14:03 lib-rw-r--r-- 1 root root 1592 Mar 23 2016 LICENSEdrwxr-xr-x 4 root root 4096 Jul 26 14:03 node_modules-rw-r--r-- 1 root root 2442 Jul 26 14:03 package.json-rw-r--r-- 1 root root 878 Feb 12 2016 README.md 修改配置Gruntfile.js，增加hostname，如下图所示启动1npm run start 浏览器访问比如我们在服务器上配置，但是在本地通过外网访问elasticsearch-head，那么elasticsearch的地址不应该是elasticsearch所在服务器的内网地址，而应该是外网地址，注意对应使用的端口应该打开。elasticsearch-head是一个查看集群信息的工具，我们现在只配置一台elasticsearch，如果是多台，也可以用于查看集群内其他elasticsearch信息。查看页面表示安装成功。以后台方式运行1# nohup npm run start &amp; 5、kibana安装1234567891011解压配置# tar -zxvf kibana-6.3.2-linux-x86_64^C# mv kibana-6.3.2-linux-x86_64 /data/kibana^C# cd /data/kibana/# cat config/kibana.yml |grep -v '^#'|grep -v '^$'server.port: 80server.host: "0.0.0.0"elasticsearch.url: "http://localhost:9200"kibana.index: ".kibana"后台启动nohup /data/kibana/bin/kibana &amp; 浏览器访问后，配置index pattern，根据日志index标识不同，自己灵活掌握。 6、kibana汉化对于习惯使用英文界面的也可以不用汉化。 1）官网汉化方式ELK6.x版本提供国际化的标准，可以自己翻译汉化1、复制src/core_plugins/kibana/translations/en.json的内容，创建一个新的json文件，比如ch.json。2、翻译并修改ch.json中对应的文字。3、 在src/core_plugins/kibana/index.js文件中，找到translations，然后添加对应的内容。4、 最后在配置文件config/kibana.yml（开发模式下，创建并使用配置文件kibana.dev.yml）中，加入默认的语言设置：i18n.defaultLocale: “ch”5、 等kibana服务器重启之后，刷新页面就可以看见效果了。 2）github个人项目翻译方式项目地址：https://github.com/anbai-inc/Kibana_Hanization具体的使用方法也有介绍，但是非官方方法，具体的效果不太理想。个人认为6.x版本使用此方法汉化后会影响系统启动。 三、高级配置1、filebeat安装12345678910111213141516171819202122下载地址https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-linux-x86_64.tar.gz解压包到对应目录# tar -zxvf filebeat-6.3.2-linux-x86_64.tar.gz# mv filebeat-6.3.2-linux-x86_64 /data/filebeat修改配置文件# cat filebeat.yml |grep -v '#'|grep -v '^$'filebeat.inputs:- type: log enabled: true paths: - /data/work/logs/*.logfilebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 3setup.kibana: host: "localhost:80"#output.elasticsearch:# hosts: ["localhost:9200"]output.logstash: hosts: ["localhost:5044"] 6.x版本中filebeat，只支持一个output输出，如果把日志输出到elasticsearch，则需要把输出到logstash段配置注释。一般情况下输出到logstash，进行过滤，再由logstash输出到elasticsearch。启动1nohup ./filebeat -c filebeat.yml &amp; 同一台服务器上可以启动多个filebeat，但是需要指定不同的配置文件。 2、logstash相关配置主要配置如下123456789101112131415161718# cat /data/logstash/conf.d/logstash_test.conf input&#123; beats &#123; port =&gt; 5044 &#125; &#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "MsgService-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; Index定义日志头Logstash可以根据conf和path.data的不同启动多个进程 3、filter配置filter主要对日志进行过滤和筛选，以剔除不必要的日志，使用的方法为grok。grok中配置macth来匹配日志，使用正则表达式。相关正则表达式字段可以查看github：https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns匹配的验证测试可以使用以下地址：https://grokconstructor.appspot.com/do/matchhttp://grokdebug.herokuapp.com/个人体验，推荐使用第一个地址，需要使用科学上网。实例： 1、匹配nginx access的日志nginx中access日志的模式配置为123log_format main '$remote_addr $remote_user $time_local $request ' '$http_referer $status $body_bytes_sent $request_body ' '"$http_user_agent" "$http_x_forwarded_for"'; 验证匹配字段其中第一个框内为nginx access的日志第二个框内为匹配准则，准则的大写字段是从github地址上查找得到，小写字段为自定义执行，得到如下所示可以看到匹配完成，match即为匹配准则，日志中不重要的部分可以不进行匹配。将match写入logstash配置文件1234567891011121314151617181920212223242526272829303132# cat conf.d/nginx_access_log.conf input&#123; beats &#123; port =&gt; 5055 &#125; &#125;filter &#123; grok &#123; match =&gt; ["message","%&#123;IP:clientip&#125; %&#123;USER:user&#125; %&#123;HTTPDATE:timestamp&#125; %&#123;WORD:request_method&#125; %&#123;URIPATHPARAM:uri&#125; HTTP/%&#123;NUMBER:httpversion&#125; (?:%&#123;URI:referrer&#125;|-) %&#123;NUMBER:status:int&#125; %&#123;NUMBER:body_bytes_sent:int&#125; "] &#125; # if [loglevel] == "DEBUG" &#123;# drop &#123;&#125;# &#125; if [uri] == "/" &#123; drop &#123;&#125; &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "nginx_access_log-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; drop是跟字段匹配进行过滤，过滤掉的日志将不会再进行output。此处drop掉的是slb的检测访问的日志，即非业务的日志。需要注意的是：对message进行匹配，后面的准测内不允许使用多个””，所以在nginx的配置文件内需要修改日志格式的相关字段，不要加双引号。 2、匹配nodejs的日志验证执行，查看结果关于每条日志的记录的行为的相应时间是没有进行匹配的，所以出现在after match处。写入logstash配置1234567891011121314151617181920212223242526272829303132# cat conf.d/nodejs_log.conf input&#123; beats &#123; port =&gt; 5077 &#125; &#125;filter &#123; grok &#123; match =&gt; ["message","logger: %&#123;TIMESTAMP_ISO8601:time&#125; %&#123;WORD:request_method&#125; %&#123;URIPATHPARAM:uri&#125; %&#123;NUMBER:status:int&#125; %&#123;NUMBER:body_bytes_sent:int&#125; "] &#125; # if [loglevel] == "DEBUG" &#123;# drop &#123;&#125;# &#125;# if [uri] == "/" &#123;# drop &#123;&#125;# &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "nodejs_log-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; 以上配置是没有对日志进行drop操作的，日志是否需要进行drop根据实际情况操作。 3、匹配java的日志java是世界上最不友好的语言，反正我就是这么认为！java的日志格式不像web应用暴露的日志一样格式规范，所以很难匹配。如下所示after match部分毫无规律，不知道这是什么玩意儿，就不匹配了，够用就行。添加logstash配置123456789101112131415161718192021222324252627282930313233# cat conf.d/springcloud_log.conf input&#123; beats &#123; port =&gt; 5044 &#125; &#125;filter &#123; grok &#123; match =&gt; ["message","%&#123;TIMESTAMP_ISO8601:datestamp&#125; *%&#123;LOGLEVEL:loglevel&#125; %&#123;INT:digital&#125; *"] &#125; # if [loglevel] == "DEBUG" &#123;# drop &#123;&#125;# &#125; if [loglevel] == "INFO" &#123; drop &#123;&#125; &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:9200"] index =&gt; "springcloud_log-%&#123;+YYYY.MM.dd&#125;" &#125;# stdout&#123;# codec=&gt;rubydebug# &#125;&#125; 此处drop的为类型是INFO的日志。 4、其他配置关于elasticsearch和kibana的配置不用调整。]]></content>
      <categories>
        <category>Monitor</category>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>日志</tag>
        <tag>head</tag>
        <tag>ELK</tag>
        <tag>Elasticsearch</tag>
        <tag>Logstash</tag>
        <tag>Kibana</tag>
        <tag>FileBeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python购物车程序]]></title>
    <url>%2Fposts%2F92266803.html</url>
    <content type="text"><![CDATA[程序：购物车程序需求 1、启动程序后，让用户输入工资，然后打开商品列表 2、允许用户根据商品编号购买商品 3、用户选择商品后，检测余额是否够，够就直接扣款，不够就提醒 4、可随时退出，退出时，打印已购商品和余额 code123456789101112131415161718192021222324252627282930313233343536373839# -*- coding:utf-8 -*-#Author:Francisproduct_list = [ ('Iphone',5800), ('Mac Pro',9800), ('Bike',800), ('Watch',10600), ('Coffee',31), ('Alex Python',120),]shopping_list = []salary = input("Input your salary:")if salary.isdigit(): salary = int(salary) while True: for index,item in enumerate(product_list): #print(product_list.index(item),item) print(index,item) user_choice = input("选择要买嘛？&gt;&gt;&gt;:") if user_choice.isdigit(): user_choice = int(user_choice) if user_choice &lt; len(product_list) and user_choice &gt;=0: p_item = product_list[user_choice] if p_item[1] &lt;= salary: #买的起 shopping_list.append(p_item) salary -= p_item[1] print("Added %s into shopping cart,your current balance is \033[31;1m%s\033[0m" %(p_item,salary) ) else: print("\033[41;1m你的余额只剩[%s]啦，还买个毛线\033[0m" % salary) else: print("product code [%s] is not exist!"% user_choice) elif user_choice == 'q': print("--------shopping list------") for p in shopping_list: print(p) print("Your current balance:",salary) exit() else: print("invalid option")]]></content>
      <categories>
        <category>Scripts</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix监控redis]]></title>
    <url>%2Fposts%2Fc4f57e63.html</url>
    <content type="text"><![CDATA[zabbix监控redis实例有个不方便的地方是只能监控固定的6379端口，如果是非6379端口的话，需要修改模板，如果主机有多个redis实例的话，需要具有不同的redis模板，然后在管理监控，很是麻烦，为了解决这个问题，我使用lld（low level discovery）方式监控redis，只需要你在正则表达式里把需要监控的端口标上，就可以监控redis多实例。 一、agent端配置agent端脚本，获取正在运行的redis实例端口1234567891011121314151617181920212223242526# pwd/etc/zabbix/scripts# cat redis_low_discovery.sh #!/bin/bash#Script_name redis_low_discovery.shredis() &#123;# port=($(sudo netstat -tpln | awk -F "[ :]+" '/redis/ &amp;&amp; /0.0.0.0/ &#123;print $5&#125;')) port=($(netstat -tpln | awk -F "[ :]+" '/redis/ &amp;&amp; /0.0.0.0/ &#123;print $5&#125;')) printf '&#123;\n' printf '\t"data":[\n' for key in $&#123;!port[@]&#125; do if [[ "$&#123;#port[@]&#125;" -gt 1 &amp;&amp; "$&#123;key&#125;" -ne "$(($&#123;#port[@]&#125;-1))" ]];then socket=`ps aux|grep $&#123;port[$&#123;key&#125;]&#125;|grep -v grep|awk -F '=' '&#123;print $10&#125;'|cut -d ' ' -f 1` printf '\t &#123;\n' printf "\t\t\t\"&#123;#REDISPORT&#125;\":\"$&#123;port[$&#123;key&#125;]&#125;\"&#125;,\n" else [[ "$&#123;key&#125;" -eq "(($&#123;#port[@]&#125;-1))" ]] socket=`ps aux|grep $&#123;port[$&#123;key&#125;]&#125;|grep -v grep|awk -F '=' '&#123;print $10&#125;'|cut -d ' ' -f 1` printf '\t &#123;\n' printf "\t\t\t\"&#123;#REDISPORT&#125;\":\"$&#123;port[$&#123;key&#125;]&#125;\"&#125;\n" fi done printf '\t ]\n' printf '&#125;\n'&#125;$1 验证脚本是否正常监控redis实例的json展示12345678910# ./redis_low_discovery.sh redis&#123; "data":[ &#123; "&#123;#REDISPORT&#125;":"6379"&#125; ] &#123; "&#123;#REDISPORT&#125;":"6380"&#125; ]&#125; 添加UserParameter12345# pwd/etc/zabbix/zabbix_agentd.d# cat userparameter_redis.conf UserParameter=zabbix_low_discovery[*],/bin/bash /etc/zabbix/scripts/redis_low_discovery.sh $1UserParameter=redis_stats[*],(/bin/echo info; sleep 1) | telnet 127.0.0.1 $1 2&gt;&amp;1 |grep $2|cut -d : -f2 注：zabbix_agentd.conf配置文件中吧UnsafeUserParameters=1设置为1并打开注释即可，这里我的redis示例没有设置密码，如果有密码就加上-a password，telnet对空密码可以。有密码的话telnet换成$(which redis-cli)。12UserParameter=zabbix_low_discovery[*],/bin/bash /etc/zabbix/scripts/redis/redis_low_discovery.sh $1UserParameter=redis_stats[*],(/bin/echo info; sleep 1) | /data/redis/bin/redis-cli -h 172.16.109.138 -p $1 -a 5U7pp/pQLbdGLA 2&gt;&amp;1 |grep $2|cut -d : -f2 然后重启agent即可把redis_low_discovery.sh文件存放到/etc/zabbix/scripts/目录下，然后给与755权限，并修改用户与组为zabbix，同时允许zabbix用户无密码运行1echo "zabbix ALL=(root) NOPASSWD:/bin/netstat"&gt;&gt;/etc/sudoers 关闭requiretty1sed -i 's/^Defaults.*.requiretty/#Defaults requiretty/' /etc/sudoers 二、server端配置使用zabbix_get获取redis键值123456789# zabbix_get -s 172.19.231.227 -p 10050 -k zabbix_low_discovery[redis]&#123;"data":[ &#123;"&#123;#REDISPORT&#125;":"6379"&#125;, &#123;"&#123;#REDISPORT&#125;":"6380"&#125; ]&#125; redis每秒更新时间12# zabbix_get -s 172.19.231.227 -p 10050 -k redis_stats[6381,uptime_in_seconds]8 三、web界面配置导入模板以及主机连接模板，还需要设置正则等模板在此处下载，然后导入模板，并且关联对应的主机。设置正则表达式name：Redis regexResult TRUE = ^(6380|6381)$正则表达式根据端口配置，可以增加最后把主机连接到模板上即可，默认间隔时间1小时，方便测试我改成60s，数据收集后然后改过了即可检查思路如下： 1：agent端可以使用脚步获取json化的信息 2：server端可以zabbix_get获取json化信息以及item的值注：基于以上2步骤，按理说可以获取到相应的item值了。 3：打开agent端debug模式获取更多的日志信息，日志无问题，显示过程中没有显示json化的item 4：检查redis多实例模板中自动发现规则的键值与agent端中UnsafeUserParameters中定义键值不一样，修改与模板中对应的键值一样即可，重启agent即可]]></content>
      <categories>
        <category>Monitor</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云ECS漏洞修复]]></title>
    <url>%2Fposts%2F54240449.html</url>
    <content type="text"><![CDATA[一、关于glibc的报警1、问题确认关于glibc的报警，具体如下所示：此处报警我们可以根据漏洞编号进行查询，可以看到是因为glibc的版本太低，具有以下上图所示两个漏洞。阿里云进行的报警的依据是根据探测ECS相关软件的版本，如下图所示： 2、解决方案上图可以看到我们需要升级的软件一共有5个，分别是glibc、glibc-common、glibc-headers、glibc-devel、nscd。rpm包可从此处下载，选择稳定版本即可。 3、升级脚本将下载、安装过程脚本话12345678910111213141516171819#!/bin/sh#Francis#切换到下载目录cd /data/backup# update glibc to 2.22 for CentOS 7wget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-common-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-headers-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/glibc-devel-2.22.90-21.el7.x86_64.rpmwget http://cbs.centos.org/kojifiles/packages/glibc/2.22.90/21.el7/x86_64/nscd-2.22.90-21.el7.x86_64.rpmrpm -Uvh glibc-2.22.90-21.el7.x86_64.rpm \ glibc-common-2.22.90-21.el7.x86_64.rpm \ glibc-devel-2.22.90-21.el7.x86_64.rpm \ glibc-headers-2.22.90-21.el7.x86_64.rpm \ nscd-2.22.90-21.el7.x86_64.rpm \ --force --nodeps 二、关于curl的报警1、问题确认关于glibc的报警，具体如下所示：此处报警我们可以根据漏洞编号进行查询，可以看到是因为curl的版本太低，具有以下上图所示四个漏洞。阿里云进行的报警的依据是根据探测ECS相关软件的版本，如下图所示： 2、解决方案上图可以看到curl版本7.12到7.58都有漏洞，所以我们选择安装7.60以后的版本 1、编译安装123456wget https://curl.haxx.se/download/curl-7.62.0.tar.gztar -zxvf curl-7.62.0.tar.gz cd curl-7.62.0./configure --prefix=/usrmakemake install 查看curl版本1234567# curl --versioncurl 7.62.0 (x86_64-pc-linux-gnu) libcurl/7.47.1 NSS/3.21.3 Basic ECC zlib/1.2.7 libidn/1.28 libssh2/1.4.3Release-Date: 2018-10-31Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp Features: AsynchDNS IDN IPv6 Largefile GSS-API Kerberos SPNEGO NTLM NTLM_WB SSL libz UnixSockets # curl-config --versionlibcurl 7.62.0 2、yum安装查看已安装版本1234# curl --versioncurl 7.29.0 (x86_64-redhat-linux-gnu) libcurl/7.29.0 NSS/3.34 zlib/1.2.7 libidn/1.28 libssh2/1.4.3Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smtp smtps telnet tftp Features: AsynchDNS GSS-Negotiate IDN IPv6 Largefile NTLM NTLM_WB SSL libz unix-sockets 安装repo1rpm -Uvh http://www.city-fan.org/ftp/contrib/yum-repo/rhel6/x86_64/city-fan.org-release-2-1.rhel6.noarch.rpm 查看该 repo 包含的 curl 版本12345678910# yum --showduplicates list curl --disablerepo="*" --enablerepo="city*"Loaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * city-fan.org: cityfan.mirror.digitalpacific.com.au * city-fan.org-debuginfo: cityfan.mirror.digitalpacific.com.au * city-fan.org-source: cityfan.mirror.digitalpacific.com.auInstalled Packagescurl.x86_64 7.29.0-51.el7 @base Available Packagescurl.x86_64 7.62.0-1.7.cf.rhel7 city-fan.org 修改该repo的enable为1123456789101112131415vi /etc/yum.repos.d/city-fan.org.repo[city-fan.org]name=city-fan.org repository for Red Hat Enterprise Linux (and clones) $releasever ($basearch)#baseurl=http://mirror.city-fan.org/ftp/contrib/yum-repo/rhel$releasever/$basearchmirrorlist=http://mirror.city-fan.org/ftp/contrib/yum-repo/mirrorlist-rhel$releaseverenabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-city-fan.org 升级最新的curl1yum upgrade curl -y 查看版本12345# curl -Vcurl 7.62.0 (x86_64-redhat-linux-gnu) libcurl/7.62.0 NSS/3.36 zlib/1.2.7 libpsl/0.7.0 (+libicu/50.1.2) libssh2/1.8.0 nghttp2/1.31.1Release-Date: 2018-10-31Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp Features: AsynchDNS IPv6 Largefile GSS-API Kerberos SPNEGO NTLM NTLM_WB SSL libz HTTP2 UnixSockets HTTPS-proxy PSL Metalink 升级完成]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
        <tag>漏洞修复</tag>
        <tag>glibc</tag>
        <tag>curl</tag>
        <tag>nss-pem</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql安装]]></title>
    <url>%2Fposts%2F41952.html</url>
    <content type="text"><![CDATA[一、软件部署1、MySQL安装123456789101112131415161718192021222324252627282930313233343536373839## 安装软件依赖shell&gt; yum install libaio -y## 创建用户和组shell&gt; groupadd mysqlshell&gt; useradd -r -g mysql -s /bin/false mysql## 解压软件包并创建软连接shell&gt; tar xzvf mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz -C /usr/local/shell&gt; cd /usr/local/shell&gt; ln -s mysql-5.7.22-linux-glibc2.12-x86_64 mysql## 修改软件目录权限为mysql用户shell&gt; cd /usr/local/mysqlshell&gt; chown -R mysql:mysql .## 创建数据目录权限并修改权限为mysql用户shell&gt; mkdir -p /data/mysql/&#123;data,tmp&#125;shell&gt; chown -R mysql:mysql /data/mysql/## 拷贝启动脚本至系统启动目录shell&gt; cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld## 执行数据库初始化操作shell&gt; cd /usr/local/mysqlshell&gt; bin/mysqld --initialize --user=mysql## 启动MySQLshell&gt; systemctl enable mysqldshell&gt; systemctl start mysqldshell&gt; systemctl status mysqldshell&gt; systemctl disable mysqldshell&gt; cat /data/mysql/data/mysql-error.log |grep passshell&gt; /usr/local/mysql/bin/mysql -S /data/mysql/data/mysql_3306.sock -p## 输入查看到的随机密码## 登录数据库后需先修改密码mysql&gt; set password='emhlbnhpbmcxMDA0';mysql&gt; exit; 2、配置环境变量12345shell&gt; vim ~/.bash_profile MYSQL_HOME=/usr/local/mysql PATH=$PATH:$HOME/bin:$MYSQL_HOME/binshell&gt; source ~/.bash_profileshell&gt; mysql -V 从库的搭建方式为在从库所在服务器重复步骤一和步骤二全部操作 二、复制配置1、复制用户创建12## 主库创建复制用户mysql&gt; grant replication slave on *.* to 'repl'@'%' identified by 'cmVwbGRiYQ=='; 2、配置复制同步123456789101112## 从库配置复制同步mysql&gt; change master to master_host='172.16.109.144',master_user='repl',master_password='cmVwbGRiYQ==',master_port=3306,master_auto_position=1;## 从库启动复制mysql&gt; start slave;mysql&gt; show slave status\G;mysql&gt; show processlist; 三、备份配置1、部署xtrabackup主从都需要部署，文件上传操作：略1234567891011## 解压percona-xtrabackupcd /opt/for_gongbao_mysql/tar xzvf percona-xtrabackup-2.4.9-Linux-x86_64.tar.gz## 拷贝命令至系统可执行目录cp percona-xtrabackup-2.4.9-Linux-x86_64/bin/* /usr/local/bin/rm percona-xtrabackup-2.4.9-Linux-x86_64 -rf## 拷贝qpress解压缩命令至系统可执行目录cd /opt/for_gongbao_mysql/cp qpress /usr/local/bin/ 2、配置自动化备份脚本脚本模板已上传，暂未配置 四、慢查询配置1、日志轮换脚本配置脚本模板已上传，暂未配置 2、日志格式化脚本配置脚本模板已上传，暂未配置]]></content>
      <categories>
        <category>DB</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
</search>
